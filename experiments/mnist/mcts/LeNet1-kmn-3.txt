Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='kmn', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet1', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet1', 'mcts', 'kmn'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7fd9535b1f28>, tc2=<function tc2 at 0x7fd9535c2048>, tc3=<function tc3 at 0x7fd9535c2158>, tfc_threshold=900, time_period=3600, verbose=True)
initial coverage: 25.625
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0eb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00120b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0eb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00048d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00126d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0eb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00047b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0eb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0eb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00047b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0eb8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0eb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0eb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0eb8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0eb8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0eb8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0eb8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0eb8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0eb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 25.624999999999996
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00125c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bba8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bba8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bba8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bba8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bba8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00840b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bba8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bba8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00840b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bba8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bba8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 25.624999999999996
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac3c8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac3c8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac3c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac3c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac3c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac3c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac3c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac3c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac3c8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac3c8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac3c8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac3c8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac3c8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac3c8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 25.624999999999996
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01accc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba4a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba4a8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba4a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba4a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba4a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba4a8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba4a8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01accc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba4a8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba4a8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba4a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba4a8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01accc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba4a8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba4a8> 0.0 16
Completed Iteration #20
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba4a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba4a8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 25.624999999999996
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012828> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012828> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01665c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012828> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012828> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01667f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012828> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012828> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012828> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01700b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012828> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012828> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01660b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012828> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012828> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012828> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012828> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012828> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012828> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 25.624999999999996
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01705c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01705c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01708d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01104e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004a58> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01102e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004a58> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004a58> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01705c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004a58> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01106a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004a58> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01705c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004a58> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01708d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004a58> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004a58> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004a58> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004a58> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004a58> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004a58> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004a58> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01705c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004a58> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 25.624999999999996
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01237f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123400> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123400> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123400> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01371d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01376d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123400> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123400> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123400> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01704e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123400> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01664e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123400> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01704e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123400> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01704e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123400> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123400> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01708d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123400> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123400> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01704e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123400> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123400> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123400> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 25.624999999999996
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012208> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012208> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012208> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012208> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012208> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012208> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00045c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012208> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012208> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012208> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012208> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012208> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01100f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012208> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012208> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012208> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012208> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012208> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01106d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012208> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00045c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012208> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b7f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012208> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00045c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 25.624999999999996
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01108d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01102b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.10416666666666785 5
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.10416666666666785 6
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137710> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137898> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.2083333333333357 7
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01375c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.2083333333333357 8
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002be10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.2083333333333357 9
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.2083333333333357 10
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01375c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.2083333333333357 11
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137898> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.2083333333333357 12
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.2083333333333357 13
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.2083333333333357 14
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #0
root
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.10416666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.2083333333333357 15
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.10416666666666785 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.2083333333333357 16
Completed Iteration #1
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.10416666666666785 6
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.2083333333333357 17
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.10416666666666785 7
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.2083333333333357 18
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.10416666666666785 8
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.2083333333333357 19
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01102b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.10416666666666785 9
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.2083333333333357 20
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.10416666666666785 10
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.2083333333333357 21
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.10416666666666785 11
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.2083333333333357 22
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01376a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 0.10416666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.10416666666666785 12
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.2083333333333357 23
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01230f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01102b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.10416666666666785 13
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.2083333333333357 24
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.10416666666666785 14
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.2083333333333357 25
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.10416666666666785 15
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.2083333333333357 26
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #1
root->7
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e83c8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 0.2083333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.2083333333333357 16
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.31250000000000355 27
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 0.2083333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.2083333333333357 17
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.31250000000000355 28
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101b38> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101e80> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 0.31250000000000355 7
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.31250000000000355 18
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.4166666666666714 29
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01018d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e83c8> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 0.31250000000000355 8
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.31250000000000355 19
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.4166666666666714 30
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 0.31250000000000355 9
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.31250000000000355 20
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.4166666666666714 31
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110860> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b7f0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 0.4166666666666714 10
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.4166666666666714 21
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.5208333333333393 32
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b7f0> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 0.4166666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.4166666666666714 22
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.5208333333333393 33
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101b38> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101e80> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 0.4166666666666714 12
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.4166666666666714 23
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.5208333333333393 34
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 0.5208333333333393 13
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.5208333333333393 24
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.6250000000000071 35
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101e80> 0.10416666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 0.5208333333333393 14
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.5208333333333393 25
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.6250000000000071 36
Completed Iteration #23
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 0.5208333333333393 15
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.5208333333333393 26
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.6250000000000071 37
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #2
root->7->15
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0748> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.31250000000000355 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 0.6250000000000071 16
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.6250000000000071 27
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.729166666666675 38
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0748> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.31250000000000355 6
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 0.6250000000000071 17
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.6250000000000071 28
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.729166666666675 39
Completed Iteration #3
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.31250000000000355 7
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 0.6250000000000071 18
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.6250000000000071 29
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.729166666666675 40
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170160> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.4166666666666714 8
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 0.729166666666675 19
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.729166666666675 30
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.8333333333333428 41
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170160> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.4166666666666714 9
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 0.729166666666675 20
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.729166666666675 31
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.8333333333333428 42
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.4166666666666714 10
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 0.729166666666675 21
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.729166666666675 32
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.8333333333333428 43
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004f98> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.5208333333333393 11
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 0.8333333333333428 22
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.8333333333333428 33
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.9375000000000107 44
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.5208333333333393 12
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 0.8333333333333428 23
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.8333333333333428 34
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.9375000000000107 45
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012a90> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.6250000000000071 13
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 0.9375000000000107 24
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 0.9375000000000107 35
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.0416666666666785 46
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8e10> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.729166666666675 14
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.0416666666666785 25
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.0416666666666785 36
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.1458333333333464 47
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8e10> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.729166666666675 15
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.0416666666666785 26
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.0416666666666785 37
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.1458333333333464 48
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c01377f0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.8333333333333428 16
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.1458333333333464 27
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.1458333333333464 38
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.2500000000000142 49
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004f98> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.8333333333333428 17
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.1458333333333464 28
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.1458333333333464 39
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.2500000000000142 50
Completed Iteration #24
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004f98> 0.10416666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.8333333333333428 18
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.1458333333333464 29
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.1458333333333464 40
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.2500000000000142 51
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #3
root->7->15->2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.9375000000000107 19
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.2500000000000142 30
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.2500000000000142 41
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.354166666666682 52
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.9375000000000107 20
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.2500000000000142 31
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.2500000000000142 42
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.354166666666682 53
Completed Iteration #1
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.2083333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.9375000000000107 21
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.2500000000000142 32
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.2500000000000142 43
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.354166666666682 54
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.2083333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.9375000000000107 22
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.2500000000000142 33
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.2500000000000142 44
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.354166666666682 55
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.2083333333333357 7
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.9375000000000107 23
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.2500000000000142 34
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.2500000000000142 45
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.354166666666682 56
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.2083333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.9375000000000107 24
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.2500000000000142 35
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.2500000000000142 46
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.354166666666682 57
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01013c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.2083333333333357 9
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.9375000000000107 25
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.2500000000000142 36
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.2500000000000142 47
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.354166666666682 58
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b84a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.2083333333333357 10
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.9375000000000107 26
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.2500000000000142 37
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.2500000000000142 48
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.354166666666682 59
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b84a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.2083333333333357 11
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.9375000000000107 27
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.2500000000000142 38
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.2500000000000142 49
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.354166666666682 60
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.2083333333333357 12
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.9375000000000107 28
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.2500000000000142 39
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.2500000000000142 50
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.354166666666682 61
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.2083333333333357 13
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.9375000000000107 29
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.2500000000000142 40
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.2500000000000142 51
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.354166666666682 62
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.2083333333333357 14
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 0.9375000000000107 30
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.2500000000000142 41
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.2500000000000142 52
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.354166666666682 63
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c550> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.31250000000000355 15
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.0416666666666785 31
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.354166666666682 42
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.354166666666682 53
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.45833333333335 64
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #4
root->7->15->2->1
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cc50> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.31250000000000355 5
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.4166666666666714 16
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.1458333333333464 32
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.45833333333335 43
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.45833333333335 54
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.5625000000000178 65
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.31250000000000355 6
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.4166666666666714 17
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.1458333333333464 33
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.45833333333335 44
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.45833333333335 55
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.5625000000000178 66
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b84e0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8390> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.4166666666666714 7
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.5208333333333393 18
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.2500000000000142 34
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.5625000000000178 45
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.5625000000000178 56
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.6666666666666856 67
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c550> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.4166666666666714 8
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.5208333333333393 19
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.2500000000000142 35
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.5625000000000178 46
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.5625000000000178 57
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.6666666666666856 68
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cc50> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.4166666666666714 9
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.5208333333333393 20
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.2500000000000142 36
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.5625000000000178 47
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.5625000000000178 58
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.6666666666666856 69
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c00680b8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.5208333333333393 10
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.6250000000000071 21
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.354166666666682 37
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.6666666666666856 48
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.6666666666666856 59
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.7708333333333535 70
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf278> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.6250000000000071 11
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.729166666666675 22
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.45833333333335 38
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.7708333333333535 49
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.7708333333333535 60
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.8750000000000213 71
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.6250000000000071 12
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.729166666666675 23
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.45833333333335 39
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.7708333333333535 50
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.7708333333333535 61
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.8750000000000213 72
Completed Iteration #23
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf278> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.6250000000000071 13
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.729166666666675 24
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.45833333333335 40
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.7708333333333535 51
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.7708333333333535 62
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.8750000000000213 73
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #5
root->7->15->2->1->8
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068eb8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081470> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.729166666666675 14
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.8333333333333428 25
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.5625000000000178 41
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.8750000000000213 52
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.8750000000000213 63
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.9791666666666892 74
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00814a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8390> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 0.31250000000000355 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.729166666666675 15
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.8333333333333428 26
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.5625000000000178 42
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.8750000000000213 53
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.8750000000000213 64
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.9791666666666892 75
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081470> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 0.31250000000000355 6
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.729166666666675 16
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.8333333333333428 27
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.5625000000000178 43
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.8750000000000213 54
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.8750000000000213 65
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.9791666666666892 76
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 0.31250000000000355 7
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.729166666666675 17
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.8333333333333428 28
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.5625000000000178 44
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.8750000000000213 55
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.8750000000000213 66
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.9791666666666892 77
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 0.31250000000000355 8
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.729166666666675 18
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.8333333333333428 29
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.5625000000000178 45
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.8750000000000213 56
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.8750000000000213 67
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.9791666666666892 78
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 0.31250000000000355 9
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.729166666666675 19
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.8333333333333428 30
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.5625000000000178 46
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.8750000000000213 57
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.8750000000000213 68
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.9791666666666892 79
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 0.31250000000000355 10
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.729166666666675 20
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.8333333333333428 31
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.5625000000000178 47
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.8750000000000213 58
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.8750000000000213 69
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.9791666666666892 80
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 0.31250000000000355 11
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.729166666666675 21
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.8333333333333428 32
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.5625000000000178 48
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.8750000000000213 59
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.8750000000000213 70
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 1.9791666666666892 81
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081400> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf4e0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068eb8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081470> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 0.4166666666666714 12
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.8333333333333428 22
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.9375000000000107 33
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.6666666666666856 49
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.9791666666666892 60
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.9791666666666892 71
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 2.083333333333357 82
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 0.4166666666666714 13
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.8333333333333428 23
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 0.9375000000000107 34
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.6666666666666856 50
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 1.9791666666666892 61
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 1.9791666666666892 72
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 2.083333333333357 83
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #6
root->7->15->2->1->8->3
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081ef0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081470> 0.31250000000000355 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 0.5208333333333393 14
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.9375000000000107 24
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 1.0416666666666785 35
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.7708333333333535 51
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 2.083333333333357 62
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 2.083333333333357 73
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 2.187500000000025 84
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00220f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081470> 0.31250000000000355 6
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 0.5208333333333393 15
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.9375000000000107 25
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 1.0416666666666785 36
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.7708333333333535 52
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 2.083333333333357 63
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 2.083333333333357 74
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 2.187500000000025 85
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c9e8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081470> 0.4166666666666714 7
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 0.6250000000000071 16
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 1.0416666666666785 26
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 1.1458333333333464 37
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.8750000000000213 53
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 2.187500000000025 64
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 2.187500000000025 75
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 2.2916666666666927 86
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081470> 0.4166666666666714 8
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 0.6250000000000071 17
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 1.0416666666666785 27
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 1.1458333333333464 38
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.8750000000000213 54
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 2.187500000000025 65
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 2.187500000000025 76
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 2.2916666666666927 87
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081ef0> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081470> 0.4166666666666714 9
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 0.6250000000000071 18
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 1.0416666666666785 28
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 1.1458333333333464 39
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.8750000000000213 55
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 2.187500000000025 66
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 2.187500000000025 77
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 2.2916666666666927 88
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081470> 0.4166666666666714 10
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 0.6250000000000071 19
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 1.0416666666666785 29
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 1.1458333333333464 40
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.8750000000000213 56
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 2.187500000000025 67
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 2.187500000000025 78
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 2.2916666666666927 89
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081470> 0.4166666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 0.6250000000000071 20
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 1.0416666666666785 30
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 1.1458333333333464 41
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.8750000000000213 57
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 2.187500000000025 68
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 2.187500000000025 79
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 2.2916666666666927 90
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bfe10> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00225c0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081ef0> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081470> 0.5208333333333393 12
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 0.729166666666675 21
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 1.1458333333333464 31
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 1.2500000000000142 42
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 1.9791666666666892 58
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 2.2916666666666927 69
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 2.2916666666666927 80
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 2.3958333333333606 91
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022748> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022470> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c9e8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081470> 0.6250000000000071 13
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 0.8333333333333428 22
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 1.2500000000000142 32
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 1.354166666666682 43
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 2.083333333333357 59
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 2.3958333333333606 70
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 2.3958333333333606 81
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 2.5000000000000284 92
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022b38> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081470> 0.729166666666675 14
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 0.9375000000000107 23
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 1.354166666666682 33
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 1.45833333333335 44
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 2.187500000000025 60
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 2.5000000000000284 71
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 2.5000000000000284 82
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 2.6041666666666963 93
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035080> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf4e0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068eb8> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081470> 0.8333333333333428 15
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 1.0416666666666785 24
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 1.45833333333335 34
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 1.5625000000000178 45
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 2.2916666666666927 61
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 2.6041666666666963 72
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 2.6041666666666963 83
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 2.708333333333364 94
Completed Iteration #24
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c00356a0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00225c0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081ef0> 0.31250000000000355 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081470> 0.9375000000000107 16
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 1.1458333333333464 25
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 1.5625000000000178 35
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 1.6666666666666856 46
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 2.3958333333333606 62
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 2.708333333333364 73
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 2.708333333333364 84
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 2.812500000000032 95
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #7
root->7->15->2->1->8->3->6
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
coverage_call_count 400
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022438> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf4e0> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068eb8> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081470> 1.0416666666666785 17
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 1.2500000000000142 26
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 1.6666666666666856 36
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 1.7708333333333535 47
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 2.5000000000000284 63
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 2.812500000000032 74
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 2.812500000000032 85
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 2.9166666666667 96
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022438> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf4e0> 0.31250000000000355 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068eb8> 0.4166666666666714 6
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081470> 1.0416666666666785 18
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 1.2500000000000142 27
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 1.6666666666666856 37
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 1.7708333333333535 48
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 2.5000000000000284 64
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 2.812500000000032 75
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 2.812500000000032 86
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 2.9166666666667 97
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068eb8> 0.4166666666666714 7
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081470> 1.0416666666666785 19
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 1.2500000000000142 28
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 1.6666666666666856 38
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 1.7708333333333535 49
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 2.5000000000000284 65
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 2.812500000000032 76
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 2.812500000000032 87
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 2.9166666666667 98
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081400> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf4e0> 0.31250000000000355 6
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068eb8> 0.4166666666666714 8
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081470> 1.0416666666666785 20
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 1.2500000000000142 29
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 1.6666666666666856 39
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 1.7708333333333535 50
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 2.5000000000000284 66
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 2.812500000000032 77
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 2.812500000000032 88
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 2.9166666666667 99
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068eb8> 0.4166666666666714 9
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081470> 1.0416666666666785 21
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 1.2500000000000142 30
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 1.6666666666666856 40
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 1.7708333333333535 51
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 2.5000000000000284 67
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 2.812500000000032 78
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 2.812500000000032 89
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 2.9166666666667 100
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41785c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068eb8> 0.4166666666666714 10
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081470> 1.0416666666666785 22
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 1.2500000000000142 31
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 1.6666666666666856 41
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 1.7708333333333535 52
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 2.5000000000000284 68
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 2.812500000000032 79
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 2.812500000000032 90
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 2.9166666666667 101
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068eb8> 0.4166666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081470> 1.0416666666666785 23
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 1.2500000000000142 32
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 1.6666666666666856 42
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 1.7708333333333535 53
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 2.5000000000000284 69
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 2.812500000000032 80
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 2.812500000000032 91
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 2.9166666666667 102
Completed Iteration #23
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01accc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068eb8> 0.4166666666666714 12
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081470> 1.0416666666666785 24
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 1.2500000000000142 33
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 1.6666666666666856 43
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 1.7708333333333535 54
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 2.5000000000000284 70
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 2.812500000000032 81
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 2.812500000000032 92
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 2.9166666666667 103
Completed Iteration #24
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00228d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068eb8> 0.4166666666666714 13
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081470> 1.0416666666666785 25
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8780> 1.2500000000000142 34
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 1.6666666666666856 44
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cbe0> 1.7708333333333535 55
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137358> 2.5000000000000284 71
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c88> 2.812500000000032 82
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110160> 2.812500000000032 93
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 2.9166666666667 104
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #8
root->7->15->2->1->8->3->6->10
Best Reward: 0.10416666666666785
iteration: 8
found coverage increase 0.10416666666666785
Current Total Coverage 25.729166666666664
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c50> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41788d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c50> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41788d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c50> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c50> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41782b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c50> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c50> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41992b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c50> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41994e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c50> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41994e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c50> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c50> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c50> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c50> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41782b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c50> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41788d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c50> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c50> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 25.729166666666664
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199e10> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00815f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199e10> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199e10> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00682b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199e10> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199e10> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199e10> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199e10> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199e10> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199e10> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41787f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199e10> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199e10> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199e10> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00224e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199e10> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199e10> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 25.729166666666664
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41995c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178358> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41aba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178358> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178358> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178358> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178358> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178358> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178358> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178358> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178358> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178358> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178358> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 25.729166666666664
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00351d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00225f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a160> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a160> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a160> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a160> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a160> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a160> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a160> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a160> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a160> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a160> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a160> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a160> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a160> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 25.729166666666664
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175860> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41032e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41036d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175860> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175860> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175860> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175860> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175860> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175860> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175860> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175860> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175860> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175860> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175860> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175860> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175860> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175860> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 25.729166666666664
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.1041666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.1041666666666714 8
Completed Iteration #9
Best Reward: 0.1041666666666714
Completed Iteration #10
Best Reward: 0.1041666666666714
Completed Iteration #11
Best Reward: 0.1041666666666714
Completed Iteration #12
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.1041666666666714 9
Completed Iteration #13
Best Reward: 0.1041666666666714
Completed Iteration #14
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd91f7d0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41036a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.1041666666666714 10
Completed Iteration #15
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.1041666666666714 11
Completed Iteration #16
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.1041666666666714 12
Completed Iteration #17
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00a6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41036a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.1041666666666714 13
Completed Iteration #18
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.1041666666666714 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.1041666666666714 14
Completed Iteration #19
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.1041666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.1041666666666714 15
Completed Iteration #20
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41039b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.1041666666666714 16
Completed Iteration #21
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.1041666666666714 17
Completed Iteration #22
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8ca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.1041666666666714 18
Completed Iteration #23
Best Reward: 0.1041666666666714
Completed Iteration #24
Best Reward: 0.1041666666666714
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #0
root
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.1041666666666714 6
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.1041666666666714 19
Completed Iteration #0
Best Reward: 0.1041666666666714
Completed Iteration #1
Best Reward: 0.1041666666666714
Completed Iteration #2
Best Reward: 0.1041666666666714
Completed Iteration #3
Best Reward: 0.1041666666666714
Completed Iteration #4
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.1041666666666714 7
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.1041666666666714 20
Completed Iteration #5
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.1041666666666714 8
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.1041666666666714 21
Completed Iteration #6
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3240> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.2083333333333428 9
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.2083333333333428 22
Completed Iteration #7
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c668> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.3125000000000142 10
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.3125000000000142 23
Completed Iteration #8
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.3125000000000142 11
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.3125000000000142 24
Completed Iteration #9
Best Reward: 0.1041666666666714
Completed Iteration #10
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00a6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.3125000000000142 12
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.3125000000000142 25
Completed Iteration #11
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3080> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d128> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cb8d0> 0.1041666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.4166666666666856 13
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.4166666666666856 26
Completed Iteration #12
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b9e8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b198> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cb8d0> 0.2083333333333428 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.520833333333357 14
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.520833333333357 27
Completed Iteration #13
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8a41039e8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbe10> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cb940> 0.1041666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.6250000000000284 15
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.6250000000000284 28
Completed Iteration #14
Best Reward: 0.1041666666666714
Completed Iteration #15
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.6250000000000284 16
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.6250000000000284 29
Completed Iteration #16
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.6250000000000284 17
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.6250000000000284 30
Completed Iteration #17
Best Reward: 0.1041666666666714
Completed Iteration #18
Best Reward: 0.1041666666666714
Completed Iteration #19
Best Reward: 0.1041666666666714
Completed Iteration #20
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.6250000000000284 18
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.6250000000000284 31
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.6250000000000284 19
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.6250000000000284 32
Completed Iteration #23
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c9e8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cc50> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cb940> 0.2083333333333428 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.7291666666666998 20
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.7291666666666998 33
Completed Iteration #24
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bfac8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.8333333333333712 21
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.8333333333333712 34
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #1
root->2
Best Reward: 0.1041666666666714
Completed Iteration #0
Best Reward: 0.1041666666666714
coverage_call_count 600
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf710> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.9375000000000426 22
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 0.9375000000000426 35
Completed Iteration #1
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8f98> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 1.041666666666714 23
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 1.041666666666714 36
Completed Iteration #2
Best Reward: 0.1041666666666714
Completed Iteration #3
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b84a8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8ba8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf710> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 1.1458333333333854 24
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 1.1458333333333854 37
Completed Iteration #4
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8588> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 1.2500000000000568 25
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 1.2500000000000568 38
Completed Iteration #5
Best Reward: 0.1041666666666714
Completed Iteration #6
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 1.3541666666667282 26
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 1.3541666666667282 39
Completed Iteration #7
Best Reward: 0.1041666666666714
Completed Iteration #8
Best Reward: 0.1041666666666714
Completed Iteration #9
Best Reward: 0.1041666666666714
Completed Iteration #10
Best Reward: 0.1041666666666714
Completed Iteration #11
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0ba8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0048> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 0.8333333333333712 9
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 1.4583333333333997 27
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 1.4583333333333997 40
Completed Iteration #12
Best Reward: 0.1041666666666714
Completed Iteration #13
Best Reward: 0.1041666666666714
Completed Iteration #14
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0b70> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d198> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 0.9375000000000426 10
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 1.562500000000071 28
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 1.562500000000071 41
Completed Iteration #15
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8a41036d8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0048> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 1.041666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 1.6666666666667425 29
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 1.6666666666667425 42
Completed Iteration #16
Best Reward: 0.1041666666666714
Completed Iteration #17
Best Reward: 0.1041666666666714
Completed Iteration #18
Best Reward: 0.1041666666666714
Completed Iteration #19
Best Reward: 0.1041666666666714
Completed Iteration #20
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c240> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c438> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 1.1458333333333854 12
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 1.7708333333334139 30
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 1.7708333333334139 43
Completed Iteration #21
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0f28> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 0.8333333333333712 9
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 1.2500000000000568 13
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 1.8750000000000853 31
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 1.8750000000000853 44
Completed Iteration #22
Best Reward: 0.1041666666666714
Completed Iteration #23
Best Reward: 0.1041666666666714
Completed Iteration #24
Best Reward: 0.1041666666666714
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #2
root->2->17
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0da0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 0.9375000000000426 10
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 1.3541666666667282 14
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 1.9791666666667567 32
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 1.9791666666667567 45
Completed Iteration #0
Best Reward: 0.1041666666666714
Completed Iteration #1
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bfa90> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf240> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8f98> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 1.041666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 1.4583333333333997 15
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 2.083333333333428 33
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 2.083333333333428 46
Completed Iteration #2
Best Reward: 0.1041666666666714
Completed Iteration #3
Best Reward: 0.1041666666666714
Completed Iteration #4
Best Reward: 0.1041666666666714
Completed Iteration #5
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7b70> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 1.1458333333333854 12
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 1.562500000000071 16
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 2.1875000000000995 34
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 2.1875000000000995 47
Completed Iteration #6
Best Reward: 0.1041666666666714
Completed Iteration #7
Best Reward: 0.1041666666666714
Completed Iteration #8
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f79b0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a06d8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c668> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 1.2500000000000568 13
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 1.6666666666667425 17
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 2.291666666666771 35
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 2.291666666666771 48
Completed Iteration #9
Best Reward: 0.1041666666666714
Completed Iteration #10
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7908> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7c18> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0da0> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 1.3541666666667282 14
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 1.7708333333334139 18
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 2.3958333333334423 36
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 2.3958333333334423 49
Completed Iteration #11
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0da0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8390> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0f28> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 1.4583333333333997 15
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 1.8750000000000853 19
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 2.5000000000001137 37
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 2.5000000000001137 50
Completed Iteration #12
Best Reward: 0.1041666666666714
Completed Iteration #13
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101cc0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7c18> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0da0> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 1.562500000000071 16
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 1.9791666666667567 20
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 2.604166666666785 38
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 2.604166666666785 51
Completed Iteration #14
Best Reward: 0.1041666666666714
Completed Iteration #15
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101668> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 1.6666666666667425 17
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 2.083333333333428 21
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 2.7083333333334565 39
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 2.7083333333334565 52
Completed Iteration #16
Best Reward: 0.1041666666666714
Completed Iteration #17
Best Reward: 0.1041666666666714
Completed Iteration #18
Best Reward: 0.1041666666666714
Completed Iteration #19
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8588> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c438> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 1.7708333333334139 18
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 2.1875000000000995 22
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 2.812500000000128 40
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 2.812500000000128 53
Completed Iteration #20
Best Reward: 0.1041666666666714
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Completed Iteration #23
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c0f0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c438> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101668> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 1.8750000000000853 19
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 2.291666666666771 23
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 2.9166666666667993 41
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 2.9166666666667993 54
Completed Iteration #24
Best Reward: 0.1041666666666714
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #3
root->2->17->1
Best Reward: 0.1041666666666714
Completed Iteration #0
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a05c0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 1.9791666666667567 20
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 2.3958333333334423 24
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 3.0208333333334707 42
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 3.0208333333334707 55
Completed Iteration #1
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f79e8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 2.083333333333428 21
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 2.5000000000001137 25
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 3.125000000000142 43
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 3.125000000000142 56
Completed Iteration #2
Best Reward: 0.1041666666666714
Completed Iteration #3
Best Reward: 0.1041666666666714
Completed Iteration #4
Best Reward: 0.1041666666666714
Completed Iteration #5
Best Reward: 0.1041666666666714
Completed Iteration #6
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101630> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101c18> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 2.1875000000000995 22
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 2.604166666666785 26
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 3.2291666666668135 44
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 3.2291666666668135 57
Completed Iteration #7
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bfb70> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bfdd8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101630> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101c18> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 2.291666666666771 23
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 2.7083333333334565 27
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 3.333333333333485 45
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 3.333333333333485 58
Completed Iteration #8
Best Reward: 0.1041666666666714
Completed Iteration #9
Best Reward: 0.1041666666666714
Completed Iteration #10
Best Reward: 0.1041666666666714
Completed Iteration #11
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c01019b0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01017f0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 0.8333333333333712 9
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 2.3958333333334423 24
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 2.812500000000128 28
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 3.4375000000001563 46
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 3.4375000000001563 59
Completed Iteration #12
Best Reward: 0.1041666666666714
Completed Iteration #13
Best Reward: 0.1041666666666714
Completed Iteration #14
Best Reward: 0.1041666666666714
Completed Iteration #15
Best Reward: 0.1041666666666714
Completed Iteration #16
Best Reward: 0.1041666666666714
Completed Iteration #17
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8080> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c438> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 0.9375000000000426 10
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 2.5000000000001137 25
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 2.9166666666667993 29
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 3.5416666666668277 47
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 3.5416666666668277 60
Completed Iteration #18
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8e80> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01017f0> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 1.041666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 2.604166666666785 26
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 3.0208333333334707 30
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 3.645833333333499 48
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 3.645833333333499 61
Completed Iteration #19
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101b00> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bff28> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 1.1458333333333854 12
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 2.7083333333334565 27
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 3.125000000000142 31
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 3.7500000000001705 49
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 3.7500000000001705 62
Completed Iteration #20
Best Reward: 0.1041666666666714
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Completed Iteration #23
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b438> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 1.2500000000000568 13
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 2.812500000000128 28
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 3.2291666666668135 32
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 3.854166666666842 50
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 3.854166666666842 63
Completed Iteration #24
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b9b0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bf98> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 1.3541666666667282 14
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 2.9166666666667993 29
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 3.333333333333485 33
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 3.9583333333335133 51
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 3.9583333333335133 64
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #4
root->2->17->1->14
Best Reward: 0.1041666666666714
Completed Iteration #0
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c400> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 1.4583333333333997 15
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 3.0208333333334707 30
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 3.4375000000001563 34
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 4.062500000000185 52
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 4.062500000000185 65
Completed Iteration #1
Best Reward: 0.1041666666666714
Completed Iteration #2
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b87b8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 1.562500000000071 16
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 3.125000000000142 31
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 3.5416666666668277 35
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 4.166666666666856 53
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 4.166666666666856 66
Completed Iteration #3
Best Reward: 0.1041666666666714
Completed Iteration #4
Best Reward: 0.1041666666666714
Completed Iteration #5
Best Reward: 0.1041666666666714
Completed Iteration #6
Best Reward: 0.1041666666666714
Completed Iteration #7
Best Reward: 0.1041666666666714
Completed Iteration #8
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 1.6666666666667425 17
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 3.2291666666668135 32
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 3.645833333333499 36
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 4.2708333333335275 54
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 4.2708333333335275 67
Completed Iteration #9
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b7f0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001beb8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 1.7708333333334139 18
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 3.333333333333485 33
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 3.7500000000001705 37
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 4.375000000000199 55
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 4.375000000000199 68
Completed Iteration #10
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bfa20> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7940> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c400> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 0.8333333333333712 9
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 1.8750000000000853 19
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 3.4375000000001563 34
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 3.854166666666842 38
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 4.47916666666687 56
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 4.47916666666687 69
Completed Iteration #11
Best Reward: 0.1041666666666714
Completed Iteration #12
Best Reward: 0.1041666666666714
Completed Iteration #13
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b630> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 0.9375000000000426 10
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 1.9791666666667567 20
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 3.5416666666668277 35
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 3.9583333333335133 39
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 4.583333333333542 57
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 4.583333333333542 70
Completed Iteration #14
Best Reward: 0.1041666666666714
Completed Iteration #15
Best Reward: 0.1041666666666714
Completed Iteration #16
Best Reward: 0.1041666666666714
Completed Iteration #17
Best Reward: 0.1041666666666714
Completed Iteration #18
Best Reward: 0.1041666666666714
Completed Iteration #19
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bfc50> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b2e8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 1.041666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 2.083333333333428 21
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 3.645833333333499 36
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 4.062500000000185 40
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 4.687500000000213 58
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 4.687500000000213 71
Completed Iteration #20
Best Reward: 0.1041666666666714
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Completed Iteration #23
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137518> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137550> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f79e8> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 1.1458333333333854 12
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 2.1875000000000995 22
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 3.7500000000001705 37
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 4.166666666666856 41
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 4.791666666666885 59
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 4.791666666666885 72
Completed Iteration #24
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110f28> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01106a0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b438> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 1.2500000000000568 13
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 2.291666666666771 23
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 3.854166666666842 38
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 4.2708333333335275 42
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 4.895833333333556 60
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 4.895833333333556 73
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #5
root->2->17->1->14->5
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c01103c8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110208> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 1.3541666666667282 14
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 2.3958333333334423 24
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 3.9583333333335133 39
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 4.375000000000199 43
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 5.000000000000227 61
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 5.000000000000227 74
Completed Iteration #0
Best Reward: 0.1041666666666714
Completed Iteration #1
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170a90> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110208> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 1.4583333333333997 15
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 2.5000000000001137 25
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 4.062500000000185 40
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 4.47916666666687 44
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 5.104166666666899 62
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 5.104166666666899 75
Completed Iteration #2
Best Reward: 0.1041666666666714
Completed Iteration #3
Best Reward: 0.1041666666666714
Completed Iteration #4
Best Reward: 0.1041666666666714
Completed Iteration #5
Best Reward: 0.1041666666666714
Completed Iteration #6
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101e80> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01014a8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170a90> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110208> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 1.562500000000071 16
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 2.604166666666785 26
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 4.166666666666856 41
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 4.583333333333542 45
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 5.20833333333357 63
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 5.20833333333357 76
Completed Iteration #7
Best Reward: 0.1041666666666714
Completed Iteration #8
Best Reward: 0.1041666666666714
Completed Iteration #9
Best Reward: 0.1041666666666714
Completed Iteration #10
Best Reward: 0.1041666666666714
coverage_call_count 700
Completed Iteration #11
Best Reward: 0.1041666666666714
Completed Iteration #12
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7c88> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110208> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 1.6666666666667425 17
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 2.7083333333334565 27
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 4.2708333333335275 42
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 4.687500000000213 46
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 5.312500000000242 64
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 5.312500000000242 77
Completed Iteration #13
Best Reward: 0.1041666666666714
Completed Iteration #14
Best Reward: 0.1041666666666714
Completed Iteration #15
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c01105f8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001beb8> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 0.8333333333333712 9
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 1.7708333333334139 18
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 2.812500000000128 28
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 4.375000000000199 43
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 4.791666666666885 47
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 5.416666666666913 65
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 5.416666666666913 78
Completed Iteration #16
Best Reward: 0.1041666666666714
Completed Iteration #17
Best Reward: 0.1041666666666714
Completed Iteration #18
Best Reward: 0.1041666666666714
Completed Iteration #19
Best Reward: 0.1041666666666714
Completed Iteration #20
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110320> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001beb8> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 0.9375000000000426 10
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 1.8750000000000853 19
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 2.9166666666667993 29
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 4.47916666666687 44
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 4.895833333333556 48
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 5.520833333333584 66
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 5.520833333333584 79
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Completed Iteration #23
Best Reward: 0.1041666666666714
Completed Iteration #24
Best Reward: 0.1041666666666714
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #6
root->2->17->1->14->5->18
Best Reward: 0.1041666666666714
Completed Iteration #0
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c01664e0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01014a8> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170a90> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110208> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 1.041666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 1.9791666666667567 20
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 3.0208333333334707 30
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 4.583333333333542 45
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 5.000000000000227 49
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 5.625000000000256 67
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 5.625000000000256 80
Completed Iteration #1
Best Reward: 0.1041666666666714
Completed Iteration #2
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c01230b8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110208> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 1.1458333333333854 12
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 2.083333333333428 21
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 3.125000000000142 31
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 4.687500000000213 46
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 5.104166666666899 50
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 5.729166666666927 68
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 5.729166666666927 81
Completed Iteration #3
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c01234e0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01014a8> 0.3125000000000142 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170a90> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110208> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 1.2500000000000568 13
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 2.1875000000000995 22
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 3.2291666666668135 32
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 4.791666666666885 47
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 5.20833333333357 51
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 5.833333333333599 69
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 5.833333333333599 82
Completed Iteration #4
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be710> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00841d0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170a90> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110208> 0.8333333333333712 9
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 1.3541666666667282 14
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 2.291666666666771 23
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 3.333333333333485 33
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 4.895833333333556 48
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 5.312500000000242 52
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 5.93750000000027 70
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 5.93750000000027 83
Completed Iteration #5
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101518> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110208> 0.9375000000000426 10
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 1.4583333333333997 15
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 2.3958333333334423 24
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 3.4375000000001563 34
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 5.000000000000227 49
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 5.416666666666913 53
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 6.041666666666941 71
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 6.041666666666941 84
Completed Iteration #6
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7f98> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110208> 1.041666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 1.562500000000071 16
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 2.5000000000001137 25
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 3.5416666666668277 35
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 5.104166666666899 50
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 5.520833333333584 54
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 6.145833333333613 72
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 6.145833333333613 85
Completed Iteration #7
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c01372e8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110208> 1.1458333333333854 12
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 1.6666666666667425 17
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 2.604166666666785 26
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 3.645833333333499 36
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 5.20833333333357 51
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 5.625000000000256 55
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 6.250000000000284 73
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 6.250000000000284 86
Completed Iteration #8
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166a20> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166668> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01372e8> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110208> 1.2500000000000568 13
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 1.7708333333334139 18
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 2.7083333333334565 27
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 3.7500000000001705 37
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 5.312500000000242 52
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 5.729166666666927 56
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 6.354166666666956 74
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 6.354166666666956 87
Completed Iteration #9
Best Reward: 0.1041666666666714
Completed Iteration #10
Best Reward: 0.1041666666666714
Completed Iteration #11
Best Reward: 0.1041666666666714
Completed Iteration #12
Best Reward: 0.1041666666666714
Completed Iteration #13
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123e10> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110208> 1.3541666666667282 14
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 1.8750000000000853 19
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 2.812500000000128 28
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 3.854166666666842 38
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 5.416666666666913 53
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 5.833333333333599 57
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 6.458333333333627 75
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 6.458333333333627 88
Completed Iteration #14
Best Reward: 0.1041666666666714
Completed Iteration #15
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123be0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123cf8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01230b8> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110208> 1.4583333333333997 15
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 1.9791666666667567 20
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 2.9166666666667993 29
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 3.9583333333335133 39
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 5.520833333333584 54
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 5.93750000000027 58
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 6.562500000000298 76
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 6.562500000000298 89
Completed Iteration #16
Best Reward: 0.1041666666666714
Completed Iteration #17
Best Reward: 0.1041666666666714
Completed Iteration #18
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110b70> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c0b8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01103c8> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110208> 1.562500000000071 16
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 2.083333333333428 21
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 3.0208333333334707 30
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 4.062500000000185 40
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 5.625000000000256 55
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 6.041666666666941 59
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 6.66666666666697 77
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 6.66666666666697 90
Completed Iteration #19
Best Reward: 0.1041666666666714
Completed Iteration #20
Best Reward: 0.1041666666666714
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baf60> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cda0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123e10> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110208> 1.6666666666667425 17
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 2.1875000000000995 22
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 3.125000000000142 31
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 4.166666666666856 41
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 5.729166666666927 56
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 6.145833333333613 60
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 6.770833333333641 78
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 6.770833333333641 91
Completed Iteration #23
Best Reward: 0.1041666666666714
Completed Iteration #24
Best Reward: 0.1041666666666714
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #7
root->2->17->1->14->5->18->4
Best Reward: 0.1041666666666714
Completed Iteration #0
Best Reward: 0.1041666666666714
Completed Iteration #1
Best Reward: 0.1041666666666714
Completed Iteration #2
Best Reward: 0.1041666666666714
Completed Iteration #3
Best Reward: 0.1041666666666714
Completed Iteration #4
Best Reward: 0.1041666666666714
Completed Iteration #5
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be8d0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004828> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170a90> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110208> 1.7708333333334139 18
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 2.291666666666771 23
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 3.2291666666668135 32
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 4.2708333333335275 42
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 5.833333333333599 57
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 6.250000000000284 61
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 6.875000000000313 79
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 6.875000000000313 92
Completed Iteration #6
Best Reward: 0.1041666666666714
Completed Iteration #7
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110278> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01014a8> 0.4166666666666856 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170a90> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110208> 1.8750000000000853 19
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 2.3958333333334423 24
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 3.333333333333485 33
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 4.375000000000199 43
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 5.93750000000027 58
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 6.354166666666956 62
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 6.979166666666984 80
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 6.979166666666984 93
Completed Iteration #8
Best Reward: 0.1041666666666714
Completed Iteration #9
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166978> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00841d0> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170a90> 0.8333333333333712 9
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110208> 1.9791666666667567 20
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 2.5000000000001137 25
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 3.4375000000001563 34
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 4.47916666666687 44
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 6.041666666666941 59
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 6.458333333333627 63
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 7.0833333333336554 81
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 7.0833333333336554 94
Completed Iteration #10
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123080> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01014a8> 0.520833333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170a90> 0.9375000000000426 10
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110208> 2.083333333333428 21
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 2.604166666666785 26
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 3.5416666666668277 35
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 4.583333333333542 45
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 6.145833333333613 60
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 6.562500000000298 64
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 7.187500000000327 82
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 7.187500000000327 95
Completed Iteration #11
Best Reward: 0.1041666666666714
Completed Iteration #12
Best Reward: 0.1041666666666714
Completed Iteration #13
Best Reward: 0.1041666666666714
Completed Iteration #14
Best Reward: 0.1041666666666714
Completed Iteration #15
Best Reward: 0.1041666666666714
Completed Iteration #16
Best Reward: 0.1041666666666714
Completed Iteration #17
Best Reward: 0.1041666666666714
Completed Iteration #18
Best Reward: 0.1041666666666714
Completed Iteration #19
Best Reward: 0.1041666666666714
Completed Iteration #20
Best Reward: 0.1041666666666714
Completed Iteration #21
Best Reward: 0.1041666666666714
Completed Iteration #22
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c01aca20> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004978> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123080> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01014a8> 0.6250000000000284 7
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170a90> 1.041666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110208> 2.1875000000000995 22
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 2.7083333333334565 27
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 3.645833333333499 36
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 4.687500000000213 46
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 6.250000000000284 61
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 6.66666666666697 65
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 7.291666666666998 83
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 7.291666666666998 96
Completed Iteration #23
Best Reward: 0.1041666666666714
Reward: 0.1041666666666714
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac4a8> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01accc0> 0.1041666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101e80> 0.2083333333333428 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01014a8> 0.7291666666666998 8
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170a90> 1.1458333333333854 12
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110208> 2.291666666666771 23
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8358> 2.812500000000128 28
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d048> 3.7500000000001705 37
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 4.791666666666885 47
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103be0> 6.354166666666956 62
backprop <src.mcts.MCTS_Node object at 0x7fd8e0136780> 6.770833333333641 66
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 7.39583333333367 84
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c588> 7.39583333333367 97
Completed Iteration #24
Best Reward: 0.1041666666666714
Completed Iteration #25
Best Reward: 0.1041666666666714
Completed MCTS Level/Depth: #8
root->2->17->1->14->5->18->4->3
Best Reward: 0.1041666666666714
iteration: 14
found coverage increase 0.1041666666666714
Current Total Coverage 25.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac978> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac978> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac978> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac978> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac978> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac978> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac978> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac978> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac978> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac978> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac978> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac978> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac978> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac978> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac978> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac978> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01aca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac978> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac978> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 25.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01235c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00681d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a20> 0.0 7
Completed Iteration #8
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a20> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00687b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00687b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41755f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01235c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a20> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00356a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a20> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a20> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00687b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a20> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01235c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a20> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 25.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00680b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00229b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00222b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b390> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00225f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b390> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b390> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b390> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00222b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b390> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b390> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b390> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b390> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 25.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00815f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a978> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00352b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415aa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a978> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415aa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a978> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a978> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a978> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415aa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a978> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a978> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415aa20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a978> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a978> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a978> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a978> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 25.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00049e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081128> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01662e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081128> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081128> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081128> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081128> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081128> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081128> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081128> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081128> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081128> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081128> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081128> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081128> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 25.833333333333336
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00688d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00688d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00688d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00688d0> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00688d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00688d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00688d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c00688d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00688d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00688d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01661d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00688d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00688d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00688d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00688d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00688d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414de80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00688d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00688d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00688d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415ad68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00688d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 25.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41999b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41785c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41789e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c1d0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.10416666666666785 15
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.10416666666666785 16
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 0.10416666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.10416666666666785 17
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.10416666666666785 18
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.10416666666666785 19
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199978> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 0.2083333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.2083333333333357 20
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #0
root
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 0.2083333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.2083333333333357 21
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 0.2083333333333357 7
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.2083333333333357 22
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 0.2083333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.2083333333333357 23
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abbe0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 0.31250000000000355 9
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.31250000000000355 24
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 0.31250000000000355 10
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.31250000000000355 25
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a7b8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 0.4166666666666714 11
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.4166666666666714 26
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 0.4166666666666714 12
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.4166666666666714 27
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 0.4166666666666714 13
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.4166666666666714 28
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00229e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abbe0> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 0.4166666666666714 14
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.4166666666666714 29
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 0.4166666666666714 15
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.4166666666666714 30
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 0.4166666666666714 16
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.4166666666666714 31
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c4a8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01aceb8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a7b8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 0.5208333333333393 17
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.5208333333333393 32
Completed Iteration #18
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00049e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a7b8> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 0.5208333333333393 18
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.5208333333333393 33
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175dd8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acb70> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068ac8> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 0.6250000000000071 19
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.6250000000000071 34
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 0.6250000000000071 20
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.6250000000000071 35
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 0.729166666666675 21
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.729166666666675 36
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #1
root->2
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 0.8333333333333428 22
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.8333333333333428 37
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd88c043dd8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 0.9375000000000107 23
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.9375000000000107 38
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 0.31250000000000355 5
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 0.9375000000000107 24
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.9375000000000107 39
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c043e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 0.31250000000000355 6
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 0.9375000000000107 25
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 0.9375000000000107 40
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #2
root->2->7
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bab70> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 0.31250000000000355 5
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 0.4166666666666714 7
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 1.0416666666666785 26
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 1.0416666666666785 41
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175f98> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cf28> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043dd8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 0.4166666666666714 6
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 0.5208333333333393 8
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 1.1458333333333464 27
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 1.1458333333333464 42
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
coverage_call_count 1000
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd88c043be0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 0.5208333333333393 7
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 0.6250000000000071 9
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 1.2500000000000142 28
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 1.2500000000000142 43
Completed Iteration #5
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d278> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 0.6250000000000071 8
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 0.729166666666675 10
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 1.354166666666682 29
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 1.354166666666682 44
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd88c03db38> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 0.729166666666675 9
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 0.8333333333333428 11
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 1.45833333333335 30
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 1.45833333333335 45
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b5f8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 0.8333333333333428 10
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 0.9375000000000107 12
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 1.5625000000000178 31
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 1.5625000000000178 46
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03db38> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 0.8333333333333428 11
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 0.9375000000000107 13
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 1.5625000000000178 32
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 1.5625000000000178 47
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 0.8333333333333428 12
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 0.9375000000000107 14
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 1.5625000000000178 33
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 1.5625000000000178 48
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 0.8333333333333428 13
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 0.9375000000000107 15
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 1.5625000000000178 34
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 1.5625000000000178 49
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #3
root->2->7->2
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b940> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 0.9375000000000107 14
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 1.0416666666666785 16
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 1.6666666666666856 35
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 1.6666666666666856 50
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8869a42e8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 1.0416666666666785 15
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 1.1458333333333464 17
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 1.7708333333333535 36
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 1.7708333333333535 51
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4630> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 1.1458333333333464 16
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 1.2500000000000142 18
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 1.8750000000000213 37
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 1.8750000000000213 52
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d518> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d4e0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 1.2500000000000142 17
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 1.354166666666682 19
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 1.9791666666666892 38
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 1.9791666666666892 53
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd88c043320> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 1.354166666666682 18
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 1.45833333333335 20
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 2.083333333333357 39
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 2.083333333333357 54
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd88c04be10> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 0.8333333333333428 9
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 1.45833333333335 19
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 1.5625000000000178 21
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 2.187500000000025 40
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 2.187500000000025 55
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #4
root->2->7->2->3
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd88c067e10> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 0.9375000000000107 10
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 1.5625000000000178 20
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 1.6666666666666856 22
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 2.2916666666666927 41
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 2.2916666666666927 56
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4c88> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 0.8333333333333428 9
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 1.0416666666666785 11
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 1.6666666666666856 21
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 1.7708333333333535 23
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 2.3958333333333606 42
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 2.3958333333333606 57
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4080> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 0.9375000000000107 10
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 1.1458333333333464 12
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 1.7708333333333535 22
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 1.8750000000000213 24
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 2.5000000000000284 43
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 2.5000000000000284 58
Completed Iteration #14
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4470> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 1.0416666666666785 11
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 1.2500000000000142 13
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 1.8750000000000213 23
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 1.9791666666666892 25
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 2.6041666666666963 44
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 2.6041666666666963 59
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4b38> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 1.1458333333333464 12
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 1.354166666666682 14
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 1.9791666666666892 24
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 2.083333333333357 26
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 2.708333333333364 45
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 2.708333333333364 60
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4e80> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 1.2500000000000142 13
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 1.45833333333335 15
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 2.083333333333357 25
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 2.187500000000025 27
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 2.812500000000032 46
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 2.812500000000032 61
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8869c49b0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 1.354166666666682 14
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 1.5625000000000178 16
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 2.187500000000025 26
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 2.2916666666666927 28
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 2.9166666666667 47
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 2.9166666666667 62
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b278> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199cc0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c49b0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 1.45833333333335 15
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 1.6666666666666856 17
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 2.2916666666666927 27
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 2.3958333333333606 29
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 3.0208333333333677 48
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 3.0208333333333677 63
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #5
root->2->7->2->3->0
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c0436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c49b0> 0.2083333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 1.45833333333335 16
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 1.6666666666666856 18
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 2.2916666666666927 28
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 2.3958333333333606 30
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 3.0208333333333677 49
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 3.0208333333333677 64
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd886995550> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acf28> 0.10416666666666785 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869c49b0> 0.31250000000000355 5
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 1.5625000000000178 17
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 1.7708333333333535 19
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 2.3958333333333606 29
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 2.5000000000000284 31
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 3.1250000000000355 50
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 3.1250000000000355 65
Completed Iteration #7
Best Reward: 0.10416666666666785
Completed Iteration #8
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb240> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199cc0> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869c49b0> 0.4166666666666714 6
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 1.6666666666666856 18
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 1.8750000000000213 20
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 2.5000000000000284 30
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 2.6041666666666963 32
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 3.2291666666667034 51
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 3.2291666666667034 66
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #6
root->2->7->2->3->0->1
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd886965898> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199cc0> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869c49b0> 0.5208333333333393 7
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 1.7708333333333535 19
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 1.9791666666666892 21
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 2.6041666666666963 31
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 2.708333333333364 33
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 3.3333333333333712 52
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 3.3333333333333712 67
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8869787b8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199cc0> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7fd8869c49b0> 0.6250000000000071 8
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 1.8750000000000213 20
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 2.083333333333357 22
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 2.708333333333364 32
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 2.812500000000032 34
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 3.437500000000039 53
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 3.437500000000039 68
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd886978e80> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199cc0> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7fd8869c49b0> 0.729166666666675 9
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 1.9791666666666892 21
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 2.187500000000025 23
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 2.812500000000032 33
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 2.9166666666667 35
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 3.541666666666707 54
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 3.541666666666707 69
Completed Iteration #8
Best Reward: 0.10416666666666785
coverage_call_count 1100
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd88c0674a8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199cc0> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7fd8869c49b0> 0.8333333333333428 10
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 2.083333333333357 22
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 2.2916666666666927 24
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 2.9166666666667 34
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 3.0208333333333677 36
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 3.645833333333375 55
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 3.645833333333375 70
Completed Iteration #21
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd8a411ccf8> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b780> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c0674a8> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199cc0> 0.729166666666675 8
backprop <src.mcts.MCTS_Node object at 0x7fd8869c49b0> 0.9375000000000107 11
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 2.187500000000025 23
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 2.3958333333333606 25
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 3.0208333333333677 35
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 3.1250000000000355 37
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 3.7500000000000426 56
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 3.7500000000000426 71
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #7
root->2->7->2->3->0->1->0
Best Reward: 0.10416666666666785
Completed Iteration #0
Best Reward: 0.10416666666666785
Completed Iteration #1
Best Reward: 0.10416666666666785
Completed Iteration #2
Best Reward: 0.10416666666666785
Completed Iteration #3
Best Reward: 0.10416666666666785
Completed Iteration #4
Best Reward: 0.10416666666666785
Completed Iteration #5
Best Reward: 0.10416666666666785
Completed Iteration #6
Best Reward: 0.10416666666666785
Completed Iteration #7
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd886978ef0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b780> 0.2083333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c0674a8> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199cc0> 0.8333333333333428 9
backprop <src.mcts.MCTS_Node object at 0x7fd8869c49b0> 1.0416666666666785 12
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 2.2916666666666927 24
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 2.5000000000000284 26
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 3.1250000000000355 36
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 3.2291666666667034 38
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 3.8541666666667105 57
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 3.8541666666667105 72
Completed Iteration #8
Best Reward: 0.10416666666666785
Completed Iteration #9
Best Reward: 0.10416666666666785
Completed Iteration #10
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd886981be0> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b780> 0.31250000000000355 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c0674a8> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199cc0> 0.9375000000000107 10
backprop <src.mcts.MCTS_Node object at 0x7fd8869c49b0> 1.1458333333333464 13
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 2.3958333333333606 25
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 2.6041666666666963 27
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 3.2291666666667034 37
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 3.3333333333333712 39
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 3.9583333333333783 58
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 3.9583333333333783 73
Completed Iteration #11
Best Reward: 0.10416666666666785
Completed Iteration #12
Best Reward: 0.10416666666666785
Completed Iteration #13
Best Reward: 0.10416666666666785
Completed Iteration #14
Best Reward: 0.10416666666666785
Completed Iteration #15
Best Reward: 0.10416666666666785
Completed Iteration #16
Best Reward: 0.10416666666666785
Completed Iteration #17
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd88698d588> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b780> 0.4166666666666714 5
backprop <src.mcts.MCTS_Node object at 0x7fd88c0674a8> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199cc0> 1.0416666666666785 11
backprop <src.mcts.MCTS_Node object at 0x7fd8869c49b0> 1.2500000000000142 14
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 2.5000000000000284 26
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 2.708333333333364 28
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 3.3333333333333712 38
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 3.437500000000039 40
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 4.062500000000046 59
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 4.062500000000046 74
Completed Iteration #18
Best Reward: 0.10416666666666785
Completed Iteration #19
Best Reward: 0.10416666666666785
Completed Iteration #20
Best Reward: 0.10416666666666785
Reward: 0.10416666666666785
backprop <src.mcts.MCTS_Node object at 0x7fd88698de80> 0.10416666666666785 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b780> 0.5208333333333393 6
backprop <src.mcts.MCTS_Node object at 0x7fd88c0674a8> 0.6250000000000071 7
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199cc0> 1.1458333333333464 12
backprop <src.mcts.MCTS_Node object at 0x7fd8869c49b0> 1.354166666666682 15
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 2.6041666666666963 27
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 2.812500000000032 29
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 3.437500000000039 39
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 3.541666666666707 41
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab198> 4.166666666666714 60
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abac8> 4.166666666666714 75
Completed Iteration #21
Best Reward: 0.10416666666666785
Completed Iteration #22
Best Reward: 0.10416666666666785
Completed Iteration #23
Best Reward: 0.10416666666666785
Completed Iteration #24
Best Reward: 0.10416666666666785
Completed Iteration #25
Best Reward: 0.10416666666666785
Completed MCTS Level/Depth: #8
root->2->7->2->3->0->1->0->6
Best Reward: 0.10416666666666785
iteration: 21
found coverage increase 0.10416666666666785
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869345f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869345c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869347f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965f98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c0677b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965f98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965f98> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869343c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886965f98> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869655c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965f98> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869343c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886965f98> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869785c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886965f98> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886965f98> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886978518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c0677b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886965f98> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965f98> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869810b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886965f98> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886965f98> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886965f98> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c043f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886965f98> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869789b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869655c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886965f98> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c0677b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886965f98> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886965f98> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869345c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886965f98> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c46a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c46a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c46a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869c46a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c46a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c46a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869c46a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c46a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869c46a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698dc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869c46a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8869c46a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869c46a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869c46a0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869c46a0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c46a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c46a0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869c46a0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8869c46a0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698dc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8869c46a0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869340f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869340f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869340f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869340f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869340f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869340f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869340f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869340f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869340f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869340f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869340f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869340f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869340f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869001d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869340f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869340f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8869340f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869340f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869340f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869000f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869340f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868911d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886900eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868915c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868917f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868917b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868917b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886900eb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868919e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900eb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900eb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868910b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886900eb8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868917b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886900eb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900eb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868914e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900eb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886900eb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900eb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886900eb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868914e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886900eb8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900eb8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868917b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd886900eb8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4668> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4668> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4668> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4668> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4668> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869655f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4668> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869789b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869655f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4668> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869655f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4668> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869340b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4668> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4668> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4668> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4668> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4668> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4668> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900400> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900400> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886900400> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869957f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900400> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900400> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900400> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886900400> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886900400> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd886900400> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868914a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900400> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900400> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869344e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886900400> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886900400> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886900400> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886900400> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886900400> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88685c198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c198> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88685c198> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c198> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c198> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88685c198> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c198> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88685c198> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c198> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c198> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88685c198> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88685c198> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c198> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c198> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88685c198> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88685c198> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 25.937500000000004
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4f60> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4f60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869009e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4f60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4f60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4f60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4f60> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4f60> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869009e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4f60> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4f60> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4f60> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869009e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4f60> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4f60> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4f60> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4f60> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868914a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686dba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4f60> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4f60> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4f60> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4f60> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868918d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4f60> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4f60> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685cc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4f60> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4f98> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4f98> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4f98> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4f98> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41756a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4f98> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4f98> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4f98> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4f98> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4f98> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4f98> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4f98> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4f98> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4f98> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4f98> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4f98> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4f98> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4f98> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a45f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4f98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869344e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869344e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869344e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869344e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869343c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869344e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869344e0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869344e0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869344e0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869344e0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868352b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869344e0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869344e0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868357f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869344e0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868357f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869344e0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869344e0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869344e0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868357f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869344e0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869344e0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869344e0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869344e0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8869344e0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869344e0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868472b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868472b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868472b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868472b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868472b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868472b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868472b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868472b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868472b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868472b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8868472b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868472b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868477b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868472b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868472b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868472b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868472b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8868472b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8868472b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868477b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8868472b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 25.937500000000004
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868476d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd886847128> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.1041666666666643 9
Completed Iteration #9
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.1041666666666643 10
Completed Iteration #10
Best Reward: 0.1041666666666643
Completed Iteration #11
Best Reward: 0.1041666666666643
Completed Iteration #12
Best Reward: 0.1041666666666643
Completed Iteration #13
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 0.1041666666666643 4
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.1041666666666643 11
Completed Iteration #14
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.1041666666666643 12
Completed Iteration #15
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.1041666666666643 13
Completed Iteration #16
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 0.1041666666666643 5
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.1041666666666643 14
Completed Iteration #17
Best Reward: 0.1041666666666643
Completed Iteration #18
Best Reward: 0.1041666666666643
Completed Iteration #19
Best Reward: 0.1041666666666643
Completed Iteration #20
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.1041666666666643 15
Completed Iteration #21
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.1041666666666643 16
Completed Iteration #22
Best Reward: 0.1041666666666643
Completed Iteration #23
Best Reward: 0.1041666666666643
Completed Iteration #24
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.1041666666666643 17
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #0
root
Best Reward: 0.1041666666666643
Completed Iteration #0
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 0.1041666666666643 6
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.1041666666666643 18
Completed Iteration #1
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847128> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 0.1041666666666643 7
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.1041666666666643 19
Completed Iteration #2
Best Reward: 0.1041666666666643
Completed Iteration #3
Best Reward: 0.1041666666666643
Completed Iteration #4
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847128> 0.1041666666666643 4
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 0.1041666666666643 8
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.1041666666666643 20
Completed Iteration #5
Best Reward: 0.1041666666666643
Completed Iteration #6
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 0.1041666666666643 9
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.1041666666666643 21
Completed Iteration #7
Best Reward: 0.1041666666666643
Completed Iteration #8
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 0.2083333333333286 10
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.2083333333333286 22
Completed Iteration #9
Best Reward: 0.1041666666666643
Completed Iteration #10
Best Reward: 0.1041666666666643
Completed Iteration #11
Best Reward: 0.1041666666666643
Completed Iteration #12
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 0.2083333333333286 11
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.2083333333333286 23
Completed Iteration #13
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 0.2083333333333286 12
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.2083333333333286 24
Completed Iteration #14
Best Reward: 0.1041666666666643
Completed Iteration #15
Best Reward: 0.1041666666666643
Completed Iteration #16
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd88685c940> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 0.3124999999999929 13
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.3124999999999929 25
Completed Iteration #17
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 0.3124999999999929 14
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.3124999999999929 26
Completed Iteration #18
Best Reward: 0.1041666666666643
Completed Iteration #19
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bde470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 0.3124999999999929 15
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.3124999999999929 27
Completed Iteration #20
Best Reward: 0.1041666666666643
Completed Iteration #21
Best Reward: 0.1041666666666643
Completed Iteration #22
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bdec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bdebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 0.3124999999999929 16
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.3124999999999929 28
Completed Iteration #23
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bdeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 0.3124999999999929 17
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.3124999999999929 29
Completed Iteration #24
Best Reward: 0.1041666666666643
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #1
root->5
Best Reward: 0.1041666666666643
Completed Iteration #0
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885bded68> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81400> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 0.4166666666666572 18
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.4166666666666572 30
Completed Iteration #1
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b81390> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde898> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 0.4166666666666572 5
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 0.5208333333333215 19
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.5208333333333215 31
Completed Iteration #2
Best Reward: 0.1041666666666643
Completed Iteration #3
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b819b0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 0.5208333333333215 6
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 0.6249999999999858 20
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.6249999999999858 32
Completed Iteration #4
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde898> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 0.5208333333333215 7
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 0.6249999999999858 21
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.6249999999999858 33
Completed Iteration #5
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd8869810b8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835940> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 0.6249999999999858 8
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 0.7291666666666501 22
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.7291666666666501 34
Completed Iteration #6
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb208> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f208> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81390> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bde898> 0.2083333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 0.7291666666666501 9
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 0.8333333333333144 23
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.8333333333333144 35
Completed Iteration #7
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd886934e48> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934da0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bded68> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b81400> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 0.8333333333333144 10
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 0.9374999999999787 24
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.9374999999999787 36
Completed Iteration #8
Best Reward: 0.1041666666666643
Completed Iteration #9
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178588> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 0.9374999999999787 11
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 1.041666666666643 25
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 1.041666666666643 37
Completed Iteration #10
Best Reward: 0.1041666666666643
Completed Iteration #11
Best Reward: 0.1041666666666643
Completed Iteration #12
Best Reward: 0.1041666666666643
Completed Iteration #13
Best Reward: 0.1041666666666643
Completed Iteration #14
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885bdecf8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde588> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178588> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 0.4166666666666572 5
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 1.041666666666643 12
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 1.1458333333333073 26
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 1.1458333333333073 38
Completed Iteration #15
Best Reward: 0.1041666666666643
Completed Iteration #16
Best Reward: 0.1041666666666643
Completed Iteration #17
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4a90> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bdef98> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 1.1458333333333073 13
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 1.2499999999999716 27
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 1.2499999999999716 39
Completed Iteration #18
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835940> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 1.1458333333333073 14
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 1.2499999999999716 28
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 1.2499999999999716 40
Completed Iteration #19
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4a90> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bdef98> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 1.1458333333333073 15
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 1.2499999999999716 29
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 1.2499999999999716 41
Completed Iteration #20
Best Reward: 0.1041666666666643
Completed Iteration #21
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde898> 0.2083333333333286 5
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 1.1458333333333073 16
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 1.2499999999999716 30
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 1.2499999999999716 42
Completed Iteration #22
Best Reward: 0.1041666666666643
Completed Iteration #23
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b97ac8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97860> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934e48> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fd886934da0> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bded68> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b81400> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 1.2499999999999716 17
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 1.3541666666666359 31
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 1.3541666666666359 43
Completed Iteration #24
Best Reward: 0.1041666666666643
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #2
root->5->19
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b81710> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97f98> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b819b0> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 0.5208333333333215 6
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 1.3541666666666359 18
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 1.4583333333333002 32
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 1.4583333333333002 44
Completed Iteration #0
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 0.6249999999999858 7
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 1.4583333333333002 19
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 1.5624999999999645 33
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 1.5624999999999645 45
Completed Iteration #1
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c940> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 0.6249999999999858 8
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 1.4583333333333002 20
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 1.5624999999999645 34
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 1.5624999999999645 46
Completed Iteration #2
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3828> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 0.7291666666666501 9
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 1.5624999999999645 21
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 1.6666666666666288 35
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 1.6666666666666288 47
Completed Iteration #3
Best Reward: 0.1041666666666643
Completed Iteration #4
Best Reward: 0.1041666666666643
Completed Iteration #5
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868355f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b819b0> 0.2083333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 0.7291666666666501 10
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 1.5624999999999645 22
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 1.6666666666666288 36
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 1.6666666666666288 48
Completed Iteration #6
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885bdef60> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 0.8333333333333144 11
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 1.6666666666666288 23
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 1.770833333333293 37
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 1.770833333333293 49
Completed Iteration #7
Best Reward: 0.1041666666666643
coverage_call_count 1500
Completed Iteration #8
Best Reward: 0.1041666666666643
Completed Iteration #9
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bdef60> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 0.8333333333333144 12
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 1.6666666666666288 24
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 1.770833333333293 38
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 1.770833333333293 50
Completed Iteration #10
Best Reward: 0.1041666666666643
Completed Iteration #11
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b97518> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81d68> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 0.9374999999999787 13
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 1.770833333333293 25
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 1.8749999999999574 39
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 1.8749999999999574 51
Completed Iteration #12
Best Reward: 0.1041666666666643
Completed Iteration #13
Best Reward: 0.1041666666666643
Completed Iteration #14
Best Reward: 0.1041666666666643
Completed Iteration #15
Best Reward: 0.1041666666666643
Completed Iteration #16
Best Reward: 0.1041666666666643
Completed Iteration #17
Best Reward: 0.1041666666666643
Completed Iteration #18
Best Reward: 0.1041666666666643
Completed Iteration #19
Best Reward: 0.1041666666666643
Completed Iteration #20
Best Reward: 0.1041666666666643
Completed Iteration #21
Best Reward: 0.1041666666666643
Completed Iteration #22
Best Reward: 0.1041666666666643
Completed Iteration #23
Best Reward: 0.1041666666666643
Completed Iteration #24
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3a90> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81d68> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 1.041666666666643 14
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 1.8749999999999574 26
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 1.9791666666666217 40
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 1.9791666666666217 52
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #3
root->5->19->3
Best Reward: 0.1041666666666643
Completed Iteration #0
Best Reward: 0.1041666666666643
Completed Iteration #1
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe2b0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe0f0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 0.4166666666666572 5
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 1.1458333333333073 15
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 1.9791666666666217 27
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 2.083333333333286 41
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 2.083333333333286 53
Completed Iteration #2
Best Reward: 0.1041666666666643
Completed Iteration #3
Best Reward: 0.1041666666666643
Completed Iteration #4
Best Reward: 0.1041666666666643
Completed Iteration #5
Best Reward: 0.1041666666666643
Completed Iteration #6
Best Reward: 0.1041666666666643
Completed Iteration #7
Best Reward: 0.1041666666666643
Completed Iteration #8
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe630> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 0.5208333333333215 6
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 1.2499999999999716 16
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 2.083333333333286 28
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 2.1874999999999503 42
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 2.1874999999999503 54
Completed Iteration #9
Best Reward: 0.1041666666666643
Completed Iteration #10
Best Reward: 0.1041666666666643
Completed Iteration #11
Best Reward: 0.1041666666666643
Completed Iteration #12
Best Reward: 0.1041666666666643
Completed Iteration #13
Best Reward: 0.1041666666666643
Completed Iteration #14
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 0.6249999999999858 7
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 1.3541666666666359 17
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 2.1874999999999503 29
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 2.2916666666666146 43
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 2.2916666666666146 55
Completed Iteration #15
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97518> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b81d68> 0.2083333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 0.6249999999999858 8
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 1.3541666666666359 18
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 2.1874999999999503 30
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 2.2916666666666146 44
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 2.2916666666666146 56
Completed Iteration #16
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b4aba8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a908> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 0.7291666666666501 9
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 1.4583333333333002 19
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 2.2916666666666146 31
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 2.395833333333279 45
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 2.395833333333279 57
Completed Iteration #17
Best Reward: 0.1041666666666643
Completed Iteration #18
Best Reward: 0.1041666666666643
Completed Iteration #19
Best Reward: 0.1041666666666643
Completed Iteration #20
Best Reward: 0.1041666666666643
Completed Iteration #21
Best Reward: 0.1041666666666643
Completed Iteration #22
Best Reward: 0.1041666666666643
Completed Iteration #23
Best Reward: 0.1041666666666643
Completed Iteration #24
Best Reward: 0.1041666666666643
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #4
root->5->19->3->18
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885bde390> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 0.4166666666666572 5
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 0.8333333333333144 10
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 1.5624999999999645 20
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 2.395833333333279 32
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 2.499999999999943 46
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 2.499999999999943 58
Completed Iteration #0
Best Reward: 0.1041666666666643
Completed Iteration #1
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885bbeac8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 0.5208333333333215 6
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 0.9374999999999787 11
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 1.6666666666666288 21
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 2.499999999999943 33
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 2.6041666666666075 47
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 2.6041666666666075 59
Completed Iteration #2
Best Reward: 0.1041666666666643
Completed Iteration #3
Best Reward: 0.1041666666666643
Completed Iteration #4
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b814a8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3208> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbeac8> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 0.6249999999999858 7
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 1.041666666666643 12
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 1.770833333333293 22
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 2.6041666666666075 34
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 2.7083333333332718 48
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 2.7083333333332718 60
Completed Iteration #5
Best Reward: 0.1041666666666643
Completed Iteration #6
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a550> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a160> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 0.7291666666666501 8
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 1.1458333333333073 13
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 1.8749999999999574 23
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 2.7083333333332718 35
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 2.812499999999936 49
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 2.812499999999936 61
Completed Iteration #7
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b4add8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 0.8333333333333144 9
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 1.2499999999999716 14
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 1.9791666666666217 24
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 2.812499999999936 36
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 2.9166666666666003 50
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 2.9166666666666003 62
Completed Iteration #8
Best Reward: 0.1041666666666643
Completed Iteration #9
Best Reward: 0.1041666666666643
Completed Iteration #10
Best Reward: 0.1041666666666643
Completed Iteration #11
Best Reward: 0.1041666666666643
Completed Iteration #12
Best Reward: 0.1041666666666643
Completed Iteration #13
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bde6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 0.8333333333333144 10
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 1.2499999999999716 15
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 1.9791666666666217 25
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 2.812499999999936 37
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 2.9166666666666003 51
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 2.9166666666666003 63
Completed Iteration #14
Best Reward: 0.1041666666666643
Completed Iteration #15
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c208> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 0.9374999999999787 11
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 1.3541666666666359 16
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 2.083333333333286 26
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 2.9166666666666003 38
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 3.0208333333332646 52
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 3.0208333333332646 64
Completed Iteration #16
Best Reward: 0.1041666666666643
Completed Iteration #17
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 0.9374999999999787 12
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 1.3541666666666359 17
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 2.083333333333286 27
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 2.9166666666666003 39
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 3.0208333333332646 53
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 3.0208333333332646 65
Completed Iteration #18
Best Reward: 0.1041666666666643
Completed Iteration #19
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b65550> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 1.041666666666643 13
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 1.4583333333333002 18
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 2.1874999999999503 28
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 3.0208333333332646 40
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 3.124999999999929 54
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 3.124999999999929 66
Completed Iteration #20
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 1.041666666666643 14
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 1.4583333333333002 19
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 2.1874999999999503 29
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 3.0208333333332646 41
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 3.124999999999929 55
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 3.124999999999929 67
Completed Iteration #21
Best Reward: 0.1041666666666643
Completed Iteration #22
Best Reward: 0.1041666666666643
Completed Iteration #23
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b65320> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 1.1458333333333073 15
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 1.5624999999999645 20
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 2.2916666666666146 30
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 3.124999999999929 42
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 3.2291666666665932 56
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 3.2291666666665932 68
Completed Iteration #24
Best Reward: 0.1041666666666643
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #5
root->5->19->3->18->1
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe9e8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a160> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 0.4166666666666572 5
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 1.2499999999999716 16
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 1.6666666666666288 21
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 2.395833333333279 31
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 3.2291666666665932 43
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 3.3333333333332575 57
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 3.3333333333332575 69
Completed Iteration #0
Best Reward: 0.1041666666666643
Completed Iteration #1
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bde940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 0.4166666666666572 6
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 1.2499999999999716 17
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 1.6666666666666288 22
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 2.395833333333279 32
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 3.2291666666665932 44
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 3.3333333333332575 58
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 3.3333333333332575 70
Completed Iteration #2
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 0.4166666666666572 7
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 1.2499999999999716 18
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 1.6666666666666288 23
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 2.395833333333279 33
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 3.2291666666665932 45
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 3.3333333333332575 59
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 3.3333333333332575 71
Completed Iteration #3
Best Reward: 0.1041666666666643
Completed Iteration #4
Best Reward: 0.1041666666666643
Completed Iteration #5
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 0.4166666666666572 8
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 1.2499999999999716 19
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 1.6666666666666288 24
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 2.395833333333279 34
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 3.2291666666665932 46
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 3.3333333333332575 60
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 3.3333333333332575 72
Completed Iteration #6
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 0.4166666666666572 9
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 1.2499999999999716 20
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 1.6666666666666288 25
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 2.395833333333279 35
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 3.2291666666665932 47
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 3.3333333333332575 61
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 3.3333333333332575 73
Completed Iteration #7
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b656d8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe978> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 0.5208333333333215 10
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 1.3541666666666359 21
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 1.770833333333293 26
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 2.499999999999943 36
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 3.3333333333332575 48
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 3.437499999999922 62
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 3.437499999999922 74
Completed Iteration #8
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b65128> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3f98> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 0.6249999999999858 11
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 1.4583333333333002 22
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 1.8749999999999574 27
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 2.6041666666666075 37
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 3.437499999999922 49
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 3.541666666666586 63
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 3.541666666666586 75
Completed Iteration #9
Best Reward: 0.1041666666666643
Completed Iteration #10
Best Reward: 0.1041666666666643
Completed Iteration #11
Best Reward: 0.1041666666666643
Completed Iteration #12
Best Reward: 0.1041666666666643
Completed Iteration #13
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 0.6249999999999858 12
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 1.4583333333333002 23
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 1.8749999999999574 28
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 2.6041666666666075 38
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 3.437499999999922 50
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 3.541666666666586 64
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 3.541666666666586 76
Completed Iteration #14
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b00780> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe978> 0.2083333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 0.7291666666666501 13
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 1.5624999999999645 24
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 1.9791666666666217 29
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 2.7083333333332718 39
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 3.541666666666586 51
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 3.6458333333332504 65
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 3.6458333333332504 77
Completed Iteration #15
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 0.7291666666666501 14
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 1.5624999999999645 25
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 1.9791666666666217 30
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 2.7083333333332718 40
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 3.541666666666586 52
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 3.6458333333332504 66
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 3.6458333333332504 78
Completed Iteration #16
Best Reward: 0.1041666666666643
Completed Iteration #17
Best Reward: 0.1041666666666643
Completed Iteration #18
Best Reward: 0.1041666666666643
Completed Iteration #19
Best Reward: 0.1041666666666643
Completed Iteration #20
Best Reward: 0.1041666666666643
Completed Iteration #21
Best Reward: 0.1041666666666643
Completed Iteration #22
Best Reward: 0.1041666666666643
Completed Iteration #23
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b65080> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe978> 0.3124999999999929 5
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 0.8333333333333144 15
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 1.6666666666666288 26
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 2.083333333333286 31
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 2.812499999999936 41
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 3.6458333333332504 53
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 3.7499999999999147 67
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 3.7499999999999147 79
Completed Iteration #24
Best Reward: 0.1041666666666643
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #6
root->5->19->3->18->1->4
Best Reward: 0.1041666666666643
Completed Iteration #0
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b5ce10> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a160> 0.3124999999999929 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 0.9374999999999787 16
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 1.770833333333293 27
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 2.1874999999999503 32
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 2.9166666666666003 42
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 3.7499999999999147 54
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 3.854166666666579 68
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 3.854166666666579 80
Completed Iteration #1
Best Reward: 0.1041666666666643
Completed Iteration #2
Best Reward: 0.1041666666666643
Completed Iteration #3
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885ba38d0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a160> 0.4166666666666572 5
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 1.041666666666643 17
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 1.8749999999999574 28
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 2.2916666666666146 33
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 3.0208333333332646 43
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 3.854166666666579 55
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 3.9583333333332433 69
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 3.9583333333332433 81
Completed Iteration #4
Best Reward: 0.1041666666666643
Completed Iteration #5
Best Reward: 0.1041666666666643
Completed Iteration #6
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d2b0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a160> 0.5208333333333215 6
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 1.1458333333333073 18
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 1.9791666666666217 29
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 2.395833333333279 34
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 3.124999999999929 44
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 3.9583333333332433 56
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 4.062499999999908 70
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 4.062499999999908 82
Completed Iteration #7
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d668> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a160> 0.6249999999999858 7
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 1.2499999999999716 19
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 2.083333333333286 30
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 2.499999999999943 35
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 3.2291666666665932 45
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 4.062499999999908 57
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 4.166666666666572 71
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 4.166666666666572 83
Completed Iteration #8
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b0da90> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a160> 0.7291666666666501 8
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 1.3541666666666359 20
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 2.1874999999999503 31
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 2.6041666666666075 36
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 3.3333333333332575 46
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 4.166666666666572 58
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 4.270833333333236 72
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 4.270833333333236 84
Completed Iteration #9
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba38d0> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a160> 0.7291666666666501 9
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 1.3541666666666359 21
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 2.1874999999999503 32
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 2.6041666666666075 37
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 3.3333333333332575 47
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 4.166666666666572 59
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 4.270833333333236 73
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 4.270833333333236 85
Completed Iteration #10
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a748> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a160> 0.8333333333333144 10
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 1.4583333333333002 22
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 2.2916666666666146 33
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 2.7083333333332718 38
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 3.437499999999922 48
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 4.270833333333236 60
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 4.3749999999999005 74
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 4.3749999999999005 86
Completed Iteration #11
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d668> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a160> 0.8333333333333144 11
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 1.4583333333333002 23
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 2.2916666666666146 34
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 2.7083333333332718 39
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 3.437499999999922 49
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 4.270833333333236 61
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 4.3749999999999005 75
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 4.3749999999999005 87
Completed Iteration #12
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c748> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a160> 0.9374999999999787 12
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 1.5624999999999645 24
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 2.395833333333279 35
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 2.812499999999936 40
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 3.541666666666586 50
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 4.3749999999999005 62
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 4.479166666666565 76
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 4.479166666666565 88
Completed Iteration #13
Best Reward: 0.1041666666666643
coverage_call_count 1600
Completed Iteration #14
Best Reward: 0.1041666666666643
Completed Iteration #15
Best Reward: 0.1041666666666643
Completed Iteration #16
Best Reward: 0.1041666666666643
Completed Iteration #17
Best Reward: 0.1041666666666643
Completed Iteration #18
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dfd0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a160> 1.041666666666643 13
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 1.6666666666666288 25
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 2.499999999999943 36
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 2.9166666666666003 41
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 3.6458333333332504 51
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 4.479166666666565 63
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 4.583333333333229 77
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 4.583333333333229 89
Completed Iteration #19
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a5f8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a160> 1.1458333333333073 14
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 1.770833333333293 26
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 2.6041666666666075 37
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 3.0208333333332646 42
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 3.7499999999999147 52
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 4.583333333333229 64
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 4.687499999999893 78
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 4.687499999999893 90
Completed Iteration #20
Best Reward: 0.1041666666666643
Completed Iteration #21
Best Reward: 0.1041666666666643
Completed Iteration #22
Best Reward: 0.1041666666666643
Completed Iteration #23
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c6a0> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a160> 1.2499999999999716 15
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 1.8749999999999574 27
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 2.7083333333332718 38
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 3.124999999999929 43
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 3.854166666666579 53
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 4.687499999999893 65
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 4.791666666666558 79
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 4.791666666666558 91
Completed Iteration #24
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c908> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c390> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a550> 0.2083333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a160> 1.3541666666666359 16
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 1.9791666666666217 28
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 2.812499999999936 39
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 3.2291666666665932 44
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 3.9583333333332433 54
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 4.791666666666558 66
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 4.895833333333222 80
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 4.895833333333222 92
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #7
root->5->19->3->18->1->4->0
Best Reward: 0.1041666666666643
Completed Iteration #0
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c390> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a550> 0.2083333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a160> 1.3541666666666359 17
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 1.9791666666666217 29
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 2.812499999999936 40
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 3.2291666666665932 45
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 3.9583333333332433 55
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 4.791666666666558 67
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 4.895833333333222 81
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 4.895833333333222 93
Completed Iteration #1
Best Reward: 0.1041666666666643
Completed Iteration #2
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c390> 0.1041666666666643 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a550> 0.2083333333333286 5
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a160> 1.3541666666666359 18
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 1.9791666666666217 30
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 2.812499999999936 41
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 3.2291666666665932 46
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 3.9583333333332433 56
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 4.791666666666558 68
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 4.895833333333222 82
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 4.895833333333222 94
Completed Iteration #3
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd885b2ccf8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b006d8> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a550> 0.3124999999999929 6
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a160> 1.4583333333333002 19
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 2.083333333333286 31
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 2.9166666666666003 42
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 3.3333333333332575 47
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 4.062499999999908 57
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 4.895833333333222 69
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 4.999999999999886 83
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 4.999999999999886 95
Completed Iteration #4
Best Reward: 0.1041666666666643
Completed Iteration #5
Best Reward: 0.1041666666666643
Completed Iteration #6
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b006d8> 0.1041666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a550> 0.3124999999999929 7
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a160> 1.4583333333333002 20
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 2.083333333333286 32
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 2.9166666666666003 43
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 3.3333333333332575 48
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 4.062499999999908 58
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 4.895833333333222 70
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 4.999999999999886 84
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 4.999999999999886 96
Completed Iteration #7
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b006d8> 0.1041666666666643 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a550> 0.3124999999999929 8
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a160> 1.4583333333333002 21
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 2.083333333333286 33
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 2.9166666666666003 44
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 3.3333333333332575 49
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 4.062499999999908 59
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 4.895833333333222 71
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 4.999999999999886 85
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 4.999999999999886 97
Completed Iteration #8
Best Reward: 0.1041666666666643
Completed Iteration #9
Best Reward: 0.1041666666666643
Completed Iteration #10
Best Reward: 0.1041666666666643
Completed Iteration #11
Best Reward: 0.1041666666666643
Completed Iteration #12
Best Reward: 0.1041666666666643
Completed Iteration #13
Best Reward: 0.1041666666666643
Completed Iteration #14
Best Reward: 0.1041666666666643
Completed Iteration #15
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c390> 0.1041666666666643 5
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a550> 0.3124999999999929 9
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a160> 1.4583333333333002 22
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 2.083333333333286 34
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 2.9166666666666003 45
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 3.3333333333332575 50
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 4.062499999999908 60
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 4.895833333333222 72
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 4.999999999999886 86
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 4.999999999999886 98
Completed Iteration #16
Best Reward: 0.1041666666666643
Completed Iteration #17
Best Reward: 0.1041666666666643
Completed Iteration #18
Best Reward: 0.1041666666666643
Completed Iteration #19
Best Reward: 0.1041666666666643
Completed Iteration #20
Best Reward: 0.1041666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bdee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b006d8> 0.1041666666666643 5
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a550> 0.3124999999999929 10
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a160> 1.4583333333333002 23
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 2.083333333333286 35
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 2.9166666666666003 46
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 3.3333333333332575 51
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 4.062499999999908 61
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 4.895833333333222 73
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 4.999999999999886 87
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 4.999999999999886 99
Completed Iteration #21
Best Reward: 0.1041666666666643
Completed Iteration #22
Best Reward: 0.1041666666666643
Completed Iteration #23
Best Reward: 0.1041666666666643
Reward: 0.1041666666666643
backprop <src.mcts.MCTS_Node object at 0x7fd886847f98> 0.1041666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b006d8> 0.2083333333333286 6
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a550> 0.4166666666666572 11
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a160> 1.5624999999999645 24
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a390> 2.1874999999999503 36
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36d8> 3.0208333333332646 47
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3160> 3.437499999999922 52
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4cc0> 4.166666666666572 62
backprop <src.mcts.MCTS_Node object at 0x7fd886934908> 4.999999999999886 74
backprop <src.mcts.MCTS_Node object at 0x7fd886847e48> 5.104166666666551 88
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 5.104166666666551 100
Completed Iteration #24
Best Reward: 0.1041666666666643
Completed Iteration #25
Best Reward: 0.1041666666666643
Completed MCTS Level/Depth: #8
root->5->19->3->18->1->4->0->16
Best Reward: 0.1041666666666643
iteration: 33
found coverage increase 0.1041666666666643
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d630> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88686d630> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88686d630> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d630> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88686d630> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869008d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d630> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88686d630> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88686d630> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d630> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d630> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88686d630> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d630> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88686d630> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bdef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886835f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886835f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835f60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835f60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886835f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835f60> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886835f60> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835f60> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886835f60> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886835f60> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886835f60> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886835f60> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835f60> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886835f60> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886835f60> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886835f60> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd886835f60> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868911d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868916d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891940> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886891940> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891940> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891940> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886891940> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886891940> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869345c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891940> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886891940> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869345c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886891940> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886891940> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891940> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bde128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a49e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886891940> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886891d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd886891940> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886891940> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886891940> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886891940> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868916d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698dac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88698de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698dac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88698d898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d898> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869005c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88687f128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687fdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88687f128> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f128> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bdef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f128> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f128> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f128> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869005c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88687f128> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687fdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88687f128> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88687f128> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88687f128> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f128> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f128> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687fdd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd88687f128> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88687f128> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bdef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88687f128> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869819b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c4e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88685c4e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869811d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c4e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869814a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c4e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c4e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88685c4e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c4e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c4e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869815f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c4e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88685c4e0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886978550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869815f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88685c4e0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88685c4e0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869654a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c4e0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886978208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88685c4e0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886978710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88685c4e0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886978b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88685c4e0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886978278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88685c4e0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869784e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd88685c4e0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981550> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd88685c4e0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88685c4e0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886978240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869787f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886978588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981f28> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886981f28> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981f28> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 1800
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886981f28> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981f28> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981f28> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981f28> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886981f28> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886995710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886981f28> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd886981f28> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886981f28> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869814a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886981f28> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869654a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869814e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869814e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869814e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886978710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869814e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886978cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869814e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868356d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869814e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869814e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869814e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869814e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869814e0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869814e0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869814e0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869814e0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869814e0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869814e0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869814e0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869814e0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869814e0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886900fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886995550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886900fd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886995ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900fd0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900fd0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886900fd0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886995390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886900fd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886995198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd886900fd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900fd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886934fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd886900fd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886900fd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886995ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886900fd0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900fd0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900fd0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900fd0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c0672e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886900fd0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c067ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687fdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886900fd0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c067e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c067198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c067e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c067048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c043d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c067e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c0433c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067e80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c067e80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067e80> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c067f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c067e80> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88c067e80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886978470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c067e80> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c0671d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067e80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c043fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c0678d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067e80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c043908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd88c067e80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c043198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c0678d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c067e80> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c067e80> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88c067e80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043940> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c043940> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043940> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c043940> 0.0 9
Completed Iteration #7
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c043940> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043940> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043940> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88c043940> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c043940> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c043940> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c043898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043940> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c043908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c043940> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c043c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c043940> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c043940> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c043940> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c043668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c043940> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c043940> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bf60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd88c043940> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c043ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c043e10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043e10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043e10> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c043e10> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886995c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043e10> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043e10> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c043e10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c0434a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c043e10> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c067908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c043e10> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c0671d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c043e10> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c067e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043e10> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c043e10> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c043e10> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886995940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c043e10> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c0674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88c043e10> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868356d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886978518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c0675f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869780f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868915c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869780f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c067f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068240> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068240> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068240> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068240> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068240> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068240> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068240> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068240> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068240> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068240> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00813c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068240> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068240> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068240> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068240> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068240> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068240> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068240> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db38> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db38> 0.0 7
Completed Iteration #5
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db38> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db38> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41997f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db38> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db38> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414da90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db38> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db38> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db38> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db38> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db38> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db38> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414da90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db38> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886978470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db38> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db38> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414da90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db38> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869652b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db38> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178be0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db38> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db38> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbcf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8a414db38> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868915c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868356d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c400> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88685c400> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869654a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88685c400> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c0434a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c400> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c067908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c400> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868356d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88685c400> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88685c400> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868356d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88685c400> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abf98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88685c400> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886995b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868356d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88685c400> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88685c400> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886995ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88685c400> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88685c400> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c067400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88685c400> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88685c400> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4cc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4cc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c043ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4cc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00819e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4cc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00224a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00819e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4cc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00225c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4cc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00225c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4cc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41783c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00819e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4cc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00819e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4cc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4cc0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00225c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4cc0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4cc0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00351d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4cc0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00819e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4cc0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0084be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac048> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac048> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c043710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac048> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac048> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac048> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac048> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00229e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac048> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00354a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac048> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac048> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acac8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac048> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac048> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac048> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41997b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01aceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a58> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00047f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a58> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a58> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00354a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00047f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a58> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a58> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a58> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a58> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00047f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a58> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a58> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a58> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a58> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a58> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022be0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022be0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022be0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022be0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41783c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022be0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022be0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022be0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886995ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022be0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022be0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022be0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c067da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022be0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022be0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022be0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022be0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022be0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022be0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022be0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022be0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01babe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c0672e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01239e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c50> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01662e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c50> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01665c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c50> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01664e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c50> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c50> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01239e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c50> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01700b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c50> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c50> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01665c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c50> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c50> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c50> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c50> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c50> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01669e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01babe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c50> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01239e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c50> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c50> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01705c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01705c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01705c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01100b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01705c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01105f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01705c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01705c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01705c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01705c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01705c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01705c0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01705c0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01705c0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01705c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01374e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01705c0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c01705c0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c01705c0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01705c0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 2200
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01705c0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01103c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bad30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bad30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bad30> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bad30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886995d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bad30> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bad30> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04ba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bad30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bad30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bad30> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bad30> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bad30> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04ba90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bad30> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bad30> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bad30> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bad30> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869654a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bad30> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00125c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00122b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c043ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f60> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f60> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f60> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f60> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00124a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f60> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f60> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f60> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f60> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f60> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f60> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01014e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f60> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110ac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f60> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00120f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0710> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0710> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0710> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0710> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0710> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0710> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0710> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0710> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0710> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0710> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0710> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0710> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd921ab34a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd921ab34a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd921ab34a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e31d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd921ab34a8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41754a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd921ab34a8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd921ab34a8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd921ab34a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd921ab34a8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd921ab34a8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd921ab34a8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f77b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd921ab34a8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e31d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd921ab34a8> 0.0 13
Completed Iteration #20
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd921ab34a8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd921ab34a8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd91f7d0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd921ab34a8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd921ab34a8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3208> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3208> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3208> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3208> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3208> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3208> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3208> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b88d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3208> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3208> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3208> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a09e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3208> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a09e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3208> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41783c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3208> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3208> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3208> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b38> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b38> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b38> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b38> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00a6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b38> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b38> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b38> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01706d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b38> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b38> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b38> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00121d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b38> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b38> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b38> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41754e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41754e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41754e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41754e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41754e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41754e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41754e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41754e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a41754e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41754e0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bfa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41754e0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bfa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a41754e0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41754e0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41036a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41754e0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a41754e0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c4a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c4a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c4a8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c4a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c4a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c4a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c4a8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c4a8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c4a8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c4a8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c4a8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c4a8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c4a8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c4a8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c4a8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c4a8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170cf8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01706d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170cf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00a6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170cf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170cf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886995b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170cf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00122b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00120f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170cf8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01014a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bfe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170cf8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170cf8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170cf8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170cf8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170cf8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bfe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170cf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bfcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170cf8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b38> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b38> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b38> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b38> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00229e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b38> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a07b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b38> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b38> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a07b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b38> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b38> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f75c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b38> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b38> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b38> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b38> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b38> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b38> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b38> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c2b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b975f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c2b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c2b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c2b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b816a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c2b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c2b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c2b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c2b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c2b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b975f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c2b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c2b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c2b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c2b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b816a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c2b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c2b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c2b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00f98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c2b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c2b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c2b0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00120f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00359e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7cc0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7cc0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7cc0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00a6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7cc0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7cc0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7cc0> 0.0 10
Completed Iteration #15
Best Reward: 0
coverage_call_count 2500
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7cc0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7cc0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00120f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7cc0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7cc0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b001d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7cc0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7cc0> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b810b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cc18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cc18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cc18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cc18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cc18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cc18> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cc18> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cc18> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885437400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cc18> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cc18> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885437128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cc18> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8854379e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cc18> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012e10> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012e10> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012e10> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012e10> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8854379b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012e10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885437a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012e10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885437940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012e10> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885437f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41783c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012e10> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885437d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41783c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012e10> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012e10> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012e10> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012e10> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012e10> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012e10> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012e10> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012e10> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012e10> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012e10> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012e10> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405aa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012e10> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c198> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c198> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88406c198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88406c198> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88406c198> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88406c198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88406c198> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c198> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c198> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8854374a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c198> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8854374a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88406c198> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885437c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88406c198> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885437f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88406c198> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8854377f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88406c198> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88406c198> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88406c198> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88406c198> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885437cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437780> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885437780> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885437780> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885437780> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885437780> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885437780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437780> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437780> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885437780> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac87f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885437780> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885437780> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885437780> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd885437780> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd885437780> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00359e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cc0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cc0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88406c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cc0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cc0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cc0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00359e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cc0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cc0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8840380b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cc0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840381d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8840387f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840387b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840381d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840389e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840381d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840381d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840381d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840381d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840381d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8840381d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840431d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840381d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8840381d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840434e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840381d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8840439e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840387b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8840381d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8840381d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840387b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8840381d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8840381d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8840381d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8840381d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840389e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8840381d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8840381d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8840381d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00a6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8744850b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038780> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8744857f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884038780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038780> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884038780> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744852e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884038780> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8840381d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884038780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8840385c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038780> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884038780> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd884038780> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8840387f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744852e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd884038780> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd884038780> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884038780> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884038780> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd884038780> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a198> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a198> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88405a198> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88405a198> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a198> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88405a198> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840387b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a198> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88405a198> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407eda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88405a198> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88405a198> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407eda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88405a198> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885437d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a198> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88405a198> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407ebe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88405a198> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840387b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88405a198> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a198> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043b70> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043b70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043b70> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac84a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884043b70> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043b70> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043b70> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac80b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884043b70> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8744415c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac80b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd884043b70> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884043b70> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043b70> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884043b70> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043b70> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac84a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd884043b70> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884043b70> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884043b70> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd884043b70> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd884043b70> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd884043b70> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444d438> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444d438> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87444d438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444d438> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8744412e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444d438> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444d438> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87444d438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87444d438> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87444d438> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd87444d438> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444d438> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8840434e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744411d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87444d438> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8744413c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87444d438> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87444d438> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd87444d438> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444d438> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c240> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd87444d438> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444df98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87444d438> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444df98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd87444d438> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b278> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b278> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b278> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87446b278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87446b278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87446b278> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446ba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87446b278> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b278> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b278> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87446b278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87446b278> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87446b278> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87446b278> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd87446b278> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87446b2e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b2e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 2800
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b2e8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b2e8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b2e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd921ab34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87446b2e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87446b2e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87446b2e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87446b2e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87446b2e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd87446b2e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87446b2e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444db00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87446b2e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444db00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd87446b2e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01665c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b2e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cb9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87446b2e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01664e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cb9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87446b2e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446bf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87446b2e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01370f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba550> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba550> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01105f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba550> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01100b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba550> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba550> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba550> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba550> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba550> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01105f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba550> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba550> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01105f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba550> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba550> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba550> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba550> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba550> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba550> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba550> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba550> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac7f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac7f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac7f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac7f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac7f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac7f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac7f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac7f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41994a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac7f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41994a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac7f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac7f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac7f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac7f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac7f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41994a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac7f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415aba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac7f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac7f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac7f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022d30> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022d30> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00818d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022d30> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00818d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022d30> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022d30> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022d30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022d30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022d30> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022d30> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022d30> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00229e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022d30> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022d30> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022d30> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acdd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022d30> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022d30> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00818d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022d30> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00818d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022d30> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022d30> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbef0> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd921ab34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00a6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd921ab34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd921ab34a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbef0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbef0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbef0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01accc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bacc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbef0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbef0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbef0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01662b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbef0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199908> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199908> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199908> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199908> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0114390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199908> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199908> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199908> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199908> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199908> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199908> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199908> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03db00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199908> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199908> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03db00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199908> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199908> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ae80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ae80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ae80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ae80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ae80> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ae80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd91f7d0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ae80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ae80> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ae80> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ae80> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ae80> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ae80> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ae80> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ae80> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4afd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ae80> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ae80> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ae80> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dd30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dd30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dd30> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dd30> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dd30> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dd30> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dd30> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dd30> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dd30> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dd30> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dd30> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dd30> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dd30> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dd30> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dd30> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dd30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 26.041666666666668
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbef98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbef98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01accc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbef98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01accc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bbef98> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbef98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbef98> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbef98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01100f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbef98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bbef98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbef98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885bbef98> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bbef98> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbedd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bbef98> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbeda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd885bbef98> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01accc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885bbef98> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbef98> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41780f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01accc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd885bbef98> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c4a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd885bbef98> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbedd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885bbef98> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e74a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869659b0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b97ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97ba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97ba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b97ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97ba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b97ba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97ba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97ba8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b97ba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba36a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b97ba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd885b97ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b97ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b97ba8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba39b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b97ba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd885b97ba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe1d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe1d0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbeeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe1d0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe1d0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe1d0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe1d0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe1d0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe1d0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe1d0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe1d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe1d0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178588> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe1d0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178588> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe1d0> 0.0 16
Completed Iteration #23
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbeeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe1d0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe1d0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dc18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dc18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dc18> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dc18> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dc18> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e01143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dc18> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dc18> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e01143c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dc18> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e01143c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dc18> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dc18> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e01143c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dc18> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dc18> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b2b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b2b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b2b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b2b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b2b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b2b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b2b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b2b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868a47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b2b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0da90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b2b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b2b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b2b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b2b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b2b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b2b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869347f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c067a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869347f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c067cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869347f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886995f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869347f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886995f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869347f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869347f0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869347f0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868918d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869347f0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869347f0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869347f0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869347b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c0675f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869347f0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869347f0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869347f0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8869347f0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869347f0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8869347f0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869347f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444db00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444db00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87444db00> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87444db00> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444db00> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87444db00> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444db00> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444db00> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444db00> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444db00> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87444db00> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87444db00> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87444db00> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87444db00> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444db00> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686de10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd87444db00> 0.0 17
Completed Iteration #22
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87444db00> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5cb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87444db00> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87444db00> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41995c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869955f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869812b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bef0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bef0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869815f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bef0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bef0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869811d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bef0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bef0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bef0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bef0> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bef0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886995278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bef0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bef0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bef0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bef0> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bde6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bef0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bded68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bdec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bdeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bde518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bdeac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bde438> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde438> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886978f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde438> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886978c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde438> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde438> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde438> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869789b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bde438> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bde438> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde438> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885bde438> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885bde438> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd885bde438> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bde438> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bdee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bdeac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885bde438> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde438> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f2b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f2b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88687f2b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f2b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f2b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88687f2b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f2b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88687f2b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88687f2b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869782b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88687f2b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869782e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f2b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bdea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88687f2b0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869787f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88687f2b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bded68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88687f2b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bde048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88687f2b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bde160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88687f2b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88687f2b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869812b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bde588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869780b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965208> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886965208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886965208> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886965208> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd886965208> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c067278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965208> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886965208> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886965208> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd886965208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685ca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886965208> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bde400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981780> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd886965208> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 3300
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869955f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965208> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886965208> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb860> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb860> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886978160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb860> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb860> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb860> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb860> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868478d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb860> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb860> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb860> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb860> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868352b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb748> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb860> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb860> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb860> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb860> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868351d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868351d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886835898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868351d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886835898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744851d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886835898> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835898> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744854a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886835898> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744854e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835898> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835898> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868351d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd886835898> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835898> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744851d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886835898> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744854e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886835898> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886835898> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8744856a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835898> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886835898> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868351d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd886835898> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744851d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886835898> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886835898> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744854e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886835898> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb208> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb208> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb208> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb208> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb208> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb208> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb208> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb208> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb208> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886978f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb208> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb208> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb208> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb208> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb208> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb208> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb208> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb208> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bde7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb208> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb208> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8a58> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bdecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8a58> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8744411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8a58> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8a58> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8a58> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886995fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8a58> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8a58> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8a58> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8a58> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8a58> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8a58> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8a58> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8a58> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8744416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bdecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8a58> 0.0 15
Completed Iteration #17
Best Reward: 0
coverage_call_count 3400
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8a58> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8a58> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8a58> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac82b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8a58> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8a58> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8854378d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8a58> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41754e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8744419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885437da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744415c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744415c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885437e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885437e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437e48> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744415c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885437e48> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01234e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437e48> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01234e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885437e48> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b818d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437e48> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8854379e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437e48> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01234e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885437e48> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b816a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885437e48> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744415c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd885437e48> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885437e48> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869955f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437e48> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885437e48> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885437d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b000b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b009e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b003c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b009e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759b0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759b0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175630> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175630> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8744417f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175630> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886978f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175630> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175630> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175630> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175630> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885437cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175630> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b006d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175630> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175630> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175630> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175630> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175630> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885437630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175630> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175630> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175630> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bde4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb198> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb198> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb198> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb198> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb198> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb198> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb198> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb198> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb198> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00046a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb198> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00359e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb198> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb198> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8854379e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb198> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb198> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685cc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb198> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb198> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00122b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012550> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012550> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012550> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012550> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012550> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8744416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012550> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012550> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00124a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012550> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012550> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012550> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012550> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012550> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012550> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012550> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012550> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012550> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012550> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012550> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012550> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012550> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8400> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c043518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c0434a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8400> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c0439e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8400> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8400> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8400> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8400> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8400> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c0439e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8400> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c0439e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8400> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8400> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8400> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8400> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8400> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c0439e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8400> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8400> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e85f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e85f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e85f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e85f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e85f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886995ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e85f8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bde748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e85f8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e85f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e85f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e85f8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e85f8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e89e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e85f8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00046a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e85f8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e85f8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e85f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885437ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e85f8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e85f8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e85f8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e85f8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e85f8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e85f8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8780> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41757f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8780> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8780> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8780> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8780> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8780> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8780> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8780> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c043438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8780> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407ee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8780> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8780> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407ee10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8780> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8780> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8780> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407ea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8780> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01705c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b278> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b278> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b278> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840433c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b278> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00359e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b278> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b278> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8840431d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b278> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8840437f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b278> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b278> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b278> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b278> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b278> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b278> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b278> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b278> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b278> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01016a0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01016a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01016a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01016a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01016a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01016a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8840435c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01016a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01016a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01016a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88406c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01016a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01016a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c01016a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01016a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01016a0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c043278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01016a0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8854379b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01016a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c01016a0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885437470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d46a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01016a0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8744419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8c01016a0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e828> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e828> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e828> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c0433c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e828> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e828> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41039e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e828> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88407e828> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88407e828> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c067748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88407e828> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bdea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88407e828> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88407e828> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e828> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e828> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c0433c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88407e828> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c860> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c860> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88406c860> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c860> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c860> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 3700
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c860> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c860> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41757b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88406c860> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c860> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88406c860> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88406c860> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8840381d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41757b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88406c860> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88406c860> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88406c860> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88406c860> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88406c860> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88406c860> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88406c860> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88406c860> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a400> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87447a400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87447a400> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0976d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0976a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a400> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87447a400> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a400> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87447a908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87447a400> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00124a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0976a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87447a400> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a400> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0976a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87447a400> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8840387b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447ad68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87447a400> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87447a400> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a400> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd87447a400> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bdea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c043278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885437470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c043e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886978160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0b8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0b8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0975c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41039e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0975c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406ccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0b8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0b8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405ac88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0b8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8744411d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0b8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c097f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097f60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c097f60> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097f60> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0585f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c097f60> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c097f60> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097f60> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04ceb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c097f60> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0585c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c097f60> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c097f60> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04ca58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c097f60> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c097f60> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04ca58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd86c097f60> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c097f60> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c097f60> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0580b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0588d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058b38> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c058b38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c058b38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c058b38> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0588d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c058b38> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0585c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c058b38> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0023c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058b38> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058b38> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0588d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c058b38> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0586a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0588d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd86c058b38> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0023c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c058b38> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c058b38> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c0588d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd86c058b38> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41750f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41750f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41750f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41750f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a41750f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41750f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41750f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41750f0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41750f0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01016a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41750f0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41750f0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41750f0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04cc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a41750f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8744411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41750f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41750f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04cc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8a41750f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8a41750f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a41750f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a438> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a438> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0022e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a438> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88405a438> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0025c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88405a438> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a438> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c002ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a438> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a438> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88405a438> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0020f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c002ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88405a438> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2cba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88405a438> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88405a438> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2cba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88405a438> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88405a438> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0368d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88405a438> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0027b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88405a438> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0022e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88405a438> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0362e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036128> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c067748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c036128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c036128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036128> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c036128> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c036128> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd86c036128> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c036128> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd86c036128> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0979e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c002780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036128> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036128> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c036128> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c002780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c036128> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ceb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ceac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036128> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c036128> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ceef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ceeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036128> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036128> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ceac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c036128> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c036128> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0320> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0320> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0320> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0320> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0320> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0320> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0320> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0320> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0320> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0320> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0320> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e06d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0320> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886978160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c036898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036898> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c043278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c036898> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c036898> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036898> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036898> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8744411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c036898> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c036898> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c036898> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c036898> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8854379b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c036898> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c036898> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405ac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c036898> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405ac18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd86c036898> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c036898> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd86c036898> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0eb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9917f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0eb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e02e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0eb8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0eb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0eb8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0eb8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0eb8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0eb8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0eb8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e02e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0eb8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6390> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6390> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6390> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6390> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6390> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6390> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6390> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6390> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6390> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6390> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9485c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6390> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b30f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b30f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9912e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b30f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b30f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b30f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b30f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b30f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b30f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b30f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8840389e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b30f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b30f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b30f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b30f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b30f0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b30f0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b30f0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c0435f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e08d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b30f0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b30f0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b30f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0364e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0278> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0278> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0278> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0278> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0278> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f948780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0278> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f948240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0278> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9489b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0278> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ceeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0278> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f948b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0278> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0278> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f948390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0360f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0278> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405ac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0278> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0278> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405ac18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0278> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0278> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f948550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991128> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f991128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f991128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f991128> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f991128> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f991128> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991128> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f991128> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9039e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f991128> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f991128> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f991128> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991128> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f991128> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f991128> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a240> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a240> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a240> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9281d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a240> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a240> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f928198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a240> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a240> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a240> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a240> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a240> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a240> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9039b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a240> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a240> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a240> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a240> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a240> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9031d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a240> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9030b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a240> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8744411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a240> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a240> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f948e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f948be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f948048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ceeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0368d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0363c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96ffd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96ffd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96ffd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96ffd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41750f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96ffd0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8840389e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96ffd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f948b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96ffd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96ffd0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9910b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f96ffd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9286a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f96ffd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f96ffd0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9285c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f96ffd0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0364a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f96ffd0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9286a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f96ffd0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0364a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f96ffd0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f96ffd0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0364a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f96ffd0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e04a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8edb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e04a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8edda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8edc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8edf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0a20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ede10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889128> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f889128> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8894e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f889128> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e07f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f889128> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889128> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889128> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e07f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f889128> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889128> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8894e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f889128> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889128> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f889128> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8890b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f889128> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8edbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f889128> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8edb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e07f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83f889128> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8895f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889128> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00046a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed3c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed3c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed3c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed3c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed3c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed3c8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed3c8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed3c8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed3c8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed3c8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00046a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed3c8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00046a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed3c8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed3c8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed3c8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed3c8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed3c8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed3c8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed3c8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869813c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed3c8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41781d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869814a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869814a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869814a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00359e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869814a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01705c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869814a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869814a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869814a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869814a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00359e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869814a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41781d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886981a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869814a8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869814a8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00359e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869814a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00359e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8869814a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869814a8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869814a8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869814a8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869814a8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886981a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869814a8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bfcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869814a8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869814a8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8869814a8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869814a8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406ca90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406ca90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406ca90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8edcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406ca90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406ca90> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88406ca90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88406ca90> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406ca90> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406ca90> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88406ca90> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 4300
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88406ca90> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406ca90> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8840434a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88406ca90> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88406ca90> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406ca90> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88406ca90> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c898> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8744418d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c898> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c898> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8744417b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c898> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c898> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c898> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c898> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c898> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c898> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c898> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c898> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8744411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c898> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c898> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c898> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c898> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b7f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b7f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b7f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b7f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b7f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8840436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b7f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bfcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b7f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b7f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bfcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b7f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00046a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b7f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8840435c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b7f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b7f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b7f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b7f0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b7f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869815f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869818d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885437c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869818d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41034a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869818d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885437a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885437208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b810f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869818d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869815f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869818d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869812e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b813c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b81278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81278> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868359e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81278> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868359e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b81278> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b813c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b81278> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b813c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b81278> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b81278> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b816a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b81278> 0.0 12
Completed Iteration #15
Best Reward: 0
coverage_call_count 4400
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81278> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b81278> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b81278> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81278> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81278> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b81278> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd885b81278> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd885b81278> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81278> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01233c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01233c8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01233c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01233c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01233c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01233c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01233c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01233c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01233c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8744856a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01233c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868355f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c01233c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01233c8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b810f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00eb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8c01233c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01233c8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8854372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00eb8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd8c01233c8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01233c8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c01233c8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01233c8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687f978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8c01233c8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889e80> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889e80> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885437358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f889e80> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01706d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889e80> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889e80> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889e80> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889e80> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b814a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889e80> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9917f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f889e80> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01706d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f889e80> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01706d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f889e80> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889e80> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b814a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f889e80> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01706d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f889e80> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01706d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83f889e80> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744410b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01234e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744410b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744410b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744410b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744410b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8744410b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8744410b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8744410b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bdecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744410b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bde358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8744410b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8744410b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744410b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8744410b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8744410b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8744410b8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884043cc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8744410b8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869341d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886995278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934748> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869341d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886934748> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bde160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934748> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934748> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c067438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886934748> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934748> 0.0 9
Completed Iteration #11
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934748> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886934748> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b007f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886934748> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886934748> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bde898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886995cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886934748> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868918d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934748> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd886934748> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869954a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868918d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886934748> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886934748> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868918d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886934748> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869341d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886934748> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886900320> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bdeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bde518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886900320> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c0675f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900320> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886900320> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bde198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886900320> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900320> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886900320> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886900320> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886900320> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd886900320> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886900320> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886900320> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd886900320> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885437c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c0675f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886900320> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e76d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e76d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868473c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e76d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e76d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868351d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e76d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868e76d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885437898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e76d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868e76d8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41787f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e76d8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868e76d8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a47b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868e76d8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e76d8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88406c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868e76d8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868e76d8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8868e76d8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b977b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e76d8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a47b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8868e76d8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8868e76d8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8868e76d8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88685c8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c8d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c8d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c8d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c8d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88685c8d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c8d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c8d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88685c8d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88685c8d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba30b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88685c8d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88685c8d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba35c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88685c8d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88685c8d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c8d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88685c8d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88685c8d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41999b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97a58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97a58> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e01143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b97a58> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97a58> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 4600
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b97a58> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b97a58> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b97a58> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b97a58> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97a58> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b97a58> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b97a58> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97a58> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b97a58> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b97a58> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b97a58> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b97a58> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3470> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3470> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3470> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3470> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3470> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3470> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3470> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3470> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3470> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3470> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3470> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3470> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41787f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3470> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3470> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c067128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3470> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f991d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f991d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bde2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991d68> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991d68> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f991d68> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991d68> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bde518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f991d68> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f991d68> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991d68> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f991d68> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991d68> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f991d68> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f991d68> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f991d68> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f991d68> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f991d68> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01234e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f991d68> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043358> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043358> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043358> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884043358> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043358> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043358> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00bea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043358> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043358> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884043358> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884043358> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd884043358> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043358> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884043358> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd884043358> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884043358> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd884043358> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd884043358> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00680b8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00680b8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00680b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00680b8> 0.0 5
Completed Iteration #6
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00680b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00680b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01377f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00680b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00680b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00680b8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00680b8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00222e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00680b8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00680b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00685c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00680b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01accc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c00680b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447ad68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00680b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00680b8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c160> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c160> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c160> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c160> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c160> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c160> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0084be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c160> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bde9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c160> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c160> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c160> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c160> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c160> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c160> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c160> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c160> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c160> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c160> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c160> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88698d6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d6a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd91f7d0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88698d6a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d6a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868470f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a45f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88698d6a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d6a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88698d6a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d6a0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bdecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88698d6a0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88698d6a0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d6a0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88698d6a0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88698d6a0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d6a0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88698d6a0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d6a0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88698d6a0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a45f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88698d6a0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88698d6a0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b550> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b550> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b550> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87446b550> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87446b550> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd87446b550> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b550> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b550> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87446b550> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b550> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87446b550> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87446b550> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87446b550> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87446b550> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd87446b550> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87446b550> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87446b550> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87446b550> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b438> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41787f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b438> 0.0 5
Completed Iteration #4
Best Reward: 0
coverage_call_count 4800
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87446b438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b438> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b438> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87446b438> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87446b438> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b438> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87446b438> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87446b438> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd87446b438> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd87446b438> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b438> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87444d8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87446b438> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87446b438> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0eb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd87446b438> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87446b438> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444d8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd87446b438> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd91f7d0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bdecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88685c240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446ba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 20
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886847b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446ba20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a2b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a2b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8840383c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a2b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840389b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a2b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9280f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a2b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840389b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a2b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a2b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9284e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a2b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a2b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a2b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a2b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a2b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840389b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a2b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a2b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a2b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9287f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0027b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043128> 0.0 2
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c002630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043128> 0.0 3
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043128> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c043ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043128> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043128> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043128> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0023c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c002dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043128> 0.0 8
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886978e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0027b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c043128> 0.0 9
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886978710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c043128> 0.0 10
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0024a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043128> 0.0 11
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c002dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c043128> 0.0 12
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88c043128> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9283c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928668> 0.0 2
Completed Iteration #1
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f928668> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f928668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928668> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f928668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414de80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f928668> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928668> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f928668> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f928668> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f928668> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f928668> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f928668> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f928668> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928668> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f928668> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0021d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869783c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928c88> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f928c88> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f928c88> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f928c88> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928c88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f928c88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928c88> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f928c88> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928c88> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f928c88> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f928c88> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928c88> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407ee10> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407ee10> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407ee10> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407ee10> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0588d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407ee10> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88407ee10> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0588d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88407ee10> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88407ee10> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88407ee10> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407ee10> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88407ee10> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88407ee10> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407ee10> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88407ee10> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88407ee10> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407ee10> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ceda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88407ee10> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88407ee10> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cee10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cee10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0585c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cee10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cee10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cee10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cee10> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0586a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cee10> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cee10> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cee10> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cee10> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cee10> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cee10> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cee10> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cee10> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0361d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cee10> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cecf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cee10> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cee10> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cecf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cee10> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cee10> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0588d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cee10> 0.0 21
Completed Iteration #24
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cee10> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0366a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c036e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c036e48> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c036e48> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869789b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c036e48> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c036e48> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c036e48> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd86c036e48> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01662b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036e48> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c036e48> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b650b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036e48> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c036e48> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c036e48> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c036e48> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8891d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c036e48> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cf98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cf98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cf98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cf98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cf98> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cf98> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cf98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a63c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cf98> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cf98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a64e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cf98> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cf98> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0973c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a64e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cf98> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0972b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cf98> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cf98> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0976a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cf98> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cf98> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cf98> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cf98> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b65048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b65048> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65048> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b65048> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65048> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65048> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b65048> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd885b65048> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b65048> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b31d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b65048> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e0b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd885b65048> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b31d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b65048> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b65048> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9480f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65048> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b65048> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f948940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c080> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f948b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f948b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9483c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c080> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c080> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c080> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c080> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c080> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0084be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c080> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f948278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c080> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f948eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c080> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c080> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c080> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c080> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c080> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c080> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f948048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c080> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c080> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b37b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b37b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b37b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b37b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b37b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b37b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b37b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b37b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b37b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01662b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b37b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b37b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b37b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b36a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b37b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b37b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b37b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b36a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b37b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b37b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b37b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b37b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce470> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce470> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce470> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce470> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce470> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869780b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce470> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce470> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce470> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce470> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce470> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce470> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce470> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce470> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce470> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce470> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cea90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce470> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cea90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce470> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c400> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce470> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce470> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce470> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9033c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903898> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9030b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903898> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9032b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903898> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903898> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9030b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f903898> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9033c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f903898> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9033c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f903898> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903898> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8975c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9033c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f903898> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f897668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f897630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903898> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8979b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f903898> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f903898> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f897978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903898> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f897438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f903898> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f897630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f903898> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f903898> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f903898> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f903898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9037f0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9037f0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869789b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9037f0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9037f0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9037f0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9037f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01662b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9037f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9037f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9037f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9288d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9037f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8891d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9037f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9037f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9037f0> 0.0 14
Completed Iteration #17
Best Reward: 0
coverage_call_count 5200
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9037f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9037f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9037f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e08d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9037f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e02e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9037f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e08d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f9037f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f897278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d30> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f897c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f897908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f897b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f897dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f897f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f897f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f897eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d30> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f897f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f897908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f897dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d30> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d30> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f897588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d30> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0366a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f897908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d30> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f897c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d30> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f897f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d30> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac81d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88405ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d30> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f897f28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d30> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9283c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d30> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f897908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d30> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f897588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d30> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f897588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c097d30> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f897160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b240> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b240> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b240> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b240> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b240> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b240> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b240> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b240> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b240> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b240> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b240> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b240> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7bac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b240> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b240> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b240> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b240> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f897b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a7b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a7b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a7b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a7b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a7b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a7b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a7b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a7b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a7b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb384e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a7b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb384e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a7b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a7b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a7b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a7b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a7b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7be48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7be48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7be48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7be48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7be48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7be48> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7be48> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7be48> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7be48> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01662b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7be48> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7be48> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7be48> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7be48> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f897240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7be48> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7be48> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b6a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869780b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b6a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b6a0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b6a0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b6a0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f897c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f897c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b6a0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b6a0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b6a0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b6a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b6a0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b6a0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0976a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f897c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b6a0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b6a0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b6a0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb388d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38ac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38ac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38ac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38ac8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38ac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38ac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38ac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38ac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38ac8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb386d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38ac8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38ac8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38ac8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebd68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38ac8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38ac8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f897da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb748> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f897da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb748> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb748> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb748> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb748> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb748> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea904e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f897da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb748> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb748> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb748> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb748> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb748> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f897da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb748> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea905f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb748> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebf60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebf60> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0970f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9037f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebf60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebf60> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebf60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebf60> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebf60> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0974a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebf60> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0976a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebf60> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9037f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebf60> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0976a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebf60> 0.0 12
Completed Iteration #15
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebf60> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb389e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebf60> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb389e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebf60> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebf60> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9037f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebf60> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9037f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebf60> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f897518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ac88> 0.0 2
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ac88> 0.0 3
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ac88> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ac88> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ac88> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ac88> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ac88> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea427b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ac88> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ac88> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ac88> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ac88> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ac88> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ac88> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea420b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ac88> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ac88> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea515f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51208> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51208> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea428d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51208> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea518d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51208> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51208> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51208> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb389b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51208> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb389b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51208> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51208> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51208> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51208> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea682b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea518d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51208> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea685f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea682b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea518d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51208> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51208> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea688d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea688d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea688d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea688d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea688d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea688d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea688d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea688d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea688d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea688d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea518d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea688d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83ea688d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea688d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea688d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea688d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea688d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83ea688d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83ea688d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea688d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea688d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea428d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68be0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68be0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68be0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea427b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68be0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f897c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68be0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68be0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9034a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68be0> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 5500
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68be0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68be0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68be0> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68be0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8891d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8898> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8898> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8898> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8898> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8898> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8898> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8898> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8898> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7dcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8898> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8898> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8898> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7dcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8898> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da20> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea370f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea374a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea376d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da20> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da20> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f897c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da20> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2aef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da20> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea377f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da20> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea379e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da20> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da20> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7deb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da20> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da20> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da20> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da20> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2aef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da20> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d59b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d59b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea376d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d59b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d59b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d59b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d59b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea374a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d59b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea374a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d59b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d59b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d59b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d59b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d59b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d59b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea374a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d59b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d59b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d59b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d59b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d59b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a208> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a208> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a208> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a208> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a208> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a208> 0.0 7
Completed Iteration #11
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a208> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a208> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a208> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a208> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a208> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a208> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a208> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a208> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42d68> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42d68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f897c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42d68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42d68> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42d68> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea514a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42d68> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42d68> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb388d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42d68> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42d68> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea424e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42d68> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42d68> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42d68> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e594198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb388d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42d68> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e594400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42d68> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e594780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42d68> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42d68> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42d68> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e594a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e594dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594748> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e594f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594748> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594748> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e594748> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5add68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e594748> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ade10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5addd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594748> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5addd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e594748> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594748> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e594748> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e594748> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e594748> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e594748> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e594748> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e594518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e594748> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e594940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e594748> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e594748> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e594550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5943c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e594400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad6a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e594898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad6a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5943c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad6a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb388d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad6a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad6a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e57f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad6a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad6a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5943c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad6a0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad6a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea424e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad6a0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad6a0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad6a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad6a0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad6a0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad6a0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7de10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7de10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7de10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7de10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7de10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7de10> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7de10> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 5700
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7de10> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e566198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7de10> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e566470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7de10> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e566978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7de10> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5665c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7de10> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7de10> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7de10> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7de10> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bfc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7de10> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7de10> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e566908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5661d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5661d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5661d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5665f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e5661d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e566390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5660b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5661d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e566ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5661d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5661d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5661d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5661d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e566eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5661d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5661d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5661d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5661d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e5661d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5661d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5661d0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e5661d0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e50efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ea58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ea58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ea58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e520160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e520198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ea58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5204e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ea58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5206a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e520198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ea58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e520748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e520710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ea58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e520940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ea58> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e520a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ea58> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ea58> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e566c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e520940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ea58> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ea58> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e520198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ea58> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ea58> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e520940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ea58> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ea58> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e520940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ea58> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ea58> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e520710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ea58> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ea58> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e566f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d438> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e566da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d438> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d438> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5665c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d438> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d438> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9034a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d438> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d438> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d438> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0974a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d438> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5668d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d438> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d438> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d438> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea420f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d438> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d438> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d438> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5203c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a400> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5208d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a400> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5949e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a400> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e520908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a400> 0.0 5
Completed Iteration #7
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a400> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e520ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a400> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a400> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5663c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a400> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a400> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5202b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a400> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e520f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a400> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a400> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a400> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e520e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a400> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e520e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e520908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e594400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a400> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a400> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da780> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da780> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e520fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da780> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da780> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da780> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da780> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da780> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da780> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da780> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da780> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da780> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e520fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da780> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dadd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da780> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da780> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da780> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da780> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da780> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e520eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adc50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adc50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adc50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50eac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adc50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adc50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adc50> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e493080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adc50> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e493320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4932e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adc50> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e520f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adc50> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adc50> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adc50> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adc50> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50eac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adc50> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adc50> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4932e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adc50> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adc50> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adc50> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e594c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50eac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adc50> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adc50> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adc50> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e594198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dacf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dacf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dacf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dacf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e520dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dacf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dacf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dacf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dacf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e520fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dacf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dadd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dacf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dacf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dacf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dacf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dacf8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dacf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dacf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dadd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dacf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dacf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dacf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dacf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e566eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e566f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42518> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 5900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4932b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e520ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42518> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4931d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42518> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e566a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42518> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4937b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4931d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42518> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e493828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4937f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42518> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e493b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42518> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e493dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e493da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42518> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4937f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42518> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e493eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e493da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42518> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e493198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4931d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42518> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e566860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e493da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42518> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e520ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42518> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42518> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42518> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42518> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfda0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfda0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfda0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfda0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfda0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfda0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e566f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfda0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e493c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfda0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e493cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfda0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfda0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfda0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e493cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfda0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfda0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfda0> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfda0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfda0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfda0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfda0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfda0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfda0> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a240> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e46aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a240> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e46aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a240> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a240> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a240> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a240> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a240> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a240> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a240> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a240> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd921ab34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a240> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a240> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46aa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a240> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46aa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a240> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a240> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a240> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a240> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a240> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a240> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea427f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a240> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e44dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e44da90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea426a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea427b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e44da90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e44da90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e44da90> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e44dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e44da90> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e46af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea427b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e44da90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e46af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e44dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e44da90> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e44dcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e44da90> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e44dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e44da90> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e44da90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88406c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e44da90> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e44da90> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e46aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e44dcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e44da90> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e44da90> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e44da90> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea370b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e44da90> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e44da90> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e44da90> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e44da90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37e48> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 6000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37e48> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37e48> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37e48> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37e48> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407ef28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37e48> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37e48> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88407ef28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37e48> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37e48> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37e48> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37e48> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1dba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37e48> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37e48> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37e48> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37e48> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37e48> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a5f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a5f8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88405a5f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a5f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a5f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88405a5f8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a5f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a5f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a5f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88405a5f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88405a5f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88405a5f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88405a5f8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f948ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a5f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd88405a5f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f948940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88405a5f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f948c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd88405a5f8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f948780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd88405a5f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dc88> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dc88> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f948358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dc88> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dc88> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dc88> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dc88> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dc88> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f948ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dc88> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dc88> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dc88> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dc88> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dc88> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dc88> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b2c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dc88> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f96fa20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e57dc88> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d358> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d358> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d358> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d358> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d358> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea374a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d358> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d358> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea374a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d358> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d358> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea376a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d358> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d358> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d358> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d358> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e44dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d358> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 6100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ceef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f948cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948cc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0366a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948cc0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948cc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f948cc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f948cc0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f948cc0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0366a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f948cc0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9480b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f948cc0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f948cc0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f948cc0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f948cc0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f948cc0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0366a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f948cc0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0361d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0583c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c043160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175320> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884038978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175320> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c043898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884038438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175320> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175320> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0027f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175320> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4103048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869789b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175320> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175320> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175320> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175320> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0027f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175320> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869789b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175320> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0027f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175320> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c043a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4175320> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f948908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886978160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978160> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88698d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886978160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886978160> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978160> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ceac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886978160> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c043fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886978160> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886978160> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886978160> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea42dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd886978160> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886978160> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886978160> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886978160> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea372e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886978160> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c036278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886978160> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd886978160> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8840434e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46ae80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46ae80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46ae80> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46ae80> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840436d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e46ae80> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46ae80> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e46ae80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46ae80> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e46ae80> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840436d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e46ae80> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46ae80> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e46ae80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e46ae80> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840436d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e46ae80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46ae80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e46ae80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9480b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e46ae80> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e46ae80> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e46ae80> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46ae80> 0.0 21
Completed Iteration #24
Best Reward: 0
coverage_call_count 6200
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178160> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178160> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178160> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178160> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178160> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178160> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178160> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868e7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178160> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178160> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178160> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178160> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178160> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178160> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e003ce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178160> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178160> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178160> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88406c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65940> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65940> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41786a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b65940> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01accc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65940> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65940> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65940> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b65940> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b65940> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b65940> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00222e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65940> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b65940> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65940> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b65940> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0081400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0110048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b65940> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0137128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ac748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b65940> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a9e8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a9e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87447a9e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a9e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a9e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a9e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444dda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87447a9e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00b0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87447a9e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87447a9e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd884043668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87447a9e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e57da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840434e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a9e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a9e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8840434e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87447a9e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd87447a9e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87447a9e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87447a9e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b4ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd87447a9e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87446b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a198> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea424a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a198> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a198> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea424a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a198> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a198> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f96f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a198> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a198> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87446bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a198> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea424a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a198> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bcbe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a198> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868d4a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a198> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a198> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 6300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01bacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a198> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9ce828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a198> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baef0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baef0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baef0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baef0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baef0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baef0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baef0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b0d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baef0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baef0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baef0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baef0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baef0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a42b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baef0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5cd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baef0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baef0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b5cd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baef0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b0dc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba33c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bde400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bde518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c0672e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbef0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbef0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbef0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41ab5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbef0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c002828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbef0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886900be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbef0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bde5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88686de80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c043fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8869cbef0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c058390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0366a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0360f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88698dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c01baef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88686d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a4178240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c058390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8840436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0101898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd91f7d0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37710> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01ba860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9cec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886995fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886934198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0068710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886934940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 19
Completed Iteration #19
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869347b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868d46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0022748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e57d940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd884043518> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885437c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8854371d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891cc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88685c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b814e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885437128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886891cc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8854371d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886891cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891cc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886891cc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891cc0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886891cc0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891cc0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886891cc0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885437a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886891cc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b816a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b815c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886891cc0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd886891cc0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8854371d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886891cc0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd886891cc0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886891cc0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd886891cc0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874441e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e0012dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7ac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7ac8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7ac8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7ac8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7ac8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7ac8> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8744856a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7ac8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868359b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7ac8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8854370b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7ac8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885437128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7ac8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441a90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7ac8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7ac8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88687fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7ac8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874441b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7ac8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7ac8> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b814a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7ac8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd91f7e3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8854374a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d198> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d198> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869342e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d198> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886995278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d198> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b810f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d198> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d198> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd91f7d0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886900048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87447a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d198> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ac80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b97278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d198> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d198> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886847400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d198> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e44d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d198> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c067cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414dbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d198> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b4aba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d198> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c04b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a414d198> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01106a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885bbe630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885437c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0366a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885437c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88405a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437c18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c01acda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8869a4320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885437c18> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885437c18> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437c18> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c001b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885437c18> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885437c18> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885437c18> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885437c18> 0.0 15
Completed Iteration #15
Best Reward: 0
coverage_call_count 6500
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885437c18> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886891f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd885437c18> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a415a320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd885437c18> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e80f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885437c18> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885437c18> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0170ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f991b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f991b00> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f991b00> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991b00> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f897c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991b00> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f897780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f991b00> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f897438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8976d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991b00> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0166588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991b00> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f991b00> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00f7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991b00> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9912e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f991b00> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f991b00> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f897eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f991b00> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f897978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f991b00> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8974a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f991b00> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a415ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f991b00> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f897b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83f991b00> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c005cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c06bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8160> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8160> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886965da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8160> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c04c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8160> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e46a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8160> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8160> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87447a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8160> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b97278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8160> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886835588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8160> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8160> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8160> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c067cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd886835208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8160> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8160> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8160> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3518> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8160> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8160> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f948908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035208> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e002bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035208> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035208> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e003ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035208> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035208> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035208> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9286d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035208> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035208> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035208> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035208> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00a6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035208> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00046a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035208> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035208> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e09b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035208> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ede48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c0035208> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ede10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8eda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8eda58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8edb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed7b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8897f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed7b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed7b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed7b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed7b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8eda58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed7b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9288d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8eda58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed7b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8edf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed7b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed7b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed7b8> 0.0 14
Completed Iteration #14
Best Reward: 0
coverage_call_count 6600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed7b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed7b8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed7b8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed7b8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed7b8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed7b8> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed7b8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed7b8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8eda58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed7b8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5660f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e566ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e566128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e566400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e566c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e566e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566400> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e493390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4930f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566400> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4933c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e566400> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e493438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566400> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5667f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e493438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e566400> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4936a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566400> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e493f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4930f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e566400> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4931d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e566400> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4934a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e566400> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e493470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e566400> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4936d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e566400> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4930f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e566400> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5660f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e566400> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e566400> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e566400> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4930f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e566400> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e566f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e566400> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88407e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8e0004eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e493c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8895c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8895f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e493898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c18> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c18> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c18> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c18> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd874485908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9286a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c18> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ede10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c18> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e493c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c18> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e493da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e493c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c18> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e493c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c18> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd874485ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c18> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd87444def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c18> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885ba3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c18> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f897470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f991c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a41abe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9b3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb1df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a63c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00bf198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a63c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005ce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b65898> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a414dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e493278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf2e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00be710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf2e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf2e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf2e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf2e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e493278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf2e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e493978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf2e8> 0.0 9
Completed Iteration #11
Best Reward: 0
coverage_call_count 6700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf2e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf2e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf2e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf2e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf2e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf2e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf2e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8edd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf2e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e493278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf2e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea511d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ab70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ab70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea514a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ab70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea511d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ab70> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ab70> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea511d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ab70> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea514a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ab70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ab70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ab70> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886891e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ab70> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd88c03d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ab70> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ab70> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ab70> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ab70> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ab70> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea514a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ab70> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6ab70> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f897470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e00cbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51048> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51048> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88c067cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e50eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51048> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51048> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51048> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51048> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f991fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51048> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51048> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51048> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a411cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51048> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51048> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51048> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9286d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51048> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83ea51048> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868a4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81438> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e493da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81438> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e493da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b81438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e493e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea689e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81438> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b81438> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b81438> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81438> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c0366a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e493da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b81438> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8a4199320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea689e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b81438> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81438> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81438> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd87444dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b81438> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea684e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b81438> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b81438> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81438> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f889c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b81438> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e6d8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9030b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e6d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e6d8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9033c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e6d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9038d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e6d8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e6d8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea906a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e6d8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e6d8> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea905f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e6d8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e6d8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9038d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e6d8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea906a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e6d8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e6d8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e6d8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9038d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e6d8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ada90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad9b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad9b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad9b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad9b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5add30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad9b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad9b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad9b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad9b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9037b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad9b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad9b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad9b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f903710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad9b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad9b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adfd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad9b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad9b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea903c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad9b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e566cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad9b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaebb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad9b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4bf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5adf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e08d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8898d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8edb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744857b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4932e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b5cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744857b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea519b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea689b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8edb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8744857b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f8e0438> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8cf8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8cf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5add68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8cf8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9039e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8cf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f928278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8cf8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8cf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0974a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8cf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50e6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8cf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5205f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8cf8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e520ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8cf8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c0974a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8cf8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5209e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e520e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5e80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e520710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e520a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e520e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5e80> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5e80> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e520208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5203c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5e80> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5e80> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e520a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5e80> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5e80> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5200b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5e80> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5e80> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5203c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5e80> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5e80> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5e80> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bff60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5e80> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5e80> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5200b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5e80> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c036278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e520f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5e80> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886965320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5200b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5e80> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5e80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886995eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c005ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8e009d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b00d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8898d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea519b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea519b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b00d68> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ede10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00d68> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f91a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00d68> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd96fe8c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e50eeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b00d68> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b00d68> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e566198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00d68> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b00d68> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f903f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd885b00d68> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea519b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd885b00d68> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b00d68> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b81080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd885b00d68> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00e8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c0123e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd885b00d68> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd885b00d68> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e520390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e520550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5206d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5a90> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e520978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5a90> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5a90> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5a90> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5a90> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5a90> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5a90> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e520550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5a90> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8869a42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5a90> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5a90> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f948908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd88687fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5a90> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5a90> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5a90> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5a90> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5a90> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5a90> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bb00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bb00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bb00> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bb00> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bb00> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bb00> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bb00> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bb00> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bb00> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bb00> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e04e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bb00> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bb00> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e594978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b89e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bb00> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b89e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bb00> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bb00> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bb00> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e594d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bb00> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e594dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b89e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bb00> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e594f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b83c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b89e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bb00> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e594da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e594438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8744857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa20> 0.0 6
Completed Iteration #5
Best Reward: 0
coverage_call_count 7000
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5945c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa20> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa20> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa20> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa20> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb385f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa20> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb383c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa20> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb389b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa20> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa20> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa20> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa20> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa20> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e594dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaf8cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa20> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa20> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4daa20> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594ba8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4dab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e594ba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e594be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594ba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594ba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e520550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e594ba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e594ba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e594ba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb6a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e594ba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5202b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83e594ba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e594ba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0438> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd83e594ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886995eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e594ba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e594ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c06b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd886981898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea682b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea515c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e594198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e50eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed400> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed400> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8868477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed400> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed400> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed400> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea90e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed400> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7ba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed400> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed400> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb380b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed400> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea682b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed400> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8898d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed400> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed400> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8898d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed400> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83f8898d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83f8ed400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5d68> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5d68> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5d68> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5d68> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5d68> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5d68> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5d68> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5d68> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5d68> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5d68> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5d68> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b70f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5d68> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5206d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5d68> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5d68> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5d68> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d64e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d64e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d64e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d64e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d64e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d64e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d64e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7fd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d64ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7fd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d64ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d64e0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7fd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d64e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d64ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7fd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d64e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d64e0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7fd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7fd0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d64ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7fd0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d64e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7fd0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f928978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d64e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7fd0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7fd0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7fd0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 247
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d64edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097748> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea68eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c097748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c097748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097748> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e53c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c097748> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd86c097748> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c097748> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e53c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd86c097748> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b81080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c097748> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd86c097748> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd86c097748> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 248
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b8d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b8d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd8c00b83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b8d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b8d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e520b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b8d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d6016d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b8d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d601898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b8d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d601a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b8d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4da240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b8d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d601b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b8d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d601668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b8d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d601d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b8d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b8d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b8d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d601dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b8d0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d601e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b8d0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b3c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b8d0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b8d0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 249
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d60dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d60da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d6a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d6a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e520550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d6a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d6a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d6012b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d6a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d6a0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d60dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d60dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d6a0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d60df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d6a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d60df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d6a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d60dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d6a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d601c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d6a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d627710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d6a0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d6278d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d6a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d627a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d6a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d6a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d627c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d6a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d6270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb2b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d6a0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d627ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eaeb2b0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d6a0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 250
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d0f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d627f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d0f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d627be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d0f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d627278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d0f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d627748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d0f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9036d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d0f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d0f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d0f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d0f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d627b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d0f0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d627390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e4f9550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d0f0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb0b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d0f0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d0f0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d60dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d0f0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d6272e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d0f0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e520b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d0f0> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d60da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d0f0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d601358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d0f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d601b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d0f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 251
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d601128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d601a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6278d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea682b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd885b00d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea37470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d64ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9a63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea682b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e594198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5bf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6278d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d64ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6278d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 252
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d63dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d50b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d63dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d50b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d63df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d50b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d50b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d63dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d50b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d50b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d50b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d50b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d50b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d64e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d50b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d50b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d50b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d50b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d50b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d50b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d50b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83f9e0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d50b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d50b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 253
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1824a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182240> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d182908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1828d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182240> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d182978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1826a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182240> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1829e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182240> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d182278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182240> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d182e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d191080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d191438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d182240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1915f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d182da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d182240> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1916a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1826a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d182240> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d191860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1826a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d182240> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d191a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d182240> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d191ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d191a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1916a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d1826a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83d182240> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d191eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d191e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182240> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 7300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d191dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d182240> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d182a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1828d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d182240> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d191e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d182240> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 254
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d64e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9dd8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9dd8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1912b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d64e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9dd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d182668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d191748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9dd8> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d182588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d191f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9dd8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d63da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d191f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9dd8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9dd8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9dd8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea682b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9dd8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d191748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9dd8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d191748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9dd8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9dd8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9dd8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e594e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9dd8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d601710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d191f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9dd8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 255
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d627978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d60ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d60d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6016a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e57f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e57f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb38da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d14a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d14a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 256
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d14a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601a58> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d14a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601a58> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d14ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601a58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d14ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601a58> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d14ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601a58> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d14aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d601a58> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1621d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d162198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601a58> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d601a58> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d162898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d601a58> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d14afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d601a58> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d162940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601a58> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d162668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14a358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d601a58> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1620b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d601a58> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d162d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d601a58> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d162ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d601a58> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d162c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a55f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d601a58> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d162e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a55f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83d601a58> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d162f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d162198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d601a58> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d173470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d601a58> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 257
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d173780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d173358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d173278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d173b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d173b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d173278> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d173e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d173b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d173278> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d173f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d173ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d173278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1735c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d173a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d173278> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d162828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d173ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d173278> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1072b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d107278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d173278> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1074e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1074a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d173278> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d107828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1074a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d173278> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1079e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1738d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d173278> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d173240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d107a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d173278> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1730b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d173ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d173278> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d173898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d173198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d173278> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d173c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1074a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d173278> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d162a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d107278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d173278> 0.0 16
Completed Iteration #16
Best Reward: 0
coverage_call_count 7400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1624a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d173358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d173278> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d162a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d173198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d173278> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e50ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d173358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d173278> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d162630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d107a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d173278> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1737f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d107278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d173278> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d60ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d107278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83d173278> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 258
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6276d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627860> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d173860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a54a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d627860> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d14a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627860> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d14a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6276d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d627860> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d14ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627860> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d14a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627860> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d627860> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d627860> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a54a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d627860> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d6016a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d627860> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6276d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d627860> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14a780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d627860> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 259
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d191c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83eb7bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d191390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182e10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d64e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5ad9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d64e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d182e10> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea2a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182e10> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e594978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d173588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182e10> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d601dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d182e10> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d162c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d182e10> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d107438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d162eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182e10> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d601ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d182e10> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d182e10> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d107f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d182e10> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1075c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d64e5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d182e10> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 260
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c10b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c10b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d191cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c10b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c10b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c10b8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c10b8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d107f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c1550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c10b8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14a518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c10b8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c10b8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c10b8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c10b8> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c10b8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cb710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c10b8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c14e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c10b8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c10b8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cb4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c10b8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 261
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e14e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e14e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1550> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d162d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1550> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1550> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1550> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d64e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cb898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1550> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d107d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d182e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1550> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d107080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1550> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d182668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cb898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1550> 0.0 12
Completed Iteration #16
Best Reward: 0
coverage_call_count 7500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d107c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cb898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1550> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e14e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1550> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d6b7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1550> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83ea7d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1550> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e4e55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e14e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1550> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1550> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 262
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d107be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1912b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d191630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d601eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d191630> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d14a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d191630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d14a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d191630> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d14afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d191630> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d627588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d191630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d14a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6016a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d191630> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d173d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1912b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d191630> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d191630> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1912b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d191630> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d191630> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d162898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d191630> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6016a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d191630> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1621d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d191630> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d6016a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d191630> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d14a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d191630> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d191630> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14acf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83d191630> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d191630> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d191630> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d191748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14ac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d191630> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d182b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d191630> 0.0 23
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14ac18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83d191630> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d627860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14acf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83d191630> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 263
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d107ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5eb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5eb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d099198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d099160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0994e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e12e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5eb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d099160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0990f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cbb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5eb8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d099860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d099828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d099198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d099160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5eb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d099ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d162550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5eb8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d099d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cbac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5eb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d099f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d099550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5eb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d099cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5eb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d099748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d099d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5eb8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d099278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d099d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5eb8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cbb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5eb8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5eb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 264
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5358> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5358> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5358> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5358> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5358> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5358> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d099eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5358> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d63d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5358> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d14ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5358> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d099128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5358> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5358> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d099eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5358> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5358> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5358> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5358> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5358> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d099048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5358> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5358> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5358> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d099eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5358> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5358> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 265
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052240> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052240> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b7cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d052240> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052240> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052240> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052240> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 7600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d099e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052240> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d099860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0992b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052240> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0994a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d052240> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d052240> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b74e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d052240> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b74e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d052240> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d173470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0994a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d052240> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d052240> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d191390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0992b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d052240> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 266
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d099eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1668> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1668> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd86c097dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1668> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1668> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d099eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1668> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1668> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1627f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1668> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1668> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d162b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1627f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1668> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1668> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cbfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1668> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d14aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1668> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d14a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1668> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d107710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1668> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a51d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1668> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0990f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83e5e5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1668> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 267
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d052550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d052908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0528d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052438> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d052438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d052d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d052630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0526a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d052438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0524a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052438> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0002b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052438> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d107c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d052438> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0004a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052438> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0005c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d052438> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d000390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052438> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d000cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0528d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d052438> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d000e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83d052438> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d00e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0004a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d052438> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d000f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0004a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d052438> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d000630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052438> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d052438> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d052438> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 268
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d00e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000710> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1e9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d00e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000710> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d14afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0525c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000710> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d601eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000710> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d00e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d00e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000710> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d00e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000710> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d00ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0525c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d000710> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d00eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d000710> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d00ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d000710> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d052c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0525c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d000710> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d00e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d000710> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d02a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d00e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000710> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d02a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d02a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000710> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d00e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d00e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d000710> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d052f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0524a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000710> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d052b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d00e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d000710> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 269
found coverage increase 0
Current Total Coverage 26.041666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d000cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0002b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000a20> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d000278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000a20> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d627588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000a20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d00e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0526a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d000a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d107ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000a20> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d000a20> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 7700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d000a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d00e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000a20> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d052780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0526a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d000a20> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d14aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000a20> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d627860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d000a20> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d000c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d000a20> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0e1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000a20> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d162898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d000a20> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d00ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d000358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d000a20> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d14ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cbbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d000a20> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d00eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d1a5b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d000a20> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0c1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0002b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d000a20> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d099da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0002b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d000a20> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 270
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d14ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d00e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d052b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d02ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d02ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5b38> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d02af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5b38> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d00edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d02a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5b38> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d02ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5b38> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5b38> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0b7278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5b38> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d02ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5b38> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d02a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5b38> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d02af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5b38> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd54a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5b38> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5b38> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d02a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5b38> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbe30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5b38> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbe3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5b38> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbe3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5b38> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd54a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5b38> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 271
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbe3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbe37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbe3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbe3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbe3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbe3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d14a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0004e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbe3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5b70> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d0cbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d02aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5b70> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbe3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5b70> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbe3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5b70> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbe3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d02aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5b70> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbe3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbe3a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5b70> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbe3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbe3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5b70> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbe3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbe3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5b70> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d02aa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5b70> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbe3a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5b70> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d02aa90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5b70> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbe3668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5b70> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd55c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5b70> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5b70> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83d02aa90> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5b70> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfacf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5b70> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 272
found coverage increase 0
Current Total Coverage 26.041666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cb90048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfae80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cb901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cb90198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfae80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cb90518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cb90198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfae80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cb905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cb90588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfae80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cb907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cb907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfae80> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cb909e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfae80> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cb902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cb909e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfae80> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cb90dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cb90da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfae80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cb9f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cb909e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfae80> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cb9f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cb9f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfae80> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfa4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cb909e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfae80> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfae80> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83d02ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cb90588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfae80> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbd5c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfae80> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfae80> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fd83cbfae80> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 273
found coverage increase 0
Current Total Coverage 26.041666666666668
initial coverage: 25.625
time passed (minutes): 60.3615
iterations: 274
number of new inputs: 256
final coverage: 26.0417
total coverage increase: 0.416667
