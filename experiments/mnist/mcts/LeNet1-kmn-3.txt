Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='kmn', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, kmn_k=10000, model='LeNet1', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet1', 'mcts', 'kmn'], random_seed=3, runner='mcts', save_batch=False, skip_layers=[0, 5], tc1=<function tc1 at 0x7f85853e5f28>, tc2=<function tc2 at 0x7f85853f6048>, tc3=<function tc3 at 0x7f85853f6158>, tfc_threshold=900, time_period=3600, verbose=True)
initial coverage: 37.786
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.09687500000000426
backprop <src.mcts.MCTS_Node object at 0x7f84afddcd30> 0.09687500000000426 2
backprop <src.mcts.MCTS_Node object at 0x7f84afddcb38> 0.09687500000000426 2
backprop <src.mcts.MCTS_Node object at 0x7f850c119470> 0.09687500000000426 2
Completed Iteration #0
Best Reward: 0.09687500000000426
Reward: 0.03354166666667169
backprop <src.mcts.MCTS_Node object at 0x7f84afddcf98> 0.03354166666667169 2
backprop <src.mcts.MCTS_Node object at 0x7f84afddcb38> 0.13041666666667595 3
backprop <src.mcts.MCTS_Node object at 0x7f850c119470> 0.13041666666667595 3
Completed Iteration #1
Best Reward: 0.09687500000000426
Completed Iteration #2
Best Reward: 0.09687500000000426
Reward: 0.09125000000000227
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c5c0> 0.09125000000000227 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c518> 0.09125000000000227 2
backprop <src.mcts.MCTS_Node object at 0x7f850c119470> 0.22166666666667822 4
Completed Iteration #3
Best Reward: 0.09687500000000426
Reward: 0.08625000000000682
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c940> 0.08625000000000682 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c4a8> 0.08625000000000682 2
backprop <src.mcts.MCTS_Node object at 0x7f850c119470> 0.30791666666668505 5
Completed Iteration #4
Best Reward: 0.09687500000000426
Reward: 0.09979166666667538
backprop <src.mcts.MCTS_Node object at 0x7f84afd6ccc0> 0.09979166666667538 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c908> 0.09979166666667538 2
backprop <src.mcts.MCTS_Node object at 0x7f850c119470> 0.40770833333336043 6
Completed Iteration #5
Best Reward: 0.09979166666667538
Reward: 0.09687500000000426
backprop <src.mcts.MCTS_Node object at 0x7f84afd6cfd0> 0.09687500000000426 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6cc88> 0.09687500000000426 2
backprop <src.mcts.MCTS_Node object at 0x7f850c119470> 0.5045833333333647 7
Completed Iteration #6
Best Reward: 0.09979166666667538
Reward: 0.03187500000000654
backprop <src.mcts.MCTS_Node object at 0x7f84afd6cf60> 0.03187500000000654 2
backprop <src.mcts.MCTS_Node object at 0x7f84afddcb38> 0.1622916666666825 4
backprop <src.mcts.MCTS_Node object at 0x7f850c119470> 0.5364583333333712 8
Completed Iteration #7
Best Reward: 0.09979166666667538
Reward: 0.09437500000000654
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c240> 0.09437500000000654 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c518> 0.1856250000000088 3
backprop <src.mcts.MCTS_Node object at 0x7f850c119470> 0.6308333333333778 9
Completed Iteration #8
Best Reward: 0.09979166666667538
Reward: 0.09166666666666856
backprop <src.mcts.MCTS_Node object at 0x7f84afd8d4a8> 0.09166666666666856 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c518> 0.27729166666667737 4
backprop <src.mcts.MCTS_Node object at 0x7f850c119470> 0.7225000000000463 10
Completed Iteration #9
Best Reward: 0.09979166666667538
Reward: 0.08145833333333741
backprop <src.mcts.MCTS_Node object at 0x7f84afd8d7f0> 0.08145833333333741 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd8d438> 0.08145833333333741 2
backprop <src.mcts.MCTS_Node object at 0x7f850c119470> 0.8039583333333837 11
Completed Iteration #10
Best Reward: 0.09979166666667538
Reward: 0.10750000000000881
backprop <src.mcts.MCTS_Node object at 0x7f84afd8dac8> 0.10750000000000881 2
backprop <src.mcts.MCTS_Node object at 0x7f84afddcb38> 0.2697916666666913 5
backprop <src.mcts.MCTS_Node object at 0x7f850c119470> 0.9114583333333925 12
Completed Iteration #11
Best Reward: 0.10750000000000881
Reward: 0.06583333333333741
backprop <src.mcts.MCTS_Node object at 0x7f84afd8de10> 0.06583333333333741 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd8da90> 0.06583333333333741 2
backprop <src.mcts.MCTS_Node object at 0x7f850c119470> 0.97729166666673 13
Completed Iteration #12
Best Reward: 0.10750000000000881
Reward: 0.05416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f84afd85128> 0.05416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c908> 0.15395833333334252 3
backprop <src.mcts.MCTS_Node object at 0x7f850c119470> 1.031458333333397 14
Completed Iteration #13
Best Reward: 0.10750000000000881
Completed Iteration #14
Best Reward: 0.10750000000000881
Reward: 0.09791666666666998
backprop <src.mcts.MCTS_Node object at 0x7f84afd8d748> 0.09791666666666998 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c908> 0.2518750000000125 4
backprop <src.mcts.MCTS_Node object at 0x7f850c119470> 1.129375000000067 15
Completed Iteration #15
Best Reward: 0.10750000000000881
Completed Iteration #16
Best Reward: 0.10750000000000881
Reward: 0.050625000000003695
backprop <src.mcts.MCTS_Node object at 0x7f84afd85748> 0.050625000000003695 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c908> 0.3025000000000162 5
backprop <src.mcts.MCTS_Node object at 0x7f850c119470> 1.1800000000000708 16
Completed Iteration #17
Best Reward: 0.10750000000000881
Reward: 0.08833333333333826
backprop <src.mcts.MCTS_Node object at 0x7f84afd859b0> 0.08833333333333826 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd8d438> 0.16979166666667567 3
backprop <src.mcts.MCTS_Node object at 0x7f850c119470> 1.268333333333409 17
Completed Iteration #18
Best Reward: 0.10750000000000881
Completed Iteration #19
Best Reward: 0.10750000000000881
Completed Iteration #20
Best Reward: 0.10750000000000881
Reward: 0.09125000000000227
backprop <src.mcts.MCTS_Node object at 0x7f84afd280b8> 0.09125000000000227 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c160> 0.09125000000000227 2
backprop <src.mcts.MCTS_Node object at 0x7f850c119470> 1.3595833333334113 18
Completed Iteration #21
Best Reward: 0.10750000000000881
Reward: 0.09270833333333428
backprop <src.mcts.MCTS_Node object at 0x7f850c0a6860> 0.09270833333333428 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c160> 0.18395833333333655 3
backprop <src.mcts.MCTS_Node object at 0x7f850c119470> 1.4522916666667456 19
Completed Iteration #22
Best Reward: 0.10750000000000881
Reward: 0.09708333333333741
backprop <src.mcts.MCTS_Node object at 0x7f84afddc8d0> 0.09708333333333741 2
backprop <src.mcts.MCTS_Node object at 0x7f84afddcb38> 0.3668750000000287 6
backprop <src.mcts.MCTS_Node object at 0x7f850c119470> 1.549375000000083 20
Completed Iteration #23
Best Reward: 0.10750000000000881
Reward: 0.05520833333333286
backprop <src.mcts.MCTS_Node object at 0x7f84afddcef0> 0.05520833333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6cc88> 0.15208333333333712 3
backprop <src.mcts.MCTS_Node object at 0x7f850c119470> 1.6045833333334159 21
Completed Iteration #24
Best Reward: 0.10750000000000881
Reward: 0.08020833333333854
backprop <src.mcts.MCTS_Node object at 0x7f84afd8d048> 0.08020833333333854 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c4a8> 0.16645833333334537 3
backprop <src.mcts.MCTS_Node object at 0x7f850c119470> 1.6847916666667544 22
Completed Iteration #25
Best Reward: 0.10750000000000881
Completed MCTS Level/Depth: #0
root
Best Reward: 0.10750000000000881
No reward increase. Abort.
iteration: 0
found coverage increase 0.10750000000000881
Current Total Coverage 37.89354166666667
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.09854166666666231
backprop <src.mcts.MCTS_Node object at 0x7f84afd8d908> 0.09854166666666231 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd8d2e8> 0.09854166666666231 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd8de80> 0.09854166666666231 2
Completed Iteration #2
Best Reward: 0.09854166666666231
Completed Iteration #3
Best Reward: 0.09854166666666231
Reward: 0.09499999999999176
backprop <src.mcts.MCTS_Node object at 0x7f84afd6ceb8> 0.09499999999999176 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6cd30> 0.09499999999999176 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd8de80> 0.19354166666665407 3
Completed Iteration #4
Best Reward: 0.09854166666666231
Completed Iteration #5
Best Reward: 0.09854166666666231
Reward: 0.08895833333333059
backprop <src.mcts.MCTS_Node object at 0x7f84afd85f60> 0.08895833333333059 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6cd30> 0.18395833333332234 3
backprop <src.mcts.MCTS_Node object at 0x7f84afd8de80> 0.28249999999998465 4
Completed Iteration #6
Best Reward: 0.09854166666666231
Reward: 0.03166666666665918
backprop <src.mcts.MCTS_Node object at 0x7f84afd856a0> 0.03166666666665918 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd85cc0> 0.03166666666665918 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd8de80> 0.31416666666664383 5
Completed Iteration #7
Best Reward: 0.09854166666666231
Reward: 0.06229166666665975
backprop <src.mcts.MCTS_Node object at 0x7f84afd85ef0> 0.06229166666665975 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd8d2e8> 0.16083333333332206 3
backprop <src.mcts.MCTS_Node object at 0x7f84afd8de80> 0.3764583333333036 6
Completed Iteration #8
Best Reward: 0.09854166666666231
Reward: 0.08687499999999204
backprop <src.mcts.MCTS_Node object at 0x7f84afd85710> 0.08687499999999204 2
backprop <src.mcts.MCTS_Node object at 0x7f850c0a6550> 0.08687499999999204 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd8de80> 0.4633333333332956 7
Completed Iteration #9
Best Reward: 0.09854166666666231
Reward: 0.08958333333333002
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c7b8> 0.08958333333333002 2
backprop <src.mcts.MCTS_Node object at 0x7f850c0a6550> 0.17645833333332206 3
backprop <src.mcts.MCTS_Node object at 0x7f84afd8de80> 0.5529166666666256 8
Completed Iteration #10
Best Reward: 0.09854166666666231
Reward: 0.07395833333333002
backprop <src.mcts.MCTS_Node object at 0x7f84afd28438> 0.07395833333333002 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd281d0> 0.07395833333333002 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd8de80> 0.6268749999999557 9
Completed Iteration #11
Best Reward: 0.09854166666666231
Reward: 0.09166666666666146
backprop <src.mcts.MCTS_Node object at 0x7f84afd28710> 0.09166666666666146 2
backprop <src.mcts.MCTS_Node object at 0x7f850c0a6550> 0.2681249999999835 4
backprop <src.mcts.MCTS_Node object at 0x7f84afd8de80> 0.7185416666666171 10
Completed Iteration #12
Best Reward: 0.09854166666666231
Reward: 0.09270833333332718
backprop <src.mcts.MCTS_Node object at 0x7f84afd289e8> 0.09270833333332718 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6cd30> 0.2766666666666495 4
backprop <src.mcts.MCTS_Node object at 0x7f84afd8de80> 0.8112499999999443 11
Completed Iteration #13
Best Reward: 0.09854166666666231
Reward: 0.02833333333332888
backprop <src.mcts.MCTS_Node object at 0x7f84afd28cc0> 0.02833333333332888 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd85cc0> 0.05999999999998806 3
backprop <src.mcts.MCTS_Node object at 0x7f84afd8de80> 0.8395833333332732 12
Completed Iteration #14
Best Reward: 0.09854166666666231
Reward: 0.0918749999999946
backprop <src.mcts.MCTS_Node object at 0x7f84afd28f98> 0.0918749999999946 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd8dcc0> 0.0918749999999946 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd8de80> 0.9314583333332678 13
Completed Iteration #15
Best Reward: 0.09854166666666231
Completed Iteration #16
Best Reward: 0.09854166666666231
Reward: 0.08541666666666714
backprop <src.mcts.MCTS_Node object at 0x7f84afd28d68> 0.08541666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f850c0a6550> 0.35354166666665066 5
backprop <src.mcts.MCTS_Node object at 0x7f84afd8de80> 1.016874999999935 14
Completed Iteration #17
Best Reward: 0.09854166666666231
Reward: 0.0625
backprop <src.mcts.MCTS_Node object at 0x7f84afd284e0> 0.0625 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c780> 0.0625 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd8de80> 1.079374999999935 15
Completed Iteration #18
Best Reward: 0.09854166666666231
Reward: 0.09499999999999176
backprop <src.mcts.MCTS_Node object at 0x7f84afd57080> 0.09499999999999176 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd57588> 0.09499999999999176 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c7b8> 0.18458333333332178 3
backprop <src.mcts.MCTS_Node object at 0x7f850c0a6550> 0.4485416666666424 6
backprop <src.mcts.MCTS_Node object at 0x7f84afd8de80> 1.1743749999999267 16
Completed Iteration #19
Best Reward: 0.09854166666666231
Reward: 0.10124999999999318
backprop <src.mcts.MCTS_Node object at 0x7f84afd57940> 0.10124999999999318 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd8dcc0> 0.19312499999998778 3
backprop <src.mcts.MCTS_Node object at 0x7f84afd8de80> 1.2756249999999199 17
Completed Iteration #20
Best Reward: 0.10124999999999318
Reward: 0.0937499999999929
backprop <src.mcts.MCTS_Node object at 0x7f84afd57c18> 0.0937499999999929 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd571d0> 0.0937499999999929 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd8de80> 1.3693749999999127 18
Completed Iteration #21
Best Reward: 0.10124999999999318
Reward: 0.07562499999999517
backprop <src.mcts.MCTS_Node object at 0x7f84afd57ef0> 0.07562499999999517 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd281d0> 0.14958333333332519 3
backprop <src.mcts.MCTS_Node object at 0x7f84afd8de80> 1.444999999999908 19
Completed Iteration #22
Best Reward: 0.10124999999999318
Completed Iteration #23
Best Reward: 0.10124999999999318
Reward: 0.07874999999999943
backprop <src.mcts.MCTS_Node object at 0x7f84afd65470> 0.07874999999999943 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd281d0> 0.22833333333332462 4
backprop <src.mcts.MCTS_Node object at 0x7f84afd8de80> 1.5237499999999073 20
Completed Iteration #24
Best Reward: 0.10124999999999318
Completed Iteration #25
Best Reward: 0.10124999999999318
Completed MCTS Level/Depth: #0
root
Best Reward: 0.10124999999999318
No reward increase. Abort.
iteration: 1
found coverage increase 0.10124999999999318
Current Total Coverage 37.994791666666664
Reward: 0.11395833333333627
backprop <src.mcts.MCTS_Node object at 0x7f84afd282e8> 0.11395833333333627 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd57898> 0.11395833333333627 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd57438> 0.11395833333333627 2
Completed Iteration #0
Best Reward: 0.11395833333333627
Completed Iteration #1
Best Reward: 0.11395833333333627
Reward: 0.09687500000000426
backprop <src.mcts.MCTS_Node object at 0x7f84afd28b70> 0.09687500000000426 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd57898> 0.21083333333334053 3
backprop <src.mcts.MCTS_Node object at 0x7f84afd57438> 0.21083333333334053 3
Completed Iteration #2
Best Reward: 0.11395833333333627
Completed Iteration #3
Best Reward: 0.11395833333333627
Completed Iteration #4
Best Reward: 0.11395833333333627
Reward: 0.1216666666666697
backprop <src.mcts.MCTS_Node object at 0x7f84afd28a58> 0.1216666666666697 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd28518> 0.1216666666666697 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd57438> 0.33250000000001023 4
Completed Iteration #5
Best Reward: 0.1216666666666697
Reward: 0.10916666666666686
backprop <src.mcts.MCTS_Node object at 0x7f84afd57b00> 0.10916666666666686 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd57048> 0.10916666666666686 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd57438> 0.4416666666666771 5
Completed Iteration #6
Best Reward: 0.1216666666666697
Completed Iteration #7
Best Reward: 0.1216666666666697
Reward: 0.12270833333333542
backprop <src.mcts.MCTS_Node object at 0x7f84afd57f98> 0.12270833333333542 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd57898> 0.33354166666667595 4
backprop <src.mcts.MCTS_Node object at 0x7f84afd57438> 0.5643750000000125 6
Completed Iteration #8
Best Reward: 0.12270833333333542
Reward: 0.07437500000000341
backprop <src.mcts.MCTS_Node object at 0x7f84afd85860> 0.07437500000000341 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd85198> 0.07437500000000341 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd57438> 0.6387500000000159 7
Completed Iteration #9
Best Reward: 0.12270833333333542
Reward: 0.1145833333333357
backprop <src.mcts.MCTS_Node object at 0x7f84afd85748> 0.1145833333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd85898> 0.1145833333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd57438> 0.7533333333333516 8
Completed Iteration #10
Best Reward: 0.12270833333333542
Completed Iteration #11
Best Reward: 0.12270833333333542
Reward: 0.12041666666667084
backprop <src.mcts.MCTS_Node object at 0x7f84afd57208> 0.12041666666667084 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd85198> 0.19479166666667425 3
backprop <src.mcts.MCTS_Node object at 0x7f84afd57438> 0.8737500000000225 9
Completed Iteration #12
Best Reward: 0.12270833333333542
Reward: 0.08020833333333144
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c860> 0.08020833333333144 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6ca20> 0.08020833333333144 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd57438> 0.9539583333333539 10
Completed Iteration #13
Best Reward: 0.12270833333333542
Reward: 0.06499999999999773
backprop <src.mcts.MCTS_Node object at 0x7f84afd6ce48> 0.06499999999999773 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd28518> 0.18666666666666742 3
backprop <src.mcts.MCTS_Node object at 0x7f84afd57438> 1.0189583333333516 11
Completed Iteration #14
Best Reward: 0.12270833333333542
Reward: 0.05479166666666657
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c5c0> 0.05479166666666657 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd28518> 0.241458333333334 4
backprop <src.mcts.MCTS_Node object at 0x7f84afd57438> 1.0737500000000182 12
Completed Iteration #15
Best Reward: 0.12270833333333542
Reward: 0.11854166666666544
backprop <src.mcts.MCTS_Node object at 0x7f850c0a64a8> 0.11854166666666544 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c588> 0.11854166666666544 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd57438> 1.1922916666666836 13
Completed Iteration #16
Best Reward: 0.12270833333333542
Reward: 0.08624999999999972
backprop <src.mcts.MCTS_Node object at 0x7f84afddce48> 0.08624999999999972 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6ca20> 0.16645833333333115 3
backprop <src.mcts.MCTS_Node object at 0x7f84afd57438> 1.2785416666666833 14
Completed Iteration #17
Best Reward: 0.12270833333333542
Completed Iteration #18
Best Reward: 0.12270833333333542
Reward: 0.11354166666666998
backprop <src.mcts.MCTS_Node object at 0x7f84afddca58> 0.11354166666666998 2
backprop <src.mcts.MCTS_Node object at 0x7f84afddcd30> 0.11354166666666998 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd57b00> 0.22270833333333684 3
backprop <src.mcts.MCTS_Node object at 0x7f84afd57048> 0.22270833333333684 3
backprop <src.mcts.MCTS_Node object at 0x7f84afd57438> 1.3920833333333533 15
Completed Iteration #19
Best Reward: 0.12270833333333542
Reward: 0.09000000000000341
backprop <src.mcts.MCTS_Node object at 0x7f84afd579e8> 0.09000000000000341 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6cc88> 0.09000000000000341 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd57438> 1.4820833333333567 16
Completed Iteration #20
Best Reward: 0.12270833333333542
Completed Iteration #21
Best Reward: 0.12270833333333542
Reward: 0.07375000000000398
backprop <src.mcts.MCTS_Node object at 0x7f84afd8d278> 0.07375000000000398 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd85198> 0.2685416666666782 4
backprop <src.mcts.MCTS_Node object at 0x7f84afd57438> 1.5558333333333607 17
Completed Iteration #22
Best Reward: 0.12270833333333542
Reward: 0.10791666666666799
backprop <src.mcts.MCTS_Node object at 0x7f84afd8da58> 0.10791666666666799 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd85898> 0.2225000000000037 3
backprop <src.mcts.MCTS_Node object at 0x7f84afd57438> 1.6637500000000287 18
Completed Iteration #23
Best Reward: 0.12270833333333542
Reward: 0.05833333333333712
backprop <src.mcts.MCTS_Node object at 0x7f84afd65748> 0.05833333333333712 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd28518> 0.2997916666666711 5
backprop <src.mcts.MCTS_Node object at 0x7f84afd57438> 1.7220833333333658 19
Completed Iteration #24
Best Reward: 0.12270833333333542
Reward: 0.1075000000000017
backprop <src.mcts.MCTS_Node object at 0x7f84afd65940> 0.1075000000000017 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd65710> 0.1075000000000017 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd85860> 0.18187500000000512 3
backprop <src.mcts.MCTS_Node object at 0x7f84afd85198> 0.37604166666667993 5
backprop <src.mcts.MCTS_Node object at 0x7f84afd57438> 1.8295833333333675 20
Completed Iteration #25
Best Reward: 0.12270833333333542
Completed MCTS Level/Depth: #0
root
Best Reward: 0.12270833333333542
No reward increase. Abort.
iteration: 2
found coverage increase 0.12270833333333542
Current Total Coverage 38.1175
Reward: 0.12395833333333428
backprop <src.mcts.MCTS_Node object at 0x7f84afd65f60> 0.12395833333333428 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd65cf8> 0.12395833333333428 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd65da0> 0.12395833333333428 2
Completed Iteration #0
Best Reward: 0.12395833333333428
Reward: 0.11708333333333343
backprop <src.mcts.MCTS_Node object at 0x7f84afd8ddd8> 0.11708333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd65e48> 0.11708333333333343 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd65da0> 0.2410416666666677 3
Completed Iteration #1
Best Reward: 0.12395833333333428
Completed Iteration #2
Best Reward: 0.12395833333333428
Reward: 0.12145833333333655
backprop <src.mcts.MCTS_Node object at 0x7f84afd650b8> 0.12145833333333655 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc390> 0.12145833333333655 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd65da0> 0.36250000000000426 4
Completed Iteration #3
Best Reward: 0.12395833333333428
Reward: 0.11604166666666771
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc5f8> 0.11604166666666771 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc160> 0.11604166666666771 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd65da0> 0.47854166666667197 5
Completed Iteration #4
Best Reward: 0.12395833333333428
Reward: 0.12145833333333655
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc8d0> 0.12145833333333655 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd65cf8> 0.24541666666667084 3
backprop <src.mcts.MCTS_Node object at 0x7f84afd65da0> 0.6000000000000085 6
Completed Iteration #5
Best Reward: 0.12395833333333428
Completed Iteration #6
Best Reward: 0.12395833333333428
Reward: 0.1212499999999963
backprop <src.mcts.MCTS_Node object at 0x7f84afddceb8> 0.1212499999999963 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc390> 0.24270833333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f84afd65da0> 0.7212500000000048 7
Completed Iteration #7
Best Reward: 0.12395833333333428
Completed Iteration #8
Best Reward: 0.12395833333333428
Reward: 0.07416666666667027
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c358> 0.07416666666667027 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc390> 0.3168750000000031 4
backprop <src.mcts.MCTS_Node object at 0x7f84afd65da0> 0.7954166666666751 8
Completed Iteration #9
Best Reward: 0.12395833333333428
Reward: 0.08020833333333854
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c4a8> 0.08020833333333854 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc390> 0.39708333333334167 5
backprop <src.mcts.MCTS_Node object at 0x7f84afd65da0> 0.8756250000000136 9
Completed Iteration #10
Best Reward: 0.12395833333333428
Reward: 0.08749999999999858
backprop <src.mcts.MCTS_Node object at 0x7f84afd282b0> 0.08749999999999858 2
backprop <src.mcts.MCTS_Node object at 0x7f84afddccc0> 0.08749999999999858 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd65da0> 0.9631250000000122 10
Completed Iteration #11
Best Reward: 0.12395833333333428
Reward: 0.07937500000000597
backprop <src.mcts.MCTS_Node object at 0x7f84afd85470> 0.07937500000000597 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc160> 0.19541666666667368 3
backprop <src.mcts.MCTS_Node object at 0x7f84afd65da0> 1.0425000000000182 11
Completed Iteration #12
Best Reward: 0.12395833333333428
Reward: 0.1145833333333357
backprop <src.mcts.MCTS_Node object at 0x7f84afd57e10> 0.1145833333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c208> 0.1145833333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd65da0> 1.157083333333354 12
Completed Iteration #13
Best Reward: 0.12395833333333428
Reward: 0.06145833333333428
backprop <src.mcts.MCTS_Node object at 0x7f84afd57978> 0.06145833333333428 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd65cf8> 0.3068750000000051 4
backprop <src.mcts.MCTS_Node object at 0x7f84afd65da0> 1.2185416666666882 13
Completed Iteration #14
Best Reward: 0.12395833333333428
Reward: 0.10208333333333286
backprop <src.mcts.MCTS_Node object at 0x7f84afd8d048> 0.10208333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd8d630> 0.10208333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd65da0> 1.320625000000021 14
Completed Iteration #15
Best Reward: 0.12395833333333428
Reward: 0.11187499999999773
backprop <src.mcts.MCTS_Node object at 0x7f84afd657f0> 0.11187499999999773 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd655f8> 0.11187499999999773 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd65da0> 1.4325000000000188 15
Completed Iteration #16
Best Reward: 0.12395833333333428
Completed Iteration #17
Best Reward: 0.12395833333333428
coverage_call_count 100
Reward: 0.10687500000000227
backprop <src.mcts.MCTS_Node object at 0x7f84afd65fd0> 0.10687500000000227 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd65e48> 0.2239583333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f84afd65da0> 1.539375000000021 16
Completed Iteration #18
Best Reward: 0.12395833333333428
Reward: 0.1254166666666663
backprop <src.mcts.MCTS_Node object at 0x7f84afd65908> 0.1254166666666663 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd288d0> 0.1254166666666663 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd65da0> 1.6647916666666873 17
Completed Iteration #19
Best Reward: 0.1254166666666663
Completed Iteration #20
Best Reward: 0.1254166666666663
Reward: 0.07645833333333485
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc668> 0.07645833333333485 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc390> 0.4735416666666765 6
backprop <src.mcts.MCTS_Node object at 0x7f84afd65da0> 1.7412500000000222 18
Completed Iteration #21
Best Reward: 0.1254166666666663
Reward: 0.11583333333333456
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffca58> 0.11583333333333456 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd655f8> 0.2277083333333323 3
backprop <src.mcts.MCTS_Node object at 0x7f84afd65da0> 1.8570833333333567 19
Completed Iteration #22
Best Reward: 0.1254166666666663
Completed Iteration #23
Best Reward: 0.1254166666666663
Completed Iteration #24
Best Reward: 0.1254166666666663
Completed Iteration #25
Best Reward: 0.1254166666666663
Completed MCTS Level/Depth: #0
root
Best Reward: 0.1254166666666663
No reward increase. Abort.
iteration: 3
found coverage increase 0.1254166666666663
Current Total Coverage 38.242916666666666
Reward: 0.054999999999999716
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffce80> 0.054999999999999716 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa84e0> 0.054999999999999716 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8668> 0.054999999999999716 2
Completed Iteration #0
Best Reward: 0.054999999999999716
Completed Iteration #1
Best Reward: 0.054999999999999716
Reward: 0.116458333333334
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8860> 0.116458333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8710> 0.116458333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8668> 0.1714583333333337 3
Completed Iteration #2
Best Reward: 0.116458333333334
Reward: 0.10708333333333542
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8b00> 0.10708333333333542 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8748> 0.10708333333333542 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8668> 0.27854166666666913 4
Completed Iteration #3
Best Reward: 0.116458333333334
Reward: 0.11104166666666515
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffccc0> 0.11104166666666515 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8ac8> 0.11104166666666515 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8668> 0.3895833333333343 5
Completed Iteration #4
Best Reward: 0.116458333333334
Reward: 0.07270833333333115
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc2b0> 0.07270833333333115 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc710> 0.07270833333333115 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8668> 0.46229166666666544 6
Completed Iteration #5
Best Reward: 0.116458333333334
Reward: 0.05875000000000341
backprop <src.mcts.MCTS_Node object at 0x7f84afd8d390> 0.05875000000000341 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa84e0> 0.11375000000000313 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8668> 0.5210416666666688 7
Completed Iteration #6
Best Reward: 0.116458333333334
Completed Iteration #7
Best Reward: 0.116458333333334
Reward: 0.05875000000000341
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c080> 0.05875000000000341 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa84e0> 0.17250000000000654 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8668> 0.5797916666666723 8
Completed Iteration #8
Best Reward: 0.116458333333334
Reward: 0.07979166666666515
backprop <src.mcts.MCTS_Node object at 0x7f84afd655f8> 0.07979166666666515 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8ac8> 0.1908333333333303 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8668> 0.6595833333333374 9
Completed Iteration #9
Best Reward: 0.116458333333334
Reward: 0.12270833333332831
backprop <src.mcts.MCTS_Node object at 0x7f84afd65d30> 0.12270833333332831 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc710> 0.19541666666665947 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8668> 0.7822916666666657 10
Completed Iteration #10
Best Reward: 0.12270833333332831
Completed Iteration #11
Best Reward: 0.12270833333332831
Completed Iteration #12
Best Reward: 0.12270833333332831
Completed Iteration #13
Best Reward: 0.12270833333332831
Completed Iteration #14
Best Reward: 0.12270833333332831
Completed Iteration #15
Best Reward: 0.12270833333332831
Completed Iteration #16
Best Reward: 0.12270833333332831
Reward: 0.04270833333333712
backprop <src.mcts.MCTS_Node object at 0x7f858bb623c8> 0.04270833333333712 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8710> 0.15916666666667112 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8668> 0.8250000000000028 11
Completed Iteration #17
Best Reward: 0.12270833333332831
Reward: 0.11229166666667112
backprop <src.mcts.MCTS_Node object at 0x7f84afd8d9b0> 0.11229166666667112 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8748> 0.21937500000000654 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8668> 0.937291666666674 12
Completed Iteration #18
Best Reward: 0.12270833333332831
Reward: 0.11583333333333456
backprop <src.mcts.MCTS_Node object at 0x7f84afd65c50> 0.11583333333333456 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8710> 0.2750000000000057 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8668> 1.0531250000000085 13
Completed Iteration #19
Best Reward: 0.12270833333332831
Reward: 0.11187499999999773
backprop <src.mcts.MCTS_Node object at 0x7f84afd8d128> 0.11187499999999773 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc710> 0.3072916666666572 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8668> 1.1650000000000063 14
Completed Iteration #20
Best Reward: 0.12270833333332831
Completed Iteration #21
Best Reward: 0.12270833333332831
Completed Iteration #22
Best Reward: 0.12270833333332831
Reward: 0.10312500000000568
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c588> 0.10312500000000568 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd8d160> 0.10312500000000568 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8668> 1.268125000000012 15
Completed Iteration #23
Best Reward: 0.12270833333332831
Reward: 0.045000000000001705
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc470> 0.045000000000001705 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8710> 0.3200000000000074 5
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8668> 1.3131250000000136 16
Completed Iteration #24
Best Reward: 0.12270833333332831
Reward: 0.09916666666666885
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcb70> 0.09916666666666885 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcdd8> 0.09916666666666885 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8668> 1.4122916666666825 17
Completed Iteration #25
Best Reward: 0.12270833333332831
Completed MCTS Level/Depth: #0
root
Best Reward: 0.12270833333332831
No reward increase. Abort.
iteration: 4
found coverage increase 0.12270833333332831
Current Total Coverage 38.365624999999994
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0937500000000071
backprop <src.mcts.MCTS_Node object at 0x7f84afd85470> 0.0937500000000071 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c898> 0.0937500000000071 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc240> 0.0937500000000071 2
Completed Iteration #3
Best Reward: 0.0937500000000071
Completed Iteration #4
Best Reward: 0.0937500000000071
Completed Iteration #5
Best Reward: 0.0937500000000071
Reward: 0.0781250000000071
backprop <src.mcts.MCTS_Node object at 0x7f84afd28470> 0.0781250000000071 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd288d0> 0.0781250000000071 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc240> 0.1718750000000142 3
Completed Iteration #6
Best Reward: 0.0937500000000071
Reward: 0.0539583333333411
backprop <src.mcts.MCTS_Node object at 0x7f84afddca20> 0.0539583333333411 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc0b8> 0.0539583333333411 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc240> 0.2258333333333553 4
Completed Iteration #7
Best Reward: 0.0937500000000071
Completed Iteration #8
Best Reward: 0.0937500000000071
Reward: 0.040625000000005684
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc7f0> 0.040625000000005684 2
backprop <src.mcts.MCTS_Node object at 0x7f84afddc898> 0.040625000000005684 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc240> 0.266458333333361 5
Completed Iteration #9
Best Reward: 0.0937500000000071
Reward: 0.05562500000000625
backprop <src.mcts.MCTS_Node object at 0x7f84afd57fd0> 0.05562500000000625 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc0b8> 0.10958333333334735 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc240> 0.32208333333336725 6
Completed Iteration #10
Best Reward: 0.0937500000000071
Reward: 0.09250000000000114
backprop <src.mcts.MCTS_Node object at 0x7f84afd575f8> 0.09250000000000114 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd579b0> 0.09250000000000114 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc240> 0.4145833333333684 7
Completed Iteration #11
Best Reward: 0.0937500000000071
Reward: 0.09687500000000426
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa86d8> 0.09687500000000426 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c898> 0.19062500000001137 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc240> 0.5114583333333727 8
Completed Iteration #12
Best Reward: 0.09687500000000426
Completed Iteration #13
Best Reward: 0.09687500000000426
Reward: 0.049583333333337976
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8160> 0.049583333333337976 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc0b8> 0.15916666666668533 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc240> 0.5610416666667106 9
Completed Iteration #14
Best Reward: 0.09687500000000426
Reward: 0.09916666666666885
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c080> 0.09916666666666885 2
backprop <src.mcts.MCTS_Node object at 0x7f84afddc898> 0.13979166666667453 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc240> 0.6602083333333795 10
Completed Iteration #15
Best Reward: 0.09916666666666885
Reward: 0.08541666666667425
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8dd8> 0.08541666666667425 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd85f98> 0.08541666666667425 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc240> 0.7456250000000537 11
Completed Iteration #16
Best Reward: 0.09916666666666885
Reward: 0.06208333333334082
backprop <src.mcts.MCTS_Node object at 0x7f84afd57c50> 0.06208333333334082 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc4a8> 0.06208333333334082 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc240> 0.8077083333333945 12
Completed Iteration #17
Best Reward: 0.09916666666666885
Completed Iteration #18
Best Reward: 0.09916666666666885
Completed Iteration #19
Best Reward: 0.09916666666666885
Completed Iteration #20
Best Reward: 0.09916666666666885
Reward: 0.09479166666667282
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7cac8> 0.09479166666667282 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd579b0> 0.18729166666667396 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc240> 0.9025000000000674 13
Completed Iteration #21
Best Reward: 0.09916666666666885
Completed Iteration #22
Best Reward: 0.09916666666666885
Reward: 0.100833333333334
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7ceb8> 0.100833333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd85f98> 0.18625000000000824 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc240> 1.0033333333334014 14
Completed Iteration #23
Best Reward: 0.100833333333334
Completed Iteration #24
Best Reward: 0.100833333333334
Reward: 0.03270833333333911
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c710> 0.03270833333333911 2
backprop <src.mcts.MCTS_Node object at 0x7f84afddc898> 0.17250000000001364 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc240> 1.0360416666667405 15
Completed Iteration #25
Best Reward: 0.100833333333334
Completed MCTS Level/Depth: #0
root
Best Reward: 0.100833333333334
No reward increase. Abort.
iteration: 5
found coverage increase 0.100833333333334
Current Total Coverage 38.46645833333333
Reward: 0.10291666666667254
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7cb00> 0.10291666666667254 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08390> 0.10291666666667254 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08518> 0.10291666666667254 2
Completed Iteration #0
Best Reward: 0.10291666666667254
Reward: 0.09791666666666998
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08828> 0.09791666666666998 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f083c8> 0.09791666666666998 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08518> 0.20083333333334252 3
Completed Iteration #1
Best Reward: 0.10291666666667254
Reward: 0.04104166666667197
backprop <src.mcts.MCTS_Node object at 0x7f84afd8d630> 0.04104166666667197 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd8d588> 0.04104166666667197 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08518> 0.2418750000000145 4
Completed Iteration #2
Best Reward: 0.10291666666667254
Completed Iteration #3
Best Reward: 0.10291666666667254
Reward: 0.100833333333334
backprop <src.mcts.MCTS_Node object at 0x7f84afd28a90> 0.100833333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08390> 0.20375000000000654 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08518> 0.3427083333333485 5
Completed Iteration #4
Best Reward: 0.10291666666667254
Reward: 0.11583333333334167
backprop <src.mcts.MCTS_Node object at 0x7f84afd658d0> 0.11583333333334167 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd28630> 0.11583333333334167 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08518> 0.45854166666669016 6
Completed Iteration #5
Best Reward: 0.11583333333334167
Reward: 0.09666666666667112
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc7b8> 0.09666666666667112 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd28630> 0.2125000000000128 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08518> 0.5552083333333613 7
Completed Iteration #6
Best Reward: 0.11583333333334167
Reward: 0.056875000000005116
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8be0> 0.056875000000005116 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc630> 0.056875000000005116 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08518> 0.6120833333333664 8
Completed Iteration #7
Best Reward: 0.11583333333334167
Completed Iteration #8
Best Reward: 0.11583333333334167
Reward: 0.05416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa87b8> 0.05416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8080> 0.05416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08518> 0.6662500000000335 9
Completed Iteration #9
Best Reward: 0.11583333333334167
Completed Iteration #10
Best Reward: 0.11583333333334167
Completed Iteration #11
Best Reward: 0.11583333333334167
Completed Iteration #12
Best Reward: 0.11583333333334167
Reward: 0.10625000000000284
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c160> 0.10625000000000284 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08390> 0.3100000000000094 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08518> 0.7725000000000364 10
Completed Iteration #13
Best Reward: 0.11583333333334167
Reward: 0.09333333333333371
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7ce48> 0.09333333333333371 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd28630> 0.3058333333333465 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08518> 0.8658333333333701 11
Completed Iteration #14
Best Reward: 0.11583333333334167
Reward: 0.10583333333334366
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7ca90> 0.10583333333334366 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd8d588> 0.14687500000001563 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08518> 0.9716666666667138 12
Completed Iteration #15
Best Reward: 0.11583333333334167
Reward: 0.06333333333333968
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08550> 0.06333333333333968 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc630> 0.1202083333333448 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08518> 1.0350000000000534 13
Completed Iteration #16
Best Reward: 0.11583333333334167
Completed Iteration #17
Best Reward: 0.11583333333334167
Reward: 0.10854166666666742
backprop <src.mcts.MCTS_Node object at 0x7f84afd85cf8> 0.10854166666666742 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08390> 0.4185416666666768 5
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08518> 1.1435416666667209 14
Completed Iteration #18
Best Reward: 0.11583333333334167
Completed Iteration #19
Best Reward: 0.11583333333334167
Completed Iteration #20
Best Reward: 0.11583333333334167
Completed Iteration #21
Best Reward: 0.11583333333334167
Completed Iteration #22
Best Reward: 0.11583333333334167
Reward: 0.1097916666666734
backprop <src.mcts.MCTS_Node object at 0x7f84b3ec0320> 0.1097916666666734 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd28630> 0.4156250000000199 5
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08518> 1.2533333333333943 15
Completed Iteration #23
Best Reward: 0.11583333333334167
Completed Iteration #24
Best Reward: 0.11583333333334167
Reward: 0.11541666666666828
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08da0> 0.11541666666666828 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c2b0> 0.11541666666666828 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08518> 1.3687500000000625 16
Completed Iteration #25
Best Reward: 0.11583333333334167
Completed MCTS Level/Depth: #0
root
Best Reward: 0.11583333333334167
No reward increase. Abort.
iteration: 6
found coverage increase 0.11583333333334167
Current Total Coverage 38.58229166666667
Reward: 0.11437499999999545
backprop <src.mcts.MCTS_Node object at 0x7f84afd85f98> 0.11437499999999545 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd85470> 0.11437499999999545 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08208> 0.11437499999999545 2
Completed Iteration #0
Best Reward: 0.11437499999999545
Reward: 0.048541666666658045
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c710> 0.048541666666658045 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7cbe0> 0.048541666666658045 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08208> 0.1629166666666535 3
Completed Iteration #1
Best Reward: 0.11437499999999545
Reward: 0.09583333333333144
backprop <src.mcts.MCTS_Node object at 0x7f84afd282e8> 0.09583333333333144 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c128> 0.09583333333333144 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08208> 0.25874999999998494 4
Completed Iteration #2
Best Reward: 0.11437499999999545
Reward: 0.04458333333332831
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c080> 0.04458333333332831 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7cbe0> 0.09312499999998636 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08208> 0.30333333333331325 5
Completed Iteration #3
Best Reward: 0.11437499999999545
Reward: 0.06833333333332803
backprop <src.mcts.MCTS_Node object at 0x7f84afd57198> 0.06833333333332803 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c128> 0.16416666666665947 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08208> 0.3716666666666413 6
Completed Iteration #4
Best Reward: 0.11437499999999545
Reward: 0.06979166666666003
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8160> 0.06979166666666003 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd85470> 0.1841666666666555 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08208> 0.4414583333333013 7
Completed Iteration #5
Best Reward: 0.11437499999999545
Completed Iteration #6
Best Reward: 0.11437499999999545
Reward: 0.10291666666666544
backprop <src.mcts.MCTS_Node object at 0x7f84b3ec0710> 0.10291666666666544 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd65780> 0.10291666666666544 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08208> 0.5443749999999667 8
Completed Iteration #7
Best Reward: 0.11437499999999545
Reward: 0.10520833333333002
backprop <src.mcts.MCTS_Node object at 0x7f84b3ec09b0> 0.10520833333333002 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c128> 0.2693749999999895 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08208> 0.6495833333332968 9
Completed Iteration #8
Best Reward: 0.11437499999999545
Completed Iteration #9
Best Reward: 0.11437499999999545
Reward: 0.10499999999999687
backprop <src.mcts.MCTS_Node object at 0x7f84afddca20> 0.10499999999999687 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffca58> 0.10499999999999687 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08208> 0.7545833333332936 10
Completed Iteration #10
Best Reward: 0.11437499999999545
Completed Iteration #11
Best Reward: 0.11437499999999545
coverage_call_count 200
Reward: 0.05104166666666288
backprop <src.mcts.MCTS_Node object at 0x7f84b3ec0550> 0.05104166666666288 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7cbe0> 0.14416666666664923 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08208> 0.8056249999999565 11
Completed Iteration #12
Best Reward: 0.11437499999999545
Completed Iteration #13
Best Reward: 0.11437499999999545
Reward: 0.07208333333333172
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08e48> 0.07208333333333172 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c128> 0.3414583333333212 5
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08208> 0.8777083333332882 12
Completed Iteration #14
Best Reward: 0.11437499999999545
Completed Iteration #15
Best Reward: 0.11437499999999545
Reward: 0.0970833333333303
backprop <src.mcts.MCTS_Node object at 0x7f84afd28fd0> 0.0970833333333303 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08e10> 0.0970833333333303 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08208> 0.9747916666666185 13
Completed Iteration #16
Best Reward: 0.11437499999999545
Reward: 0.09645833333333087
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c9e8> 0.09645833333333087 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffca58> 0.20145833333332774 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08208> 1.0712499999999494 14
Completed Iteration #17
Best Reward: 0.11437499999999545
Reward: 0.10166666666666657
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08320> 0.10166666666666657 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c780> 0.10166666666666657 2
backprop <src.mcts.MCTS_Node object at 0x7f84afddca20> 0.20666666666666345 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffca58> 0.3031249999999943 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08208> 1.172916666666616 15
Completed Iteration #18
Best Reward: 0.11437499999999545
Completed Iteration #19
Best Reward: 0.11437499999999545
Completed Iteration #20
Best Reward: 0.11437499999999545
Reward: 0.11562499999999432
backprop <src.mcts.MCTS_Node object at 0x7f84afd65da0> 0.11562499999999432 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd85470> 0.2997916666666498 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08208> 1.2885416666666103 16
Completed Iteration #21
Best Reward: 0.11562499999999432
Reward: 0.10124999999999318
backprop <src.mcts.MCTS_Node object at 0x7f84afd57cc0> 0.10124999999999318 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08e10> 0.19833333333332348 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08208> 1.3897916666666035 17
Completed Iteration #22
Best Reward: 0.11562499999999432
Reward: 0.08374999999999488
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8f28> 0.08374999999999488 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffca58> 0.3868749999999892 5
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08208> 1.4735416666665984 18
Completed Iteration #23
Best Reward: 0.11562499999999432
Reward: 0.11104166666666515
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc160> 0.11104166666666515 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa82b0> 0.11104166666666515 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08208> 1.5845833333332635 19
Completed Iteration #24
Best Reward: 0.11562499999999432
Reward: 0.10270833333333229
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffceb8> 0.10270833333333229 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ec0978> 0.10270833333333229 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08208> 1.6872916666665958 20
Completed Iteration #25
Best Reward: 0.11562499999999432
Completed MCTS Level/Depth: #0
root
Best Reward: 0.11562499999999432
No reward increase. Abort.
iteration: 7
found coverage increase 0.11562499999999432
Current Total Coverage 38.697916666666664
Reward: 0.09708333333333741
backprop <src.mcts.MCTS_Node object at 0x7f84afddcfd0> 0.09708333333333741 2
backprop <src.mcts.MCTS_Node object at 0x7f84afddceb8> 0.09708333333333741 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd57978> 0.09708333333333741 2
Completed Iteration #0
Best Reward: 0.09708333333333741
Reward: 0.10729166666666856
backprop <src.mcts.MCTS_Node object at 0x7f84b3ec04e0> 0.10729166666666856 2
backprop <src.mcts.MCTS_Node object at 0x7f84afddceb8> 0.20437500000000597 3
backprop <src.mcts.MCTS_Node object at 0x7f84afd57978> 0.20437500000000597 3
Completed Iteration #1
Best Reward: 0.10729166666666856
Reward: 0.0937500000000071
backprop <src.mcts.MCTS_Node object at 0x7f84b3ec03c8> 0.0937500000000071 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ec00f0> 0.0937500000000071 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd57978> 0.2981250000000131 4
Completed Iteration #2
Best Reward: 0.10729166666666856
Completed Iteration #3
Best Reward: 0.10729166666666856
Completed Iteration #4
Best Reward: 0.10729166666666856
Reward: 0.04833333333333201
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd630> 0.04833333333333201 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ec0828> 0.04833333333333201 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd57978> 0.3464583333333451 5
Completed Iteration #5
Best Reward: 0.10729166666666856
Reward: 0.10229166666667311
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd940> 0.10229166666667311 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd668> 0.10229166666667311 2
backprop <src.mcts.MCTS_Node object at 0x7f84afddcfd0> 0.19937500000001052 3
backprop <src.mcts.MCTS_Node object at 0x7f84afddceb8> 0.3066666666666791 4
backprop <src.mcts.MCTS_Node object at 0x7f84afd57978> 0.4487500000000182 6
Completed Iteration #6
Best Reward: 0.10729166666666856
Reward: 0.05000000000000426
backprop <src.mcts.MCTS_Node object at 0x7f84b3eddc88> 0.05000000000000426 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ec0828> 0.09833333333333627 3
backprop <src.mcts.MCTS_Node object at 0x7f84afd57978> 0.49875000000002245 7
Completed Iteration #7
Best Reward: 0.10729166666666856
Reward: 0.06812500000000199
backprop <src.mcts.MCTS_Node object at 0x7f84b3eddfd0> 0.06812500000000199 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3eddc50> 0.06812500000000199 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd57978> 0.5668750000000244 8
Completed Iteration #8
Best Reward: 0.10729166666666856
Completed Iteration #9
Best Reward: 0.10729166666666856
Reward: 0.05104166666666998
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91550> 0.05104166666666998 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ec0828> 0.14937500000000625 4
backprop <src.mcts.MCTS_Node object at 0x7f84afd57978> 0.6179166666666944 9
Completed Iteration #10
Best Reward: 0.10729166666666856
Reward: 0.05520833333333286
backprop <src.mcts.MCTS_Node object at 0x7f84b3e917b8> 0.05520833333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ec0828> 0.2045833333333391 5
backprop <src.mcts.MCTS_Node object at 0x7f84afd57978> 0.6731250000000273 10
Completed Iteration #11
Best Reward: 0.10729166666666856
Reward: 0.09937500000000199
backprop <src.mcts.MCTS_Node object at 0x7f84b3eddf28> 0.09937500000000199 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91780> 0.09937500000000199 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd57978> 0.7725000000000293 11
Completed Iteration #12
Best Reward: 0.10729166666666856
Reward: 0.10812500000000114
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91b38> 0.10812500000000114 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3eddc50> 0.17625000000000313 3
backprop <src.mcts.MCTS_Node object at 0x7f84afd57978> 0.8806250000000304 12
Completed Iteration #13
Best Reward: 0.10812500000000114
Reward: 0.057916666666670835
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91c88> 0.057916666666670835 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91ac8> 0.057916666666670835 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd57978> 0.9385416666667012 13
Completed Iteration #14
Best Reward: 0.10812500000000114
Reward: 0.10041666666666771
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91f28> 0.10041666666666771 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91780> 0.1997916666666697 3
backprop <src.mcts.MCTS_Node object at 0x7f84afd57978> 1.038958333333369 14
Completed Iteration #15
Best Reward: 0.10812500000000114
Completed Iteration #16
Best Reward: 0.10812500000000114
Completed Iteration #17
Best Reward: 0.10812500000000114
Completed Iteration #18
Best Reward: 0.10812500000000114
Reward: 0.09083333333333599
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9d940> 0.09083333333333599 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91ac8> 0.14875000000000682 3
backprop <src.mcts.MCTS_Node object at 0x7f84afd57978> 1.129791666666705 15
Completed Iteration #19
Best Reward: 0.10812500000000114
Reward: 0.09604166666667169
backprop <src.mcts.MCTS_Node object at 0x7f84b3f081d0> 0.09604166666667169 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ec00f0> 0.1897916666666788 3
backprop <src.mcts.MCTS_Node object at 0x7f84afd57978> 1.2258333333333766 16
Completed Iteration #20
Best Reward: 0.10812500000000114
Reward: 0.10041666666666771
backprop <src.mcts.MCTS_Node object at 0x7f84afddcc88> 0.10041666666666771 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3eddc50> 0.27666666666667084 4
backprop <src.mcts.MCTS_Node object at 0x7f84afd57978> 1.3262500000000443 17
Completed Iteration #21
Best Reward: 0.10812500000000114
Reward: 0.05562500000000625
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc4a8> 0.05562500000000625 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91ac8> 0.20437500000001307 4
backprop <src.mcts.MCTS_Node object at 0x7f84afd57978> 1.3818750000000506 18
Completed Iteration #22
Best Reward: 0.10812500000000114
Completed Iteration #23
Best Reward: 0.10812500000000114
Reward: 0.09666666666667112
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7cf98> 0.09666666666667112 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ec0828> 0.30125000000001023 6
backprop <src.mcts.MCTS_Node object at 0x7f84afd57978> 1.4785416666667217 19
Completed Iteration #24
Best Reward: 0.10812500000000114
Reward: 0.0762500000000017
backprop <src.mcts.MCTS_Node object at 0x7f84b3ec04a8> 0.0762500000000017 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c908> 0.0762500000000017 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd57978> 1.5547916666667234 20
Completed Iteration #25
Best Reward: 0.10812500000000114
Completed MCTS Level/Depth: #0
root
Best Reward: 0.10812500000000114
No reward increase. Abort.
iteration: 8
found coverage increase 0.10812500000000114
Current Total Coverage 38.806041666666665
Completed Iteration #0
Best Reward: 0
Reward: 0.03499999999999659
backprop <src.mcts.MCTS_Node object at 0x7f84afd65be0> 0.03499999999999659 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c278> 0.03499999999999659 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd7f0> 0.03499999999999659 2
Completed Iteration #1
Best Reward: 0.03499999999999659
Completed Iteration #2
Best Reward: 0.03499999999999659
Reward: 0.09500000000000597
backprop <src.mcts.MCTS_Node object at 0x7f84b3eddc18> 0.09500000000000597 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3eddb38> 0.09500000000000597 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd7f0> 0.13000000000000256 3
Completed Iteration #3
Best Reward: 0.09500000000000597
Reward: 0.08958333333333712
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91a90> 0.08958333333333712 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd048> 0.08958333333333712 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd7f0> 0.21958333333333968 4
Completed Iteration #4
Best Reward: 0.09500000000000597
Reward: 0.10479166666667084
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91668> 0.10479166666667084 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd1d0> 0.10479166666667084 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd7f0> 0.3243750000000105 5
Completed Iteration #5
Best Reward: 0.10479166666667084
Reward: 0.11833333333333229
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd278> 0.11833333333333229 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91470> 0.11833333333333229 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3eddc18> 0.21333333333333826 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3eddb38> 0.21333333333333826 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd7f0> 0.4427083333333428 6
Completed Iteration #6
Best Reward: 0.11833333333333229
Completed Iteration #7
Best Reward: 0.11833333333333229
Completed Iteration #8
Best Reward: 0.11833333333333229
Reward: 0.1197916666666643
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c898> 0.1197916666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd6a0> 0.1197916666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd7f0> 0.5625000000000071 7
Completed Iteration #9
Best Reward: 0.1197916666666643
Reward: 0.1060416666666697
backprop <src.mcts.MCTS_Node object at 0x7f84afd57438> 0.1060416666666697 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd6a0> 0.225833333333334 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd7f0> 0.6685416666666768 8
Completed Iteration #10
Best Reward: 0.1197916666666643
Reward: 0.12020833333333769
backprop <src.mcts.MCTS_Node object at 0x7f84b3f080f0> 0.12020833333333769 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd1d0> 0.22500000000000853 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd7f0> 0.7887500000000145 9
Completed Iteration #11
Best Reward: 0.12020833333333769
Reward: 0.039791666666666003
backprop <src.mcts.MCTS_Node object at 0x7f84b3ec00f0> 0.039791666666666003 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c278> 0.07479166666666259 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd7f0> 0.8285416666666805 10
Completed Iteration #12
Best Reward: 0.12020833333333769
Completed Iteration #13
Best Reward: 0.12020833333333769
Reward: 0.12479166666666686
backprop <src.mcts.MCTS_Node object at 0x7f84b3eddfd0> 0.12479166666666686 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd6a0> 0.35062500000000085 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd7f0> 0.9533333333333474 11
Completed Iteration #14
Best Reward: 0.12479166666666686
Reward: 0.06395833333333201
backprop <src.mcts.MCTS_Node object at 0x7f84b3ec0b38> 0.06395833333333201 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd1d0> 0.28895833333334053 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd7f0> 1.0172916666666794 12
Completed Iteration #15
Best Reward: 0.12479166666666686
Completed Iteration #16
Best Reward: 0.12479166666666686
Completed Iteration #17
Best Reward: 0.12479166666666686
Reward: 0.0729166666666714
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7cc50> 0.0729166666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd6a0> 0.42354166666667226 5
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd7f0> 1.0902083333333508 13
Completed Iteration #18
Best Reward: 0.12479166666666686
Reward: 0.07375000000000398
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7cf60> 0.07375000000000398 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd1d0> 0.3627083333333445 5
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd7f0> 1.1639583333333547 14
Completed Iteration #19
Best Reward: 0.12479166666666686
Reward: 0.10354166666666487
backprop <src.mcts.MCTS_Node object at 0x7f84afd65f60> 0.10354166666666487 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd240> 0.10354166666666487 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd7f0> 1.2675000000000196 15
Completed Iteration #20
Best Reward: 0.12479166666666686
Completed Iteration #21
Best Reward: 0.12479166666666686
Reward: 0.10958333333333314
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91f60> 0.10958333333333314 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd65710> 0.10958333333333314 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd7f0> 1.3770833333333528 16
Completed Iteration #22
Best Reward: 0.12479166666666686
Reward: 0.11104166666667226
backprop <src.mcts.MCTS_Node object at 0x7f84b3e917b8> 0.11104166666667226 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c278> 0.18583333333333485 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd7f0> 1.488125000000025 17
Completed Iteration #23
Best Reward: 0.12479166666666686
Completed Iteration #24
Best Reward: 0.12479166666666686
Reward: 0.116458333333334
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9d5c0> 0.116458333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9d710> 0.116458333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd7f0> 1.604583333333359 18
Completed Iteration #25
Best Reward: 0.12479166666666686
Completed MCTS Level/Depth: #0
root
Best Reward: 0.12479166666666686
No reward increase. Abort.
iteration: 9
found coverage increase 0.12479166666666686
Current Total Coverage 38.93083333333333
Reward: 0.08250000000000313
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffce10> 0.08250000000000313 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcf28> 0.08250000000000313 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcc50> 0.08250000000000313 2
Completed Iteration #0
Best Reward: 0.08250000000000313
Reward: 0.10687500000000227
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08128> 0.10687500000000227 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c400> 0.10687500000000227 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcc50> 0.1893750000000054 3
Completed Iteration #1
Best Reward: 0.10687500000000227
Reward: 0.11000000000000654
backprop <src.mcts.MCTS_Node object at 0x7f84afd57e10> 0.11000000000000654 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcf28> 0.19250000000000966 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcc50> 0.29937500000001194 4
Completed Iteration #2
Best Reward: 0.11000000000000654
Reward: 0.07104166666667311
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd4a8> 0.07104166666667311 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c400> 0.17791666666667538 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcc50> 0.37041666666668505 5
Completed Iteration #3
Best Reward: 0.11000000000000654
Reward: 0.07250000000000512
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd2b0> 0.07250000000000512 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c400> 0.2504166666666805 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcc50> 0.44291666666669016 6
Completed Iteration #4
Best Reward: 0.11000000000000654
Reward: 0.09833333333332916
backprop <src.mcts.MCTS_Node object at 0x7f84b3eddc50> 0.09833333333332916 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ec0cc0> 0.09833333333332916 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcc50> 0.5412500000000193 7
Completed Iteration #5
Best Reward: 0.11000000000000654
Reward: 0.07520833333333599
backprop <src.mcts.MCTS_Node object at 0x7f84b3ec02e8> 0.07520833333333599 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08ef0> 0.07520833333333599 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcc50> 0.6164583333333553 8
Completed Iteration #6
Best Reward: 0.11000000000000654
Completed Iteration #7
Best Reward: 0.11000000000000654
Completed Iteration #8
Best Reward: 0.11000000000000654
Reward: 0.10333333333333172
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7cc88> 0.10333333333333172 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08ef0> 0.1785416666666677 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcc50> 0.719791666666687 9
Completed Iteration #9
Best Reward: 0.11000000000000654
Reward: 0.09541666666667226
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c3c8> 0.09541666666667226 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ec0b70> 0.09541666666667226 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcc50> 0.8152083333333593 10
Completed Iteration #10
Best Reward: 0.11000000000000654
Reward: 0.09791666666666998
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91208> 0.09791666666666998 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91860> 0.09791666666666998 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcc50> 0.9131250000000293 11
Completed Iteration #11
Best Reward: 0.11000000000000654
Reward: 0.09291666666666742
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91f28> 0.09291666666666742 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ec0b70> 0.18833333333333968 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcc50> 1.0060416666666967 12
Completed Iteration #12
Best Reward: 0.11000000000000654
Reward: 0.0904166666666697
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8cc0> 0.0904166666666697 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ec0cc0> 0.18874999999999886 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcc50> 1.0964583333333664 13
Completed Iteration #13
Best Reward: 0.11000000000000654
Completed Iteration #14
Best Reward: 0.11000000000000654
Reward: 0.09916666666666885
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9d400> 0.09916666666666885 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ec0b70> 0.2875000000000085 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcc50> 1.1956250000000352 14
Completed Iteration #15
Best Reward: 0.11000000000000654
Completed Iteration #16
Best Reward: 0.11000000000000654
Reward: 0.11562500000000142
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9db00> 0.11562500000000142 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9d780> 0.11562500000000142 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcc50> 1.3112500000000367 15
Completed Iteration #17
Best Reward: 0.11562500000000142
Reward: 0.0435416666666697
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9de80> 0.0435416666666697 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9d780> 0.15916666666667112 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcc50> 1.3547916666667064 16
Completed Iteration #18
Best Reward: 0.11562500000000142
Completed Iteration #19
Best Reward: 0.11562500000000142
Completed Iteration #20
Best Reward: 0.11562500000000142
Completed Iteration #21
Best Reward: 0.11562500000000142
Reward: 0.06520833333333087
backprop <src.mcts.MCTS_Node object at 0x7f84b3e002b0> 0.06520833333333087 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f08ef0> 0.24374999999999858 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcc50> 1.4200000000000372 17
Completed Iteration #22
Best Reward: 0.11562500000000142
Reward: 0.07083333333333286
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00668> 0.07083333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c400> 0.32125000000001336 5
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcc50> 1.49083333333337 18
Completed Iteration #23
Best Reward: 0.11562500000000142
Reward: 0.09729166666667055
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00940> 0.09729166666667055 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c780> 0.09729166666667055 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcc50> 1.5881250000000406 19
Completed Iteration #24
Best Reward: 0.11562500000000142
Reward: 0.07520833333333599
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00c88> 0.07520833333333599 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00908> 0.07520833333333599 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9de80> 0.11875000000000568 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9d780> 0.2343750000000071 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcc50> 1.6633333333333766 20
Completed Iteration #25
Best Reward: 0.11562500000000142
Completed MCTS Level/Depth: #0
root
Best Reward: 0.11562500000000142
No reward increase. Abort.
iteration: 10
found coverage increase 0.11562500000000142
Current Total Coverage 39.046458333333334
Reward: 0.10499999999999687
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00f60> 0.10499999999999687 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c240> 0.10499999999999687 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c0f0> 0.10499999999999687 2
Completed Iteration #0
Best Reward: 0.10499999999999687
Reward: 0.10270833333333229
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9dcc0> 0.10270833333333229 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e000f0> 0.10270833333333229 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c0f0> 0.20770833333332916 3
Completed Iteration #1
Best Reward: 0.10499999999999687
Reward: 0.06854166666666828
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c588> 0.06854166666666828 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c048> 0.06854166666666828 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c0f0> 0.27624999999999744 4
Completed Iteration #2
Best Reward: 0.10499999999999687
Reward: 0.07937499999999886
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c860> 0.07937499999999886 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c438> 0.07937499999999886 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c0f0> 0.3556249999999963 5
Completed Iteration #3
Best Reward: 0.10499999999999687
coverage_call_count 300
Completed Iteration #4
Best Reward: 0.10499999999999687
Reward: 0.10333333333333172
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0ce48> 0.10333333333333172 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c438> 0.18270833333333059 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c0f0> 0.45895833333332803 6
Completed Iteration #5
Best Reward: 0.10499999999999687
Completed Iteration #6
Best Reward: 0.10499999999999687
Reward: 0.10125000000000028
backprop <src.mcts.MCTS_Node object at 0x7f84b3eddd68> 0.10125000000000028 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e000f0> 0.20395833333333258 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c0f0> 0.5602083333333283 7
Completed Iteration #7
Best Reward: 0.10499999999999687
Reward: 0.07604166666666856
backprop <src.mcts.MCTS_Node object at 0x7f84b3f084a8> 0.07604166666666856 2
backprop <src.mcts.MCTS_Node object at 0x7f84afddcfd0> 0.07604166666666856 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c0f0> 0.6362499999999969 8
Completed Iteration #8
Best Reward: 0.10499999999999687
Reward: 0.109375
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c4e0> 0.109375 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c438> 0.2920833333333306 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c0f0> 0.7456249999999969 9
Completed Iteration #9
Best Reward: 0.109375
Reward: 0.10208333333333286
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8f28> 0.10208333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e000f0> 0.30604166666666544 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c0f0> 0.8477083333333297 10
Completed Iteration #10
Best Reward: 0.109375
Reward: 0.10374999999999801
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91128> 0.10374999999999801 2
backprop <src.mcts.MCTS_Node object at 0x7f84afddcfd0> 0.17979166666666657 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c0f0> 0.9514583333333277 11
Completed Iteration #11
Best Reward: 0.109375
Reward: 0.07416666666666316
backprop <src.mcts.MCTS_Node object at 0x7f84b3ec0550> 0.07416666666666316 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c048> 0.14270833333333144 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c0f0> 1.025624999999991 12
Completed Iteration #12
Best Reward: 0.109375
Reward: 0.12125000000000341
backprop <src.mcts.MCTS_Node object at 0x7f84afd28518> 0.12125000000000341 2
backprop <src.mcts.MCTS_Node object at 0x7f84afddcfd0> 0.30104166666667 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c0f0> 1.1468749999999943 13
Completed Iteration #13
Best Reward: 0.12125000000000341
Reward: 0.12166666666666259
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd8d0> 0.12166666666666259 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91198> 0.12166666666666259 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c0f0> 1.268541666666657 14
Completed Iteration #14
Best Reward: 0.12166666666666259
Reward: 0.11312499999999659
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00e80> 0.11312499999999659 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e005f8> 0.11312499999999659 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c0f0> 1.3816666666666535 15
Completed Iteration #15
Best Reward: 0.12166666666666259
Reward: 0.07416666666666316
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00898> 0.07416666666666316 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e005f8> 0.18729166666665975 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c0f0> 1.4558333333333167 16
Completed Iteration #16
Best Reward: 0.12166666666666259
Reward: 0.040416666666665435
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9dda0> 0.040416666666665435 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91198> 0.16208333333332803 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c0f0> 1.496249999999982 17
Completed Iteration #17
Best Reward: 0.12166666666666259
Reward: 0.102291666666666
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9d240> 0.102291666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9dc88> 0.102291666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c0f0> 1.598541666666648 18
Completed Iteration #18
Best Reward: 0.12166666666666259
Reward: 0.10166666666666657
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c080> 0.10166666666666657 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c438> 0.39374999999999716 5
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c0f0> 1.7002083333333147 19
Completed Iteration #19
Best Reward: 0.12166666666666259
Reward: 0.10062500000000085
backprop <src.mcts.MCTS_Node object at 0x7f84afd65e48> 0.10062500000000085 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9dc88> 0.20291666666666686 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c0f0> 1.8008333333333155 20
Completed Iteration #20
Best Reward: 0.12166666666666259
Reward: 0.07854166666666629
backprop <src.mcts.MCTS_Node object at 0x7f84afddcc88> 0.07854166666666629 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c438> 0.47229166666666345 6
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c0f0> 1.8793749999999818 21
Completed Iteration #21
Best Reward: 0.12166666666666259
Reward: 0.10541666666667027
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00278> 0.10541666666667027 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c438> 0.5777083333333337 7
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c0f0> 1.984791666666652 22
Completed Iteration #22
Best Reward: 0.12166666666666259
Completed Iteration #23
Best Reward: 0.12166666666666259
Reward: 0.11062499999999886
backprop <src.mcts.MCTS_Node object at 0x7f84afd57fd0> 0.11062499999999886 2
backprop <src.mcts.MCTS_Node object at 0x7f84afddcfd0> 0.41166666666666885 5
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c0f0> 2.095416666666651 23
Completed Iteration #24
Best Reward: 0.12166666666666259
Reward: 0.07895833333333258
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9d780> 0.07895833333333258 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e005f8> 0.2662499999999923 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3e0c0f0> 2.1743749999999835 24
Completed Iteration #25
Best Reward: 0.12166666666666259
Completed MCTS Level/Depth: #0
root
Best Reward: 0.12166666666666259
No reward increase. Abort.
iteration: 11
found coverage increase 0.12166666666666259
Current Total Coverage 39.168124999999996
Reward: 0.09020833333333655
backprop <src.mcts.MCTS_Node object at 0x7f85ac913940> 0.09020833333333655 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91940> 0.09020833333333655 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91c88> 0.09020833333333655 2
Completed Iteration #0
Best Reward: 0.09020833333333655
Reward: 0.08729166666666544
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00128> 0.08729166666666544 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00ba8> 0.08729166666666544 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91c88> 0.177500000000002 3
Completed Iteration #1
Best Reward: 0.09020833333333655
Reward: 0.069583333333334
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00710> 0.069583333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e002b0> 0.069583333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91c88> 0.24708333333333599 4
Completed Iteration #2
Best Reward: 0.09020833333333655
Reward: 0.09145833333333542
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9dc50> 0.09145833333333542 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e002b0> 0.16104166666666941 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91c88> 0.3385416666666714 5
Completed Iteration #3
Best Reward: 0.09145833333333542
Reward: 0.06750000000000256
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9dda0> 0.06750000000000256 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9d1d0> 0.06750000000000256 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91c88> 0.40604166666667396 6
Completed Iteration #4
Best Reward: 0.09145833333333542
Reward: 0.0852083333333411
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9d978> 0.0852083333333411 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00ba8> 0.17250000000000654 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91c88> 0.49125000000001506 7
Completed Iteration #5
Best Reward: 0.09145833333333542
Completed Iteration #6
Best Reward: 0.09145833333333542
Completed Iteration #7
Best Reward: 0.09145833333333542
Reward: 0.100833333333334
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd400> 0.100833333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e002b0> 0.2618750000000034 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91c88> 0.5920833333333491 8
Completed Iteration #8
Best Reward: 0.100833333333334
Reward: 0.08604166666667368
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9dbe0> 0.08604166666667368 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00ba8> 0.2585416666666802 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91c88> 0.6781250000000227 9
Completed Iteration #9
Best Reward: 0.100833333333334
Reward: 0.08958333333333712
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9d080> 0.08958333333333712 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9d1d0> 0.15708333333333968 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91c88> 0.7677083333333599 10
Completed Iteration #10
Best Reward: 0.100833333333334
Reward: 0.08041666666666458
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9dcc0> 0.08041666666666458 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00278> 0.08041666666666458 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91c88> 0.8481250000000244 11
Completed Iteration #11
Best Reward: 0.100833333333334
Reward: 0.08625000000000682
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9dac8> 0.08625000000000682 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00ba8> 0.34479166666668704 5
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91c88> 0.9343750000000313 12
Completed Iteration #12
Best Reward: 0.100833333333334
Reward: 0.08541666666667425
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00cf8> 0.08541666666667425 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91940> 0.1756250000000108 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91c88> 1.0197916666667055 13
Completed Iteration #13
Best Reward: 0.100833333333334
Completed Iteration #14
Best Reward: 0.100833333333334
Completed Iteration #15
Best Reward: 0.100833333333334
Reward: 0.08229166666666998
backprop <src.mcts.MCTS_Node object at 0x7f84b3eddcc0> 0.08229166666666998 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00278> 0.16270833333333456 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91c88> 1.1020833333333755 14
Completed Iteration #16
Best Reward: 0.100833333333334
Reward: 0.08729166666666544
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd160> 0.08729166666666544 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3eddd68> 0.08729166666666544 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91c88> 1.189375000000041 15
Completed Iteration #17
Best Reward: 0.100833333333334
Reward: 0.0520833333333357
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd438> 0.0520833333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3eddd68> 0.13937500000000114 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91c88> 1.2414583333333766 16
Completed Iteration #18
Best Reward: 0.100833333333334
Reward: 0.09479166666666572
backprop <src.mcts.MCTS_Node object at 0x7f84b3e910f0> 0.09479166666666572 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00278> 0.2575000000000003 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91c88> 1.3362500000000423 17
Completed Iteration #19
Best Reward: 0.100833333333334
Completed Iteration #20
Best Reward: 0.100833333333334
Reward: 0.0870833333333394
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00400> 0.0870833333333394 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00278> 0.3445833333333397 5
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91c88> 1.4233333333333817 18
Completed Iteration #21
Best Reward: 0.100833333333334
Reward: 0.026666666666670835
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91c50> 0.026666666666670835 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00b70> 0.026666666666670835 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91c88> 1.4500000000000526 19
Completed Iteration #22
Best Reward: 0.100833333333334
Completed Iteration #23
Best Reward: 0.100833333333334
Reward: 0.09000000000000341
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91c18> 0.09000000000000341 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3eddd68> 0.22937500000000455 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91c88> 1.540000000000056 20
Completed Iteration #24
Best Reward: 0.100833333333334
Completed Iteration #25
Best Reward: 0.100833333333334
Completed MCTS Level/Depth: #0
root
Best Reward: 0.100833333333334
No reward increase. Abort.
iteration: 12
found coverage increase 0.100833333333334
Current Total Coverage 39.26895833333333
Reward: 0.08083333333333798
backprop <src.mcts.MCTS_Node object at 0x7f84b3e917b8> 0.08083333333333798 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c630> 0.08083333333333798 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c390> 0.08083333333333798 2
Completed Iteration #0
Best Reward: 0.08083333333333798
Reward: 0.0364583333333357
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c828> 0.0364583333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91cc0> 0.0364583333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c390> 0.11729166666667368 3
Completed Iteration #1
Best Reward: 0.08083333333333798
Reward: 0.09062500000000284
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7cc18> 0.09062500000000284 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c8d0> 0.09062500000000284 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c390> 0.20791666666667652 4
Completed Iteration #2
Best Reward: 0.09062500000000284
Reward: 0.060833333333341955
backprop <src.mcts.MCTS_Node object at 0x7f850c119470> 0.060833333333341955 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c780> 0.060833333333341955 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c390> 0.2687500000000185 5
Completed Iteration #3
Best Reward: 0.09062500000000284
Completed Iteration #4
Best Reward: 0.09062500000000284
Reward: 0.03541666666666998
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8ef0> 0.03541666666666998 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8a90> 0.03541666666666998 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c390> 0.30416666666668846 6
Completed Iteration #5
Best Reward: 0.09062500000000284
Reward: 0.032083333333332575
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa83c8> 0.032083333333332575 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8a90> 0.06750000000000256 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c390> 0.33625000000002103 7
Completed Iteration #6
Best Reward: 0.09062500000000284
Reward: 0.07500000000000284
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8748> 0.07500000000000284 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8278> 0.07500000000000284 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c390> 0.4112500000000239 8
Completed Iteration #7
Best Reward: 0.09062500000000284
Reward: 0.08124999999999716
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7ca90> 0.08124999999999716 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8860> 0.08124999999999716 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c390> 0.49250000000002103 9
Completed Iteration #8
Best Reward: 0.09062500000000284
Reward: 0.07583333333333542
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc400> 0.07583333333333542 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8a90> 0.14333333333333798 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c390> 0.5683333333333564 10
Completed Iteration #9
Best Reward: 0.09062500000000284
Reward: 0.03458333333333741
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcb00> 0.03458333333333741 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8a90> 0.17791666666667538 5
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c390> 0.6029166666666939 11
Completed Iteration #10
Best Reward: 0.09062500000000284
Completed Iteration #11
Best Reward: 0.09062500000000284
Reward: 0.06583333333333741
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcc18> 0.06583333333333741 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc3c8> 0.06583333333333741 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c390> 0.6687500000000313 12
Completed Iteration #12
Best Reward: 0.09062500000000284
Completed Iteration #13
Best Reward: 0.09062500000000284
Reward: 0.08729166666666544
backprop <src.mcts.MCTS_Node object at 0x7f84afddceb8> 0.08729166666666544 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c8d0> 0.17791666666666828 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c390> 0.7560416666666967 13
Completed Iteration #14
Best Reward: 0.09062500000000284
Reward: 0.054999999999999716
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9d320> 0.054999999999999716 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c8d0> 0.232916666666668 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c390> 0.8110416666666964 14
Completed Iteration #15
Best Reward: 0.09062500000000284
Reward: 0.08791666666667197
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9db38> 0.08791666666667197 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c8d0> 0.32083333333333997 5
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c390> 0.8989583333333684 15
Completed Iteration #16
Best Reward: 0.09062500000000284
Reward: 0.03854166666666714
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00a58> 0.03854166666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91cc0> 0.07500000000000284 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c390> 0.9375000000000355 16
Completed Iteration #17
Best Reward: 0.09062500000000284
Reward: 0.0837500000000091
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91080> 0.0837500000000091 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c8d0> 0.40458333333334906 6
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c390> 1.0212500000000446 17
Completed Iteration #18
Best Reward: 0.09062500000000284
Reward: 0.07750000000000057
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91f60> 0.07750000000000057 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c780> 0.13833333333334252 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c390> 1.0987500000000452 18
Completed Iteration #19
Best Reward: 0.09062500000000284
Completed Iteration #20
Best Reward: 0.09062500000000284
Completed Iteration #21
Best Reward: 0.09062500000000284
Reward: 0.07458333333333655
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa87f0> 0.07458333333333655 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc3c8> 0.14041666666667396 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c390> 1.1733333333333817 19
Completed Iteration #22
Best Reward: 0.09062500000000284
Completed Iteration #23
Best Reward: 0.09062500000000284
Reward: 0.0818750000000037
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91b38> 0.0818750000000037 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c630> 0.16270833333334167 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c390> 1.2552083333333854 20
Completed Iteration #24
Best Reward: 0.09062500000000284
Reward: 0.03375000000000483
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c6a0> 0.03375000000000483 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91cc0> 0.10875000000000767 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c390> 1.2889583333333903 21
Completed Iteration #25
Best Reward: 0.09062500000000284
Completed MCTS Level/Depth: #0
root
Best Reward: 0.09062500000000284
No reward increase. Abort.
iteration: 13
found coverage increase 0.09062500000000284
Current Total Coverage 39.35958333333333
Completed Iteration #0
Best Reward: 0
Reward: 0.03916666666666657
backprop <src.mcts.MCTS_Node object at 0x7f84b3eddac8> 0.03916666666666657 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00240> 0.03916666666666657 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd668> 0.03916666666666657 2
Completed Iteration #1
Best Reward: 0.03916666666666657
Reward: 0.07354166666667084
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa88d0> 0.07354166666667084 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3eddbe0> 0.07354166666667084 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd668> 0.11270833333333741 3
Completed Iteration #2
Best Reward: 0.07354166666667084
Reward: 0.08937500000000398
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc0f0> 0.08937500000000398 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffc518> 0.08937500000000398 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd668> 0.2020833333333414 4
Completed Iteration #3
Best Reward: 0.08937500000000398
Completed Iteration #4
Best Reward: 0.08937500000000398
Completed Iteration #5
Best Reward: 0.08937500000000398
Reward: 0.09020833333333655
backprop <src.mcts.MCTS_Node object at 0x7f84afd650f0> 0.09020833333333655 2
backprop <src.mcts.MCTS_Node object at 0x7f84afddca20> 0.09020833333333655 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd668> 0.29229166666667794 5
Completed Iteration #6
Best Reward: 0.09020833333333655
Reward: 0.037708333333334565
backprop <src.mcts.MCTS_Node object at 0x7f84afd659b0> 0.037708333333334565 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00240> 0.07687500000000114 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd668> 0.3300000000000125 6
Completed Iteration #7
Best Reward: 0.09020833333333655
Reward: 0.09499999999999886
backprop <src.mcts.MCTS_Node object at 0x7f84afd65710> 0.09499999999999886 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd7b8> 0.09499999999999886 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd668> 0.42500000000001137 7
Completed Iteration #8
Best Reward: 0.09499999999999886
Reward: 0.06104166666666799
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd940> 0.06104166666666799 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd65e48> 0.06104166666666799 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd668> 0.48604166666667936 8
Completed Iteration #9
Best Reward: 0.09499999999999886
Reward: 0.09333333333333371
backprop <src.mcts.MCTS_Node object at 0x7f84afddc860> 0.09333333333333371 2
backprop <src.mcts.MCTS_Node object at 0x7f84afddca20> 0.18354166666667027 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd668> 0.5793750000000131 9
Completed Iteration #10
Best Reward: 0.09499999999999886
Completed Iteration #11
Best Reward: 0.09499999999999886
Completed Iteration #12
Best Reward: 0.09499999999999886
Reward: 0.07500000000000284
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa8208> 0.07500000000000284 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c668> 0.07500000000000284 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd668> 0.6543750000000159 10
Completed Iteration #13
Best Reward: 0.09499999999999886
Completed Iteration #14
Best Reward: 0.09499999999999886
Completed Iteration #15
Best Reward: 0.09499999999999886
Reward: 0.03625000000000256
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91be0> 0.03625000000000256 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00240> 0.1131250000000037 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd668> 0.6906250000000185 11
Completed Iteration #16
Best Reward: 0.09499999999999886
Completed Iteration #17
Best Reward: 0.09499999999999886
Reward: 0.09250000000000114
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7cfd0> 0.09250000000000114 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd7b8> 0.1875 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd668> 0.7831250000000196 12
Completed Iteration #18
Best Reward: 0.09499999999999886
Reward: 0.09770833333332973
backprop <src.mcts.MCTS_Node object at 0x7f84afddce48> 0.09770833333332973 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7c668> 0.17270833333333258 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd668> 0.8808333333333493 13
Completed Iteration #19
Best Reward: 0.09770833333332973
Reward: 0.09583333333333144
backprop <src.mcts.MCTS_Node object at 0x7f84afd655f8> 0.09583333333333144 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd7b8> 0.28333333333333144 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd668> 0.9766666666666808 14
Completed Iteration #20
Best Reward: 0.09770833333332973
Completed Iteration #21
Best Reward: 0.09770833333332973
Completed Iteration #22
Best Reward: 0.09770833333332973
coverage_call_count 400
Reward: 0.10312499999999858
backprop <src.mcts.MCTS_Node object at 0x7f84afd577f0> 0.10312499999999858 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd575c0> 0.10312499999999858 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd668> 1.0797916666666794 15
Completed Iteration #23
Best Reward: 0.10312499999999858
Completed Iteration #24
Best Reward: 0.10312499999999858
Reward: 0.08270833333333627
backprop <src.mcts.MCTS_Node object at 0x7f84afd65860> 0.08270833333333627 2
backprop <src.mcts.MCTS_Node object at 0x7f84afddca20> 0.26625000000000654 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3edd668> 1.1625000000000156 16
Completed Iteration #25
Best Reward: 0.10312499999999858
Completed MCTS Level/Depth: #0
root
Best Reward: 0.10312499999999858
No reward increase. Abort.
iteration: 14
found coverage increase 0.10312499999999858
Current Total Coverage 39.46270833333333
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.05666666666667197
backprop <src.mcts.MCTS_Node object at 0x7f84b3f7cbe0> 0.05666666666667197 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcb38> 0.05666666666667197 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91400> 0.05666666666667197 2
Completed Iteration #4
Best Reward: 0.05666666666667197
Completed Iteration #5
Best Reward: 0.05666666666667197
Completed Iteration #6
Best Reward: 0.05666666666667197
Reward: 0.10125000000000028
backprop <src.mcts.MCTS_Node object at 0x7f84afddcc88> 0.10125000000000028 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91fd0> 0.10125000000000028 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91400> 0.15791666666667226 3
Completed Iteration #7
Best Reward: 0.10125000000000028
Completed Iteration #8
Best Reward: 0.10125000000000028
Reward: 0.07520833333333599
backprop <src.mcts.MCTS_Node object at 0x7f84afd65fd0> 0.07520833333333599 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd65470> 0.07520833333333599 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91400> 0.23312500000000824 4
Completed Iteration #9
Best Reward: 0.10125000000000028
Reward: 0.05833333333333712
backprop <src.mcts.MCTS_Node object at 0x7f84b3e9df60> 0.05833333333333712 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcb38> 0.1150000000000091 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91400> 0.29145833333334537 5
Completed Iteration #10
Best Reward: 0.10125000000000028
Reward: 0.09458333333333258
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa87b8> 0.09458333333333258 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e915c0> 0.09458333333333258 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91400> 0.38604166666667794 6
Completed Iteration #11
Best Reward: 0.10125000000000028
Reward: 0.07375000000000398
backprop <src.mcts.MCTS_Node object at 0x7f84afddcfd0> 0.07375000000000398 2
backprop <src.mcts.MCTS_Node object at 0x7f84afd65470> 0.14895833333333997 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91400> 0.4597916666666819 7
Completed Iteration #12
Best Reward: 0.10125000000000028
Reward: 0.08833333333333115
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcd30> 0.08833333333333115 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e915c0> 0.18291666666666373 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91400> 0.5481250000000131 8
Completed Iteration #13
Best Reward: 0.10125000000000028
Reward: 0.05312500000000142
backprop <src.mcts.MCTS_Node object at 0x7f84b3fa86a0> 0.05312500000000142 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcb38> 0.16812500000001052 4
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91400> 0.6012500000000145 9
Completed Iteration #14
Best Reward: 0.10125000000000028
Reward: 0.08708333333333229
backprop <src.mcts.MCTS_Node object at 0x7f84b3e00c18> 0.08708333333333229 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91ef0> 0.08708333333333229 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91400> 0.6883333333333468 10
Completed Iteration #15
Best Reward: 0.10125000000000028
Completed Iteration #16
Best Reward: 0.10125000000000028
Reward: 0.0899999999999963
backprop <src.mcts.MCTS_Node object at 0x7f84afd57cf8> 0.0899999999999963 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91ef0> 0.1770833333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91400> 0.7783333333333431 11
Completed Iteration #17
Best Reward: 0.10125000000000028
Completed Iteration #18
Best Reward: 0.10125000000000028
Reward: 0.086666666666666
backprop <src.mcts.MCTS_Node object at 0x7f850c0a6978> 0.086666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e915f8> 0.086666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91400> 0.8650000000000091 12
Completed Iteration #19
Best Reward: 0.10125000000000028
Completed Iteration #20
Best Reward: 0.10125000000000028
Completed Iteration #21
Best Reward: 0.10125000000000028
Completed Iteration #22
Best Reward: 0.10125000000000028
Completed Iteration #23
Best Reward: 0.10125000000000028
Completed Iteration #24
Best Reward: 0.10125000000000028
Reward: 0.0956250000000054
backprop <src.mcts.MCTS_Node object at 0x7f84afd6c908> 0.0956250000000054 2
backprop <src.mcts.MCTS_Node object at 0x7f84b3ffcb38> 0.2637500000000159 5
backprop <src.mcts.MCTS_Node object at 0x7f84b3e91400> 0.9606250000000145 13
Completed Iteration #25
Best Reward: 0.10125000000000028
Completed MCTS Level/Depth: #0
root
Best Reward: 0.10125000000000028
No reward increase. Abort.
iteration: 15
found coverage increase 0.10125000000000028
Current Total Coverage 39.56395833333333
initial coverage: 37.786
time passed (minutes): 14.2201
iterations: 16
number of new inputs: 1024
final coverage: 39.564
total coverage increase: 1.77792
