Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='nbc', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet1', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet1', 'mcts', 'nbc'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7f092c75ff28>, tc2=<function tc2 at 0x7f092c770048>, tc3=<function tc3 at 0x7f092c770158>, tfc_threshold=900, time_period=3600, verbose=True)
initial coverage: 29.1667
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01447b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0eb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0eb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0eb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0eb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0eb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01447f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0eb8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0eb8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0eb8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0eb8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0eb8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0eb8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0eb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01c40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a208> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01445c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b016a208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a208> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b016a208> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01c40b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b016a208> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01449b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a208> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a208> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b016a208> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b016a208> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b016a208> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d2e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d2e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d2e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d2e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b011d2e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d2e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d2e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b011d2e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b011d2e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b011d2e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d2e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b011d2e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b011d2e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b011d2e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011db38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b011d2e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b011db38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b011d2e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b011d908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08b011d2e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d2e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b048> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b048> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b048> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b012b048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b012b048> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01446d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b048> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b048> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b012b048> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b048> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b012b048> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b012b048> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b048> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b012b048> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b012b048> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b012b048> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b012b048> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b012b048> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01510f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151e48> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151e48> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0151e48> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0151e48> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013f358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0151e48> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0151e48> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0151e48> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013f358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b0151e48> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0151e48> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151e48> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0151e48> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0151b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b0151e48> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151e48> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fc50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fc50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fc50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fc50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fc50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b013fc50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fc50> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fc50> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b013fc50> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b013fc50> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b013fc50> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b013fc50> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b013fc50> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b013fc50> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b013fc50> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00fff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b013fc50> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b013fc50> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00fffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b013fc50> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fc50> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00935f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b013fc50> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b013fc50> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093550> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093550> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093550> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00930b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0093550> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093550> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093550> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b0093550> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093550> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0093550> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093550> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093550> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0093550> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b0093550> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0093550> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093550> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e32b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e32b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e32b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e32b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e32b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00e32b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b00e32b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00e32b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e32b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013f4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b00e32b0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fa90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b00e32b0> 0.0 12
Completed Iteration #19
Best Reward: 0
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e32b0> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a588> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b017a588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b017a588> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a588> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a588> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b017a588> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b017a588> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a588> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b017a588> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b017a588> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b017a588> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b017a588> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b017a588> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b017a588> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b017a588> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b017a588> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00617b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5ac8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5ac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5ac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0061cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5ac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5ac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5ac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5ac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5ac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5ac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5ac8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5ac8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5ac8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00616a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b006e128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b000a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006e8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017aba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017aba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01445c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017aba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017aba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017aba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b017aba8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b017aba8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b017aba8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b017aba8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017aba8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017aba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b017aba8> 0.0 13
Completed Iteration #17
Best Reward: 0
coverage_call_count 300
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017ae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b017aba8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b017aba8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b017aba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017aba8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017aba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017ae10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b017aba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e36a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e36a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e36a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e36a0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e36a0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00e36a0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e36a0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00367b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e36a0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00361d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e36a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006e518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b00e36a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00367b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00e36a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00e36a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00e36a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00e36a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00361d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00e36a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b00e36a0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00e36a0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b00e36a0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc940> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc940> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc940> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00366d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc940> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc940> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00366d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947bc940> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc940> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00366d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947bc940> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947bc940> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bcb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947bc940> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bcb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947bc940> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947bc940> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947bc940> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947bc940> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d23c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947bc940> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947d2e80> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947d2e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947d2e80> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2e80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947d2e80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2e80> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947d2e80> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d20f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947d2e80> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947d2e80> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08947d2e80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00939e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b000a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947d2e80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947d2e80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00363c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2e80> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00361d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2e80> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000aac8> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00611d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000aac8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01445c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000aac8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00611d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b000aac8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000aac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b000aac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b000aac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000aac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000aac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000aac8> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b000aac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000aac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b000aac8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b000aac8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947ebfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01447f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b000aac8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00367b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000aac8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00367b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b000aac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792358> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947924a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894792358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947927f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792358> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792358> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894792358> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792358> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947927f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894792358> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792358> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947929b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894792358> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894792358> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947927f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894792358> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894792358> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0894792358> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894792358> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792358> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01510f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894792358> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894792358> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0894792358> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894792358> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0894792358> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792358> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894792358> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947ebb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d278> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d278> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089473d278> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089473d278> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089473d278> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089473d278> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089473d278> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f089473d278> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d278> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479ee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f089473d278> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479ee10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f089473d278> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089473d278> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f089473d278> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f089473d278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947ebba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479efd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947ebd30> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947ebd30> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947ebd30> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d20f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947ebd30> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947ebd30> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d20f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947ebd30> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00368d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947ebac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947ebd30> 0.0 8
Completed Iteration #11
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947ebd30> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d26a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947ebd30> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947ebd30> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947ebd30> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013f780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947ebd30> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947ebd30> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947ebd30> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947ebd30> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947ebd30> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08947ebd30> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb710> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb710> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb710> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947eb710> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb710> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947927b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb710> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb710> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947142b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947eb710> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947eb710> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb710> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947eb710> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947eb710> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947eb710> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb710> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947eb710> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffe10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08947eb710> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffe10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08947eb710> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08947eb710> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947eb710> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947264a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947264e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947264e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947264e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947264e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947269b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947264e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947264e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947370b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947264e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947264a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947264e0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947264e0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947264a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947264e0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947377f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947264e0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947267b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947377f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947264e0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947264e0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947148d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947264e0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947140b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947148d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947264e0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947264a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08947264e0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947377f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947264e0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f094903a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08fac214e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947264e0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08f01674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01e6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f0167518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a320> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0644f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0644dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a320> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01e6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f094903a320> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08f0167080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f0167518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f094903a320> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01671d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a320> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f0167518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f094903a320> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0644ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01512e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a320> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947266d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a320> 0.0 11
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0644dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f094903a320> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f094903a320> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01c4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0644dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f094903a320> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f0167198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a320> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714320> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714320> 0.0 4
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714320> 0.0 5
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714320> 0.0 6
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714320> 0.0 7
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714320> 0.0 8
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f094903a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714320> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0644e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013f438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894714320> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714320> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f0167240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714320> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714320> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0644a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714320> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08f0154f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013f438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0894714320> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714320> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011deb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894714320> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011dcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00362b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011dcc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011dcc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b011dcc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011dcc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b011dcc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011dcc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011db38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b011dcc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b011dcc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b011dcc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b011dcc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011dcc0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b011dcc0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011dcc0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00364e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011dcc0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b011dcc0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fdef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fdef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fdef0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fdef0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08946fdef0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fdef0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08f0154fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01672b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fdef0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fdef0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08946fdef0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fdef0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fdef0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08946fdef0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08946fdef0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947260f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01672b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08946fdef0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08946fdef0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08946fdef0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08946fdef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08946fdef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947146d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01672e8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01672e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08f01672e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f094903a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01672e8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f094903a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00365f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08f01672e8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08f01672e8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08f01672e8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01672e8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01672e8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01672e8> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b06448d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01672e8> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b06448d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08f01672e8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08f01672e8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0644f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01672e8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01672e8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08946fd780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0644f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08946fd780> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00365c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f094903a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd780> 0.0 9
Completed Iteration #8
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01c4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f0167278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0036208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08946fd780> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08946fd780> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08946fd780> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd780> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08946fd780> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08946fd780> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08946fd780> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a9e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08946fd780> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08946fd780> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08946fd780> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd780> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f094903a710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08946fd780> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b017a978> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b017a978> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a978> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a978> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a978> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b017a978> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b017a978> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b017a978> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b017a978> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b017a978> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01670b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01670b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01670b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01670b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01670b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08f01670b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01670b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01670b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08f01670b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08f01670b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08f01670b8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016aa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08f01670b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08f01670b8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08f01670b8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f094903a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2940> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947146d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2940> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2940> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2940> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2940> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2940> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947d2940> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00361d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947d2748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947d2940> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947d2940> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947d2940> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01c40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947d2940> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2940> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947d2940> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947d2940> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011df98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947d2940> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011df98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08947d2940> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08946fd978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0644dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd978> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd978> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08946fd978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd978> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08946fd978> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08946fd978> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd978> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08946fd978> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08946fd978> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08946fd978> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08946fd978> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08946fd978> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd978> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08946fd978> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00939b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08946fd978> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08946fd978> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00938d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093940> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093940> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093940> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473dba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0093940> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0093940> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093940> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0093940> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093940> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093940> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093940> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093940> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093940> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 2
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 3
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 5
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0644fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 6
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 7
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 8
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00934a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473df98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00364a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00364a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00364a8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00364a8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00364a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00364a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00364a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01674e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00364a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00364a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b00364a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b00364a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08f0167240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00364a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00364a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00364a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00364a8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b00364a8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b00364a8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a0b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08b00364a8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474add8> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474add8> 0.0 3
Completed Iteration #4
Best Reward: 0
coverage_call_count 900
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474add8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474add8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474add8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474add8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474add8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474add8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474add8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474add8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947923c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474add8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f089474add8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474add8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474add8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f089474add8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01f02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792f60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947ebfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894792f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792f60> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894792f60> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792f60> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947ebfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947eb9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894792f60> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894792f60> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894792f60> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792f60> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947ebba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792f60> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792f60> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f00f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894792f60> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947927b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894792f60> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0894792f60> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f00f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894792f60> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b9b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b9b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b9b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b9b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b9b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b012b9b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947ebdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b9b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b012b9b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b9b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0644f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b012b9b0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b012b9b0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b012b9b0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b012b9b0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012bbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b012b9b0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b012b9b0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00939b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947929b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479ed68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947375c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947929b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947929b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 1000
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c0564a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947925f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c0567f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04ac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c0564a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056d68> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c056d68> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505aba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c056d68> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505abe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505aba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056d68> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c0562b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056d68> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505abfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056d68> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f086c056d68> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c056d68> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f086c056d68> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c0562b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c056d68> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c0564a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c0562b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f086c056d68> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f086c056d68> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a8d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c04a8d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a8d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c04a8d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947376d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a8d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a8d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a8d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c04a8d0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947376d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c04a8d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a8d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c04a8d0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f086c04a8d0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c04a8d0> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947371d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f086c04a8d0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c04a8d0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0644f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a8d0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f086c04a8d0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947376d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f086c04a8d0> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474ae80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08f01674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474ae80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01fea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474ae80> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474ae80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474ae80> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f089474ae80> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474ae80> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474ae80> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474a9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f089474ae80> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474ae80> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474ae80> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b012bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474ae80> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474ae80> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f089474ae80> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012bf98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f089474ae80> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bbc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474ae80> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012bf98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f089474ae80> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bbc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f089474ae80> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085056c5f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c5f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c5f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c5f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085056c5f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0644ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c5f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c5f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085056c5f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085056c5f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085056c5f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085056c5f8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085056c5f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505835f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c5f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505839e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085056c5f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505837f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c5f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f085056c5f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab4e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f085056c5f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583320> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505148d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583320> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583320> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850583320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505836a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505141d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505839e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583320> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583320> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850583320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583320> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505141d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850583320> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850583320> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0850583320> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514ac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0850583320> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850583320> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056cc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850583320> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505837b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850583320> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850583320> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850583320> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583320> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0850583320> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08f0167240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474a128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a128> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474a128> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0644f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474a128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505abeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474a128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f089474a128> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a128> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f089474a128> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f089474a128> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474a128> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a128> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb9b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f089474a128> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f089474a128> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474a128> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474a128> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04ac18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04ac18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505145f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04ac18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bbba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04ac18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505145f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c04ac18> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c04ac18> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04ac18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04ac18> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c04ac18> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505474e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04ac18> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505474e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c04ac18> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505474e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f086c04ac18> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04ac18> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505145f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f086c04ac18> 0.0 15
Completed Iteration #22
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505476d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c04ac18> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04ac18> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505474a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc160> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504dc160> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc160> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc160> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc160> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc160> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504dc160> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504dc160> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc160> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504dc160> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08504dc160> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08504dc160> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504dc160> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504dc160> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc160> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505475f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504f0390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0390> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0390> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505140b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504f0390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505472b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08504f0390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08504f0390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504f0390> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08504f0390> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0390> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504f0390> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0390> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504f0390> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08504f0390> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0644f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08504f0390> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08f0167240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504f0390> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08504f0390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547828> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547828> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547828> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547828> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547828> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547828> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547828> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547828> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547828> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850547828> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547828> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547828> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547828> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0850547828> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850547828> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0fd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0fd0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504f0fd0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504f0fd0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0fd0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504f0fd0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08504f0fd0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08504f0fd0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0fd0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0fd0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0fd0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0fd0> 0.0 15
Completed Iteration #20
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504f0fd0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08504f0fd0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08504f0fd0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bccf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bccf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bccf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bccf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504bccf8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504bccf8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bccf8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bcef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504bccf8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504bccf8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504bccf8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08504bccf8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08504bccf8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bccf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08504bccf8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bccf8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bccf8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504bccf8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504bccf8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc9b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc9b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc9b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc9b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc9b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bcba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504bc2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504bc9b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc9b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bcda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504bc9b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504bc9b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504bc9b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc9b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bcda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08504bc9b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504bc9b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08504bc9b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fcb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504bc9b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947371d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504bc9b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5eb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5eb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505476d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5eb8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5eb8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5eb8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5eb8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f0167240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5eb8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5eb8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5eb8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045fba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045fba8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045fba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045fba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045fba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085045fba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085045fba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045fba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045fba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085045fba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085045fba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045fba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085045fba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085045fba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f085045fba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085041b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085045fba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f085045fba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504278d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085045fba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085045fba8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085045fba8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d208> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504279e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d208> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d208> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d208> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085043d208> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085043d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085043d208> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085043d208> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085043d208> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504270b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d208> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d208> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d208> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085043d208> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085043d208> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085043d208> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085043d208> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f085043d208> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f710> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f710> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f710> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f710> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085045f710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f710> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085045f710> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505abc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085045f710> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f710> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085045f710> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085045f710> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f710> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085045f710> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f710> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f710> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fcb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085045f710> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f085045f710> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085045f710> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0d68> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504f0d68> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0d68> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0d68> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504f0d68> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504f0d68> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504f0d68> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0d68> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0d68> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504f0d68> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0d68> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504f0d68> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504f0d68> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08504f0d68> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504f0d68> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a60b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08504f0d68> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b860> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487eca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085044b860> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ece48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b860> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b860> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085044b860> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ecd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085044b860> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487eceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085044b860> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085044b860> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085044b860> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085044b860> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085044b860> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b860> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f085044b860> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b860> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877da20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877da20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877da20> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ecda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877da20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084877da20> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084877da20> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877da20> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877da20> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877da20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084877da20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084877da20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877deb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084877da20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877da20> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084877da20> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877da20> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084877da20> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f084877da20> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084877da20> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084877da20> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084877da20> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041bc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041bc18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487eca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041bc18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041bc18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041bc18> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041bc18> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041bc18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041bc18> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085041bc18> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085041bc18> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085041bc18> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505472b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487eca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085041bc18> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041bc18> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085041bc18> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a60b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085041bc18> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085041bc18> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085041bc18> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085041bc18> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085041bc18> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085041bc18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427828> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427828> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ecb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850427828> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850427828> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850427828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850427828> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487465f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850427828> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427828> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850427828> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427828> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850427828> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850427828> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487540b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850427828> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427828> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0850427828> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547780> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487967b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547780> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547780> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547780> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487967b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547780> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850547780> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547780> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547780> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547780> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487967b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850547780> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547780> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547780> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850547780> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754c18> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487465f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754c18> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754c18> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754c18> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0848754c18> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0848754c18> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0848754c18> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0848754c18> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0848754c18> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0848754c18> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487547f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754c18> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0848754c18> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0848754c18> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0848754c18> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0848754c18> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487548d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487966d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0848754f60> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754f60> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0848754f60> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754f60> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0848754f60> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754f60> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0848754f60> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0848754f60> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0848754f60> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0848754f60> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0848754f60> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0848754f60> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c0561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056cc0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c0566a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c056cc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056cc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c056e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c056cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056cc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056cc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056cc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056cc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c056cc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487545f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056cc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504276a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c056cc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f086c056cc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c056cc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c0561d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c056cc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f086c056cc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487545f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c056cc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c0561d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f086c056cc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f086c056cc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f086c056cc0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474a390> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a390> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01f02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474a390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a390> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f089474a390> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479ee80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f089474a390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947ebf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a390> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474a390> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f089474a390> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a390> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f089474a390> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474a390> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a390> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474a390> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e048> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e048> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c0561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e048> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089479e048> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e048> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e048> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e048> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f089479e048> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089479e048> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e048> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f089479e048> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f089479e048> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e048> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089479e048> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f089479e048> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504274a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427710> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504272b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427710> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427710> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850427710> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487967f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850427710> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427710> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487966d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427710> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487967f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850427710> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504272b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850427710> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504272b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850427710> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850427710> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427710> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504272b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0850427710> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504274a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850427710> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850427710> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850427710> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504272b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0850427710> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e39b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850427710> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850427710> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c056710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056710> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c056710> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c056710> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056710> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056710> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f086c056710> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056710> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c056710> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f086c056710> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f086c056710> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f086c056710> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f086c056710> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01e6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c056710> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c056710> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2940> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f086c056710> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017acc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0644d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0644b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017acc0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b06af828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0644b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b017acc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00362b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017acc0> 0.0 5
Completed Iteration #6
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08f01670f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017acc0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01674e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b017acc0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0644d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0644b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b017acc0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017acc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017acc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00362b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b017acc0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0644d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017acc0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01e6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01674e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b017acc0> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b017acc0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0644ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00362b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b017acc0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017acc0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000ae48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00617b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017ac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000ae48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947ebba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754b38> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01e6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754b38> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754b38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0848754b38> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754b38> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0848754b38> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754b38> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0848754b38> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0848754b38> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0848754b38> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f094903a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08fac214a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08fac214e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08fac214e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08fac214e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08fac214e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08fac214e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947147f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08fac214e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08fac214e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08f0154f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08fac214e0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08fac214a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08fac214e0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08fac214e0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08fac214e0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08fac214e0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947142e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08fac214e0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08fac214e0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947269e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08fac214a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08fac214e0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08fac214e0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08fac214a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08fac214e0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947265f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08fac214e0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08fac214e0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08fac214e0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08fac214e0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947374a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08fac214e0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f094903a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 5
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947265f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 6
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947379b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08f0154f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c0561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947377b8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0198> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01c4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0198> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947ebfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947ebfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0198> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947ebfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0198> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0198> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0198> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0198> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0198> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947ebfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0198> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0198> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0198> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0198> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0198> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0198> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0198> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e2e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0198> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714dd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714dd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894714dd8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714dd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714dd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0894714dd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714dd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714dd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714dd8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714dd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894714dd8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714dd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894714dd8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894714dd8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473dbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473dbe0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473dbe0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473dbe0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473dbe0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089473dbe0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473dbe0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473dbe0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089473dbe0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f089473dbe0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089473dbe0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473dbe0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f089473dbe0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089473dbe0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089473dbe0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00939e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f04a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089473dbe0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00938d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00937f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00937f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093cc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093cc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093cc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093cc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093cc0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093cc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093cc0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093cc0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0093cc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093cc0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093cc0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0093cc0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061e80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0061e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947264a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061e80> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061e80> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f094903a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061e80> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061e80> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0061e80> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00617b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061e80> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061e80> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947264a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0061e80> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0061e80> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0061e80> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0061e80> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0061e80> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061e80> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c04ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0061e80> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487eca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ece48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043da20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011de10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011de10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb5c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bbeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505bb5c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb5c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb5c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb5c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505bb5c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505abc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ecf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505bb5c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505abeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08505bb5c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb5c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505abf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ecb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb5c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ecb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505bb5c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505bb5c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08505bb5c0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505aba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb5c0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505abda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505bb5c0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505abac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bbeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08505bb5c0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505bb5c0> 0.0 20
Completed Iteration #24
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505bb5c0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f2b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085045f2b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085045f2b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ecac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085045f2b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085045f2b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f2b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f2b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085045f2b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085045f2b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487eccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f2b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487eccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085045f2b0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085045f2b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043dac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085045f2b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505aba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f085045f2b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085045f2b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947142e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f2b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f085045f2b0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085045f2b0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947d2550> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2550> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947d2550> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2550> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006e198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947d2550> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947d2550> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947d2550> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006e198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08947d2550> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947d2550> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2550> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2550> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947d2550> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2550> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947d2550> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947d2550> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947d2550> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fb38> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fb38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fb38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b013fb38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b013fb38> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fb38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b013fb38> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fb38> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b013fb38> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fb38> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b013fb38> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505470f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013fb38> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b013fb38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b013fb38> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b013fb38> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b013fb38> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b013fb38> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fce10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fce10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fce10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fce10> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fce10> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504fce10> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504fce10> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504fce10> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fce10> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08504fce10> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fce10> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08504fce10> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08504fce10> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fcda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504fce10> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dccc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08504fce10> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fce10> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504fce10> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504fce10> 0.0 19
Completed Iteration #20
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fce10> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504fce10> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487545f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547ef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547ef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547ef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547ef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547ef0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547ef0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547ef0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547ef0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850547ef0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547ef0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547ef0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487545f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547ef0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a60b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850547ef0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547ef0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487545f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850547ef0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a60b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0850547ef0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0850547ef0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505aba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d6a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085043d6a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487eca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ecb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d6a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d6a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d6a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085043d6a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d6a0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ecc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505aba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085043d6a0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085043d6a0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045ff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085043d6a0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f085043d6a0> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085043d6a0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d6a0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ecb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085043d6a0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085043d6a0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f085043d6a0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085043d6a0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085043d6a0> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505837b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505831d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505831d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505831d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505831d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505831d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505831d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505831d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505837b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505831d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08505831d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505831d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505831d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505831d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08505831d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505831d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505831d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505831d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505837b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08505831d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505831d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877d048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08505831d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08505831d0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b358> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f08505831d0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c550> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505835f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c550> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c550> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c550> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c550> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c550> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084876c550> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084876c550> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c550> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505835f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084876c550> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084876c550> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c550> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084876c550> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084876c550> 0.0 16
Completed Iteration #18
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084876cc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084876c550> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505835f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084876c550> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f084876c550> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583080> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947149b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583080> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583080> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583080> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505470f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947149b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850583080> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850583080> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583080> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583080> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583080> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850583080> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947149b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850583080> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850583080> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850583080> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850583080> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850583080> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0850583080> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583080> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044be48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085044be48> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044be48> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044be48> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487545f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044be48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044be48> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085044be48> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487545f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085044be48> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044be48> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044be48> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085044be48> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044be48> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085044be48> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044be10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085044be48> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085044be48> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044be10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f085044be48> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1630> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1630> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1630> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1630> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb19e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1630> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e416a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1630> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1630> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1630> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1630> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1630> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1630> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1630> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1630> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1630> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1630> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1630> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e530b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e410b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53128> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e412b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53128> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53128> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53128> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53128> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53128> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e530b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53128> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e530b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829e53128> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e530b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0829e53128> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53128> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53128> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53128> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505470f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829e53128> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53128> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01c4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012bc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e41a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e535c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e535c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e535c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e535c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e535c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e535c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e535c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e535c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e535c0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e535c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e535c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829e535c0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293df2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829e535c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293df4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829e535c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e535c0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0829e535c0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293df400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e535c0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829e535c0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0829e535c0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53048> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293df5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293dfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53048> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293df630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53048> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53048> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293dfa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53048> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293dfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53048> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53048> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53048> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53048> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f89b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53048> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829e53048> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0829e53048> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e532b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53048> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293df0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0829e53048> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293dfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf978> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f0829e53048> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293df8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cfbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293cf630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cfbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293cf630> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293cf630> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293cf630> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293cf630> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf630> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01c4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293cf630> 0.0 12
Completed Iteration #13
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293cf630> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293cf630> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cfc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293cf630> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08293cf630> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08fac217b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08293cf630> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293dfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293cf1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08293cf630> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08293cf630> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cfbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08293cf630> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf630> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cfbe0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08293cf630> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583780> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850583780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583780> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583780> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cfdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850583780> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583780> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850583780> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850583780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0850583780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583780> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea60f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850583780> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583780> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850583780> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850583780> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850583780> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850583780> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850583780> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850583780> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b09e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b09e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b09e8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b03c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293b09e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b09e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b09e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b09e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b03c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293b09e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b09e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293b09e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b0a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293b09e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293b09e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b0cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293b09e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293b03c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08293b09e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b09e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293b09e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293b09e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b0cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293b09e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293b09e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b09e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359400> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359400> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359400> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359400> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829359400> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829359400> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829359400> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359400> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359400> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829359400> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359400> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359400> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829359eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829359400> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf6d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293bf6d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf6d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293bff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293bf6d8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293bf6d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf6d8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf6d8> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 2600
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf6d8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf6d8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293bf6d8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01c4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293bf6d8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf6d8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293bf6d8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293a3c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293bf6d8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293bf6d8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293bf6d8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e537b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08293bf6d8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e531d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293df9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e537f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877dc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cfac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cfac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293f8828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293272e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829327400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829327400> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327400> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327400> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293304a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829327400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293306d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829327400> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829327400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829327400> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327400> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327400> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829327400> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829327400> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829327400> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829327400> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0829327400> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327400> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829327400> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293302e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330c50> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330c50> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330c50> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829330c50> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330c50> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829330c50> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829330c50> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293277b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829330c50> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829330c50> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829330c50> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829330c50> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829330c50> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330c50> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829330c50> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829330c50> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829330c50> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0829330c50> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ee10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082936ee10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ef60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082936ee10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ee10> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ee10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ee10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ee10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ee10> 0.0 9
Completed Iteration #8
Best Reward: 0
coverage_call_count 2700
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ee10> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082936ee10> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ef60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082936ee10> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082936ee10> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082936ee10> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082936ee10> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ee10> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea60f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082936ee10> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293df828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327780> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829327780> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829327780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829327780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327780> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829327780> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292822e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327780> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ecc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829327780> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327780> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292824e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829327780> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ecc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0829327780> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829327780> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829327780> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ecc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0829327780> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327780> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829282ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829327780> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829327780> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0829327780> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292822e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829327780> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829327780> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292826d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082928f320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f320> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082928f320> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082928f320> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f320> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928fb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082928f320> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f320> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082928f320> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082928f320> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082928f320> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082928f320> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f320> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082928f320> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b80f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08292b8160> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8160> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8160> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a04e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08292b8160> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8160> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a0d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08292b8160> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8160> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8160> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08292b8160> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08292b8160> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08292b8160> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8160> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8160> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a0d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08292b8160> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b80f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08292b8160> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cb70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cb70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cb70> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293309b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084876cb70> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cb70> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cb70> 0.0 8
Completed Iteration #6
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cb70> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cb70> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084876cb70> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084876cb70> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084876cb70> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084876cb70> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f084876cb70> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cb70> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f084876cb70> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084876cb70> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084876cb70> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a0a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084876cb70> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a0a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084876cb70> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f084876cb70> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084876cb70> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084876cb70> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505146a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547470> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505476d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547470> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547470> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547470> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547470> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487eca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547470> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547470> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505476d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547470> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505147f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547470> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850547470> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bcc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547470> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505abe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850547470> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505476d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0850547470> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0850547470> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547470> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505abc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505abeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505abc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505ab6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505abeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505ab6a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab6a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab6a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505ab6a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab6a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab6a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505ab6a0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab6a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473da90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08505ab6a0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505ab6a0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473da90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08505ab6a0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505ab6a0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045ffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08505ab6a0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505abeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08505ab6a0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00930b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab6a0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505abc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08505ab6a0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08505ab6a0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00932e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00932e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093e80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093e80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00939e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00939b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093e80> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006e828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0093e80> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093e80> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093e80> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00930f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093e80> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0093e80> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093e80> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093e80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b0093e80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505abeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473de48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0093e80> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093e80> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093e80> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006e828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b0093e80> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505abc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093e80> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505aba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505aba90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505aba90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505149e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505aba90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505aba90> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505aba90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505aba90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505aba90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f05c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08505aba90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08505aba90> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505aba90> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dcb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505aba90> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505aba90> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dcb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505aba90> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505aba90> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505aba90> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505aba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505aba90> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505aba90> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08505aba90> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08505aba90> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08505aba90> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08505aba90> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044bcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044bcf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044bcf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044bcf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044bcf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085044bcf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f094903a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044bcf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f0154fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044bcf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085044bcf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f094903a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f0154fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085044bcf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044bcf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085044bcf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085044bcf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f085044bcf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947266a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085044bcf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085044bcf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085044bcf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044bcf8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085044bcf8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f085044bcf8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085044bcf8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08f01671d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714e80> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714e80> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947264a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714e80> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947142e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714e80> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714e80> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b06af780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714e80> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714e80> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714e80> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714e80> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714e80> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894714e80> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f094903a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947143c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714e80> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947142e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714e80> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b06af780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714e80> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947264a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714e80> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f094903a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714e80> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0894714e80> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b06af780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894714e80> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947143c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894714e80> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714e80> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737b00> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737b00> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00930b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947370b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737b00> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894737b00> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737b00> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894737b00> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894737b00> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894737b00> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894737b00> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737b00> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894737b00> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737b00> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894737b00> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894737b00> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0894737b00> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a828> 0.0 2
Completed Iteration #1
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a828> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01e6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a828> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a828> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a828> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a828> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b000a828> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a828> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0644ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a828> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0644ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b000a828> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b000a828> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0644d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a828> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b000a828> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f02e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b000a828> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0644d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b000a828> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f02e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b000a828> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b000a828> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fdb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fdb00> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fdb00> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fdb00> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01f02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08946fdb00> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fdb00> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947ebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08946fdb00> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947ebf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fdb00> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474ab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08946fdb00> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08946fdb00> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fdb00> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08946fdb00> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947926d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08946fdb00> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474ab00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08946fdb00> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08946fdb00> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fdb00> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08946fdb00> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08946fdb00> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0036b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c0564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036b00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0036b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c0564e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0036b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c0564e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0036b00> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947ebd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036b00> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036b00> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c0564e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b0036b00> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036b00> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c0564e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08b0036b00> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0036b00> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947ebd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0036b00> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0036b00> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479ec50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0036b00> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0036b00> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0036b00> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01445c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01445c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b06448d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01445c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947ebba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01445c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01445c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b06448d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01445c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01445c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01445c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01445c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01445c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01445c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01445c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01445c0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08fac983c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01445c0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fdf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01445c0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b01445c0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01445c0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b01445c0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b01445c0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b01445c0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947265f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505149e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947265f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947265f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947265f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947265f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947265f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947265f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947265f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487467b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947265f8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487467b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947265f8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947265f8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487463c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947265f8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947265f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947265f8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504279e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08947265f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504274a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947265f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504277b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947265f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947265f8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504275f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487960f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487960f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487960f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b068d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487960f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487960f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487960f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08487960f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947379b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487960f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08487960f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487967f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08487960f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487960f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08487960f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08487960f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08d400e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08487960f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487967f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08487960f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487967f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08487960f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08487960f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08487960f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f518> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082928f518> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292827f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f518> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01517b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082928f518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f518> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082928f518> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487960f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f518> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928fe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082928f518> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fcbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082928f518> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504279e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082928f518> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947379b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082928f518> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f518> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082928f518> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082928f518> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928fe80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082928f518> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928fe80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f082928f518> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487465c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504276a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487465c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504270b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504276a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504276a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473d198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 21
Completed Iteration #21
Best Reward: 0
coverage_call_count 3200
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0644d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504276a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292822b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947ebdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056438> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c056438> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056438> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c056438> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056438> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c056438> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f086c056438> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056438> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f086c056438> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c056438> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c056438> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f086c056438> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f086c056438> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292824a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea67f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6c50> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292824a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6c50> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6c50> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292824a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6c50> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293df320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6c50> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6c50> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6c50> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293dfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6c50> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293dfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6c50> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293df0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea67f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6c50> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293df9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6c50> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08fac217b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea67f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6c50> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293df630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6c50> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293dfe80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293dfe80> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293dfe80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293dfe80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293dfe80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293dfe80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293dfe80> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293dfe80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00616a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293dfe80> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293dfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bcc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293dfe80> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293df5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293dfe80> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293dfe80> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293dfe80> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293dfe80> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293dfe80> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293dfe80> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08293dfe80> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293dfe80> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bcc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293dfe80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01e6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293df710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cfda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cfda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829282f28> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504274a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cfda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829282f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282f28> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829282f28> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cfda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0829282f28> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282f28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293592b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293597f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282f28> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282f28> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504274a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829282f28> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293597f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829282f28> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829282f28> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829282f28> 0.0 17
Completed Iteration #19
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829282f28> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504274a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829282f28> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282f28> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cfda0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0829282f28> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829282f28> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb15c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293595f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb15c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb15c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb15c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb15c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e415f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb15c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e418d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829eb15c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb15c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829eb15c0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb15c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829eb15c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829eb15c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829eb15c0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb15c0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829eb15c0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0829eb15c0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829eb15c0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e3c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e3c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e3c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082936e3c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082936e3c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082936e3c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082936e3c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e3c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e3c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e3c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e3c8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082936e3c8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ee10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082936e3c8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082936e3c8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293591d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082936e3c8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936efd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082936e3c8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ee10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f082936e3c8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082936e3c8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487549e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487545c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0644b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a90> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505149e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a90> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293dfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293dfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a90> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947ebdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505149e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829359940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a90> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a90> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a90> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293dfc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a90> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a90> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a90> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c8d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a90> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a90> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293dfc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e414e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e414e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e414e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e414e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e414e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487467b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829e414e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b0588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e414e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e414e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e414e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b0588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829e414e0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e414e0> 0.0 12
Completed Iteration #15
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0829e414e0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df2b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0829e414e0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e414e0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e414e0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b0588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0829e414e0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293df080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947d2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e414e0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012bda0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012bda0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012bda0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b012bda0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012bda0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b012bda0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b012bda0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b012bda0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012bda0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012bda0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b012bda0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012bda0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012bda0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b012bda0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012bda0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b012bda0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043dd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b012bda0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b012bda0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08b012bda0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b012bda0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4908> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f08b012bda0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b012bda0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e532b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293f8198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504274a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c46a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082936e2e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e2e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e2e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082936e2e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e2e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082936e2e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293dff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e2e8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082936e2e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e2e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f89b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082936e2e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3828> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f082936e2e8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293dff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082936e2e8> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487467b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082936e2e8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061d68> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061d68> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061d68> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061d68> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061d68> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0061d68> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0061d68> 0.0 8
Completed Iteration #13
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0061d68> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061d68> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0061d68> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061d68> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e415c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0061d68> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b0061d68> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e415f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061d68> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877df98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877df98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877df98> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877df98> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084877df98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084877df98> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877df98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877df98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084877df98> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084877df98> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084877df98> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f084877df98> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877df98> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084877df98> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f084877df98> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877df98> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084877df98> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327860> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f084877df98> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f084877df98> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b85c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084877df98> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829327dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829327dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829327dd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829327dd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829327dd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327dd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327dd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327dd8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829327dd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3ab70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0829327dd8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327dd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829327dd8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829327dd8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cfc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829327dd8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3ab70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0829327dd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293271d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293271d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293271d0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293271d0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293dff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a62e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293271d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293271d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293271d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a62e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08293271d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293271d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293271d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0644b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293271d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08293271d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a62e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08293271d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293271d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293271d0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293271d0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4c18> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4c18> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08292c4c18> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4c18> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4c18> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4c18> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4c18> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08292c4c18> 0.0 9
Completed Iteration #11
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08292c4c18> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08292c4c18> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08292c4c18> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08292c4c18> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4c18> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08292c4c18> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4c18> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285858d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08292c4c18> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4c18> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b02b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b02b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293b02b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b02b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b02b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b02b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293b02b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877dc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293b02b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b02b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877dc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08293b02b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b02b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293b02b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828585dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293b02b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293b02b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293b02b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285b3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f92b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293b02b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285858d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2400> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285a2400> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2400> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2400> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285a2400> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2400> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285a2400> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285a2400> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08285a2400> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2400> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285a2400> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2400> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f95c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285a2400> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0644b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6fd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6fd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293df2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6fd0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6fd0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285b31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6fd0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6fd0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6fd0> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285b36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6fd0> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6fd0> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285585c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285588d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3cc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3cc0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3cc0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285588d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285b3cc0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285654e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285585c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285b3cc0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3cc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3cc0> 0.0 10
Completed Iteration #12
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285b3cc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285b3cc0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3cc0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285588d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08285b3cc0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285b3cc0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a588> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a588> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082857a588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a588> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082857a588> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a588> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082857a588> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a588> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a588> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082857a588> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285154a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082857a588> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857ac88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082857a588> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a588> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285159e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857ac88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082857a588> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082857a588> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082857a588> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082857a588> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285657f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285583c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285657f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285657f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285657f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285657f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285657f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285587b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285657f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285588d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285657f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285b39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285657f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285657f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285657f0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487545c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08285657f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08285657f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285657f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08285657f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285657f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08285657f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285587b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285657f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285b38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285858d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558e10> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828558e10> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828558e10> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828515a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558e10> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828515a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828558e10> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828558e10> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828558e10> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828558e10> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828558e10> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3af60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828558e10> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828558e10> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828558e10> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0828558e10> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828515b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8550> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8550> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828515b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c8550> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8550> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8550> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8550> 0.0 7
Completed Iteration #9
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c8550> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c8550> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c8550> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8550> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c8550> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285582e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8550> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284c8550> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c8550> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285158d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8550> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284c8550> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284c8550> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828515b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284c8550> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285157b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4c88> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f17f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284d4c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4c88> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284d4c88> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4c88> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4c88> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284d4c88> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284d4c88> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4c88> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284806d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08284d4c88> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284d4c88> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284d4c88> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284d4c88> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08284d4c88> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08284d4c88> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4c88> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284d4c88> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1748> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f08284d4c88> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3acc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828a3acc0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3acc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3acc0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828a3acc0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828a3acc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3acc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828a3acc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285157f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3acc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3acc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3acc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3acc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3acc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a21d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828a3acc0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828a3acc0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285157f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828a3acc0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828a3acc0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a21d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828a3acc0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828a3acc0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828a3acc0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828a3acc0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285b3fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3fd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285b3fd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3fd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3fd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3fd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3fd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285b3fd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08285b3fd0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285b3fd0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08285b3fd0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285b3fd0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08285b3fd0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480da0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828480da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480da0> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 3900
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b22b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828480da0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480da0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828480da0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480da0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284490f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b22b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0828480da0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284495f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284495c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480da0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828480da0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828480da0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828480da0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828480da0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284495c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828480da0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480da0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284595c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459048> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284595f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459048> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b27f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828459048> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284595c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828459048> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459048> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828459048> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284590f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459048> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459048> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284596d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459048> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828459d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828459048> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459048> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284596d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828459048> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828459048> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828459048> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828459048> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2a58> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2a58> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2a58> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2a58> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284b2a58> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b87b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284b2a58> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2a58> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284598d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2a58> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284b2a58> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284b2a58> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284b2a58> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285157f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2a58> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857ab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284b2a58> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01f01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c81d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c81d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285b3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c81d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828515e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c81d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c81d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828469240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285850f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c81d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828515e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c81d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285583c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c81d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284802b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285850f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c81d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c81d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c81d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c81d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285583c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c81d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285a2978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c81d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c81d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284691d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285850f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284c81d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828469908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284c81d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828469ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c81d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828469c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285850f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08284c81d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585748> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585748> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828585748> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284247f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585748> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828469f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585748> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284249e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585748> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585748> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284247f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828585748> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585748> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284302b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828585748> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284304a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828585748> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284309b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585748> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828430eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284247f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828585748> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828430f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828585748> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284308d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284304a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828469fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828585748> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284303c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828585748> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7048> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293df2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7048> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7048> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7048> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7048> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7048> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7048> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7048> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7048> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc75f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7048> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7048> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7048> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7048> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7048> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284490f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7048> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7048> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7048> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7048> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828515c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2470> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828469160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284b2470> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828430cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284b2470> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285b31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284305c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2470> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284302e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284b2470> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284303c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08284b2470> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828430860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828515c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284b2470> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828430b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2470> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2470> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284305c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284b2470> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828430518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284245f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2470> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284b2470> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284b2470> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284b2470> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08284b2470> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828469908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0644b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284249b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1a58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284241d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1a58> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1a58> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828430d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1a58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284f1a58> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284f1a58> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284f1a58> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284f1a58> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284f1a58> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284f1a58> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1a58> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284f1a58> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284f1a58> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284f1a58> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f896a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 4100
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbef0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbef0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbef0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbef0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbef0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbef0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbef0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbef0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbef0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284246d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc75c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbef0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc75c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbef0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbef0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbef0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89128> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc77f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f89128> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89128> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89128> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284305f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f89128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f89128> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f89128> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89128> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284695f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284307f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828430f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f89128> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284697f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f89128> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f89128> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f89128> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0827f89128> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828469160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f89128> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f89128> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430d30> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284241d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828430d30> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430d30> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9cdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828430d30> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430d30> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f48240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828430d30> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828430d30> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f48668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430d30> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f48828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828430d30> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828430d30> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828430d30> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f48a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828430d30> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0828430d30> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f48dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b208> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b208> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f48e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b208> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f684a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b208> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f68668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b208> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f689e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b208> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b208> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f68c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b208> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f68160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b208> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b208> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5ba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b208> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f68f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e3c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828469710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e3c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e3c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e3c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f68128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e3c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e3c8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e3c8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e3c8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f68470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5bf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e3c8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e3c8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e3c8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e3c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f18278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e3c8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5bf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e3c8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f68ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f18278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e3c8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f684a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f18278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e3c8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f681d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e3c8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f68240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e3c8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f68a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68898> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68898> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68898> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68898> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f68898> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68898> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f68898> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285584a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f68898> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7ea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f68898> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f68898> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68898> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68898> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285587f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7ee48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f68898> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7ea20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0827f68898> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f68898> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f685c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f68898> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f68898> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f68550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f68898> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285580b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285580b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285580b8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285580b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285580b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285580b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285580b8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285580b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285580b8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285580b8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285580b8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285580b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08285580b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08285580b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08285580b8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08285580b8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285580b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ecda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ecda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08487ec240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08487ec240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ecda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08487ec240> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec240> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08487ec240> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec240> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec240> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec240> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec240> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08487ec240> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293276d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec240> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08487ec240> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08487ec240> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08487ec240> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 29.166666666666668
coverage_call_count 4300
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53ef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53ef0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53ef0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e534a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53ef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53ef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53ef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53ef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53ef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53ef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53ef0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53ef0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53ef0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829e53ef0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0829e53ef0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829e53ef0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829e53ef0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53ef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53ef0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf588> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293cf588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293cf588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf588> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf588> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293cf588> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf588> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08487ec940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293cf588> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293cf588> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08293cf588> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293cf588> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293cf588> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293cf588> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293cf588> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf588> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043dd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293cf588> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f68080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f685c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f68780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68780> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f68780> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f685c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f68780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f68780> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f68780> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68780> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68780> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e417b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f68780> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f685c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0827f68780> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0827f68780> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68780> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68780> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f68780> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f68780> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53cc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53cc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53cc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53cc0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53cc0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e416d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53cc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293599e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53cc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829e53cc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829e53cc0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829e53cc0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53cc0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293590b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53cc0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293595c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53cc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53cc0> 0.0 18
Completed Iteration #22
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bfba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53cc0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829e53cc0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53cc0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1f60> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b013ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1f60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1f60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1f60> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293df278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1f60> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1f60> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1f60> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1f60> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1f60> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b013f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1f60> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1f60> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293592e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1f60> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1f60> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1f60> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1f60> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f689b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f685c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285587f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e415c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293276d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9940> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9940> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9940> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9940> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ecbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9940> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293dfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9940> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293df4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ecbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285f9940> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285f9940> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285f9940> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293276d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285f9940> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08285f9940> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ecbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08285f9940> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9940> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487ec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9940> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08285f9940> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08285f9940> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293dfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9940> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e53208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285f9940> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f68080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293276d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08285f9940> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd208> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd208> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd208> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504277f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd208> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292829b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd208> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292823c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd208> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd208> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd208> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487962e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd208> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd208> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd208> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd208> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd208> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01e6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c0568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848796a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01e6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292826d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01e6cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829282390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292824a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c0561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c0561d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01e6cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c0568d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08fac214e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850514400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0036d68> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc668> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc668> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947bc668> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947bc668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc668> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293dfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293df780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947bc668> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc668> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947bc668> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947bc668> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08947bc668> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947bc668> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc668> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08947bc668> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293276d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08947bc668> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df780> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f08947bc668> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151c18> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487461d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151c18> 0.0 3
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151c18> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151c18> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0151c18> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151c18> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151c18> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0151c18> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0151c18> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0151c18> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b0151c18> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947ebfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0061dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0151c18> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0151c18> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0151c18> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0151c18> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0151c18> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a0b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474a0b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a0b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a0b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a0b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474a0b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a0b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f089474a0b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474a0b8> 0.0 12
Completed Iteration #14
Best Reward: 0
coverage_call_count 4600
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a0b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f089474a0b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474a0b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a0b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474a0b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474a0b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089474a0b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf2b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293bf2b0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf2b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf2b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf2b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf2b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf2b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293dfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf2b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293bf2b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f686d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293bf2b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293dfa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293bf2b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293bf2b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293bf2b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504a6b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293bf2b0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293bf2b0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08293bf2b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487549e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f686d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293bf2b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01670f0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947269e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01670f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947264e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01670f0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947264e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08f01670f0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947268d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08f01670f0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01670f0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08f01670f0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01670f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08f01670f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089479e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01670f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01670f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08f01670f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0036cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01670f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08f01670f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08f01670f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08f01670f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08f01670f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01670f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08f01670f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947146d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b940> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b940> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00ffba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b940> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085041b940> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085041b940> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00e3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085041b940> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b940> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085041b940> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085041b940> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085041b940> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085041b940> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505abeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085041b940> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085041b940> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00939b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085056ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085041b940> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f09b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f09b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f09b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00fffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f09b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f09b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504f09b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504f09b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00932e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f09b0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504f09b0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f09b0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f09b0> 0.0 12
Completed Iteration #10
Best Reward: 0
coverage_call_count 4700
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504f09b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504f09b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08504f09b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08504f09b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504f09b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08504f09b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505ab9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947269e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08f01674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947bc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850547be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041bbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ecc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dcf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ecc0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ecc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ecc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ecc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fcbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b006ecc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ecc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b006ecc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b006ecc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fcbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b006ecc0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b006ecc0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b006ecc0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b006ecc0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006ecc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b006ecc0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b006ecc0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f550> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f550> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f550> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f550> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082928f550> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f550> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f550> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f550> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850583b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f550> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f550> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a0a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082928f550> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082928f550> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829330dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082928f550> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a0c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082928f550> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947264a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082928f550> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082928f550> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f082928f550> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082928f550> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505830b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a09e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829330ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828515550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828515da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828515550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829330ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505830b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829330ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330ba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 4800
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828515550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829330ba8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330ba8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330ba8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829330ba8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330ba8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829330ba8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330ba8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08f01674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293dfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947268d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894726c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947264a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829330908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b011d780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285152e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d780> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b011d780> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b011d780> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d780> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d780> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d780> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285152e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b011d780> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284497b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828515860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d780> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d780> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f48fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d780> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285152e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b011d780> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f48b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828515860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b011d780> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f48860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b011d780> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f48128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284496a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b011d780> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b011d780> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f48240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565940> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565940> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565940> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565940> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285659e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828565940> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565940> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828565940> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828565940> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565940> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828565940> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565940> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828565940> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565940> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284490f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828565940> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f48e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828565940> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828565940> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285659e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828565940> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828585cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585cf8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828585cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828585cf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585cf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585cf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f48f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828585cf8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f48208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585cf8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828585cf8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828585cf8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828585cf8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585cf8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828585cf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9cc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828585cf8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828585cf8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0828585cf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f485c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285156d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285156d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08f01674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285156d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01674e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828449b00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293309b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f485c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585e48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828585e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828585e48> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585e48> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585e48> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828585e48> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585e48> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585e48> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828585e48> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828585e48> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585e48> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585e48> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828585e48> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828585e48> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c8f28> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8f28> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285b3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8f28> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285b3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284c8f28> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f895f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8f28> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8f28> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285b3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8f28> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285b3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8f28> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c8f28> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c8f28> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c8f28> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8f28> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284c8f28> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f895f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c8f28> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c8f28> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f898d0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08f01674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f898d0> 0.0 3
Completed Iteration #3
Best Reward: 0
coverage_call_count 5000
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848796d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f898d0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f898d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f898d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284248d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f898d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01670f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f898d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293dfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f898d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f890f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f898d0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285b3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01670f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f898d0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284240f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f898d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f898d0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f898d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947268d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f898d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0827f898d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f898d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285b35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285157b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828469dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585a58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284490b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585a58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585a58> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828469a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585a58> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585a58> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828585a58> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585a58> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828469160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828585a58> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828585a58> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5bb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828585a58> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828585a58> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828585a58> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828585a58> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0828585a58> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284807f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2c18> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284b2c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828469438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2c18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284b2c18> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284698d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2c18> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284b2c18> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08284b2c18> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08284b2c18> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2c18> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828430a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284b2c18> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828430ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284b2c18> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284b2c18> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284b2c18> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828430128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b25f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284b2c18> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480630> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f08284b2c18> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284599e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284300f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284599e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284594e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828430898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284300f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828430c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284307b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284300f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828430cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 20
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 21
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284599e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 22
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 23
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 24
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284599e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 25
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 26
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459160> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f0828459d30> 0.0 27
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 29.166666666666668
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285156d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828430f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449198> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828449198> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449198> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828449198> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449198> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449198> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828469588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828449198> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828469dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828449198> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828449198> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449198> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828449198> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828469080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449198> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828469748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449198> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828449198> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f13c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828449198> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08f01674e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0828449198> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f13c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0828449198> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285b3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828449198> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828469978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c84a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f898d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c84a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c84a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c84a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c84a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c84a8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947268d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c84a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828469160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c84a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c84a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c84a8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c84a8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c84a8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c84a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c84a8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284c84a8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284c84a8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c84a8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08284c84a8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08284c84a8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f89390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284c84a8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08284c84a8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a518> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a518> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082857a518> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082857a518> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f18390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc71d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082857a518> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082857a518> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082857a518> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f18470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a518> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f18860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a518> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f18978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f18940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a518> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f18e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082857a518> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f18ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082857a518> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082857a518> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f18940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082857a518> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f187f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082857a518> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f18f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f187b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857ad68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857ad68> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f18d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082857ad68> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f18eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f18fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857ad68> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f18b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f188d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857ad68> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947268d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082857ad68> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857ad68> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857ad68> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f187b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082857ad68> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082857ad68> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082857ad68> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f082857ad68> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f18710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857ad68> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f18fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082857ad68> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 5200
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082857ad68> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285b3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285156d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d68> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d68> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d68> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d68> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d68> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d68> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828469470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f16d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d68> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f18978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d68> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285156d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d68> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0644d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d68> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d68> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d68> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857ae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d68> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d68> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857ae10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b0093d68> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01670f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469b00> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469b00> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469b00> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469b00> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d22e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828469b00> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827181080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469b00> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827181438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828469b00> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271815f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469b00> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f01670f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828469b00> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d2518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828469b00> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d22e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828469b00> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827181978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828469b00> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827181198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828469b00> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827181c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d2908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828469b00> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827181e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828469b00> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469b00> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827181fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828469b00> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181ba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827181ba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827181588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181ba8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827181208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181ba8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827181ba8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827181ba8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827181b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181ba8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181ba8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271a0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181ba8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271a0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827181ba8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271a08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827181ba8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827181ba8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827181ba8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181da0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181da0> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181da0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181da0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181da0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d2438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827181da0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181da0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181da0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f18390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181da0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827181da0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285b35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827181da0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828469438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827181da0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827181080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827181da0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181da0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827181da0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827181da0> 0.0 17
Completed Iteration #21
Best Reward: 0
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827181da0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285b3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827181da0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271a0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0908> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271a0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0908> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0908> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0908> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271814e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0908> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271a0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0908> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0908> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850427b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08271a0908> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f18e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08271a0908> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a07b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08271a0908> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827181470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a04e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08271a0908> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08271a0908> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0908> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08271a0908> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08271a0908> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08271a0908> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08271a0908> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08271a0908> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08271a0908> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827164198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714ff98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827164320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271642e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714ff98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271642e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082714ff98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714ff98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827164668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714ff98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827164080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271641d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714ff98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827164908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714ff98> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827164b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714ff98> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827164d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714ff98> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827164f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827171160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714ff98> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271649e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827171160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082714ff98> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827164400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271648d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082714ff98> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271642e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082714ff98> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271648d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082714ff98> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082714ff98> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082714ff98> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271a04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082714ff98> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082714ff98> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827164710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827171160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082714ff98> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271642e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082714ff98> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827171160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082714ff98> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827171630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827171390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827171390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827171390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827171eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827171390> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827171390> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827171390> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827171390> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827171390> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271719b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827171390> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827171630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827171390> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827171390> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827171eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827171390> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827171390> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271719b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827171390> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827171860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08271719b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827171390> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271719b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0827171390> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827171630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827171390> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827164b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0827171390> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827164c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827171390> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271645f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271649b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271649b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271649b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08271649b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08271649b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08271649b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b017ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271649b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827164198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271649b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08271649b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271649b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08271649b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827164f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08271649b0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08271649b0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271715c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271649b0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08271649b0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08271649b0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271a0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08271649b0> 0.0 18
Completed Iteration #17
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271a00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08271649b0> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08271649b0> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271649b0> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f186a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271649b0> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271715c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08271649b0> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08271649b0> 0.0 24
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827164dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164438> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f08271649b0> 0.0 25
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827181240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f278> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f278> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f278> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082718f278> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f278> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f278> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082718f278> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827181d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082718f278> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f278> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082718f278> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f278> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f278> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082718f278> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082718f278> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270cf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711ff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082718f278> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f18128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082718f278> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271814e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271a0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d2908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082710f198> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f198> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270cf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082710f198> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270cff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f198> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cf3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082710f198> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f198> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f198> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270cff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f198> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082710f198> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270e5eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270e5eb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5eb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270e5eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270e5eb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270e5eb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270cf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5eb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5eb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270cf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270e5eb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270cf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270e5eb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270e5eb8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08270e5eb8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e56a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270e5eb8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270e5eb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270cf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270cf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4240> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270f4240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cfba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270f4240> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270f4240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08270f4240> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270f4240> 0.0 13
Completed Iteration #14
Best Reward: 0
coverage_call_count 5500
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270f4240> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285b3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cfba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270f4240> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271a0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08270f4240> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cf9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270f4240> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cf9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270f4240> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cfba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08270f4240> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711feb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711feb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711feb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827164f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082711feb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827164438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711feb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082710f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082711feb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711feb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270ab048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082711feb8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270ab208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711feb8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270ab550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082711feb8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082711feb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f18128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082711feb8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711feb8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270cfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827164eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082711feb8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082711feb8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270ab3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082711feb8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270ab7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082711feb8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082711feb8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270aba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082711feb8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270ab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164eb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f082711feb8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270abda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711feb8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270ab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270becc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270bee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270bef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270bef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270beb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827051908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827051ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270beef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827051a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270beef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827051898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827051cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827062080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827062400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827062588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0850427b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062198> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271814e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062198> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827062198> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827171e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062198> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827164cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062198> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827062198> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827062198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0827062198> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0827062198> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827062198> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271a0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062198> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271641d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164668> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f0827062198> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164668> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f0827062198> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270cfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827062198> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270cf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827062198> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270cf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827062198> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270ab4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270ab940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270aba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270becf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270abb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270abd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270aba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 8
Completed Iteration #11
Best Reward: 0
coverage_call_count 5600
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827051e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270becf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270abd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270abef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270aba90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827051198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827051748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827051cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827051ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270becf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828469be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270ab668> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270bed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827051f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827051320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270be4a8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270abba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be4a8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827051b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be4a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270cfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270bed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270be4a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827062748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be4a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827062c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be4a8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827062e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be4a8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be4a8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827062f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be4a8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270be4a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270be4a8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270be4a8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270be4a8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270be4a8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270629e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08270be4a8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270be4a8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701ad68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701ad68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082701ad68> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082701ad68> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701ad68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701ad68> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701ad68> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701ad68> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082701ad68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701ad68> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082701ad68> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827062668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827051588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701ad68> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082701ad68> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082701ad68> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702bdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082701ad68> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270629e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082701ad68> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270623c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082701ad68> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062710> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827062b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827062710> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827051128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062710> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827051320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270512b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062710> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827051cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827062710> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062710> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270abeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062710> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827051390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062710> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827062eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827051390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827062710> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270ab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270512b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827062710> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062710> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270cfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827062710> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270ab7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827062710> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062710> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827051390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827062710> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271a0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270510b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827062710> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270385f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827062710> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270388d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270ab2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270388d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827038630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038630> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270388d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827038630> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038630> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038630> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270621d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827038630> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827038630> 0.0 11
Completed Iteration #9
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827038630> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826be1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827038630> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826be1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827038630> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270abb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038630> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827062cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270388d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0827038630> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826be1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270388d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0827038630> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826be19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038630> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826be1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827038630> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826be1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827038630> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826be1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf60f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b892b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b895f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf60f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b897b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf60f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b89748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b891d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b89be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf68d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b89da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b89f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826be1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be14e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be17f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b89208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be17f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b89cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be17f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b896a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826be17f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826be17f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be17f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826be17f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be17f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b9ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826be17f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b9bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be17f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b9be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826be17f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be17f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826be17f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b89550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826be17f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b89be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9ba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826be17f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b895f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826be17f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826be17f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b89940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826be17f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b89f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826be17f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826be1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826be1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b438> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826be1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b438> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b438> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b89630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b438> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827051f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b438> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827051cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b438> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b438> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b438> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b438> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b438> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b89438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b438> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b89278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b438> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270bea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b438> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b438> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827051390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b438> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b438> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be13c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be13c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be13c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be13c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be13c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be13c8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826be13c8> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 5800
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827062dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826be13c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827062940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826be13c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270628d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826be13c8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270aba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827038128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826be13c8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be13c8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b55048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b55278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be13c8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826be13c8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b55780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826be13c8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b55940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826be13c8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b55b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a668> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826be13c8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701aac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826be13c8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b55a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826be13c8> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be13c8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b55f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826be13c8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b620b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62128> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62128> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62128> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827062f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62128> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b55588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62128> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b55400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62128> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b55400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b62128> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62128> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b62128> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b79160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b62128> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b62128> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b629b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b55b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62128> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b790f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62128> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b796a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9bba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b62128> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b79860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b620b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b62128> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b62128> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b79e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b793c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79978> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b79978> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b79978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b79e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b799b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79978> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b796a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b79f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826b79978> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b799b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b79978> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b621d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270abcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79978> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b629b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b79978> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b79898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b79978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b79978> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b55c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79978> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b79978> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b79978> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b79978> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b79c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b794a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b790b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b790b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b55ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b790b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b55cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b55dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b790b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b55080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b790b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b55cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b790b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b790b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270389e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b790b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270386d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b790b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b790b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b89d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270386d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b790b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271a04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b55208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b790b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b55208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b790b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b79208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b55dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b790b8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b55dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b790b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b790b8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826be1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b790b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826b790b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b794a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b790b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
coverage_call_count 5900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038780> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826be1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038780> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827038780> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038780> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038780> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827038780> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038780> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038780> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827038780> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827038780> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827038780> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b89630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0efd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827038780> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b79080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf68d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827038780> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0eac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0eac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b3da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0eac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b3dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0eac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b3df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0eac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b3dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b0eac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b0eac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b0eac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3dcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b0eac8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0eac8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ad37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ef98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b0eac8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b0eac8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ef98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826b0eac8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b0eac8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ae75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b0eac8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0eac8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad35f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b0eac8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0eac8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ae79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b0eac8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7390> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ae73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7390> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7390> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7390> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7390> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504a6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7390> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ae78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7390> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7390> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ae79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7390> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894737278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7390> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7390> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ad30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7390> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7390> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7390> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7390> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad35f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7390> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ad36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894737208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3048> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3048> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ad38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3048> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3048> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3048> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3048> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3048> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3048> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f40b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3048> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3048> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3048> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3048> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3048> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3048> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f40b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3048> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ae7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ae75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ae75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3c18> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 6000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3c18> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3c18> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3c18> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3c18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3c18> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0644d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ae75c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3c18> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f46d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3c18> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3c18> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f46d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3c18> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3c18> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3c18> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3c18> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3c18> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3c18> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947268d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726dd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894726dd8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726dd8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726dd8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894726dd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726dd8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894726dd8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894726dd8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894726dd8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894726dd8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894726dd8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0644f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894726dd8> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947260f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894726dd8> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894726dd8> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0894726dd8> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857ad68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894726dd8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc73c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894726dd8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0894726dd8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285a2588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2588> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08285a2588> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285a2588> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2588> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2588> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2588> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0644f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2588> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285a2588> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08285a2588> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffbcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08285a2588> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284f1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285a2588> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ad38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285a2588> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2588> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827ffb7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285a2588> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082718f668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f668> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284f14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d2c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082718f668> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082718f668> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082718f668> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d2c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082718f668> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082718f668> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082718f668> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285a2ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082718f668> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f668> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082718f668> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082718f668> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d2c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082718f668> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082718f668> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711f208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082718f668> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ae75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d2c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f082718f668> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 29.166666666666668
coverage_call_count 6100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284592b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284594e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270e5ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284592e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270e5ef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270e5ef0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270e5ef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5ef0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5ef0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284594e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270e5ef0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270e5ef0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e56a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270e5ef0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284594e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270e5ef0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5ef0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285b3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5ef0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270e5ef0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270e5ef0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270e5ef0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270e5ef0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459b00> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459b00> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828459b00> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459b00> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487549e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459b00> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459b00> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850547f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487549e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828459b00> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828459b00> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285850f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828565ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828459b00> 0.0 10
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08487549e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828459b00> 0.0 11
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285b3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459b00> 0.0 12
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285b3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459b00> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 239
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284597b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ae72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c84e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271d2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284597b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285b3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284592e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284c8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c84e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877d438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 240
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270f4d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4d68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4d68> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4d68> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270f4d68> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4d68> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270f4d68> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827fc72e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270f4d68> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270f4d68> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270f4d68> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08270f4d68> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270f4d68> 0.0 17
Completed Iteration #23
Best Reward: 0
coverage_call_count 6200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270f4d68> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828515c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f4d68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 241
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293306a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285157b8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285157b8> 0.0 3
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285157b8> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828515e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285157b8> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285157b8> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828515e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285157b8> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285157b8> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285157f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285157b8> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08285157b8> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285157b8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285157f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285157b8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a0320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285157b8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285157f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08285157b8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085044b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285157b8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285157b8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08285157b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b006ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285157b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 242
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f780> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947147f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505abda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947147f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085045f780> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894714668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085045f780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f780> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085045f780> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473da90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085045f780> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a0668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085045f780> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085056c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a0668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085045f780> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011d7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085045f780> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f780> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473da90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f085045f780> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b017a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f780> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085045f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00ff7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085045f780> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085045f780> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 243
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c04a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006eb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828515a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006eb70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828515a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b006eb70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006eb70> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089473d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006eb70> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00932e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b006eb70> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894714ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b006eb70> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085044bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504bc8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b006eb70> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505835f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006eb70> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293305f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828515a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b006eb70> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505835f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b006eb70> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006eb70> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006eb70> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082711f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828515a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08b006eb70> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b006eb70> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293a30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b006eb70> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505835f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b006eb70> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 244
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293306a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848754f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270e5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d2a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c8d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8d68> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284597b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8d68> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293b0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a0e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08271d2a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284c8d68> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b000a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8d68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848754f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270e5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c8d68> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c8d68> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284c8d68> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828565320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c8d68> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284c8d68> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 6300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271d2a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08284c8d68> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 245
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711fbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082711fbe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711fbe0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947375f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711fbe0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082711fbe0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089479e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711fbe0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711fbe0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711fbe0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b00a5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711fbe0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082711fbe0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082711fbe0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711fbe0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082711fbe0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082711fbe0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293274a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082711fbe0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b06af780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0894792160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082711fbe0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082711fbe0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f6d8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f082711fbe0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08946fd7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082711fbe0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504275f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828449518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082711fbe0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 246
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ec2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd278> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd278> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd278> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292824a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd278> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292824a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd278> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b016a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd278> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505140b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292828d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd278> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292824a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd278> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0061198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292828d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd278> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085041b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd278> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd278> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0151550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd278> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd278> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd278> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08487ece48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292828d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd278> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504cf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089474a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd278> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08b01dd278> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 247
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08946fd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293277f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084876ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293277f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293277f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828585550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eba90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947140b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08947eb0b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 248
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877dda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082857ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877dda0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00937f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877dda0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292b8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826ad3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284d4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084877dda0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827fc7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828515208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877dda0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c04aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084877dda0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828449ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877dda0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877dda0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293279e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877dda0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505ab9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084877dda0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877dda0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270f4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084877dda0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0894792080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293279e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084877dda0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285150f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828515208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084877dda0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cfe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084877dda0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b00361d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504f0048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084877dda0> 0.0 17
Completed Iteration #18
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f084877dda0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b011ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084877dda0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f084877dda0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c056198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f084877dda0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 249
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea61d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c0561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea61d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829ea61d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea61d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea61d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea61d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829ea61d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829ea61d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829ea61d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea61d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293599e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293592b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea61d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0829ea61d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293df828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829ea61d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293dfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0829ea61d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293df0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936e208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0829ea61d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea61d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0829ea61d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293592b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829ea61d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082936ea58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0829ea61d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 250
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947927f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f47b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01fe2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f47b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f084877dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f47b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504bc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f47b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082857a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f47b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292b8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f47b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b011ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01e6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f47b8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0848746c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270f47b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850583320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01f0080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270f47b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828565320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01e6d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270f47b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284d4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08947bc6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270f47b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285a2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293a3cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270f47b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b01e6d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270f47b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0848746780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270f47b8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947eba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f086c056a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270f47b8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 251
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829327ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cfd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829330400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cfd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cfd30> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cfd30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cfd30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cfd30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cf4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504cfd30> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293dfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cfd30> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504cfd30> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082928f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504cfd30> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504cfd30> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504cfd30> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828585550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504cfd30> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08504cfd30> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082718f9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08504cfd30> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cfd30> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 252
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473da58> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473da58> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473da58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089473da58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473da58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089473da58> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b016a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089473da58> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473da58> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f089473da58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473da58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089473da58> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f089473da58> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473da58> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 6500
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473da58> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284d4c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f089473da58> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f089473da58> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dc4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f089473da58> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f089473da58> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cfbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089473da58> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f089473da58> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 253
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4f28> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4f28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08292c4f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e530b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08292c4f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08292c4f28> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f18c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f18ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4f28> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08292c4f28> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292c4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f18470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4f28> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0093a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08292c4f28> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4f28> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c49b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08292c4f28> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f18470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08292c4f28> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08292c4f28> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293f8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292c4f28> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f086c0568d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a2e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08292c4f28> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f18ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08292c4f28> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 254
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085043d898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085043d898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f085043d898> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d898> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e53c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d898> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085043d898> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08292a0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f085043d898> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f094903a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d898> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293df828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293599e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d898> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085043d898> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d898> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293cf940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f085043d898> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08505bb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043d898> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504cfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08292a0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08293cf940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f085043d898> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f085043d898> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 255
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f18128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f188d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc3c8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828515a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc3c8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284246d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829ea6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc3c8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc3c8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b01c4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc3c8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082928f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504fc3c8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc3c8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e537b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc3c8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f18550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc3c8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e537b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504fc3c8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504fc3c8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f084876cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08504fc3c8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293f8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08504fc3c8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f0154fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828424828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08504fc3c8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 256
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f48898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f484e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f48240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f484e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f48e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f484e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828a3a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f484e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f486d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f484e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f484e0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f484e0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284304e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f484e0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828430048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b24e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f484e0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828430668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f484a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f484e0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f48208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f484a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f484e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f484e0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f484e0> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 6600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f484e0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0827f484e0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828430f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f484e0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0827f484e0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828469b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b21d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f484e0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b24e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f484e0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 257
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f18080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89240> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f48a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284309b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f89240> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284695c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f89240> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89240> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89240> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293df668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f89240> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f89240> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f89240> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f89240> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f89240> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0827f89240> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89240> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89240> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828469b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828469a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f89240> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f89240> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f89240> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 258
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284308d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284300f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284300f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284300f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284300f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f0154fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284300f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f0154fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284300f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504fc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284300f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284300f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f0154fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284300f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f0154fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08284300f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284300f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082936ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284b28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284300f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f0154fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08284300f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270e5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f487f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08284300f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284698d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f487f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284300f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08284300f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284300f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08f0154fd0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f08284300f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 259
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082718fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f18a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b000a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c1d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293305f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c1d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c1d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c1d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504f03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c1d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f18a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c1d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c1d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c1d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c1d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c1d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284249b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c1d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828424710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c1d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c1d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f68470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f18a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c1d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f89390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c1d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 260
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ef98> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ef98> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ef98> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f68f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ef98> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ef98> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ef98> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ef98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ef98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ef98> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829282ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ef98> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 6700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f68160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ef98> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ef98> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ef98> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f68ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ef98> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ef98> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ef98> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ef98> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b3dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0eb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ef98> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 261
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3da20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b3def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3da20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3da20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b3dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b3da20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270cfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3da20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270cfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3da20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270cfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3da20> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3da20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270cf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b3da20> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3da20> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cf710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b3da20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3dc88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826b3da20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828459a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b3da20> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f094903a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3dc88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826b3da20> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f089474a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3dc88> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f0826b3da20> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b3da20> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3da20> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b3da20> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cf710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b3da20> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b3da20> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 262
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9128> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f68160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9128> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270cfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285f9128> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b3de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9128> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9128> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9128> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f68dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9128> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9128> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e53da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9128> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f68128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08285f9128> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0850514dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285f9128> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285f9128> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08285f9128> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285f9128> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829359898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285f9128> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f48e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285f9128> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b012b518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08285f9128> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 263
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bfb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b0144ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828430080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284308d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828430a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b89f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b89438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b89f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08b0144ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f48390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 264
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285587b8> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285587b8> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827181eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285587b8> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827181048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08285587b8> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827181208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285587b8> 0.0 6
Completed Iteration #10
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285587b8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b89da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829327a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285587b8> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08285587b8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285587b8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f7b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08285587b8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f7b8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f08285587b8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270389e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b894a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285587b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827164748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271812e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082714f7b8> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f08285587b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b894a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285587b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285587b8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827181cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08285587b8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271649b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285587b8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827164cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08285587b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 265
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270beb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164550> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827164390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270beb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827164550> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271649e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164550> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271647b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164550> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270beb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827164550> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827181d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164550> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164550> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271640b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827181710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827164550> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827164550> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b89358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164550> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284b2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827164550> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827164550> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827181550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827164550> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827164550> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827164470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827164550> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b893c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270beb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0827164550> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 266
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0829e41860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827164320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e4e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f18d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e4e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08947d2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e4e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285587b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e4e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e4e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f48e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e4e0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e4e0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08284249b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e4e0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e4e0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827038da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08293bf048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e4e0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e4e0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f68a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e4e0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e4e0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e4e0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827038978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e4e0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828430a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e4e0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 267
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828430748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270beba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270bedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc50> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826be19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826be1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826be1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc50> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270becf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc50> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc50> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc50> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc50> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc50> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828424e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc50> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f18128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc50> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826be1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc50> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc50> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc50> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc50> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc50> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b890b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc50> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 268
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284807f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b908> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284807f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082702b908> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826be1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284807f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082702b908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827062d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827062f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b908> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827062128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082702b908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827062b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284807f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082702b908> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284804e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b908> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827062518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08284804e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082702b908> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828480198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082702b908> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b9ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082702b908> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b9bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082702b908> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082702b908> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b9be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082702b908> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b908> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827062978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082702b908> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082702b908> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 269
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b9be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270626a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270622b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270622e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828480588> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480588> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826be1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828480588> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828480588> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0828480588> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f89e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480588> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270626a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270622b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828480588> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480588> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480588> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08505bb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270622b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828480588> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828430f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828480588> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f18048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270622b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0828480588> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828480588> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828558908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828480588> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0828480588> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270beba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828480588> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827164320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b0ee80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0828480588> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f68a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827062630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0828480588> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 270
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f9c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270cf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271a0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271a0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293bf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271815f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f18128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271814a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271a0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f68128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 271
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827062cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270515c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827051da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f2b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827051320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082710f2b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827051860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082710f2b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f2b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082710f2b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827051390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f2b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b79278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082710f2b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082710f2b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827051080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f2b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b79dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827051da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082710f2b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827051080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082710f2b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b79da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710fc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082710f2b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b79898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710fc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082710f2b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b79630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827051080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082710f2b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b793c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827051390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082710f2b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 272
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b552b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b55630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b55e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b556d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b55358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b55eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a58> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 7000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b55e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b55f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270bed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827051b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270512b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b556d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a58> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271716a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b795f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b552b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b55630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a58> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b556d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a58> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b55080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270512b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a58> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b55a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b55eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a58> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b55cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a58> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b55518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a58> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b79080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b55630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a58> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b79c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270512b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a58> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b79898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b55630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a58> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a58> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b555c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a58> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b55eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a58> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b556d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a58> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a58> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270512b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a58> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f5b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082702b128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b79a58> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 273
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271a0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827051240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270516a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271a0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270516a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f48e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270516a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b894e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f48390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270516a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b796d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271815f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270516a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827051240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270516a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270516a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270516a0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270516a0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828430f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0829e41cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270516a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08b012bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270516a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082714f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270516a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827051240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270516a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b790b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270516a0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710fe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270516a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271815f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270516a0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827051240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08270516a0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270516a0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b79710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271815f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08270516a0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08270516a0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271a0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08270516a0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 274
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293df160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f18d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270622b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d6a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f18d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d6a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d6a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f18d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d6a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d6a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827051358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f18d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d6a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d6a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270cfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be19b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d6a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f688d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d6a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d6a0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f18d68> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d6a0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08285f9c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d6a0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270622b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d6a0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f688d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d6a0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b627b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f688d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d6a0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827f688d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d6a0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d6a0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 275
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270abc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270abb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62320> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270ab320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62320> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270cf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62320> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b3d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f085043d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b62320> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b62320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826bf6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b62320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b62320> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826b62320> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826af7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b62320> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826af75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b89c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826b62320> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826af77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b62320> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b620f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270abcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62320> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826af7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270ab160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b62320> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826af7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b62320> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826af7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270abb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b62320> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 276
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258cd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cd240> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258cd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cd240> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258cd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258cd240> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258cdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cd240> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258cdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cd240> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258cdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cdba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258cd240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258cd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cd240> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826af7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cd240> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826af7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cd240> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08258cd240> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f68128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cdba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08258cd240> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08293cfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f085043dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258cd240> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826af7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258cd240> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826be1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cdba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08258cd240> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08504dc4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cd278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08258cd240> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cdba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08258cd240> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08285f9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cdb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258cd240> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f18d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cd5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258cd240> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 277
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826af7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826be19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258cd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826af7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7eb8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b629b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7eb8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7eb8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826af7eb8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829359898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826af7eb8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826af71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7eb8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7eb8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b55978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826af7eb8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826af7eb8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271a05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826af7eb8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271814a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826af7eb8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b79048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cd1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826af7eb8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826af7eb8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 278
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270622e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827051358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b890b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62278> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62278> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258de240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62278> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258de860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270622e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b62278> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258dea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b890b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b62278> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258debe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270622e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b62278> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827051d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62278> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258dec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b62278> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258de390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b62278> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258de668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270622e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826b62278> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082588e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270622e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826b62278> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258de208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62278> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826af7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258de208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826b62278> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b0e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827051ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62278> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b89f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827051160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62278> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270ab2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710fe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826b62278> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258de9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258de7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62278> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 279
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082588e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258def98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258de128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082588e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258def98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258de128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258de2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258de128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082588e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258de128> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082588ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258de128> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082588eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258de128> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082588ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258de128> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258a42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258de128> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082588ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258def98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08258de128> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258de1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258de128> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082588e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258de128> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258a4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258de128> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082588ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258a4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258de128> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258a44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258de128> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258ba2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588e9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08258de128> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 280
found coverage increase 0
Current Total Coverage 29.166666666666668
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258ba550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258ba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258a4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258a4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba128> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258a4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258a4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082588e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258a4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba128> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082588e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba128> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082588e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258ba128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082588e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258ba128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082588ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258a44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258a4358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258ba128> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082588e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258a4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba128> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258a4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258ba128> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba128> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082710fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258ba128> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258a4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258a4400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258ba128> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082588eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588ea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08258ba128> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08258ba128> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b89240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258a4358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08258ba128> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258de978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08258ba128> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 281
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258a4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258de2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258def98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082588e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827051160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258def98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258de6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258a4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258de2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258def98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0828430f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ded68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258def98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258de2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0828558908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258def98> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826af7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258def98> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258de208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258def98> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b79c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258def98> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271814a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258def98> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ded68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258def98> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827051160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258def98> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827171940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826be1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258de208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258def98> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258de208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08258def98> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258cdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08271a0b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258def98> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cd860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0827171860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0827051160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08258def98> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258def98> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270ab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08258def98> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258ba198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08258def98> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258baa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258def98> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 282
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258bab70> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826af7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258bab70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258cd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258bab70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258bab70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ded30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258bab70> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258bac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258bab70> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258a4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082710fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258bab70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258bab70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258bae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ded30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258bab70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258ba908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258bab70> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825870470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258700f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258bab70> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825870630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258700f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08258bab70> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08258bab70> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258bafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08258bab70> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825870588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08258bab70> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258709b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258bab70> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825870cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ded30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08258bab70> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825870eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08258bab70> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825870f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258705f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258bab70> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825870e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082587e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258bab70> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 283
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825870860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082587e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082587e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082587e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082587e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870c88> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082587eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082587eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825870b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082587e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870c88> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082587eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082587eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825870c88> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082580f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082580f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870c88> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082580f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082587e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825870c88> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082580f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082587e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825870c88> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082580f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082587ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870c88> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082587e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082587ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825870c88> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082580f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082587e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825870c88> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082580fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258baa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870c88> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082580fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082587eb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0825870c88> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258bae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082587e470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0825870c88> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825870128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082587e8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0825870c88> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082587eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825870c88> 0.0 18
Completed Iteration #24
Best Reward: 0
coverage_call_count 7300
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 284
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825870e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270cf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258700f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825870cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258700b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829eb1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825870ac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870ac8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270abcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258700b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825870ac8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258bab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258700f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825870ac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258bae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825870ac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b79048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258700b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0825870ac8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258cd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870ac8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826af7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258cd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870ac8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258ba198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870ac8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082587e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258700b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0825870ac8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825870f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825870ac8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0825870ac8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270be2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825870ac8> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258de6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258707b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870ac8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271a05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0825870ac8> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258a4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825870ac8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258bac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0825870ac8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258dea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258707b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825870ac8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 285
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082580f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588ecf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082580fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082580fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588ecf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b9b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082580fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588ecf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082583d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258def98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588ecf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082583d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082580f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588ecf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082583d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082583d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588ecf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588ecf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08271a0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082588ecf8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258baa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082580fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082588ecf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082580f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588ecf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258de4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588ecf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082583d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082588ecf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082583d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082583d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082588ecf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082583db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082587ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258de4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082701a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082588ecf8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082583dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588e5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082588ecf8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082583de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082580fc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082588ecf8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082583dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082588ecf8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082588ecf8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 286
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ce438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082583df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082580fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251ce1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ce5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082583d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce1d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ce860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082583d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251ce1d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ce908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce1d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ceb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ceb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce1d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251cee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ceb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251ce1d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251cef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ceef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce1d0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251cedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251dc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce1d0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082583d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ceb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08251ce1d0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251dc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08251ce1d0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251dc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08251ce1d0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251dc9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251ce1d0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251dcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251dc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce1d0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251cea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce1d0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251dcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ceef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251ce1d0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251dc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251ce1d0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251dcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ceef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08251ce1d0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251f00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251cea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251ce1d0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251f0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ceb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08251ce1d0> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825870940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ceef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08251ce1d0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 287
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082583da90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251dcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082583da90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251f0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251dcc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082583da90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251f0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082583da90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251f0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082583da90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251dcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251f0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082583da90> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251f0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251dc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082583da90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251f0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251f0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082583da90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251f0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251f0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082583da90> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251f0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251dc208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082583da90> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251f0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251f05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082583da90> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251f0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f082583da90> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251dca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251dc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082583da90> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251dcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251dc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082583da90> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082702bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082583da90> 0.0 16
Completed Iteration #20
Best Reward: 0
coverage_call_count 7400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251f0be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082583da90> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251cef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251f0898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082583da90> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251dc240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251f0be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082583da90> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251dc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251dc208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082583da90> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 288
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ce860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ce080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082583d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082583dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082583d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082583d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082583d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082583d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082583dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082583d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082583d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251ce128> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082580fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251ce128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082580f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08251ce128> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082588e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251ce128> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258a47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082583d8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08251ce128> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251f08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce128> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082588e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258dec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce128> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251ce128> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ce160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce128> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251dc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082583d8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08251ce128> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082583ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258dec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251ce128> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082583d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082588ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251ce128> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08251ce128> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 289
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082587e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7198> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825870940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b79048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082587e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826af7198> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ce470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270be240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825870630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082583d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082701a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7198> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826af7198> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258bab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258ba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7198> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cf400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826af7198> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082714f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cf400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826af7198> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082580ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7198> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258baeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cf400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0826af7198> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251878d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825187518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7198> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825187978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825187940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826af7198> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825187cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825187518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826af7198> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825187e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08270cf400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0826af7198> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258ba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826af7198> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ba358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082587e080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0826af7198> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ba518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825187940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0826af7198> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 290
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ba940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ba0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ba470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825187c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251baa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ba470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251baa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251873c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ba470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ba780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251bacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ba470> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251baef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251baeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ba470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826af71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ba470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258bac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251873c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251ba470> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082580fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251baeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251ba470> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ba828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251873c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08251ba470> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825147080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825187898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ba470> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825147400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251dc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ba470> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251475c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251baa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251ba470> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082587ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ba2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ba470> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ba5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825187898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251ba470> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825147668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251baeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08251ba470> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251479e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251baeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08251ba470> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825147ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251dc438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251ba470> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825147d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251873c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08251ba470> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825147f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251dc438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08251ba470> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825147cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ba2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251ba470> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 291
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0829e41128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825147eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825147cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251620b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ba6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825147cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251624e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251624a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825147cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825162940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825162908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825147cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825162b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825162b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825147cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251476d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825162d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825147cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825147ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825147cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827f7e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825162278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825147cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826af7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082701aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251624e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251624a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825147cf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825187860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251624a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0825147cf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0827171eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825147eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825147cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825147780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825162908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825147cf8> 0.0 13
Completed Iteration #16
Best Reward: 0
coverage_call_count 7500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825187ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251626d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825147cf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251878d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825162b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825147cf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251870b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251624a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0825147cf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825187cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251626d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0825147cf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258ba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825147eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0825147cf8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825147588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251624a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0825147cf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251477f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825162908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0825147cf8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 292
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825187828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825187898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251870f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270abcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825187a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251870f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258700f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251870f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251baf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082587e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251870f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825147cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251870f0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251870f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251dc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251870f0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258a47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082587e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251870f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258de6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251badd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251870f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251dccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251870f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825187f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251bacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251870f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251baa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ba358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251870f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251f08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251bacc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251870f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082583dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ba358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251870f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082583d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825187a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251870f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ba518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825187898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251870f0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082580fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251bacc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08251870f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 293
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ce8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ce080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251625c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825162630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251ce2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251ce7b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825162ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825162da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce7b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251627f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825162da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251ce7b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825114048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251ce7b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251144e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825162da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08251ce7b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825114748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce7b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825114978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce7b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825114630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251ce7b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825114160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825162da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08251ce7b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251ce7b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258cd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825147080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce7b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251baa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825162b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce7b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825162898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08251ce7b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082583d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce7b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825147a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825162da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f08251ce7b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825114cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce7b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825114eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08251ce7b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 294
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082512a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082512a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114898> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082512a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ba0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114898> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082512a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082512a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114898> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082512aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114898> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082512ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082512aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114898> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082512ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082512a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114898> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082512a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114898> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082513c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082513c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114898> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082513c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082512a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825114898> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082513c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082513c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825114898> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082513c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082512a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825114898> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082512ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082512a668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825114898> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082513c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114898> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08250cc2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082513c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0825114898> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 295
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08250cc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cc128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082513ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cc128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082513c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082513c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cc128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082513c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082513c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cc128> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082512a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082513cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cc128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082512aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082512aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cc128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082512add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cc048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08250cc128> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082512a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082512a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cc128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082512a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cc668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08250cc128> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082512ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082512aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08250cc128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082513c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082512aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08250cc128> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082513ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082513c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cc128> 0.0 13
Completed Iteration #14
Best Reward: 0
coverage_call_count 7600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082513c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082513c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08250cc128> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082513c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082512aac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08250cc128> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082513cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cc048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08250cc128> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251140f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082512a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08250cc128> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825114cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082513cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08250cc128> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825114a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082513c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08250cc128> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825114518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082513c208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08250cc128> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 296
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825162f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825162630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251147b8> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825162128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825162e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251147b8> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825162cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082580f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251147b8> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825114630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825162898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251147b8> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258a47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251147b8> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082583d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082583ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251147b8> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251147b8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825162898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251147b8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251bacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825162e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251147b8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08258de4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825162e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08251147b8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251147b8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082583d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251627f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825114208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08251147b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251474a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825162630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251147b8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08250cc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251147b8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825187e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251147b8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 297
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08250cc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251bab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251badd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08250cc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251badd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08250ccac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251badd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08250cccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251badd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270ab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251badd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082587ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251badd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251badd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825870908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251badd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ba400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825187898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251badd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08250840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825187898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08251badd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825187f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08251badd8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08250843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825187898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08251badd8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825084630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825187898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f08251badd8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08250846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251badd8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825084be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08251badd8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 298
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825084ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825084c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825084e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825096128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825084fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825084e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825096630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825084c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825084e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08250967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825084c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0825084e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825084f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825096860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825084e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825096898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825084048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825084e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08250963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825084048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825084e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825096048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825096198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825084e10> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825096e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825096e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825084e10> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825096fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825084048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0825084e10> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825096b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825096e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825084e10> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08250a6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825096860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825084e10> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08250a6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825084e10> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08250a6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825084048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0825084e10> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08250a6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825084048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f0825084e10> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08250a69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825096e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0825084e10> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08250a6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825084fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825084e10> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825096b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825084e10> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825084d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825084c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f0825084e10> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 299
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08250a6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250a62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250846d8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825096278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250a6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250846d8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825084390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825084748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250846d8> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825084eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825084be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250846d8> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082513cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250a6828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08250846d8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08270ab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250846d8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 7700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825084908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082583ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250846d8> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251627f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08250846d8> 0.0 9
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825162390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250846d8> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08250a6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825870940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08250846d8> 0.0 11
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825147b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825084748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08250846d8> 0.0 12
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08250ccda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cc6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250846d8> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 300
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251baef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cc400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251baf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08250cc400> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825114e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825162a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cc400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825114160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cc400> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825114128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cc400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082512a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251ce710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cc400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08250520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0826b62710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08250cc400> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08250ccac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825052470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cc400> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825052898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08250cc400> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825052a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f08250cc400> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825052c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825052240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cc400> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825052518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825052240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08250cc400> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082505f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250ccb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cc400> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082505f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250ccb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f08250cc400> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082505f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08258a47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cc400> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 301
found coverage increase 0
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825052358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082505f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082505f5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082505fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825052be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082505f5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082505f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082505fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082505f5f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825187f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251dcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082505f5f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825162128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251dcda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082505f5f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08251ba080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250cc588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082505f5f8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825052cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825052160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082505f5f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082587ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082505f5f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082505f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082505fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082505f5f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082505fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825052be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082505f5f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825079080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082505ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082505f5f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825079320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082505f5f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082505f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825079390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082505f5f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825052780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08251dcda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082505f5f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825084320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825114748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082505f5f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825079828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825079390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082505f5f8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f08250799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082505fc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f082505f5f8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825079ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082505ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f082505f5f8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 302
found coverage increase 0
Current Total Coverage 29.166666666666668
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082500e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082500e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825079e80> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082500e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082500e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825079e80> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082500e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082500e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825079e80> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082505fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082500ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825079e80> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082500ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825079cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825079e80> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082500e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082500ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825079e80> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082500eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082500e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825079e80> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082501e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082500ea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f0825079e80> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825079be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082505fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825079e80> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0826b62710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082505fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f0825079e80> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f082512a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082500ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825079e80> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825079a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f082501e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825079e80> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f0825052f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f08250792e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f0825079e80> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 303
found coverage increase 0
Current Total Coverage 29.166666666666668
initial coverage: 29.1667
time passed (minutes): 60.0102
iterations: 304
number of new inputs: 0
final coverage: 29.1667
total coverage increase: 0
