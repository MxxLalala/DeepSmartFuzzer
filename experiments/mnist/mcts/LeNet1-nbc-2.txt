Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='nbc', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet1', nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet1', 'mcts', 'nbc'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7f1e8116af28>, tc2=<function tc2 at 0x7f1e81179048>, tc3=<function tc3 at 0x7f1e81179158>, tfc_threshold=33000000, time_period=3600, verbose=True)
initial coverage: 5.20833
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1e80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1e80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1554e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1e80> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1e80> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1477f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1e80> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1554e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1e80> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1e80> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1e80> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1e80> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1e80> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1e80> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1e80> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1e80> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 5.208333333333334
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dcf8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dcf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dcf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dcf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dcf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dcf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dcf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dcf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1474e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dcf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dcf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16da20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dcf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dcf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dcf8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dcf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dcf8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dcf8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dcf8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dcf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dcf8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17ceb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dcf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 5.208333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f2b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f2b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f2b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f2b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f2b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f2b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f2b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f2b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f2b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f2b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f2b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f2b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f2b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f2b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f2b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f2b0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16de80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f2b0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 5.208333333333334
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f080> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f080> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f080> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f080> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f080> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f080> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f080> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f080> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f080> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1479b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f080> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1477b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f080> 0.0 12
Completed Iteration #19
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f080> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f080> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f080> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f080> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 5.208333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fdd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fdd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fdd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fdd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fdd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fdd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fdd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fdd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fdd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fdd8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fdd8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fdd8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fdd8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fdd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fdd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fdd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fdd8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fdd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 5.208333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e34a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e34a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e34a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e34a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e34a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0823c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e34a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e34a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0825f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e34a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e34a8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e34a8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0825f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e34a8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e34a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0825f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e34a8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e34a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e34a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e34a8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0941d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e34a8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0944a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e34a8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e34a8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0949e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0825f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e34a8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 5.208333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0828d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0947b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094780> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094780> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094780> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094780> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094780> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094780> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094780> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094780> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094780> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094780> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094780> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1478d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094780> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094780> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0828d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094780> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094780> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 5.208333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147fd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147fd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147fd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147fd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147fd0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147fd0> 0.0 12
Completed Iteration #16
Best Reward: 0
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147fd0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147fd0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0824e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147fd0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147fd0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147fd0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 5.208333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0941d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0949b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094d68> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094d68> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094d68> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094d68> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0942b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0949b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094d68> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094d68> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094d68> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094d68> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094d68> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094d68> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094d68> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094d68> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0949b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094d68> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094d68> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094d68> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0821d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094d68> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094d68> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 5.208333333333334
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d208> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d208> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d208> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d208> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d208> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0686d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d208> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d208> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d208> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d208> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0686a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d208> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d208> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d208> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d208> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d208> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05db70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d208> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d208> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d208> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 5.208333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0688d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0688d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8390> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 2.083333333333333 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 2.083333333333333 14
Completed Iteration #17
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 2.083333333333333 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 2.083333333333333 15
Completed Iteration #18
Best Reward: 2.083333333333333
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 2.083333333333333 16
Completed Iteration #19
Best Reward: 2.083333333333333
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094128> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d7b8> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8390> 5.208333333333331 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 5.208333333333331 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 5.208333333333331 17
Completed Iteration #20
Best Reward: 3.1249999999999982
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 5.208333333333331 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 5.208333333333331 18
Completed Iteration #21
Best Reward: 3.1249999999999982
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 5.208333333333331 8
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 5.208333333333331 19
Completed Iteration #22
Best Reward: 3.1249999999999982
Completed Iteration #23
Best Reward: 3.1249999999999982
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 5.208333333333331 9
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 5.208333333333331 20
Completed Iteration #24
Best Reward: 3.1249999999999982
Completed Iteration #25
Best Reward: 3.1249999999999982
Completed MCTS Level/Depth: #0
root
Best Reward: 3.1249999999999982
Completed Iteration #0
Best Reward: 3.1249999999999982
Completed Iteration #1
Best Reward: 3.1249999999999982
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7780> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3940> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094128> 7.291666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d7b8> 7.291666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8390> 9.374999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 9.374999999999996 10
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 9.374999999999996 21
Completed Iteration #2
Best Reward: 4.166666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082fd0> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082e48> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094128> 10.416666666666663 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d7b8> 10.416666666666663 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8390> 12.499999999999995 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 12.499999999999995 11
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 12.499999999999995 22
Completed Iteration #3
Best Reward: 4.166666666666666
Reward: 5.208333333333334
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c5f8> 5.208333333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082eb8> 5.208333333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7780> 9.375 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3940> 9.375 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094128> 15.624999999999996 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d7b8> 15.624999999999996 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8390> 17.70833333333333 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 17.70833333333333 12
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 17.70833333333333 23
Completed Iteration #4
Best Reward: 5.208333333333334
Completed Iteration #5
Best Reward: 5.208333333333334
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e37f0> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082e48> 6.2499999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094128> 18.749999999999993 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d7b8> 18.749999999999993 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8390> 20.83333333333333 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 20.83333333333333 13
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 20.83333333333333 24
Completed Iteration #6
Best Reward: 5.208333333333334
Completed Iteration #7
Best Reward: 5.208333333333334
Completed Iteration #8
Best Reward: 5.208333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155cf8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a87f0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8390> 21.874999999999993 8
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 21.874999999999993 14
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 21.874999999999993 25
Completed Iteration #9
Best Reward: 5.208333333333334
Completed Iteration #10
Best Reward: 5.208333333333334
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0948d0> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a87f0> 3.124999999999999 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8390> 23.958333333333325 9
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 23.958333333333325 15
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 23.958333333333325 26
Completed Iteration #11
Best Reward: 5.208333333333334
Completed Iteration #12
Best Reward: 5.208333333333334
Completed Iteration #13
Best Reward: 5.208333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c4a8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 24.999999999999993 16
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 24.999999999999993 27
Completed Iteration #14
Best Reward: 5.208333333333334
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 28.124999999999993 17
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 28.124999999999993 28
Completed Iteration #15
Best Reward: 5.208333333333334
coverage_call_count 300
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 7.291666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 32.29166666666666 18
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 32.29166666666666 29
Completed Iteration #16
Best Reward: 5.208333333333334
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d940> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 7.291666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 7.291666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 10.416666666666663 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 35.41666666666666 19
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 35.41666666666666 30
Completed Iteration #17
Best Reward: 5.208333333333334
Completed Iteration #18
Best Reward: 5.208333333333334
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082588> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094cf8> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 11.45833333333333 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 11.45833333333333 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 14.583333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 39.58333333333332 20
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 39.58333333333332 31
Completed Iteration #19
Best Reward: 5.208333333333334
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07df98> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 14.583333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 17.70833333333333 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 42.70833333333332 21
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 42.70833333333332 32
Completed Iteration #20
Best Reward: 5.208333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 42.70833333333332 22
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 42.70833333333332 33
Completed Iteration #21
Best Reward: 5.208333333333334
Completed Iteration #22
Best Reward: 5.208333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a6a0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a710> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c4a8> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 43.749999999999986 23
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 43.749999999999986 34
Completed Iteration #23
Best Reward: 5.208333333333334
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ab70> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a828> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082588> 6.249999999999999 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094cf8> 6.249999999999999 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 13.541666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 16.66666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 19.79166666666666 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 45.83333333333332 24
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 45.83333333333332 35
Completed Iteration #24
Best Reward: 5.208333333333334
Completed Iteration #25
Best Reward: 5.208333333333334
Completed MCTS Level/Depth: #1
root->6
Best Reward: 5.208333333333334
Completed Iteration #0
Best Reward: 5.208333333333334
Completed Iteration #1
Best Reward: 5.208333333333334
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030278> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 6.2499999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 16.666666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 19.791666666666657 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 22.916666666666657 8
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 48.95833333333332 25
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 48.95833333333332 36
Completed Iteration #2
Best Reward: 5.208333333333334
Completed Iteration #3
Best Reward: 5.208333333333334
Completed Iteration #4
Best Reward: 5.208333333333334
Completed Iteration #5
Best Reward: 5.208333333333334
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030d30> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 21.87499999999999 8
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 24.99999999999999 9
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 51.04166666666666 26
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 51.04166666666666 37
Completed Iteration #6
Best Reward: 5.208333333333334
Completed Iteration #7
Best Reward: 5.208333333333334
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3f60> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 8.333333333333329 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 18.749999999999996 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 23.95833333333332 9
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 27.08333333333332 10
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 53.12499999999999 27
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 53.12499999999999 38
Completed Iteration #8
Best Reward: 5.208333333333334
Completed Iteration #9
Best Reward: 5.208333333333334
Completed Iteration #10
Best Reward: 5.208333333333334
Reward: 6.249999999999998
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0823c8> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d940> 9.374999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 14.583333333333327 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 24.999999999999993 8
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 30.20833333333332 10
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 33.33333333333332 11
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 59.37499999999999 28
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 59.37499999999999 39
Completed Iteration #11
Best Reward: 6.249999999999998
Reward: 6.249999999999998
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a4a8> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a198> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0823c8> 12.499999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 12.499999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d940> 15.624999999999995 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 20.833333333333325 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 31.249999999999993 9
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 36.45833333333332 11
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 39.58333333333332 12
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 65.62499999999999 29
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 65.62499999999999 40
Completed Iteration #12
Best Reward: 6.249999999999998
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02acf8> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02aba8> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030d30> 5.208333333333331 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 39.58333333333332 12
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 42.70833333333332 13
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 68.74999999999999 30
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 68.74999999999999 41
Completed Iteration #13
Best Reward: 6.249999999999998
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07dba8> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07db00> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02acf8> 5.208333333333331 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02aba8> 5.208333333333331 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030d30> 7.291666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 41.66666666666666 13
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 44.79166666666666 14
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 70.83333333333331 31
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 70.83333333333331 42
Completed Iteration #14
Best Reward: 6.249999999999998
Completed Iteration #15
Best Reward: 6.249999999999998
Completed Iteration #16
Best Reward: 6.249999999999998
Completed Iteration #17
Best Reward: 6.249999999999998
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030320> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094940> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030278> 6.2499999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 23.95833333333332 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 34.37499999999999 10
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 44.79166666666666 14
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 47.91666666666666 15
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 73.95833333333331 32
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 73.95833333333331 43
Completed Iteration #18
Best Reward: 6.249999999999998
Completed Iteration #19
Best Reward: 6.249999999999998
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b240> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b048> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07df98> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 45.83333333333332 15
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 48.95833333333332 16
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 74.99999999999999 33
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 74.99999999999999 44
Completed Iteration #20
Best Reward: 6.249999999999998
Completed Iteration #21
Best Reward: 6.249999999999998
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b860> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02aba8> 7.291666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030d30> 9.374999999999996 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 47.91666666666666 16
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 51.04166666666666 17
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 77.08333333333331 34
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 77.08333333333331 45
Completed Iteration #22
Best Reward: 6.249999999999998
Completed Iteration #23
Best Reward: 6.249999999999998
Completed Iteration #24
Best Reward: 6.249999999999998
Completed Iteration #25
Best Reward: 6.249999999999998
Completed MCTS Level/Depth: #2
root->6->19
Best Reward: 6.249999999999998
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb38> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b048> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07df98> 7.2916666666666625 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 51.04166666666666 17
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 54.16666666666666 18
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 80.20833333333331 35
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 80.20833333333331 46
Completed Iteration #0
Best Reward: 6.249999999999998
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088358> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088198> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3f60> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 26.041666666666654 8
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 36.45833333333333 11
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 53.12499999999999 18
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 56.24999999999999 19
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 82.29166666666664 36
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 82.29166666666664 47
Completed Iteration #1
Best Reward: 6.249999999999998
Completed Iteration #2
Best Reward: 6.249999999999998
Completed Iteration #3
Best Reward: 6.249999999999998
Completed Iteration #4
Best Reward: 6.249999999999998
Completed Iteration #5
Best Reward: 6.249999999999998
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088b00> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088da0> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b860> 6.249999999999999 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02aba8> 11.45833333333333 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030d30> 13.541666666666663 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 57.29166666666666 19
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 60.41666666666666 20
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 86.45833333333331 37
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 86.45833333333331 48
Completed Iteration #6
Best Reward: 6.249999999999998
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d6d8> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b048> 7.2916666666666625 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07df98> 10.41666666666666 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 60.41666666666666 20
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 63.54166666666666 21
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 89.58333333333331 38
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 89.58333333333331 49
Completed Iteration #7
Best Reward: 6.249999999999998
Completed Iteration #8
Best Reward: 6.249999999999998
Reward: 7.291666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07df28> 7.291666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07de80> 7.291666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088b00> 11.458333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088da0> 11.458333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b860> 13.541666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02aba8> 18.749999999999996 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030d30> 20.83333333333333 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 67.70833333333333 21
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 70.83333333333333 22
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 96.87499999999999 39
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 96.87499999999999 50
Completed Iteration #9
Best Reward: 7.291666666666666
Completed Iteration #10
Best Reward: 7.291666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0880f0> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 69.79166666666666 22
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 72.91666666666666 23
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 98.95833333333331 40
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 98.95833333333331 51
Completed Iteration #11
Best Reward: 7.291666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088dd8> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088438> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082588> 9.374999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094cf8> 9.374999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 39.58333333333333 12
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 72.91666666666666 23
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 76.04166666666666 24
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 102.08333333333331 41
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 102.08333333333331 52
Completed Iteration #12
Best Reward: 7.291666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a940> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082860> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d6d8> 6.2499999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b048> 10.41666666666666 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07df98> 13.541666666666659 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 76.04166666666666 24
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 79.16666666666666 25
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 105.20833333333331 42
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 105.20833333333331 53
Completed Iteration #13
Best Reward: 7.291666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b278> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02afd0> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030320> 6.2499999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094940> 6.2499999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030278> 9.374999999999995 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 29.16666666666665 9
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 42.70833333333333 13
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 79.16666666666666 25
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 82.29166666666666 26
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 108.33333333333331 43
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 108.33333333333331 54
Completed Iteration #14
Best Reward: 7.291666666666666
Completed Iteration #15
Best Reward: 7.291666666666666
Completed Iteration #16
Best Reward: 7.291666666666666
Completed Iteration #17
Best Reward: 7.291666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f0b8> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b080> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb38> 6.2499999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b048> 13.541666666666659 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07df98> 16.666666666666657 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 82.29166666666666 26
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 85.41666666666666 27
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 111.45833333333331 44
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 111.45833333333331 55
Completed Iteration #18
Best Reward: 7.291666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f4e0> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02aba8> 22.916666666666664 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030d30> 24.999999999999993 8
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 86.45833333333333 27
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 89.58333333333333 28
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 115.62499999999999 45
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 115.62499999999999 56
Completed Iteration #19
Best Reward: 7.291666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f898> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b080> 6.2499999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb38> 9.374999999999995 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b048> 16.666666666666657 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07df98> 19.791666666666657 8
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 89.58333333333333 28
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 92.70833333333333 29
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 118.74999999999999 46
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 118.74999999999999 57
Completed Iteration #20
Best Reward: 7.291666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fd68> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fba8> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb38> 12.499999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b048> 19.791666666666657 8
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07df98> 22.916666666666657 9
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 92.70833333333333 29
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 95.83333333333333 30
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 121.87499999999999 47
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 121.87499999999999 58
Completed Iteration #21
Best Reward: 7.291666666666666
Completed Iteration #22
Best Reward: 7.291666666666666
Completed Iteration #23
Best Reward: 7.291666666666666
Completed Iteration #24
Best Reward: 7.291666666666666
Completed Iteration #25
Best Reward: 7.291666666666666
Completed MCTS Level/Depth: #3
root->6->19->2
Best Reward: 7.291666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088be0> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094cf8> 12.499999999999995 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 45.83333333333333 14
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 95.83333333333333 30
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 98.95833333333333 31
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 124.99999999999999 48
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 124.99999999999999 59
Completed Iteration #0
Best Reward: 7.291666666666666
Completed Iteration #1
Best Reward: 7.291666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f748> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f160> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088be0> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094cf8> 13.54166666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 46.87499999999999 15
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 96.875 31
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 100.0 32
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 126.04166666666666 49
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 126.04166666666666 60
Completed Iteration #2
Best Reward: 7.291666666666666
Completed Iteration #3
Best Reward: 7.291666666666666
Completed Iteration #4
Best Reward: 7.291666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09ff28> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f358> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f748> 5.208333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f160> 5.208333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088be0> 8.33333333333333 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094cf8> 17.70833333333333 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 51.04166666666666 16
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 101.04166666666667 32
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 104.16666666666667 33
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 130.20833333333331 50
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 130.20833333333331 61
Completed Iteration #5
Best Reward: 7.291666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b358> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088438> 5.208333333333331 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082588> 11.458333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094cf8> 19.79166666666666 8
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 53.12499999999999 17
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 103.125 33
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 106.25 34
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 132.29166666666666 51
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 132.29166666666666 62
Completed Iteration #6
Best Reward: 7.291666666666666
Completed Iteration #7
Best Reward: 7.291666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0308d0> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07be48> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ab70> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a828> 4.166666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082588> 13.54166666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094cf8> 21.874999999999993 9
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 55.20833333333333 18
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 105.20833333333333 34
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 108.33333333333333 35
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 134.375 52
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 134.375 63
Completed Iteration #8
Best Reward: 7.291666666666666
Completed Iteration #9
Best Reward: 7.291666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e30b8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094940> 7.2916666666666625 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030278> 10.41666666666666 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 30.208333333333314 10
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 56.24999999999999 19
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 106.25 35
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 109.375 36
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 135.41666666666666 53
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 135.41666666666666 64
Completed Iteration #10
Best Reward: 7.291666666666666
Completed Iteration #11
Best Reward: 7.291666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a64e0> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d438> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3f60> 6.249999999999999 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 32.29166666666665 11
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 58.33333333333333 20
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 108.33333333333333 36
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 111.45833333333333 37
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 137.5 54
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 137.5 65
Completed Iteration #12
Best Reward: 7.291666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147cc0> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a65c0> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0308d0> 5.208333333333331 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07be48> 5.208333333333331 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ab70> 7.291666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a828> 7.291666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082588> 16.666666666666657 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094cf8> 24.999999999999993 10
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 61.45833333333333 21
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 111.45833333333333 37
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 114.58333333333333 38
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 140.625 55
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 140.625 66
Completed Iteration #13
Best Reward: 7.291666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a68d0> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07be48> 7.291666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ab70> 9.374999999999996 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a828> 9.374999999999996 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082588> 18.74999999999999 8
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094cf8> 27.083333333333325 11
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 63.541666666666664 22
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 113.54166666666666 38
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 116.66666666666666 39
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 142.70833333333334 56
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 142.70833333333334 67
Completed Iteration #14
Best Reward: 7.291666666666666
Completed Iteration #15
Best Reward: 7.291666666666666
Completed Iteration #16
Best Reward: 7.291666666666666
Completed Iteration #17
Best Reward: 7.291666666666666
Completed Iteration #18
Best Reward: 7.291666666666666
Completed Iteration #19
Best Reward: 7.291666666666666
Completed Iteration #20
Best Reward: 7.291666666666666
Completed Iteration #21
Best Reward: 7.291666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fd30> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f1d0> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b278> 6.2499999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02afd0> 6.2499999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030320> 9.374999999999995 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094940> 10.41666666666666 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030278> 13.541666666666659 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 35.41666666666665 12
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 66.66666666666666 23
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 116.66666666666666 39
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 119.79166666666666 40
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 145.83333333333334 57
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 145.83333333333334 68
Completed Iteration #22
Best Reward: 7.291666666666666
Completed Iteration #23
Best Reward: 7.291666666666666
Completed Iteration #24
Best Reward: 7.291666666666666
Reward: 5.208333333333334
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030da0> 5.208333333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0304a8> 5.208333333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09ff28> 9.375 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f358> 9.375 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f748> 10.416666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f160> 10.416666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088be0> 13.541666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094cf8> 32.29166666666666 12
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 71.87499999999999 24
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 121.87499999999999 40
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 124.99999999999999 41
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 151.04166666666669 58
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 151.04166666666669 69
Completed Iteration #25
Best Reward: 7.291666666666666
Completed MCTS Level/Depth: #4
root->6->19->2->3
Best Reward: 7.291666666666666
Completed Iteration #0
Best Reward: 7.291666666666666
Reward: 2.083333333333333
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a438> 2.083333333333333 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094940> 12.499999999999993 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030278> 15.624999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 37.499999999999986 13
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 73.95833333333331 25
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 123.95833333333331 41
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 127.08333333333331 42
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 153.12500000000003 59
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 153.12500000000003 70
Completed Iteration #1
Best Reward: 7.291666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6a20> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 41.66666666666665 14
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 78.12499999999999 26
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 128.12499999999997 42
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 131.24999999999997 43
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 157.29166666666669 60
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 157.29166666666669 71
Completed Iteration #2
Best Reward: 7.291666666666666
Completed Iteration #3
Best Reward: 7.291666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3f98> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0302b0> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6a20> 8.333333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 45.833333333333314 15
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 82.29166666666666 27
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 132.29166666666663 43
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 135.41666666666663 44
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 161.45833333333334 61
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 161.45833333333334 72
Completed Iteration #4
Best Reward: 7.291666666666666
Completed Iteration #5
Best Reward: 7.291666666666666
Completed Iteration #6
Best Reward: 7.291666666666666
Completed Iteration #7
Best Reward: 7.291666666666666
Completed Iteration #8
Best Reward: 7.291666666666666
Completed Iteration #9
Best Reward: 7.291666666666666
Completed Iteration #10
Best Reward: 7.291666666666666
Completed Iteration #11
Best Reward: 7.291666666666666
Completed Iteration #12
Best Reward: 7.291666666666666
coverage_call_count 400
Reward: 6.249999999999998
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e5f8> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd68> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a4a8> 12.499999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a198> 12.499999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0823c8> 18.749999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 18.749999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d940> 21.874999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 52.083333333333314 16
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 88.54166666666666 28
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 138.54166666666663 44
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 141.66666666666663 45
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 167.70833333333334 62
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 167.70833333333334 73
Completed Iteration #13
Best Reward: 7.291666666666666
Completed Iteration #14
Best Reward: 7.291666666666666
Completed Iteration #15
Best Reward: 7.291666666666666
Completed Iteration #16
Best Reward: 7.291666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b160> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088198> 5.208333333333331 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3f60> 9.374999999999996 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 55.208333333333314 17
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 91.66666666666666 29
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 141.66666666666663 45
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 144.79166666666663 46
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 170.83333333333334 63
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 170.83333333333334 74
Completed Iteration #17
Best Reward: 7.291666666666666
Reward: 4.166666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b5f8> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b438> 4.166666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3f98> 8.333333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0302b0> 8.333333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6a20> 12.499999999999998 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 59.37499999999998 18
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 95.83333333333333 30
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 145.8333333333333 46
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 148.9583333333333 47
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 175.0 64
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 175.0 75
Completed Iteration #18
Best Reward: 7.291666666666666
Completed Iteration #19
Best Reward: 7.291666666666666
Completed Iteration #20
Best Reward: 7.291666666666666
Completed Iteration #21
Best Reward: 7.291666666666666
Completed Iteration #22
Best Reward: 7.291666666666666
Completed Iteration #23
Best Reward: 7.291666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a65f8> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07ddd8> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fd30> 6.2499999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f1d0> 6.2499999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b278> 9.374999999999995 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02afd0> 9.374999999999995 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030320> 12.499999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094940> 15.624999999999991 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030278> 18.749999999999993 8
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 62.49999999999998 19
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 98.95833333333333 31
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 148.9583333333333 47
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 152.0833333333333 48
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 178.125 65
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 178.125 76
Completed Iteration #24
Best Reward: 7.291666666666666
Reward: 3.1249999999999982
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088c50> 3.1249999999999982 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094940> 18.74999999999999 8
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030278> 21.874999999999993 9
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 65.62499999999997 20
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 102.08333333333333 32
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 152.0833333333333 48
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 155.2083333333333 49
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 181.25 66
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 181.25 77
Completed Iteration #25
Best Reward: 7.291666666666666
Completed MCTS Level/Depth: #5
root->6->19->2->3->8
Best Reward: 7.291666666666666
Completed Iteration #0
Best Reward: 7.291666666666666
Completed Iteration #1
Best Reward: 7.291666666666666
Completed Iteration #2
Best Reward: 7.291666666666666
Completed Iteration #3
Best Reward: 7.291666666666666
Reward: 6.249999999999998
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e470> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03be10> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e5f8> 12.499999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd68> 12.499999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a4a8> 18.749999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a198> 18.749999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0823c8> 24.999999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 24.999999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d940> 28.124999999999993 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 71.87499999999997 21
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 108.33333333333333 33
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 158.3333333333333 49
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 161.4583333333333 50
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 187.5 67
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 187.5 78
Completed Iteration #4
Best Reward: 7.291666666666666
Completed Iteration #5
Best Reward: 7.291666666666666
Completed Iteration #6
Best Reward: 7.291666666666666
Completed Iteration #7
Best Reward: 7.291666666666666
Completed Iteration #8
Best Reward: 7.291666666666666
Completed Iteration #9
Best Reward: 7.291666666666666
Completed Iteration #10
Best Reward: 7.291666666666666
Completed Iteration #11
Best Reward: 7.291666666666666
Completed Iteration #12
Best Reward: 7.291666666666666
Completed Iteration #13
Best Reward: 7.291666666666666
Completed Iteration #14
Best Reward: 7.291666666666666
Completed Iteration #15
Best Reward: 7.291666666666666
Completed Iteration #16
Best Reward: 7.291666666666666
Completed Iteration #17
Best Reward: 7.291666666666666
Reward: 7.291666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1db4565b00> 7.291666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04eac8> 7.291666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e470> 13.541666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03be10> 13.541666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e5f8> 19.791666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd68> 19.791666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a4a8> 26.041666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a198> 26.041666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0823c8> 32.29166666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 32.29166666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d940> 35.41666666666666 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 79.16666666666664 22
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 115.625 34
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 165.62499999999994 50
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 168.74999999999994 51
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 194.79166666666666 68
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 194.79166666666666 79
Completed Iteration #18
Best Reward: 7.291666666666666
Completed Iteration #19
Best Reward: 7.291666666666666
Reward: 7.291666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1db45730b8> 7.291666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 7.291666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565b00> 14.583333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04eac8> 14.583333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e470> 20.83333333333333 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03be10> 20.83333333333333 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e5f8> 27.08333333333333 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd68> 27.08333333333333 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a4a8> 33.33333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a198> 33.33333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0823c8> 39.58333333333332 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 39.58333333333332 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d940> 42.70833333333332 8
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 86.45833333333331 23
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 122.91666666666667 35
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 172.9166666666666 51
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 176.0416666666666 52
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 202.08333333333331 69
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 202.08333333333331 80
Completed Iteration #20
Best Reward: 7.291666666666666
Reward: 6.249999999999998
backprop <src.mcts.MCTS_Node object at 0x7f1db4573710> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04eac8> 20.83333333333333 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e470> 27.08333333333333 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03be10> 27.08333333333333 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e5f8> 33.33333333333333 6
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd68> 33.33333333333333 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a4a8> 39.58333333333332 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a198> 39.58333333333332 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0823c8> 45.83333333333332 8
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 45.83333333333332 8
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d940> 48.95833333333332 9
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 92.70833333333331 24
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 129.16666666666666 36
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 179.1666666666666 52
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 182.2916666666666 53
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 208.33333333333331 70
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 208.33333333333331 81
Completed Iteration #21
Best Reward: 7.291666666666666
Completed Iteration #22
Best Reward: 7.291666666666666
Completed Iteration #23
Best Reward: 7.291666666666666
Reward: 6.249999999999998
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f240> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a198> 45.83333333333332 8
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0823c8> 52.08333333333332 9
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 52.08333333333332 9
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d940> 55.20833333333332 10
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 98.95833333333331 25
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 135.41666666666666 37
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 185.4166666666666 53
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 188.5416666666666 54
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 214.58333333333331 71
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 214.58333333333331 82
Completed Iteration #24
Best Reward: 7.291666666666666
Completed Iteration #25
Best Reward: 7.291666666666666
Completed MCTS Level/Depth: #6
root->6->19->2->3->8->19
Best Reward: 7.291666666666666
Completed Iteration #0
Best Reward: 7.291666666666666
Completed Iteration #1
Best Reward: 7.291666666666666
Completed Iteration #2
Best Reward: 7.291666666666666
Completed Iteration #3
Best Reward: 7.291666666666666
Completed Iteration #4
Best Reward: 7.291666666666666
Completed Iteration #5
Best Reward: 7.291666666666666
Completed Iteration #6
Best Reward: 7.291666666666666
Reward: 6.249999999999998
backprop <src.mcts.MCTS_Node object at 0x7f1db4565550> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03be10> 33.33333333333333 6
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e5f8> 39.58333333333333 7
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd68> 39.58333333333333 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a4a8> 45.83333333333332 8
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a198> 52.08333333333332 9
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0823c8> 58.33333333333332 10
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 58.33333333333332 10
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d940> 61.45833333333332 11
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 105.20833333333331 26
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 141.66666666666666 38
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 191.6666666666666 54
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 194.7916666666666 55
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 220.83333333333331 72
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 220.83333333333331 83
Completed Iteration #7
Best Reward: 7.291666666666666
Reward: 5.208333333333334
backprop <src.mcts.MCTS_Node object at 0x7f1db45734e0> 5.208333333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 63.54166666666666 11
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d940> 66.66666666666666 12
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 110.41666666666664 27
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 146.875 39
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 196.87499999999994 55
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 199.99999999999994 56
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 226.04166666666666 73
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 226.04166666666666 84
Completed Iteration #8
Best Reward: 7.291666666666666
Reward: 7.291666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1db4573a58> 7.291666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45736d8> 7.291666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45730b8> 14.583333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 14.583333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4565b00> 21.875 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04eac8> 28.124999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e470> 34.37499999999999 6
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03be10> 40.62499999999999 7
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e5f8> 46.87499999999999 8
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd68> 46.87499999999999 8
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a4a8> 53.124999999999986 9
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a198> 59.374999999999986 10
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0823c8> 65.62499999999999 11
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 70.83333333333333 12
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d940> 73.95833333333333 13
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 117.70833333333331 28
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 154.16666666666666 40
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 204.1666666666666 56
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 207.2916666666666 57
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 233.33333333333331 74
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 233.33333333333331 85
Completed Iteration #9
Best Reward: 7.291666666666666
Completed Iteration #10
Best Reward: 7.291666666666666
Completed Iteration #11
Best Reward: 7.291666666666666
Reward: 6.249999999999998
backprop <src.mcts.MCTS_Node object at 0x7f1db458d588> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d5f8> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565550> 12.499999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03be10> 46.87499999999999 8
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e5f8> 53.12499999999999 9
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd68> 53.12499999999999 9
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a4a8> 59.374999999999986 10
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a198> 65.62499999999999 11
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0823c8> 71.87499999999999 12
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 77.08333333333333 13
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d940> 80.20833333333333 14
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 123.95833333333331 29
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 160.41666666666666 41
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 210.4166666666666 57
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 213.5416666666666 58
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 239.58333333333331 75
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 239.58333333333331 86
Completed Iteration #12
Best Reward: 7.291666666666666
Reward: 6.249999999999998
backprop <src.mcts.MCTS_Node object at 0x7f1db458dcc0> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458db00> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45734e0> 11.458333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 83.33333333333333 14
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d940> 86.45833333333333 15
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 130.20833333333331 30
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 166.66666666666666 42
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 216.6666666666666 58
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 219.7916666666666 59
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 245.83333333333331 76
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 245.83333333333331 87
Completed Iteration #13
Best Reward: 7.291666666666666
Reward: 6.249999999999998
backprop <src.mcts.MCTS_Node object at 0x7f1db4594198> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d5f8> 12.499999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4565550> 18.749999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03be10> 53.12499999999999 9
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e5f8> 59.37499999999999 10
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd68> 59.37499999999999 10
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a4a8> 65.62499999999999 11
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a198> 71.87499999999999 12
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0823c8> 78.12499999999999 13
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 89.58333333333333 15
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d940> 92.70833333333333 16
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 136.45833333333331 31
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 172.91666666666666 43
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 222.9166666666666 59
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 226.0416666666666 60
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 252.08333333333331 77
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 252.08333333333331 88
Completed Iteration #14
Best Reward: 7.291666666666666
Completed Iteration #15
Best Reward: 7.291666666666666
Completed Iteration #16
Best Reward: 7.291666666666666
Reward: 6.249999999999998
backprop <src.mcts.MCTS_Node object at 0x7f1db45655f8> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0887f0> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f240> 12.499999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a198> 78.12499999999999 13
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0823c8> 84.37499999999999 14
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 95.83333333333333 16
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d940> 98.95833333333333 17
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 142.70833333333331 32
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 179.16666666666666 44
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 229.1666666666666 60
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 232.2916666666666 61
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 258.3333333333333 78
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 258.3333333333333 89
Completed Iteration #17
Best Reward: 7.291666666666666
Completed Iteration #18
Best Reward: 7.291666666666666
Completed Iteration #19
Best Reward: 7.291666666666666
Reward: 5.208333333333334
backprop <src.mcts.MCTS_Node object at 0x7f1db45739b0> 5.208333333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 101.04166666666666 17
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d940> 104.16666666666666 18
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 147.91666666666666 33
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 184.375 45
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 234.37499999999994 61
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 237.49999999999994 62
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 263.54166666666663 79
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 263.54166666666663 90
Completed Iteration #20
Best Reward: 7.291666666666666
Completed Iteration #21
Best Reward: 7.291666666666666
Completed Iteration #22
Best Reward: 7.291666666666666
Completed Iteration #23
Best Reward: 7.291666666666666
Completed Iteration #24
Best Reward: 7.291666666666666
Reward: 6.249999999999998
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e588> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a67b8> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458dcc0> 12.499999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1db458db00> 12.499999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1db45734e0> 17.70833333333333 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 107.29166666666666 18
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d940> 110.41666666666666 19
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 154.16666666666666 34
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 190.625 46
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 240.62499999999994 62
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 243.74999999999994 63
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 269.79166666666663 80
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 269.79166666666663 91
Completed Iteration #25
Best Reward: 7.291666666666666
Completed MCTS Level/Depth: #7
root->6->19->2->3->8->19->3
Best Reward: 7.291666666666666
Completed Iteration #0
Best Reward: 7.291666666666666
Completed Iteration #1
Best Reward: 7.291666666666666
Completed Iteration #2
Best Reward: 7.291666666666666
Reward: 6.249999999999998
backprop <src.mcts.MCTS_Node object at 0x7f1db458def0> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a198> 84.37499999999999 14
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0823c8> 90.62499999999999 15
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 113.54166666666666 19
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d940> 116.66666666666666 20
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 160.41666666666666 35
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 196.875 47
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 246.87499999999994 63
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 249.99999999999994 64
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 276.04166666666663 81
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 276.04166666666663 92
Completed Iteration #3
Best Reward: 7.291666666666666
Reward: 6.249999999999998
backprop <src.mcts.MCTS_Node object at 0x7f1db4594588> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594240> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45655f8> 12.499999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0887f0> 12.499999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f240> 18.749999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a198> 90.62499999999999 15
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0823c8> 96.87499999999999 16
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 119.79166666666666 20
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d940> 122.91666666666666 21
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 166.66666666666666 36
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 203.125 48
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 253.12499999999994 64
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 256.24999999999994 65
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 282.29166666666663 82
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 282.29166666666663 93
Completed Iteration #4
Best Reward: 7.291666666666666
Completed Iteration #5
Best Reward: 7.291666666666666
Completed Iteration #6
Best Reward: 7.291666666666666
Reward: 6.249999999999998
backprop <src.mcts.MCTS_Node object at 0x7f1db4594b38> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4573cf8> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f240> 24.999999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a198> 96.87499999999999 16
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0823c8> 103.12499999999999 17
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 126.04166666666666 21
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d940> 129.16666666666666 22
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 172.91666666666666 37
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 209.375 49
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 259.37499999999994 65
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 262.49999999999994 66
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 288.54166666666663 83
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 288.54166666666663 94
Completed Iteration #7
Best Reward: 7.291666666666666
Completed Iteration #8
Best Reward: 7.291666666666666
Completed Iteration #9
Best Reward: 7.291666666666666
Reward: 6.249999999999998
backprop <src.mcts.MCTS_Node object at 0x7f1db45254e0> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a198> 103.12499999999999 17
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0823c8> 109.37499999999999 18
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 132.29166666666666 22
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d940> 135.41666666666666 23
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 179.16666666666666 38
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 215.625 50
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 265.62499999999994 66
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 268.74999999999994 67
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 294.79166666666663 84
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 294.79166666666663 95
Completed Iteration #10
Best Reward: 7.291666666666666
Completed Iteration #11
Best Reward: 7.291666666666666
Completed Iteration #12
Best Reward: 7.291666666666666
Completed Iteration #13
Best Reward: 7.291666666666666
Completed Iteration #14
Best Reward: 7.291666666666666
Completed Iteration #15
Best Reward: 7.291666666666666
Completed Iteration #16
Best Reward: 7.291666666666666
Completed Iteration #17
Best Reward: 7.291666666666666
Reward: 6.249999999999998
backprop <src.mcts.MCTS_Node object at 0x7f1db4573780> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4573ac8> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594b38> 12.499999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4573cf8> 12.499999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f240> 31.249999999999993 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a198> 109.37499999999999 18
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0823c8> 115.62499999999999 19
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 138.54166666666666 23
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d940> 141.66666666666666 24
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 185.41666666666666 39
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 221.875 51
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 271.87499999999994 67
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 274.99999999999994 68
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 301.04166666666663 85
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 301.04166666666663 96
Completed Iteration #18
Best Reward: 7.291666666666666
Reward: 6.249999999999998
backprop <src.mcts.MCTS_Node object at 0x7f1db45947b8> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458da90> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594588> 12.499999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4594240> 12.499999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1db45655f8> 18.749999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0887f0> 18.749999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f240> 37.49999999999999 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a198> 115.62499999999999 19
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0823c8> 121.87499999999999 20
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 144.79166666666666 24
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d940> 147.91666666666666 25
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 191.66666666666666 40
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 228.125 52
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 278.12499999999994 68
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 281.24999999999994 69
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 307.29166666666663 86
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 307.29166666666663 97
Completed Iteration #19
Best Reward: 7.291666666666666
Completed Iteration #20
Best Reward: 7.291666666666666
Completed Iteration #21
Best Reward: 7.291666666666666
Completed Iteration #22
Best Reward: 7.291666666666666
Reward: 6.249999999999998
backprop <src.mcts.MCTS_Node object at 0x7f1db4525320> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d438> 6.249999999999998 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4573780> 12.499999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4573ac8> 12.499999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4594b38> 18.749999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f1db4573cf8> 18.749999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f240> 43.74999999999999 8
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a198> 121.87499999999999 20
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0823c8> 128.12499999999997 21
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 151.04166666666666 25
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d940> 154.16666666666666 26
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d048> 197.91666666666666 41
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d438> 234.375 53
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f320> 284.37499999999994 69
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 287.49999999999994 70
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d6d8> 313.54166666666663 87
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068da0> 313.54166666666663 98
Completed Iteration #23
Best Reward: 7.291666666666666
Completed Iteration #24
Best Reward: 7.291666666666666
Completed Iteration #25
Best Reward: 7.291666666666666
Completed MCTS Level/Depth: #8
root->6->19->2->3->8->19->3->19
Best Reward: 7.291666666666666
iteration: 10
found coverage increase 7.291666666666666
Current Total Coverage 12.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d160> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4573e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d160> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d160> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453d160> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 500
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d160> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db453d160> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d160> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4573e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453d160> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453d160> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d160> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453d160> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4594080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d160> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453d160> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4594c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453d160> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 12.5
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594630> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4594860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594630> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4573400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45940f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594630> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4525588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594630> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4525f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45940f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4594630> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594630> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4594630> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4594630> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594630> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db4594630> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1db4594630> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4594630> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594630> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4594630> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594630> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 12.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6d68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45072b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6d68> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45076d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6d68> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6d68> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6d68> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45074a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6d68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6d68> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6d68> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6d68> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6d68> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f69e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6d68> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1de0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6d68> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1de198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6d68> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e4f66b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f69e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6d68> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e9b2b10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45074a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6d68> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1de208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6d68> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e9b2b14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f69e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6d68> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 12.5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e4d3a2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c68d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390eb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390eb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e4d3a2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e4d3a2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e9b2b1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e4d3a2470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390eb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390eb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390eb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390eb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c68d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390eb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45650f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390eb8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4565c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645be0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390eb8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45652b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390eb8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4565438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e9b2b1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390eb8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4565860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390eb8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45652e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645be0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390eb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 12.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f0f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e9b29ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f0f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f0f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f0f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f0f0> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f0f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f0f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f0f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f0f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f0f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f0f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0300b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f0f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f0f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f0f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f0f0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f0f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 12.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e1d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e1d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e1d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e1d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e1d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e1d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e1d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e1d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e1d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0889e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e1d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e1d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e1d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e1d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04eb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e1d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e1d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e1d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 12.5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0882b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030748> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030748> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030748> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030748> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030748> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030748> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030748> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030748> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030748> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0306a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030748> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1de160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c6ad6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030748> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 12.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030860> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030860> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e4d3a2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030860> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030860> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4565240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030860> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030860> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4565898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030860> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4565da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030860> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030860> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030860> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e9b2b10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030860> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030860> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030860> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030860> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 12.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0306d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4565f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088b38> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088b38> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0682e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088b38> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088b38> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088b38> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0686a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088b38> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0304a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088b38> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088b38> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088b38> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088b38> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088b38> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088b38> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088b38> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088b38> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088b38> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 12.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a080> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a080> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a080> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a080> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a080> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a080> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a080> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a080> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a080> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a080> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a080> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07ddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a080> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a080> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07ddd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a080> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07ddd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a080> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 12.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e30b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e30b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e30b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e30b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e30b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e30b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e30b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e30b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e30b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e30b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e30b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e30b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0684e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e30b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e30b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e30b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e30b8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e35c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e30b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e30b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e30b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 12.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6da0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6da0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05dba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6da0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6da0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6da0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6da0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6da0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6da0> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6da0> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6da0> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6da0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0300f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6da0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6da0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 12.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fb38> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fb38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fb38> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fb38> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fb38> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fb38> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fb38> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1476d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fb38> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fb38> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fb38> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fb38> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fb38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0825c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fb38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fb38> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fb38> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fb38> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0826d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fb38> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 12.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082940> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0306d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082940> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082940> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082940> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082940> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082940> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082940> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082940> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082940> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082940> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082940> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082940> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082940> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082940> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0306d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082940> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082940> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082940> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082940> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 12.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e4d3a20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7dd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7dd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0940f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7dd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7dd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7dd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e9b2b1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7dd8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7dd8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d71d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0880f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7dd8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7dd8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7dd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7dd8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 12.5
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d6d8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d6d8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1faa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d6d8> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d6d8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d6d8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d6d8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d6d8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d6d8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d6d8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d6d8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d6d8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d6d8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d6d8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d6d8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1556a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d6d8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1556a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d6d8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 900
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d6d8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 12.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dc50> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dc50> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dc50> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dc50> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dc50> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dc50> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dc50> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dc50> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dc50> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dc50> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dc50> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dc50> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05dd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dc50> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 12.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cda0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cda0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cda0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cda0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cda0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cda0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454c048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cda0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cda0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454c3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cda0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cda0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cda0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cda0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cda0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cda0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454c3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cda0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db454c048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cda0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cda0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 12.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a748> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a748> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a748> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17ce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a748> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a748> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4565b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02af28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a748> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e9b2b1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a748> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0880f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a748> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a748> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0940f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a748> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e4d3a2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a748> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a748> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 12.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082278> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082278> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082278> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082278> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082278> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082278> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082278> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082278> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082278> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082278> 0.0 14
Completed Iteration #19
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082278> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082278> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4525208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082278> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082278> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082278> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4565240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 12.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fc18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fc18> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4525b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fc18> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e4d3a20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fc18> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0304a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fc18> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4525240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fc18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45258d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fc18> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fc18> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4525c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fc18> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4525ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fc18> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fc18> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fc18> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fc18> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fc18> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fc18> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fc18> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 12.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05beb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05beb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05beb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05beb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05beb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05beb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05beb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05beb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4525c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05beb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4525320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05beb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4525630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05beb8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05beb8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4525f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05beb8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4525cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05beb8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05beb8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05beb8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05beb8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4525978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05beb8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05beb8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 12.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453da20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453da20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453da20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453da20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453da20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453da20> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453da20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453da20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453da20> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db453da20> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453da20> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0940f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1db453da20> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453da20> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453da20> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db453da20> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453da20> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1db453da20> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453da20> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db453da20> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453da20> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1db453da20> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 12.5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4565b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f898> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f898> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f898> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f898> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f898> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f898> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f898> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f898> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f898> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 1100
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f898> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f898> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4594ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f898> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4594400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f898> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f898> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 12.5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4594198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45940b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594c88> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4573320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4573518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45737b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4594c88> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4573978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45735c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594c88> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4573828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45735c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4594c88> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4573ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594c88> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4573c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45737b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4594c88> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4573240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594c88> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45070b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45940b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4594c88> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45737b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db4594c88> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594c88> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45732b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594c88> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4573240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4594c88> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db4594c88> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594c88> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 12.5
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4573e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45735f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4594470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4594b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4594978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 12.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d6d8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d6d8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45259b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d6d8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d6d8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc46a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d6d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d6d8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d6d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d6d8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d6d8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d6d8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d6d8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d6d8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d6d8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d6d8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d6d8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 12.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bf60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45730f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bf60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bf60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bf60> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bf60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bf60> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bf60> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bf60> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bf60> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45730f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bf60> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bf60> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bf60> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bf60> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bf60> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce74e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bf60> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bf60> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce74e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bf60> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bf60> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bf60> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 12.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc907f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc906a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb668> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb668> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc906a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb668> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb668> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb668> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb668> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb668> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb668> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb668> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc906d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb668> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb668> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 12.5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb5f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb5f8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb5f8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb5f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb5f8> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb5f8> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce71d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb5f8> 0.0 8
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb5f8> 0.0 9
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb5f8> 0.0 10
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb5f8> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb5f8> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb5f8> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb5f8> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb5f8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 12.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc44e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc44e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc44e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc44e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc44e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc44e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45735f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc44e0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc44e0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc44e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4594470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc44e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc44e0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc44e0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45736d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc44e0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc44e0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc44e0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc44e0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4594b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc44e0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc44e0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 12.5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc525f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc522b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc522b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc522b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc525f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc522b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc520b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc522b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc522b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc520b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc522b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc522b0> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc522b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc520b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc522b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc522b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc689e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc689b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc522b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc522b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc522b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc689b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc522b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc689b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc522b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc522b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc522b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 12.5
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c780> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c780> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c780> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc070b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c780> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c780> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c780> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c780> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c780> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c780> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c780> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e9b2b1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c780> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc687b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c780> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c780> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45735f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c780> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c780> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c780> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 12.5
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 1.041666666666666 4
Completed Iteration #3
Best Reward: 1.041666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52f98> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 2.083333333333332 5
Completed Iteration #4
Best Reward: 1.041666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52748> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e48> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52f98> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 3.1249999999999982 6
Completed Iteration #5
Best Reward: 1.041666666666666
Completed Iteration #6
Best Reward: 1.041666666666666
Completed Iteration #7
Best Reward: 1.041666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a87f0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 4.166666666666664 7
Completed Iteration #8
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52748> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e48> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52f98> 2.083333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 4.166666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 4.166666666666664 8
Completed Iteration #9
Best Reward: 1.041666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dac8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 5.20833333333333 7
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 5.20833333333333 9
Completed Iteration #10
Best Reward: 1.041666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4d68> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 6.2499999999999964 8
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 6.2499999999999964 10
Completed Iteration #11
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a87f0> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 6.2499999999999964 9
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 6.2499999999999964 11
Completed Iteration #12
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 6.2499999999999964 10
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 6.2499999999999964 12
Completed Iteration #13
Best Reward: 1.041666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07ba90> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7eb8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dac8> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 7.2916666666666625 11
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 7.2916666666666625 13
Completed Iteration #14
Best Reward: 1.041666666666666
Completed Iteration #15
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 7.2916666666666625 12
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 7.2916666666666625 14
Completed Iteration #16
Best Reward: 1.041666666666666
Completed Iteration #17
Best Reward: 1.041666666666666
Completed Iteration #18
Best Reward: 1.041666666666666
Completed Iteration #19
Best Reward: 1.041666666666666
Completed Iteration #20
Best Reward: 1.041666666666666
Completed Iteration #21
Best Reward: 1.041666666666666
Completed Iteration #22
Best Reward: 1.041666666666666
Completed Iteration #23
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e48> 1.041666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52f98> 2.083333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 7.2916666666666625 13
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 7.2916666666666625 15
Completed Iteration #24
Best Reward: 1.041666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbd30> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc524e0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 5.20833333333333 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 8.333333333333329 14
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 8.333333333333329 16
Completed Iteration #25
Best Reward: 1.041666666666666
Completed MCTS Level/Depth: #0
root
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 8.333333333333329 15
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 8.333333333333329 17
Completed Iteration #0
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbd30> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc524e0> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 5.20833333333333 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 8.333333333333329 16
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 8.333333333333329 18
Completed Iteration #1
Best Reward: 1.041666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafc071d0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc524e0> 2.083333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 6.2499999999999964 8
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 9.374999999999995 17
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 9.374999999999995 19
Completed Iteration #2
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e48> 1.041666666666666 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52f98> 2.083333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 9.374999999999995 18
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 9.374999999999995 20
Completed Iteration #3
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 9.374999999999995 19
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 9.374999999999995 21
Completed Iteration #4
Best Reward: 1.041666666666666
Completed Iteration #5
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 9.374999999999995 20
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 9.374999999999995 22
Completed Iteration #6
Best Reward: 1.041666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07f98> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07d30> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52f98> 3.1249999999999982 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 10.41666666666666 21
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 10.41666666666666 23
Completed Iteration #7
Best Reward: 1.041666666666666
Completed Iteration #8
Best Reward: 1.041666666666666
Completed Iteration #9
Best Reward: 1.041666666666666
Completed Iteration #10
Best Reward: 1.041666666666666
Completed Iteration #11
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 10.41666666666666 22
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 10.41666666666666 24
Completed Iteration #12
Best Reward: 1.041666666666666
Completed Iteration #13
Best Reward: 1.041666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33358> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52a20> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a87f0> 2.083333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 11.458333333333327 23
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 11.458333333333327 25
Completed Iteration #14
Best Reward: 1.041666666666666
Completed Iteration #15
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e48> 1.041666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52f98> 3.1249999999999982 8
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 11.458333333333327 24
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 11.458333333333327 26
Completed Iteration #16
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 11.458333333333327 25
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 11.458333333333327 27
Completed Iteration #17
Best Reward: 1.041666666666666
Completed Iteration #18
Best Reward: 1.041666666666666
Completed Iteration #19
Best Reward: 1.041666666666666
Completed Iteration #20
Best Reward: 1.041666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3db38> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 7.2916666666666625 9
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 12.499999999999993 26
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 12.499999999999993 28
Completed Iteration #21
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 12.499999999999993 27
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 12.499999999999993 29
Completed Iteration #22
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 12.499999999999993 28
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 12.499999999999993 30
Completed Iteration #23
Best Reward: 1.041666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8240> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8048> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33358> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52a20> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a87f0> 3.1249999999999982 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 13.541666666666659 29
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 13.541666666666659 31
Completed Iteration #24
Best Reward: 1.041666666666666
Completed Iteration #25
Best Reward: 1.041666666666666
Completed MCTS Level/Depth: #1
root->0
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 7.2916666666666625 10
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 13.541666666666659 30
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 13.541666666666659 32
Completed Iteration #0
Best Reward: 1.041666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90978> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7ca58> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 8.333333333333329 11
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 14.583333333333325 31
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 14.583333333333325 33
Completed Iteration #1
Best Reward: 1.041666666666666
Completed Iteration #2
Best Reward: 1.041666666666666
Completed Iteration #3
Best Reward: 1.041666666666666
Completed Iteration #4
Best Reward: 1.041666666666666
Completed Iteration #5
Best Reward: 1.041666666666666
coverage_call_count 1400
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07710> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc524e0> 3.1249999999999982 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 9.374999999999995 12
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 15.624999999999991 32
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 15.624999999999991 34
Completed Iteration #6
Best Reward: 1.041666666666666
Completed Iteration #7
Best Reward: 1.041666666666666
Completed Iteration #8
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90978> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7ca58> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 9.374999999999995 13
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 15.624999999999991 33
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 15.624999999999991 35
Completed Iteration #9
Best Reward: 1.041666666666666
Completed Iteration #10
Best Reward: 1.041666666666666
Completed Iteration #11
Best Reward: 1.041666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d7f0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc524e0> 4.166666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 10.41666666666666 14
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 16.666666666666657 34
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 16.666666666666657 36
Completed Iteration #12
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90978> 1.041666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7ca58> 1.041666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 10.41666666666666 15
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 16.666666666666657 35
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 16.666666666666657 37
Completed Iteration #13
Best Reward: 1.041666666666666
Completed Iteration #14
Best Reward: 1.041666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8748> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc524e0> 5.20833333333333 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 11.458333333333327 16
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 17.70833333333332 36
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 17.70833333333332 38
Completed Iteration #15
Best Reward: 1.041666666666666
Completed Iteration #16
Best Reward: 1.041666666666666
Completed Iteration #17
Best Reward: 1.041666666666666
Completed Iteration #18
Best Reward: 1.041666666666666
Completed Iteration #19
Best Reward: 1.041666666666666
Completed Iteration #20
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc076a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90978> 1.041666666666666 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7ca58> 1.041666666666666 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 11.458333333333327 17
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 17.70833333333332 37
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 17.70833333333332 39
Completed Iteration #21
Best Reward: 1.041666666666666
Completed Iteration #22
Best Reward: 1.041666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6748> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 5.20833333333333 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 12.499999999999993 18
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 18.749999999999986 38
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 18.749999999999986 40
Completed Iteration #23
Best Reward: 1.041666666666666
Completed Iteration #24
Best Reward: 1.041666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 6.2499999999999964 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 13.541666666666659 19
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 19.79166666666665 39
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 19.79166666666665 41
Completed Iteration #25
Best Reward: 1.041666666666666
Completed MCTS Level/Depth: #2
root->0->4
Best Reward: 1.041666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6fd0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6cc0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 7.2916666666666625 8
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 14.583333333333325 20
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 20.833333333333314 40
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 20.833333333333314 42
Completed Iteration #0
Best Reward: 1.041666666666666
Reward: 2.083333333333334
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6a58> 2.083333333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f22e8> 2.083333333333334 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6fd0> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6cc0> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 4.166666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 9.374999999999996 9
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 16.666666666666657 21
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 22.91666666666665 41
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 22.91666666666665 43
Completed Iteration #1
Best Reward: 2.083333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3db38> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 9.374999999999996 10
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 16.666666666666657 22
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 22.91666666666665 42
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 22.91666666666665 44
Completed Iteration #2
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1db458da20> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7eb8> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dac8> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 10.416666666666663 11
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 17.70833333333332 23
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 23.958333333333314 43
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 23.958333333333314 45
Completed Iteration #3
Best Reward: 2.083333333333334
Completed Iteration #4
Best Reward: 2.083333333333334
Completed Iteration #5
Best Reward: 2.083333333333334
Completed Iteration #6
Best Reward: 2.083333333333334
Completed Iteration #7
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8438> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6438> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6748> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 11.458333333333329 12
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 18.749999999999986 24
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 24.99999999999998 44
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 24.99999999999998 46
Completed Iteration #8
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6ac8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8668> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4d68> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 12.499999999999995 13
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 19.79166666666665 25
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 26.041666666666643 45
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 26.041666666666643 47
Completed Iteration #9
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8ef0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 13.54166666666666 14
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 20.833333333333314 26
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 27.083333333333307 46
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 27.083333333333307 48
Completed Iteration #10
Best Reward: 2.083333333333334
Completed Iteration #11
Best Reward: 2.083333333333334
Completed Iteration #12
Best Reward: 2.083333333333334
Completed Iteration #13
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ef0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6ac8> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8668> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4d68> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 14.583333333333327 15
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 21.87499999999998 27
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 28.12499999999997 47
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 28.12499999999997 49
Completed Iteration #14
Best Reward: 2.083333333333334
Completed Iteration #15
Best Reward: 2.083333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3db38> 1.041666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 14.583333333333327 16
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 21.87499999999998 28
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 28.12499999999997 48
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 28.12499999999997 50
Completed Iteration #16
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52860> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 15.624999999999993 17
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 22.916666666666643 29
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 29.166666666666636 49
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 29.166666666666636 51
Completed Iteration #17
Best Reward: 2.083333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8ef0> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 15.624999999999993 18
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 22.916666666666643 30
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 29.166666666666636 50
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 29.166666666666636 52
Completed Iteration #18
Best Reward: 2.083333333333334
Completed Iteration #19
Best Reward: 2.083333333333334
Completed Iteration #20
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2d68> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8668> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4d68> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 16.666666666666657 19
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 23.958333333333307 31
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 30.2083333333333 51
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 30.2083333333333 53
Completed Iteration #21
Best Reward: 2.083333333333334
Completed Iteration #22
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf586278> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5862e8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6a58> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f22e8> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6fd0> 4.166666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6cc0> 4.166666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 5.208333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 17.70833333333332 20
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 24.99999999999997 32
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 31.249999999999964 52
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 31.249999999999964 54
Completed Iteration #23
Best Reward: 2.083333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5867b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8438> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6438> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6748> 2.083333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 17.70833333333332 21
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 24.99999999999997 33
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 31.249999999999964 53
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 31.249999999999964 55
Completed Iteration #24
Best Reward: 2.083333333333334
Completed Iteration #25
Best Reward: 2.083333333333334
Completed MCTS Level/Depth: #3
root->0->4->6
Best Reward: 2.083333333333334
Completed Iteration #0
Best Reward: 2.083333333333334
Completed Iteration #1
Best Reward: 2.083333333333334
Completed Iteration #2
Best Reward: 2.083333333333334
Completed Iteration #3
Best Reward: 2.083333333333334
Completed Iteration #4
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d588> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6cc0> 5.208333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 6.249999999999998 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 18.749999999999986 22
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 26.041666666666636 34
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 32.29166666666663 54
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 32.29166666666663 56
Completed Iteration #5
Best Reward: 2.083333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d588> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6cc0> 5.208333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 6.249999999999998 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 18.749999999999986 23
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 26.041666666666636 35
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 32.29166666666663 55
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 32.29166666666663 57
Completed Iteration #6
Best Reward: 2.083333333333334
Completed Iteration #7
Best Reward: 2.083333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6cc0> 5.208333333333332 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 6.249999999999998 8
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 18.749999999999986 24
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 26.041666666666636 36
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 32.29166666666663 56
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 32.29166666666663 58
Completed Iteration #8
Best Reward: 2.083333333333334
Completed Iteration #9
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafc077f0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 7.291666666666664 9
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 19.79166666666665 25
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 27.0833333333333 37
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 33.33333333333329 57
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 33.33333333333329 59
Completed Iteration #10
Best Reward: 2.083333333333334
Completed Iteration #11
Best Reward: 2.083333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 7.291666666666664 10
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 19.79166666666665 26
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 27.0833333333333 38
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 33.33333333333329 58
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 33.33333333333329 60
Completed Iteration #12
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2c18> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 2.083333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 8.33333333333333 11
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 20.833333333333314 27
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 28.124999999999964 39
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 34.37499999999996 59
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 34.37499999999996 61
Completed Iteration #13
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf586550> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586c18> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2c18> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 3.1249999999999982 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 9.374999999999996 12
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 21.87499999999998 28
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 29.16666666666663 40
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 35.41666666666662 60
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 35.41666666666662 62
Completed Iteration #14
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf586710> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 4.166666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 10.416666666666663 13
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 22.916666666666643 29
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 30.208333333333293 41
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 36.458333333333286 61
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 36.458333333333286 63
Completed Iteration #15
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33da0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2470> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586710> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 5.20833333333333 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 11.458333333333329 14
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 23.958333333333307 30
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 31.249999999999957 42
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 37.49999999999995 62
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 37.49999999999995 64
Completed Iteration #16
Best Reward: 2.083333333333334
Completed Iteration #17
Best Reward: 2.083333333333334
Completed Iteration #18
Best Reward: 2.083333333333334
Completed Iteration #19
Best Reward: 2.083333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6cc0> 5.208333333333332 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 11.458333333333329 15
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 23.958333333333307 31
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 31.249999999999957 43
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 37.49999999999995 63
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 37.49999999999995 65
Completed Iteration #20
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a31d0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58df60> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586550> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf586c18> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2c18> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 6.2499999999999964 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 12.499999999999995 16
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 24.99999999999997 32
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 32.29166666666662 44
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 38.541666666666615 64
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 38.541666666666615 66
Completed Iteration #21
Best Reward: 2.083333333333334
Completed Iteration #22
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a36d8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6cc0> 6.249999999999998 9
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 13.54166666666666 17
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 26.041666666666636 33
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 33.333333333333286 45
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 39.58333333333328 65
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 39.58333333333328 67
Completed Iteration #23
Best Reward: 2.083333333333334
Completed Iteration #24
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf58db38> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f22e8> 4.166666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6fd0> 5.208333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6cc0> 7.291666666666664 10
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 14.583333333333327 18
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 27.0833333333333 34
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 34.37499999999995 46
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 40.62499999999994 66
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 40.62499999999994 68
Completed Iteration #25
Best Reward: 2.083333333333334
Completed MCTS Level/Depth: #4
root->0->4->6->4
Best Reward: 2.083333333333334
Completed Iteration #0
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf586438> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586cc0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2c18> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 7.2916666666666625 9
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 15.624999999999993 19
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 28.124999999999964 35
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 35.416666666666615 47
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 41.66666666666661 67
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 41.66666666666661 69
Completed Iteration #1
Best Reward: 2.083333333333334
Completed Iteration #2
Best Reward: 2.083333333333334
Completed Iteration #3
Best Reward: 2.083333333333334
Completed Iteration #4
Best Reward: 2.083333333333334
Completed Iteration #5
Best Reward: 2.083333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 7.2916666666666625 10
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 15.624999999999993 20
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 28.124999999999964 36
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 35.416666666666615 48
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 41.66666666666661 68
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 41.66666666666661 70
Completed Iteration #6
Best Reward: 2.083333333333334
Completed Iteration #7
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf58dba8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586cc0> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2c18> 5.20833333333333 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 8.333333333333329 11
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 16.666666666666657 21
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 29.16666666666663 37
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 36.45833333333328 49
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 42.70833333333327 69
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 42.70833333333327 71
Completed Iteration #8
Best Reward: 2.083333333333334
Completed Iteration #9
Best Reward: 2.083333333333334
Completed Iteration #10
Best Reward: 2.083333333333334
Completed Iteration #11
Best Reward: 2.083333333333334
Completed Iteration #12
Best Reward: 2.083333333333334
Completed Iteration #13
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3ef0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3f60> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33da0> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2470> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf586710> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 9.374999999999995 12
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 17.70833333333332 22
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 30.208333333333293 38
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 37.49999999999994 50
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 43.749999999999936 70
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 43.749999999999936 72
Completed Iteration #14
Best Reward: 2.083333333333334
Completed Iteration #15
Best Reward: 2.083333333333334
Completed Iteration #16
Best Reward: 2.083333333333334
Completed Iteration #17
Best Reward: 2.083333333333334
Completed Iteration #18
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf542978> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 10.41666666666666 13
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 18.749999999999986 23
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 31.249999999999957 39
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 38.54166666666661 51
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 44.7916666666666 71
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 44.7916666666666 73
Completed Iteration #19
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf542cc0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586cc0> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2c18> 6.2499999999999964 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 11.458333333333327 14
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 19.79166666666665 24
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 32.29166666666662 40
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 39.58333333333327 52
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 45.833333333333265 72
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 45.833333333333265 74
Completed Iteration #20
Best Reward: 2.083333333333334
Completed Iteration #21
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf5427f0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a208> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc077f0> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 12.499999999999993 15
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 20.833333333333314 25
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 33.333333333333286 41
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 40.624999999999936 53
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 46.87499999999993 73
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 46.87499999999993 75
Completed Iteration #22
Best Reward: 2.083333333333334
Completed Iteration #23
Best Reward: 2.083333333333334
Completed Iteration #24
Best Reward: 2.083333333333334
Completed Iteration #25
Best Reward: 2.083333333333334
Completed MCTS Level/Depth: #5
root->0->4->6->4->8
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a978> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586cc0> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2c18> 7.2916666666666625 8
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 13.541666666666659 16
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 21.87499999999998 26
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 34.37499999999995 42
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 41.6666666666666 54
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 47.91666666666659 74
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 47.91666666666659 76
Completed Iteration #0
Best Reward: 2.083333333333334
Completed Iteration #1
Best Reward: 2.083333333333334
Completed Iteration #2
Best Reward: 2.083333333333334
Completed Iteration #3
Best Reward: 2.083333333333334
coverage_call_count 1500
Completed Iteration #4
Best Reward: 2.083333333333334
Completed Iteration #5
Best Reward: 2.083333333333334
Completed Iteration #6
Best Reward: 2.083333333333334
Completed Iteration #7
Best Reward: 2.083333333333334
Completed Iteration #8
Best Reward: 2.083333333333334
Completed Iteration #9
Best Reward: 2.083333333333334
Completed Iteration #10
Best Reward: 2.083333333333334
Completed Iteration #11
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf553eb8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586c18> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2c18> 8.333333333333329 9
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 14.583333333333325 17
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 22.916666666666643 27
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 35.416666666666615 43
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 42.708333333333265 55
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 48.95833333333326 75
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 48.95833333333326 77
Completed Iteration #12
Best Reward: 2.083333333333334
Completed Iteration #13
Best Reward: 2.083333333333334
Completed Iteration #14
Best Reward: 2.083333333333334
Completed Iteration #15
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a35c0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586cc0> 5.20833333333333 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2c18> 9.374999999999995 10
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 15.624999999999991 18
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 23.958333333333307 28
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 36.45833333333328 44
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 43.74999999999993 56
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 49.99999999999992 76
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 49.99999999999992 78
Completed Iteration #16
Best Reward: 2.083333333333334
Completed Iteration #17
Best Reward: 2.083333333333334
Completed Iteration #18
Best Reward: 2.083333333333334
Completed Iteration #19
Best Reward: 2.083333333333334
Completed Iteration #20
Best Reward: 2.083333333333334
Completed Iteration #21
Best Reward: 2.083333333333334
Completed Iteration #22
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a58> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553a20> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542cc0> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf586cc0> 6.2499999999999964 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2c18> 10.41666666666666 11
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 16.666666666666657 19
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 24.99999999999997 29
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 37.49999999999994 45
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 44.79166666666659 57
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 51.041666666666586 77
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 51.041666666666586 79
Completed Iteration #23
Best Reward: 2.083333333333334
Completed Iteration #24
Best Reward: 2.083333333333334
Completed Iteration #25
Best Reward: 2.083333333333334
Completed MCTS Level/Depth: #6
root->0->4->6->4->8->8
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf553438> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586cc0> 7.2916666666666625 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2c18> 11.458333333333327 12
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 17.70833333333332 20
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 26.041666666666636 30
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 38.54166666666661 46
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 45.83333333333326 58
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 52.08333333333325 78
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 52.08333333333325 80
Completed Iteration #0
Best Reward: 2.083333333333334
Completed Iteration #1
Best Reward: 2.083333333333334
Completed Iteration #2
Best Reward: 2.083333333333334
Completed Iteration #3
Best Reward: 2.083333333333334
Completed Iteration #4
Best Reward: 2.083333333333334
Completed Iteration #5
Best Reward: 2.083333333333334
Completed Iteration #6
Best Reward: 2.083333333333334
Completed Iteration #7
Best Reward: 2.083333333333334
Completed Iteration #8
Best Reward: 2.083333333333334
Completed Iteration #9
Best Reward: 2.083333333333334
Completed Iteration #10
Best Reward: 2.083333333333334
Completed Iteration #11
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf563470> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5637b8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a35c0> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf586cc0> 8.333333333333329 9
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2c18> 12.499999999999993 13
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 18.749999999999986 21
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 27.0833333333333 31
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 39.58333333333327 47
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 46.87499999999992 59
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 53.124999999999915 79
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 53.124999999999915 81
Completed Iteration #12
Best Reward: 2.083333333333334
Completed Iteration #13
Best Reward: 2.083333333333334
Completed Iteration #14
Best Reward: 2.083333333333334
Completed Iteration #15
Best Reward: 2.083333333333334
Completed Iteration #16
Best Reward: 2.083333333333334
Completed Iteration #17
Best Reward: 2.083333333333334
Completed Iteration #18
Best Reward: 2.083333333333334
Completed Iteration #19
Best Reward: 2.083333333333334
Completed Iteration #20
Best Reward: 2.083333333333334
Completed Iteration #21
Best Reward: 2.083333333333334
Completed Iteration #22
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d080> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504fd0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a978> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf586cc0> 9.374999999999995 10
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2c18> 13.541666666666659 14
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 19.79166666666665 22
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 28.124999999999964 32
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 40.624999999999936 48
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 47.916666666666586 60
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 54.16666666666658 80
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 54.16666666666658 82
Completed Iteration #23
Best Reward: 2.083333333333334
Completed Iteration #24
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7f0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553a20> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf542cc0> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf586cc0> 10.41666666666666 11
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2c18> 14.583333333333325 15
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 20.833333333333314 23
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 29.16666666666663 33
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 41.6666666666666 49
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 48.95833333333325 61
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 55.20833333333324 81
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 55.20833333333324 83
Completed Iteration #25
Best Reward: 2.083333333333334
Completed MCTS Level/Depth: #7
root->0->4->6->4->8->8->6
Best Reward: 2.083333333333334
Completed Iteration #0
Best Reward: 2.083333333333334
Completed Iteration #1
Best Reward: 2.083333333333334
Completed Iteration #2
Best Reward: 2.083333333333334
Completed Iteration #3
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf516198> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a58> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf553a20> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf542cc0> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf586cc0> 11.458333333333327 12
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2c18> 15.624999999999991 16
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 21.87499999999998 24
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 30.208333333333293 34
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 42.708333333333265 50
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 49.999999999999915 62
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 56.24999999999991 82
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 56.24999999999991 84
Completed Iteration #4
Best Reward: 2.083333333333334
Completed Iteration #5
Best Reward: 2.083333333333334
Completed Iteration #6
Best Reward: 2.083333333333334
Completed Iteration #7
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf586898> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a58> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf553a20> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf542cc0> 5.20833333333333 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf586cc0> 12.499999999999993 13
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2c18> 16.666666666666657 17
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 22.916666666666643 25
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 31.249999999999957 35
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 43.74999999999993 51
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 51.04166666666658 63
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 57.29166666666657 83
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 57.29166666666657 85
Completed Iteration #8
Best Reward: 2.083333333333334
Completed Iteration #9
Best Reward: 2.083333333333334
Completed Iteration #10
Best Reward: 2.083333333333334
Completed Iteration #11
Best Reward: 2.083333333333334
Completed Iteration #12
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf504080> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5631d0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586898> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a58> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf553a20> 5.20833333333333 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf542cc0> 6.2499999999999964 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf586cc0> 13.541666666666659 14
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2c18> 17.70833333333332 18
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 23.958333333333307 26
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 32.29166666666662 36
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 44.79166666666659 52
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 52.08333333333324 64
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 58.333333333333236 84
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 58.333333333333236 86
Completed Iteration #13
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf54ac88> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a58> 5.20833333333333 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf553a20> 6.2499999999999964 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf542cc0> 7.2916666666666625 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf586cc0> 14.583333333333325 15
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2c18> 18.749999999999986 19
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 24.99999999999997 27
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 33.333333333333286 37
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 45.83333333333326 53
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 53.12499999999991 65
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 59.3749999999999 85
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 59.3749999999999 87
Completed Iteration #14
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d320> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553a20> 7.2916666666666625 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf542cc0> 8.333333333333329 9
backprop <src.mcts.MCTS_Node object at 0x7f1daf586cc0> 15.624999999999991 16
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2c18> 19.79166666666665 20
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 26.041666666666636 28
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 34.37499999999995 38
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 46.87499999999992 54
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 54.16666666666657 66
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 60.416666666666565 86
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 60.416666666666565 88
Completed Iteration #15
Best Reward: 2.083333333333334
Completed Iteration #16
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf563438> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50de10> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d320> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf553a20> 8.333333333333329 9
backprop <src.mcts.MCTS_Node object at 0x7f1daf542cc0> 9.374999999999995 10
backprop <src.mcts.MCTS_Node object at 0x7f1daf586cc0> 16.666666666666657 17
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2c18> 20.833333333333314 21
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 27.0833333333333 29
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 35.416666666666615 39
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 47.916666666666586 55
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 55.208333333333236 67
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 61.45833333333323 87
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 61.45833333333323 89
Completed Iteration #17
Best Reward: 2.083333333333334
Completed Iteration #18
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf5165f8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516668> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563438> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50de10> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d320> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf553a20> 9.374999999999995 10
backprop <src.mcts.MCTS_Node object at 0x7f1daf542cc0> 10.41666666666666 11
backprop <src.mcts.MCTS_Node object at 0x7f1daf586cc0> 17.70833333333332 18
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2c18> 21.87499999999998 22
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 28.124999999999964 30
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 36.45833333333328 40
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 48.95833333333325 56
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 56.2499999999999 68
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 62.49999999999989 88
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 62.49999999999989 90
Completed Iteration #19
Best Reward: 2.083333333333334
Completed Iteration #20
Best Reward: 2.083333333333334
Completed Iteration #21
Best Reward: 2.083333333333334
Completed Iteration #22
Best Reward: 2.083333333333334
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf533358> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50de10> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d320> 4.166666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf553a20> 10.41666666666666 11
backprop <src.mcts.MCTS_Node object at 0x7f1daf542cc0> 11.458333333333327 12
backprop <src.mcts.MCTS_Node object at 0x7f1daf586cc0> 18.749999999999986 19
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2c18> 22.916666666666643 23
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 29.16666666666663 31
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 37.49999999999994 41
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 49.999999999999915 57
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 57.291666666666565 69
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 63.54166666666656 89
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 63.54166666666656 91
Completed Iteration #23
Best Reward: 2.083333333333334
Completed Iteration #24
Best Reward: 2.083333333333334
Completed Iteration #25
Best Reward: 2.083333333333334
Completed MCTS Level/Depth: #8
root->0->4->6->4->8->8->6->0
Best Reward: 2.083333333333334
iteration: 44
found coverage increase 2.083333333333334
Current Total Coverage 14.583333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf563be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504710> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504710> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54ad68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf504710> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504710> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf504710> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf504710> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504710> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf504710> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5335c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf504710> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf533780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf504710> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf533940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf504710> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf533b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf504710> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54ad68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf504710> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf533278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf504710> 0.0 19
Completed Iteration #24
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf533ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54ad68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf504710> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 14.583333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f98> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f98> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f98> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f98> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f98> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f98> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f98> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f98> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f98> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f98> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f98> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf533400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f98> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1faa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f98> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f98> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f98> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf58dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f98> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f98> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 14.583333333333334
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfac8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfac8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfac8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfac8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfac8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfac8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc330f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfac8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfac8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfac8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfac8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfac8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfac8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfac8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfac8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfac8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 14.583333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6320> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6320> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6320> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6320> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6320> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6320> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6320> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6320> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6320> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f26a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6320> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6320> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6320> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6320> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6320> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 14.583333333333334
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7a90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7a90> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7a90> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7a90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7a90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7a90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7a90> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7a90> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7a90> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7a90> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7a90> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7a90> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7a90> 0.0 17
Completed Iteration #21
Best Reward: 0
coverage_call_count 1700
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7a90> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 14.583333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52588> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52588> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc073c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52588> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52588> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc077f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52588> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc529e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc078d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52588> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc079e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52588> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52588> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52588> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52588> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52588> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc078d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52588> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52cc0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52588> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52588> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 14.583333333333334
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8550> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8550> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8550> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8550> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c81d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8550> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8550> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8550> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8550> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8550> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8550> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8550> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8550> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc333c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8550> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8550> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 14.583333333333334
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf58dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cfd0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 1.041666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 1.041666666666666 9
Completed Iteration #13
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 1.041666666666666 10
Completed Iteration #14
Best Reward: 1.041666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68be0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 2.083333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 2.083333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 2.083333333333332 11
Completed Iteration #15
Best Reward: 1.041666666666666
Completed Iteration #16
Best Reward: 1.041666666666666
Completed Iteration #17
Best Reward: 1.041666666666666
Completed Iteration #18
Best Reward: 1.041666666666666
Completed Iteration #19
Best Reward: 1.041666666666666
Completed Iteration #20
Best Reward: 1.041666666666666
Completed Iteration #21
Best Reward: 1.041666666666666
Completed Iteration #22
Best Reward: 1.041666666666666
Completed Iteration #23
Best Reward: 1.041666666666666
Completed Iteration #24
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc688d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 2.083333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 2.083333333333332 12
Completed Iteration #25
Best Reward: 1.041666666666666
Completed MCTS Level/Depth: #0
root
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 2.083333333333332 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 2.083333333333332 13
Completed Iteration #0
Best Reward: 1.041666666666666
Completed Iteration #1
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68be0> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 2.083333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 2.083333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 2.083333333333332 8
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 2.083333333333332 14
Completed Iteration #2
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 2.083333333333332 9
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 2.083333333333332 15
Completed Iteration #3
Best Reward: 1.041666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafc900b8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc901d0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cfd0> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 3.1249999999999982 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 3.1249999999999982 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 3.1249999999999982 10
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 3.1249999999999982 16
Completed Iteration #4
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 3.1249999999999982 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 3.1249999999999982 11
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 3.1249999999999982 17
Completed Iteration #5
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 3.1249999999999982 12
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 3.1249999999999982 18
Completed Iteration #6
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 3.1249999999999982 13
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 3.1249999999999982 19
Completed Iteration #7
Best Reward: 1.041666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68470> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58de10> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68be0> 2.083333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 4.166666666666664 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 4.166666666666664 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 4.166666666666664 14
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 4.166666666666664 20
Completed Iteration #8
Best Reward: 1.041666666666666
Completed Iteration #9
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 4.166666666666664 15
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 4.166666666666664 21
Completed Iteration #10
Best Reward: 1.041666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb7f0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cc18> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc900b8> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc901d0> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cfd0> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 5.20833333333333 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 5.20833333333333 9
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 5.20833333333333 16
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 5.20833333333333 22
Completed Iteration #11
Best Reward: 1.041666666666666
Completed Iteration #12
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 5.20833333333333 17
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 5.20833333333333 23
Completed Iteration #13
Best Reward: 1.041666666666666
Completed Iteration #14
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 5.20833333333333 18
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 5.20833333333333 24
Completed Iteration #15
Best Reward: 1.041666666666666
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb390> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 6.2499999999999964 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 6.2499999999999964 10
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 6.2499999999999964 19
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 6.2499999999999964 25
Completed Iteration #16
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf58da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 6.2499999999999964 20
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 6.2499999999999964 26
Completed Iteration #17
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 6.2499999999999964 21
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 6.2499999999999964 27
Completed Iteration #18
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc901d0> 2.083333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cfd0> 3.1249999999999982 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 6.2499999999999964 9
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 6.2499999999999964 11
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 6.2499999999999964 22
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 6.2499999999999964 28
Completed Iteration #19
Best Reward: 1.041666666666666
Completed Iteration #20
Best Reward: 1.041666666666666
Completed Iteration #21
Best Reward: 1.041666666666666
Completed Iteration #22
Best Reward: 1.041666666666666
Completed Iteration #23
Best Reward: 1.041666666666666
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 6.2499999999999964 23
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 6.2499999999999964 29
Completed Iteration #24
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb390> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 6.2499999999999964 10
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 6.2499999999999964 12
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 6.2499999999999964 24
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 6.2499999999999964 30
Completed Iteration #25
Best Reward: 1.041666666666666
Completed MCTS Level/Depth: #1
root->3
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 6.2499999999999964 13
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 6.2499999999999964 25
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 6.2499999999999964 31
Completed Iteration #0
Best Reward: 1.041666666666666
Completed Iteration #1
Best Reward: 1.041666666666666
Completed Iteration #2
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 6.2499999999999964 11
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 6.2499999999999964 14
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 6.2499999999999964 26
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 6.2499999999999964 32
Completed Iteration #3
Best Reward: 1.041666666666666
Completed Iteration #4
Best Reward: 1.041666666666666
Completed Iteration #5
Best Reward: 1.041666666666666
Completed Iteration #6
Best Reward: 1.041666666666666
Completed Iteration #7
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4594e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 6.2499999999999964 12
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 6.2499999999999964 15
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 6.2499999999999964 27
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 6.2499999999999964 33
Completed Iteration #8
Best Reward: 1.041666666666666
Completed Iteration #9
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 6.2499999999999964 16
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 6.2499999999999964 28
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 6.2499999999999964 34
Completed Iteration #10
Best Reward: 1.041666666666666
Completed Iteration #11
Best Reward: 1.041666666666666
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cfd0> 3.1249999999999982 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 6.2499999999999964 13
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 6.2499999999999964 17
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 6.2499999999999964 29
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 6.2499999999999964 35
Completed Iteration #12
Best Reward: 1.041666666666666
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 8.333333333333327 14
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 8.333333333333327 18
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 8.333333333333327 30
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 8.333333333333327 36
Completed Iteration #13
Best Reward: 2.0833333333333304
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 8.333333333333327 19
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 8.333333333333327 31
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 8.333333333333327 37
Completed Iteration #14
Best Reward: 2.0833333333333304
Completed Iteration #15
Best Reward: 2.0833333333333304
Completed Iteration #16
Best Reward: 2.0833333333333304
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e4d3a2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 8.333333333333327 20
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 8.333333333333327 32
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 8.333333333333327 38
Completed Iteration #17
Best Reward: 2.0833333333333304
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e4d3a2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 8.333333333333327 15
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 8.333333333333327 21
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 8.333333333333327 33
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 8.333333333333327 39
Completed Iteration #18
Best Reward: 2.0833333333333304
Completed Iteration #19
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90da0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc40b8> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb390> 2.083333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 9.374999999999993 16
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 9.374999999999993 22
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 9.374999999999993 34
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 9.374999999999993 40
Completed Iteration #20
Best Reward: 2.0833333333333304
Completed Iteration #21
Best Reward: 2.0833333333333304
Completed Iteration #22
Best Reward: 2.0833333333333304
Completed Iteration #23
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb630> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbef0> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 11.458333333333323 17
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 11.458333333333323 23
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 11.458333333333323 35
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 11.458333333333323 41
Completed Iteration #24
Best Reward: 2.0833333333333304
Completed Iteration #25
Best Reward: 2.0833333333333304
Completed MCTS Level/Depth: #2
root->3->13
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4710> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07b38> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 13.541666666666654 18
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 13.541666666666654 24
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 13.541666666666654 36
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 13.541666666666654 42
Completed Iteration #0
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33080> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0b00> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb630> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbef0> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 7.291666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 14.58333333333332 19
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 14.58333333333332 25
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 14.58333333333332 37
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 14.58333333333332 43
Completed Iteration #1
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2e80> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07b38> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 9.374999999999988 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 16.66666666666665 20
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 16.66666666666665 26
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 16.66666666666665 38
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 16.66666666666665 44
Completed Iteration #2
Best Reward: 2.0833333333333304
Completed Iteration #3
Best Reward: 2.0833333333333304
Completed Iteration #4
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d5f8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58de10> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68be0> 3.1249999999999982 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 17.708333333333314 21
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 17.708333333333314 27
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 17.708333333333314 39
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 17.708333333333314 45
Completed Iteration #5
Best Reward: 2.0833333333333304
Completed Iteration #6
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8748> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4573ef0> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4710> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07b38> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 11.458333333333318 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 19.791666666666643 22
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 19.791666666666643 28
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 19.791666666666643 40
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 19.791666666666643 46
Completed Iteration #7
Best Reward: 2.0833333333333304
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4573978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d5f8> 1.041666666666666 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf58de10> 2.083333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68be0> 3.1249999999999982 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 19.791666666666643 23
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 19.791666666666643 29
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 19.791666666666643 41
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 19.791666666666643 47
Completed Iteration #8
Best Reward: 2.0833333333333304
Completed Iteration #9
Best Reward: 2.0833333333333304
Completed Iteration #10
Best Reward: 2.0833333333333304
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cfd0> 3.1249999999999982 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 19.791666666666643 24
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 19.791666666666643 30
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 19.791666666666643 42
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 19.791666666666643 48
Completed Iteration #11
Best Reward: 2.0833333333333304
Completed Iteration #12
Best Reward: 2.0833333333333304
Completed Iteration #13
Best Reward: 2.0833333333333304
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45940f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2e80> 2.0833333333333304 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07b38> 6.249999999999991 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 11.458333333333318 8
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 19.791666666666643 25
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 19.791666666666643 31
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 19.791666666666643 43
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 19.791666666666643 49
Completed Iteration #14
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafc526a0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d400> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90da0> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc40b8> 2.083333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb390> 3.1249999999999982 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 20.833333333333307 26
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 20.833333333333307 32
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 20.833333333333307 44
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 20.833333333333307 50
Completed Iteration #15
Best Reward: 2.0833333333333304
Completed Iteration #16
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33208> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 21.87499999999997 27
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 21.87499999999997 33
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 21.87499999999997 45
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 21.87499999999997 51
Completed Iteration #17
Best Reward: 2.0833333333333304
Completed Iteration #18
Best Reward: 2.0833333333333304
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4573be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc900b8> 2.083333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc901d0> 2.083333333333332 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cfd0> 3.1249999999999982 8
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 21.87499999999997 28
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 21.87499999999997 34
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 21.87499999999997 46
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 21.87499999999997 52
Completed Iteration #19
Best Reward: 2.0833333333333304
Completed Iteration #20
Best Reward: 2.0833333333333304
Completed Iteration #21
Best Reward: 2.0833333333333304
Completed Iteration #22
Best Reward: 2.0833333333333304
Completed Iteration #23
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2f28> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b8d0> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33208> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 23.9583333333333 29
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 23.9583333333333 35
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 23.9583333333333 47
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 23.9583333333333 53
Completed Iteration #24
Best Reward: 2.0833333333333304
Completed Iteration #25
Best Reward: 2.0833333333333304
Completed MCTS Level/Depth: #3
root->3->13->5
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b828> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8748> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4573ef0> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4710> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07b38> 8.333333333333321 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 13.541666666666648 9
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 26.04166666666663 30
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 26.04166666666663 36
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 26.04166666666663 48
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 26.04166666666663 54
Completed Iteration #0
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1db453d588> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbef0> 4.1666666666666625 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 14.583333333333314 10
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 27.083333333333293 31
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 27.083333333333293 37
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 27.083333333333293 49
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 27.083333333333293 55
Completed Iteration #1
Best Reward: 2.0833333333333304
Completed Iteration #2
Best Reward: 2.0833333333333304
Completed Iteration #3
Best Reward: 2.0833333333333304
Completed Iteration #4
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1db4525048> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbef0> 6.249999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 16.666666666666643 11
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 29.16666666666662 32
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 29.16666666666662 38
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 29.16666666666662 50
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 29.16666666666662 56
Completed Iteration #5
Best Reward: 2.0833333333333304
Completed Iteration #6
Best Reward: 2.0833333333333304
Completed Iteration #7
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b080> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453df98> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d588> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbef0> 7.291666666666659 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 17.708333333333307 12
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 30.208333333333286 33
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 30.208333333333286 39
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 30.208333333333286 51
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 30.208333333333286 57
Completed Iteration #8
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6710> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6ef0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525048> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbef0> 8.333333333333325 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 18.74999999999997 13
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 31.24999999999995 34
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 31.24999999999995 40
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 31.24999999999995 52
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 31.24999999999995 58
Completed Iteration #9
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c82b0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90588> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6710> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6ef0> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4525048> 4.1666666666666625 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbef0> 9.374999999999991 8
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 19.791666666666636 14
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 32.291666666666615 35
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 32.291666666666615 41
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 32.291666666666615 53
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 32.291666666666615 59
Completed Iteration #10
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0a90> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb5f8> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b828> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8748> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f1db4573ef0> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4710> 8.333333333333321 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07b38> 10.416666666666652 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 21.874999999999964 15
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 34.37499999999994 36
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 34.37499999999994 42
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 34.37499999999994 54
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 34.37499999999994 60
Completed Iteration #11
Best Reward: 2.0833333333333304
Completed Iteration #12
Best Reward: 2.0833333333333304
Completed Iteration #13
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1db453d978> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4573e48> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0a90> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb5f8> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b828> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8748> 8.333333333333321 5
backprop <src.mcts.MCTS_Node object at 0x7f1db4573ef0> 8.333333333333321 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4710> 10.416666666666652 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07b38> 12.499999999999982 8
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 23.958333333333293 16
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 36.45833333333327 37
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 36.45833333333327 43
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 36.45833333333327 55
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 36.45833333333327 61
Completed Iteration #14
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1db4525320> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07b38> 14.583333333333313 9
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 26.04166666666662 17
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 38.5416666666666 38
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 38.5416666666666 44
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 38.5416666666666 56
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 38.5416666666666 62
Completed Iteration #15
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1db4573588> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525f60> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d978> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4573e48> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0a90> 5.208333333333327 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb5f8> 5.208333333333327 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b828> 7.291666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 7.291666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8748> 9.374999999999988 6
backprop <src.mcts.MCTS_Node object at 0x7f1db4573ef0> 9.374999999999988 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4710> 11.458333333333318 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07b38> 15.624999999999979 10
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 27.083333333333286 18
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 39.583333333333265 39
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 39.583333333333265 45
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 39.583333333333265 57
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 39.583333333333265 63
Completed Iteration #16
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 29.166666666666615 19
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 41.66666666666659 40
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 41.66666666666659 46
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 41.66666666666659 58
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 41.66666666666659 64
Completed Iteration #17
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a65c0> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 31.249999999999943 20
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 43.74999999999992 41
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 43.74999999999992 47
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 43.74999999999992 59
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 43.74999999999992 65
Completed Iteration #18
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bef0> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf60> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a65c0> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 33.33333333333327 21
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 45.83333333333325 42
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 45.83333333333325 48
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 45.83333333333325 60
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 45.83333333333325 66
Completed Iteration #19
Best Reward: 2.0833333333333304
Completed Iteration #20
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f0b8> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b390> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b828> 9.374999999999988 6
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 9.374999999999988 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8748> 11.458333333333318 7
backprop <src.mcts.MCTS_Node object at 0x7f1db4573ef0> 11.458333333333318 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4710> 13.541666666666648 8
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07b38> 17.708333333333307 11
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 35.4166666666666 22
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 47.91666666666658 43
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 47.91666666666658 49
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 47.91666666666658 61
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 47.91666666666658 67
Completed Iteration #21
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f28d0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4a20> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b080> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453df98> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453d588> 3.1249999999999982 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbef0> 10.416666666666657 9
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 36.458333333333265 23
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 48.95833333333324 44
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 48.95833333333324 50
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 48.95833333333324 62
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 48.95833333333324 68
Completed Iteration #22
Best Reward: 2.0833333333333304
Completed Iteration #23
Best Reward: 2.0833333333333304
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4525860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45734a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d978> 3.1249999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f1db4573e48> 3.1249999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0a90> 5.208333333333327 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb5f8> 5.208333333333327 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b828> 9.374999999999988 7
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bd30> 9.374999999999988 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8748> 11.458333333333318 8
backprop <src.mcts.MCTS_Node object at 0x7f1db4573ef0> 11.458333333333318 8
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4710> 13.541666666666648 9
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07b38> 17.708333333333307 12
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 36.458333333333265 24
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 48.95833333333324 45
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 48.95833333333324 51
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 48.95833333333324 63
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 48.95833333333324 69
Completed Iteration #24
Best Reward: 2.0833333333333304
Completed Iteration #25
Best Reward: 2.0833333333333304
Completed MCTS Level/Depth: #4
root->3->13->5->18
Best Reward: 2.0833333333333304
Completed Iteration #0
Best Reward: 2.0833333333333304
Completed Iteration #1
Best Reward: 2.0833333333333304
Completed Iteration #2
Best Reward: 2.0833333333333304
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 6.249999999999991 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 36.458333333333265 25
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 48.95833333333324 46
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 48.95833333333324 52
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 48.95833333333324 64
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 48.95833333333324 70
Completed Iteration #3
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b710> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b4e0> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bef0> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf60> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a65c0> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 8.333333333333321 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 8.333333333333321 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 38.54166666666659 26
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 51.04166666666657 47
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 51.04166666666657 53
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 51.04166666666657 65
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 51.04166666666657 71
Completed Iteration #4
Best Reward: 2.0833333333333304
Completed Iteration #5
Best Reward: 2.0833333333333304
Completed Iteration #6
Best Reward: 2.0833333333333304
Completed Iteration #7
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1db453d828> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 8.333333333333321 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 10.416666666666652 6
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 10.416666666666652 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 40.62499999999992 27
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 53.1249999999999 48
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 53.1249999999999 54
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 53.1249999999999 66
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 53.1249999999999 72
Completed Iteration #8
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d2e8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 11.458333333333318 8
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 41.666666666666586 28
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 54.166666666666565 49
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 54.166666666666565 55
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 54.166666666666565 67
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 54.166666666666565 73
Completed Iteration #9
Best Reward: 2.0833333333333304
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 11.458333333333318 9
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 41.666666666666586 29
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 54.166666666666565 50
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 54.166666666666565 56
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 54.166666666666565 68
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 54.166666666666565 74
Completed Iteration #10
Best Reward: 2.0833333333333304
Completed Iteration #11
Best Reward: 2.0833333333333304
Completed Iteration #12
Best Reward: 2.0833333333333304
Completed Iteration #13
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c358> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11ff60> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d828> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 10.416666666666652 6
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 12.499999999999982 7
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 13.541666666666648 10
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 43.749999999999915 30
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 56.24999999999989 51
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 56.24999999999989 57
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 56.24999999999989 69
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 56.24999999999989 75
Completed Iteration #14
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0390> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 15.624999999999979 11
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 45.83333333333324 31
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 58.33333333333322 52
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 58.33333333333322 58
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 58.33333333333322 70
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 58.33333333333322 76
Completed Iteration #15
Best Reward: 2.0833333333333304
Completed Iteration #16
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1db4525b00> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90be0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d2e8> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 16.666666666666643 12
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 46.87499999999991 32
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 59.374999999999886 53
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 59.374999999999886 59
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 59.374999999999886 71
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 59.374999999999886 77
Completed Iteration #17
Best Reward: 2.0833333333333304
Completed Iteration #18
Best Reward: 2.0833333333333304
Completed Iteration #19
Best Reward: 2.0833333333333304
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0390> 2.0833333333333304 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 16.666666666666643 13
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 46.87499999999991 33
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 59.374999999999886 54
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 59.374999999999886 60
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 59.374999999999886 72
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 59.374999999999886 78
Completed Iteration #20
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6c88> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe518> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0390> 4.166666666666661 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 18.74999999999997 14
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 48.958333333333236 34
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 61.458333333333215 55
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 61.458333333333215 61
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 61.458333333333215 73
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 61.458333333333215 79
Completed Iteration #21
Best Reward: 2.0833333333333304
Completed Iteration #22
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1db4525a58> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 12.499999999999982 7
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 14.583333333333313 8
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 20.8333333333333 15
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 51.041666666666565 35
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 63.54166666666654 56
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 63.54166666666654 62
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 63.54166666666654 74
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 63.54166666666654 80
Completed Iteration #23
Best Reward: 2.0833333333333304
coverage_call_count 1900
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f908> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 14.583333333333313 8
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 16.666666666666643 9
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 22.91666666666663 16
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 53.12499999999989 36
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 65.62499999999987 57
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 65.62499999999987 63
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 65.62499999999987 75
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 65.62499999999987 81
Completed Iteration #24
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11fbe0> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6c88> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe518> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0390> 6.249999999999991 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 24.999999999999957 17
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 55.20833333333322 37
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 67.7083333333332 58
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 67.7083333333332 64
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 67.7083333333332 76
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 67.7083333333332 82
Completed Iteration #25
Best Reward: 2.0833333333333304
Completed MCTS Level/Depth: #5
root->3->13->5->18->0
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1db458d5f8> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf60> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a65c0> 8.333333333333321 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 16.666666666666643 9
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 18.74999999999997 10
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 27.083333333333286 18
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 57.29166666666655 38
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 69.79166666666653 59
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 69.79166666666653 65
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 69.79166666666653 77
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 69.79166666666653 83
Completed Iteration #0
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1db458df60> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458da20> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f908> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 18.74999999999997 10
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 20.8333333333333 11
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 29.166666666666615 19
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 59.37499999999988 39
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 71.87499999999986 60
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 71.87499999999986 66
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 71.87499999999986 78
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 71.87499999999986 84
Completed Iteration #1
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155518> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155390> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 21.874999999999964 12
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 30.20833333333328 20
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 60.41666666666654 40
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 72.91666666666653 61
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 72.91666666666653 67
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 72.91666666666653 79
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 72.91666666666653 85
Completed Iteration #2
Best Reward: 2.0833333333333304
Completed Iteration #3
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6a20> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 20.8333333333333 11
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 23.958333333333293 13
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 32.29166666666661 21
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 62.49999999999987 41
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 74.99999999999986 62
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 74.99999999999986 68
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 74.99999999999986 80
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 74.99999999999986 86
Completed Iteration #4
Best Reward: 2.0833333333333304
Completed Iteration #5
Best Reward: 2.0833333333333304
Completed Iteration #6
Best Reward: 2.0833333333333304
Completed Iteration #7
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33ef0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dd68> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525a58> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 21.874999999999964 12
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 24.999999999999957 14
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 33.33333333333327 22
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 63.541666666666536 42
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 76.04166666666653 63
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 76.04166666666653 69
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 76.04166666666653 81
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 76.04166666666653 87
Completed Iteration #8
Best Reward: 2.0833333333333304
Completed Iteration #9
Best Reward: 2.0833333333333304
Completed Iteration #10
Best Reward: 2.0833333333333304
Completed Iteration #11
Best Reward: 2.0833333333333304
Completed Iteration #12
Best Reward: 2.0833333333333304
Completed Iteration #13
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f160> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bbe0> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c358> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11ff60> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453d828> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 23.958333333333293 13
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 27.083333333333286 15
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 35.4166666666666 23
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 65.62499999999987 43
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 78.12499999999986 64
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 78.12499999999986 70
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 78.12499999999986 82
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 78.12499999999986 88
Completed Iteration #14
Best Reward: 2.0833333333333304
Completed Iteration #15
Best Reward: 2.0833333333333304
Completed Iteration #16
Best Reward: 2.0833333333333304
Completed Iteration #17
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155470> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458da20> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f908> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 26.04166666666662 14
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 29.166666666666615 16
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 37.49999999999993 24
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 67.7083333333332 44
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 80.20833333333319 65
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 80.20833333333319 71
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 80.20833333333319 83
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 80.20833333333319 89
Completed Iteration #18
Best Reward: 2.0833333333333304
Completed Iteration #19
Best Reward: 2.0833333333333304
Completed Iteration #20
Best Reward: 2.0833333333333304
Completed Iteration #21
Best Reward: 2.0833333333333304
Completed Iteration #22
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8160> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8ac8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155470> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1db458da20> 5.208333333333327 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f908> 7.291666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 27.083333333333286 15
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 30.20833333333328 17
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 38.54166666666659 25
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 68.74999999999987 45
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 81.24999999999986 66
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 81.24999999999986 72
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 81.24999999999986 84
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 81.24999999999986 90
Completed Iteration #23
Best Reward: 2.0833333333333304
Completed Iteration #24
Best Reward: 2.0833333333333304
Completed Iteration #25
Best Reward: 2.0833333333333304
Completed MCTS Level/Depth: #6
root->3->13->5->18->0->10
Best Reward: 2.0833333333333304
Completed Iteration #0
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094b70> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fe48> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b710> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b4e0> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bef0> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf60> 8.333333333333321 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a65c0> 10.416666666666652 6
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 29.166666666666615 16
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 32.29166666666661 18
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 40.62499999999992 26
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 70.8333333333332 46
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 83.33333333333319 67
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 83.33333333333319 73
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 83.33333333333319 85
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 83.33333333333319 91
Completed Iteration #1
Best Reward: 2.0833333333333304
Completed Iteration #2
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094ef0> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082f28> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d5f8> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf60> 10.416666666666652 6
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a65c0> 12.499999999999982 7
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 31.249999999999943 17
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 34.374999999999936 19
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 42.70833333333325 27
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 72.91666666666653 47
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 85.41666666666652 68
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 85.41666666666652 74
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 85.41666666666652 86
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 85.41666666666652 92
Completed Iteration #3
Best Reward: 2.0833333333333304
Completed Iteration #4
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1db4573438> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4a90> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f160> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bbe0> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c358> 5.208333333333327 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11ff60> 5.208333333333327 4
backprop <src.mcts.MCTS_Node object at 0x7f1db453d828> 7.291666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 32.29166666666661 18
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 35.4166666666666 20
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 43.749999999999915 28
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 73.9583333333332 48
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 86.45833333333319 69
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 86.45833333333319 75
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 86.45833333333319 87
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 86.45833333333319 93
Completed Iteration #5
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16df60> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f2e8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8160> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8ac8> 2.083333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155470> 4.1666666666666625 4
backprop <src.mcts.MCTS_Node object at 0x7f1db458da20> 6.249999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f908> 8.333333333333323 6
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 33.33333333333327 19
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 36.458333333333265 21
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 44.79166666666658 29
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 74.99999999999987 49
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 87.49999999999986 70
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 87.49999999999986 76
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 87.49999999999986 88
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 87.49999999999986 94
Completed Iteration #6
Best Reward: 2.0833333333333304
Completed Iteration #7
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094d30> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094080> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6a20> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 35.4166666666666 20
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 38.54166666666659 22
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 46.87499999999991 30
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 77.0833333333332 50
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 89.58333333333319 71
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 89.58333333333319 77
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 89.58333333333319 89
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 89.58333333333319 95
Completed Iteration #8
Best Reward: 2.0833333333333304
Completed Iteration #9
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a84e0> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8b00> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094b70> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fe48> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b710> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b4e0> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bef0> 8.333333333333321 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf60> 12.499999999999982 7
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a65c0> 14.583333333333313 8
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 37.49999999999993 21
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 40.62499999999992 23
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 48.958333333333236 31
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 79.16666666666653 51
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 91.66666666666652 72
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 91.66666666666652 78
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 91.66666666666652 90
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 91.66666666666652 96
Completed Iteration #10
Best Reward: 2.0833333333333304
Completed Iteration #11
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1550f0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155ef0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6a20> 5.208333333333327 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 38.54166666666659 22
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 41.666666666666586 24
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 49.9999999999999 32
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 80.2083333333332 52
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 92.70833333333319 73
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 92.70833333333319 79
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 92.70833333333319 91
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 92.70833333333319 97
Completed Iteration #12
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1e9b29ee48> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 40.62499999999992 23
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 43.749999999999915 25
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 52.08333333333323 33
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 82.29166666666653 53
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 94.79166666666652 74
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 94.79166666666652 80
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 94.79166666666652 92
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 94.79166666666652 98
Completed Iteration #13
Best Reward: 2.0833333333333304
Completed Iteration #14
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d9e8> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 42.70833333333325 24
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 45.83333333333324 26
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 54.16666666666656 34
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 84.37499999999986 54
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 96.87499999999984 75
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 96.87499999999984 81
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 96.87499999999984 93
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 96.87499999999984 99
Completed Iteration #15
Best Reward: 2.0833333333333304
Completed Iteration #16
Best Reward: 2.0833333333333304
Completed Iteration #17
Best Reward: 2.0833333333333304
Completed Iteration #18
Best Reward: 2.0833333333333304
Completed Iteration #19
Best Reward: 2.0833333333333304
Completed Iteration #20
Best Reward: 2.0833333333333304
Completed Iteration #21
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a320> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a0f0> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d9e8> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 44.79166666666658 25
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 47.91666666666657 27
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 56.249999999999886 35
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 86.45833333333319 55
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 98.95833333333317 76
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 98.95833333333317 82
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 98.95833333333317 94
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 98.95833333333317 100
Completed Iteration #22
Best Reward: 2.0833333333333304
Completed Iteration #23
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8828> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bbe0> 5.208333333333327 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c358> 7.291666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11ff60> 7.291666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f1db453d828> 9.374999999999988 6
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 46.87499999999991 26
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 49.9999999999999 28
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 58.333333333333215 36
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 88.54166666666652 56
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 101.0416666666665 77
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 101.0416666666665 83
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 101.0416666666665 95
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 101.0416666666665 101
Completed Iteration #24
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b470> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094860> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1e9b29ee48> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 48.958333333333236 27
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 52.08333333333323 29
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 60.41666666666654 37
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 90.62499999999984 57
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 103.12499999999983 78
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 103.12499999999983 84
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 103.12499999999983 96
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 103.12499999999983 102
Completed Iteration #25
Best Reward: 2.0833333333333304
Completed MCTS Level/Depth: #7
root->3->13->5->18->0->10->8
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d71d0> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d72b0> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094ef0> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082f28> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1db458d5f8> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf60> 14.583333333333313 8
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a65c0> 16.666666666666643 9
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 51.041666666666565 28
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 54.16666666666656 30
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 62.49999999999987 38
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 92.70833333333317 58
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 105.20833333333316 79
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 105.20833333333316 85
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 105.20833333333316 97
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 105.20833333333316 103
Completed Iteration #0
Best Reward: 2.0833333333333304
Completed Iteration #1
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d70f0> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf60> 16.666666666666643 9
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a65c0> 18.74999999999997 10
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 53.12499999999989 29
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 56.249999999999886 31
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 64.5833333333332 39
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 94.7916666666665 59
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 107.29166666666649 80
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 107.29166666666649 86
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 107.29166666666649 98
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 107.29166666666649 104
Completed Iteration #2
Best Reward: 2.0833333333333304
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d70f0> 2.0833333333333304 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf60> 16.666666666666643 10
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a65c0> 18.74999999999997 11
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 53.12499999999989 30
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 56.249999999999886 32
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 64.5833333333332 40
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 94.7916666666665 60
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 107.29166666666649 81
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 107.29166666666649 87
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 107.29166666666649 99
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 107.29166666666649 105
Completed Iteration #3
Best Reward: 2.0833333333333304
Completed Iteration #4
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac18> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082f28> 5.208333333333327 4
backprop <src.mcts.MCTS_Node object at 0x7f1db458d5f8> 7.291666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf60> 17.708333333333307 11
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a65c0> 19.791666666666636 12
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 54.16666666666656 31
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 57.29166666666655 33
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 65.62499999999987 41
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 95.83333333333317 61
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 108.33333333333316 82
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 108.33333333333316 88
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 108.33333333333316 100
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 108.33333333333316 106
Completed Iteration #5
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3550> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3780> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d71d0> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d72b0> 4.166666666666661 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094ef0> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082f28> 7.291666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f1db458d5f8> 9.374999999999988 6
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf60> 19.791666666666636 12
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a65c0> 21.874999999999964 13
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 56.249999999999886 32
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 59.37499999999988 34
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 67.7083333333332 42
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 97.9166666666665 62
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 110.41666666666649 83
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 110.41666666666649 89
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 110.41666666666649 101
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 110.41666666666649 107
Completed Iteration #6
Best Reward: 2.0833333333333304
Completed Iteration #7
Best Reward: 2.0833333333333304
Completed Iteration #8
Best Reward: 2.0833333333333304
Completed Iteration #9
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6dd8> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4573748> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3550> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3780> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d71d0> 5.208333333333327 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d72b0> 5.208333333333327 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094ef0> 7.291666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082f28> 8.333333333333323 6
backprop <src.mcts.MCTS_Node object at 0x7f1db458d5f8> 10.416666666666654 7
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf60> 20.8333333333333 13
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a65c0> 22.91666666666663 14
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 57.29166666666655 33
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 60.41666666666654 35
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 68.74999999999987 43
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 98.95833333333317 63
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 111.45833333333316 84
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 111.45833333333316 90
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 111.45833333333316 102
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 111.45833333333316 108
Completed Iteration #10
Best Reward: 2.0833333333333304
Completed Iteration #11
Best Reward: 2.0833333333333304
Completed Iteration #12
Best Reward: 2.0833333333333304
Completed Iteration #13
Best Reward: 2.0833333333333304
Completed Iteration #14
Best Reward: 2.0833333333333304
Completed Iteration #15
Best Reward: 2.0833333333333304
Completed Iteration #16
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e30f0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082f28> 9.37499999999999 7
backprop <src.mcts.MCTS_Node object at 0x7f1db458d5f8> 11.45833333333332 8
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf60> 21.874999999999964 14
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a65c0> 23.958333333333293 15
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 58.333333333333215 34
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 61.45833333333321 36
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 69.79166666666654 44
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 99.99999999999984 64
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 112.49999999999983 85
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 112.49999999999983 91
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 112.49999999999983 103
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 112.49999999999983 109
Completed Iteration #17
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d8d0> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fe48> 6.249999999999991 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b710> 8.333333333333321 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b4e0> 8.333333333333321 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bef0> 10.416666666666652 6
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf60> 23.958333333333293 15
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a65c0> 26.04166666666662 16
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 60.41666666666654 35
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 63.541666666666536 37
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 71.87499999999987 45
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 102.08333333333317 65
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 114.58333333333316 86
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 114.58333333333316 92
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 114.58333333333316 104
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 114.58333333333316 110
Completed Iteration #18
Best Reward: 2.0833333333333304
Completed Iteration #19
Best Reward: 2.0833333333333304
Completed Iteration #20
Best Reward: 2.0833333333333304
Reward: 2.0833333333333304
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03be10> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03bd68> 2.0833333333333304 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d70f0> 4.166666666666661 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf60> 26.04166666666662 16
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a65c0> 28.12499999999995 17
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 62.49999999999987 36
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 65.62499999999987 38
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 73.9583333333332 46
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 104.1666666666665 66
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 116.66666666666649 87
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 116.66666666666649 93
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 116.66666666666649 105
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 116.66666666666649 111
Completed Iteration #21
Best Reward: 2.0833333333333304
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a65c0> 28.12499999999995 18
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 62.49999999999987 37
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 65.62499999999987 39
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 73.9583333333332 47
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 104.1666666666665 67
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 116.66666666666649 88
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 116.66666666666649 94
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 116.66666666666649 106
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 116.66666666666649 112
Completed Iteration #22
Best Reward: 2.0833333333333304
Completed Iteration #23
Best Reward: 2.0833333333333304
Completed Iteration #24
Best Reward: 2.0833333333333304
Reward: 1.041666666666666
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088128> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030fd0> 1.041666666666666 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d5f8> 12.499999999999986 9
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf60> 27.083333333333286 17
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a65c0> 29.166666666666615 19
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 63.541666666666536 38
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 66.66666666666654 40
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 74.99999999999987 48
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0438> 105.20833333333317 68
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c748> 117.70833333333316 89
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e66a0> 117.70833333333316 95
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 117.70833333333316 107
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33320> 117.70833333333316 113
Completed Iteration #25
Best Reward: 2.0833333333333304
Completed MCTS Level/Depth: #8
root->3->13->5->18->0->10->8->0
Best Reward: 2.0833333333333304
iteration: 52
found coverage increase 2.0833333333333304
Current Total Coverage 16.666666666666664
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030160> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0827f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030160> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030160> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030160> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030160> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0827f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030160> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e37f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030160> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0827f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030160> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0827f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030160> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030160> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0827f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030160> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0889b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030160> 0.0 15
Completed Iteration #20
Best Reward: 0
coverage_call_count 2000
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030160> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030160> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030160> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 16.666666666666664
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0945f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068be0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 16.666666666666664
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ebe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ebe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4565d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ebe0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ebe0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c6ad6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ebe0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4565390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ebe0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ebe0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ebe0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ebe0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ebe0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e9b2b15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ebe0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e9b2b12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ebe0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ebe0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ebe0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ebe0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45652e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ebe0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1de160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ebe0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ebe0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ebe0> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ebe0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 16.666666666666664
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454cf98> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454cf98> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45074a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db454cf98> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45072b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454cf98> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45077b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db454cf98> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454cf98> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db454cf98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454cf98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0687f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454cf98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e4f74ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0687f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db454cf98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db454cf98> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f61d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db454cf98> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db454cf98> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db454cf98> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e9b2b1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454cf98> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f61d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1db454cf98> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454cf98> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1db454cf98> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf533898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f61d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1db454cf98> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf533c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db454cf98> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 16.666666666666664
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5337f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6c88> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5164e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6c88> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5168d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6c88> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5162b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6c88> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf533a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6c88> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5167b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5168d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6c88> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6c88> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6c88> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf542630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5337f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6c88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf542be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6c88> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6c88> 0.0 13
Completed Iteration #16
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf533898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6c88> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6c88> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5337f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6c88> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6c88> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6c88> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1de160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6c88> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6c88> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 16.666666666666664
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45075f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1de1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc680b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e9b2b1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f66d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 2.0833333333333357 13
Completed Iteration #16
Best Reward: 2.0833333333333357
Completed Iteration #17
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f66d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 2.0833333333333357 14
Completed Iteration #18
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1db4565dd8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 4.166666666666671 15
Completed Iteration #19
Best Reward: 2.0833333333333357
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3128> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565dd8> 3.125000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 3.125000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 5.208333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 5.208333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 5.208333333333343 16
Completed Iteration #20
Best Reward: 2.0833333333333357
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e400> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04eda0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3128> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4565dd8> 4.1666666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 4.1666666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 6.250000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 6.250000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 6.250000000000014 17
Completed Iteration #21
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e400> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04eda0> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3128> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f1db4565dd8> 4.1666666666666785 5
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 4.1666666666666785 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 6.250000000000014 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 6.250000000000014 6
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 6.250000000000014 18
Completed Iteration #22
Best Reward: 2.0833333333333357
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f518> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 7.291666666666686 7
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 7.291666666666686 19
Completed Iteration #23
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068b00> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 9.375000000000021 8
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 9.375000000000021 20
Completed Iteration #24
Best Reward: 2.0833333333333357
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082b00> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0688d0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f518> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 10.416666666666693 9
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 10.416666666666693 21
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #0
root
Best Reward: 2.0833333333333357
Completed Iteration #0
Best Reward: 2.0833333333333357
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f1daf542f60> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542ba8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068b00> 3.125000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 11.458333333333364 10
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 11.458333333333364 22
Completed Iteration #1
Best Reward: 2.0833333333333357
Completed Iteration #2
Best Reward: 2.0833333333333357
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f1daf542588> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04eda0> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3128> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 3.125000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f1db4565dd8> 5.20833333333335 6
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 5.20833333333335 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 7.291666666666686 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 12.500000000000036 11
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 12.500000000000036 23
Completed Iteration #3
Best Reward: 2.0833333333333357
Completed Iteration #4
Best Reward: 2.0833333333333357
Completed Iteration #5
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082b00> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0688d0> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f518> 2.083333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 12.500000000000036 12
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 12.500000000000036 24
Completed Iteration #6
Best Reward: 2.0833333333333357
Completed Iteration #7
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 7.291666666666686 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 9.375000000000021 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 14.583333333333371 13
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 14.583333333333371 25
Completed Iteration #8
Best Reward: 2.0833333333333357
Completed Iteration #9
Best Reward: 2.0833333333333357
Completed Iteration #10
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 9.375000000000021 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 11.458333333333357 9
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 16.666666666666707 14
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 16.666666666666707 26
Completed Iteration #11
Best Reward: 2.0833333333333357
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ef60> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542f98> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542f60> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf542ba8> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068b00> 4.1666666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 17.70833333333338 15
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 17.70833333333338 27
Completed Iteration #12
Best Reward: 2.0833333333333357
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fb70> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542ba8> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068b00> 5.20833333333335 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 18.75000000000005 16
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 18.75000000000005 28
Completed Iteration #13
Best Reward: 2.0833333333333357
Completed Iteration #14
Best Reward: 2.0833333333333357
Completed Iteration #15
Best Reward: 2.0833333333333357
Completed Iteration #16
Best Reward: 2.0833333333333357
Completed Iteration #17
Best Reward: 2.0833333333333357
Completed Iteration #18
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a35f8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3e48> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 11.458333333333357 9
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 13.541666666666693 10
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 20.833333333333385 17
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 20.833333333333385 29
Completed Iteration #19
Best Reward: 2.0833333333333357
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a36d8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542080> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068b00> 6.250000000000021 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 21.875000000000057 18
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 21.875000000000057 30
Completed Iteration #20
Best Reward: 2.0833333333333357
Completed Iteration #21
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5867f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 21.875000000000057 19
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 21.875000000000057 31
Completed Iteration #22
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf586908> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 13.541666666666693 10
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 15.625000000000028 11
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 23.958333333333393 20
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 23.958333333333393 32
Completed Iteration #23
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf586f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 23.958333333333393 21
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 23.958333333333393 33
Completed Iteration #24
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf586080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 23.958333333333393 22
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 23.958333333333393 34
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #1
root->1
Best Reward: 2.0833333333333357
Completed Iteration #0
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf553e10> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553a20> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565dd8> 7.291666666666686 7
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 15.625000000000028 11
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 17.708333333333364 12
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 26.04166666666673 23
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 26.04166666666673 35
Completed Iteration #1
Best Reward: 2.0833333333333357
Completed Iteration #2
Best Reward: 2.0833333333333357
Completed Iteration #3
Best Reward: 2.0833333333333357
Completed Iteration #4
Best Reward: 2.0833333333333357
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f1daf553550> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553f60> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553e10> 3.125000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf553a20> 3.125000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4565dd8> 8.333333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 16.6666666666667 12
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 18.750000000000036 13
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 27.0833333333334 24
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 27.0833333333334 36
Completed Iteration #5
Best Reward: 2.0833333333333357
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d2e8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553f60> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf553e10> 4.1666666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf553a20> 4.1666666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f1db4565dd8> 9.375000000000028 9
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 17.70833333333337 13
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 19.791666666666707 14
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 28.12500000000007 25
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 28.12500000000007 37
Completed Iteration #6
Best Reward: 2.0833333333333357
Completed Iteration #7
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf542748> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d668> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542588> 3.125000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04eda0> 4.1666666666666785 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3128> 5.20833333333335 6
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 5.20833333333335 6
backprop <src.mcts.MCTS_Node object at 0x7f1db4565dd8> 11.458333333333364 10
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 19.791666666666707 14
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 21.875000000000043 15
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 30.208333333333407 26
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 30.208333333333407 38
Completed Iteration #8
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0882b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586908> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 19.791666666666707 15
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 21.875000000000043 16
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 30.208333333333407 27
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 30.208333333333407 39
Completed Iteration #9
Best Reward: 2.0833333333333357
Completed Iteration #10
Best Reward: 2.0833333333333357
Completed Iteration #11
Best Reward: 2.0833333333333357
Completed Iteration #12
Best Reward: 2.0833333333333357
Completed Iteration #13
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3438> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5869b0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586908> 4.166666666666671 4
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 21.875000000000043 16
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 23.95833333333338 17
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 32.29166666666674 28
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 32.29166666666674 40
Completed Iteration #14
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553a20> 4.1666666666666785 5
backprop <src.mcts.MCTS_Node object at 0x7f1db4565dd8> 11.458333333333364 11
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 21.875000000000043 17
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 23.95833333333338 18
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 32.29166666666674 29
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 32.29166666666674 41
Completed Iteration #15
Best Reward: 2.0833333333333357
Completed Iteration #16
Best Reward: 2.0833333333333357
Completed Iteration #17
Best Reward: 2.0833333333333357
Completed Iteration #18
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf586278> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a32e8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 8.333333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 23.95833333333338 18
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 26.041666666666714 19
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 34.37500000000008 30
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 34.37500000000008 42
Completed Iteration #19
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf50de80> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dc50> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 10.416666666666679 6
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 26.041666666666714 19
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 28.12500000000005 20
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 36.458333333333414 31
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 36.458333333333414 43
Completed Iteration #20
Best Reward: 2.0833333333333357
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f1daf50deb8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d518> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50de80> 3.125000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dc50> 3.125000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 11.45833333333335 7
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 27.083333333333385 20
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 29.16666666666672 21
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 37.500000000000085 32
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 37.500000000000085 44
Completed Iteration #21
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dc18> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d470> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 13.541666666666686 8
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 29.16666666666672 21
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 31.250000000000057 22
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 39.58333333333342 33
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 39.58333333333342 45
Completed Iteration #22
Best Reward: 2.0833333333333357
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f1daf504a90> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04eda0> 5.20833333333335 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3128> 6.250000000000021 7
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 6.250000000000021 7
backprop <src.mcts.MCTS_Node object at 0x7f1db4565dd8> 12.500000000000036 12
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 30.208333333333393 22
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 32.29166666666673 23
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 40.62500000000009 34
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 40.62500000000009 46
Completed Iteration #23
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf504160> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553780> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 34.375000000000064 24
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 42.70833333333343 35
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 42.70833333333343 47
Completed Iteration #24
Best Reward: 2.0833333333333357
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #2
root->1->17
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5045f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542588> 3.125000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04eda0> 5.20833333333335 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3128> 6.250000000000021 8
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 6.250000000000021 8
backprop <src.mcts.MCTS_Node object at 0x7f1db4565dd8> 12.500000000000036 13
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 30.208333333333393 23
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 34.375000000000064 25
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 42.70833333333343 36
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 42.70833333333343 48
Completed Iteration #0
Best Reward: 2.0833333333333357
Completed Iteration #1
Best Reward: 2.0833333333333357
Completed Iteration #2
Best Reward: 2.0833333333333357
Completed Iteration #3
Best Reward: 2.0833333333333357
Completed Iteration #4
Best Reward: 2.0833333333333357
Completed Iteration #5
Best Reward: 2.0833333333333357
Completed Iteration #6
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf5040b8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504940> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586278> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a32e8> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 8.333333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 8.333333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 15.625000000000021 9
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 32.29166666666673 24
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 36.4583333333334 26
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 44.791666666666764 37
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 44.791666666666764 49
Completed Iteration #7
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf504780> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 10.416666666666679 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 17.708333333333357 10
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 34.375000000000064 25
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 38.541666666666735 27
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 46.8750000000001 38
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 46.8750000000001 50
Completed Iteration #8
Best Reward: 2.0833333333333357
Completed Iteration #9
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1db454c358> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068710> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3438> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5869b0> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf586908> 6.250000000000007 5
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 36.4583333333334 26
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 40.62500000000007 28
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 48.958333333333435 39
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 48.958333333333435 51
Completed Iteration #10
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d9e8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068710> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3438> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5869b0> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf586908> 8.333333333333343 6
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 38.541666666666735 27
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 42.70833333333341 29
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 51.04166666666677 40
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 51.04166666666677 52
Completed Iteration #11
Best Reward: 2.0833333333333357
Completed Iteration #12
Best Reward: 2.0833333333333357
Completed Iteration #13
Best Reward: 2.0833333333333357
coverage_call_count 2200
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf586710> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 40.62500000000007 28
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 44.79166666666674 30
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 53.12500000000011 41
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 53.12500000000011 53
Completed Iteration #14
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf563c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504a90> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04eda0> 5.20833333333335 8
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3128> 6.250000000000021 9
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0886a0> 6.250000000000021 9
backprop <src.mcts.MCTS_Node object at 0x7f1db4565dd8> 12.500000000000036 14
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 40.62500000000007 29
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 44.79166666666674 31
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 53.12500000000011 42
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 53.12500000000011 54
Completed Iteration #15
Best Reward: 2.0833333333333357
Completed Iteration #16
Best Reward: 2.0833333333333357
Completed Iteration #17
Best Reward: 2.0833333333333357
Completed Iteration #18
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf5636a0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5637b8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d9e8> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068710> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3438> 8.333333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf5869b0> 8.333333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf586908> 10.416666666666679 7
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 42.70833333333341 30
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 46.87500000000008 32
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 55.20833333333344 43
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 55.20833333333344 55
Completed Iteration #19
Best Reward: 2.0833333333333357
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f1daf563828> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 43.75000000000008 31
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 47.91666666666675 33
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 56.250000000000114 44
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 56.250000000000114 56
Completed Iteration #20
Best Reward: 2.0833333333333357
Completed Iteration #21
Best Reward: 2.0833333333333357
Completed Iteration #22
Best Reward: 2.0833333333333357
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a6d8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553f60> 3.125000000000014 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf553e10> 5.20833333333335 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf553a20> 5.20833333333335 6
backprop <src.mcts.MCTS_Node object at 0x7f1db4565dd8> 13.541666666666707 15
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 44.79166666666675 32
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 48.95833333333342 34
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 57.291666666666785 45
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 57.291666666666785 57
Completed Iteration #23
Best Reward: 2.0833333333333357
Completed Iteration #24
Best Reward: 2.0833333333333357
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #3
root->1->17->2
Best Reward: 2.0833333333333357
Completed Iteration #0
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2e8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3dd8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50de80> 5.208333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dc50> 5.208333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 19.791666666666693 11
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 46.875000000000085 33
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 51.04166666666676 35
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 59.37500000000012 46
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 59.37500000000012 58
Completed Iteration #1
Best Reward: 2.0833333333333357
Completed Iteration #2
Best Reward: 2.0833333333333357
Completed Iteration #3
Best Reward: 2.0833333333333357
Completed Iteration #4
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf516ef0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 12.500000000000014 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 21.87500000000003 12
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 48.95833333333342 34
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 53.12500000000009 36
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 61.45833333333346 47
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 61.45833333333346 59
Completed Iteration #5
Best Reward: 2.0833333333333357
Completed Iteration #6
Best Reward: 2.0833333333333357
Completed Iteration #7
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d898> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a32e8> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 10.416666666666679 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 14.58333333333335 8
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 23.958333333333364 13
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 51.04166666666676 35
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 55.20833333333343 37
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 63.54166666666679 48
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 63.54166666666679 60
Completed Iteration #8
Best Reward: 2.0833333333333357
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a588> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553588> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a35f8> 3.125000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3e48> 3.125000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 11.45833333333335 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 15.625000000000021 9
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 25.000000000000036 14
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 52.08333333333343 36
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 56.2500000000001 38
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 64.58333333333346 49
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 64.58333333333346 61
Completed Iteration #9
Best Reward: 2.0833333333333357
Completed Iteration #10
Best Reward: 2.0833333333333357
Completed Iteration #11
Best Reward: 2.0833333333333357
Completed Iteration #12
Best Reward: 2.0833333333333357
Completed Iteration #13
Best Reward: 2.0833333333333357
Completed Iteration #14
Best Reward: 2.0833333333333357
Completed Iteration #15
Best Reward: 2.0833333333333357
Completed Iteration #16
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef748> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 17.708333333333357 10
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 27.08333333333337 15
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 54.166666666666764 37
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 58.333333333333435 39
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 66.6666666666668 50
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 66.6666666666668 62
Completed Iteration #17
Best Reward: 2.0833333333333357
Completed Iteration #18
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efda0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 13.541666666666686 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 19.791666666666693 11
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 29.166666666666707 16
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 56.2500000000001 38
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 60.41666666666677 40
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 68.75000000000014 51
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 68.75000000000014 63
Completed Iteration #19
Best Reward: 2.0833333333333357
Completed Iteration #20
Best Reward: 2.0833333333333357
Completed Iteration #21
Best Reward: 2.0833333333333357
Completed Iteration #22
Best Reward: 2.0833333333333357
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f1daf563710> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef9e8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504780> 3.125000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 20.833333333333364 12
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 30.20833333333338 17
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 57.29166666666677 39
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 61.45833333333344 41
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 69.79166666666681 52
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 69.79166666666681 64
Completed Iteration #23
Best Reward: 2.0833333333333357
Completed Iteration #24
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6ac8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6b38> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2e8> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3dd8> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50de80> 7.2916666666666785 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dc50> 7.2916666666666785 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 32.291666666666714 18
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 59.37500000000011 40
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 63.54166666666678 42
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 71.87500000000014 53
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 71.87500000000014 65
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #4
root->1->17->2->11
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf2810b8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a32e8> 8.333333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 15.625000000000021 9
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 22.9166666666667 13
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 34.37500000000005 19
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 61.45833333333344 41
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 65.62500000000011 43
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 73.95833333333348 54
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 73.95833333333348 66
Completed Iteration #0
Best Reward: 2.0833333333333357
Completed Iteration #1
Best Reward: 2.0833333333333357
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f1daf281668> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2816d8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563710> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef9e8> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf504780> 4.1666666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 23.95833333333337 14
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 35.41666666666672 20
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 62.500000000000114 42
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 66.66666666666679 44
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 75.00000000000016 55
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 75.00000000000016 67
Completed Iteration #2
Best Reward: 2.0833333333333357
Completed Iteration #3
Best Reward: 2.0833333333333357
Completed Iteration #4
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3e48> 5.208333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 17.708333333333357 10
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 26.041666666666707 15
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 37.50000000000006 21
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 64.58333333333346 43
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 68.75000000000011 45
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 77.08333333333348 56
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 77.08333333333348 68
Completed Iteration #5
Best Reward: 2.0833333333333357
Completed Iteration #6
Best Reward: 2.0833333333333357
Completed Iteration #7
Best Reward: 2.0833333333333357
Completed Iteration #8
Best Reward: 2.0833333333333357
Completed Iteration #9
Best Reward: 2.0833333333333357
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f1daf563780> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efe48> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5040b8> 3.125000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf504940> 3.125000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf586278> 5.208333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a32e8> 9.375000000000014 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 18.75000000000003 11
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 27.08333333333338 16
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 38.54166666666673 22
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 65.62500000000013 44
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 69.79166666666679 46
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 78.12500000000016 57
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 78.12500000000016 69
Completed Iteration #10
Best Reward: 2.0833333333333357
Completed Iteration #11
Best Reward: 2.0833333333333357
Completed Iteration #12
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf504668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a588> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf553588> 1.0416666666666714 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a35f8> 3.125000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3e48> 5.208333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 18.75000000000003 12
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 27.08333333333338 17
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 38.54166666666673 23
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 65.62500000000013 45
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 69.79166666666679 47
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 78.12500000000016 58
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 78.12500000000016 70
Completed Iteration #13
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6d30> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 29.166666666666714 18
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 40.625000000000064 24
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 67.70833333333346 46
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 71.87500000000011 48
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 80.20833333333348 59
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 80.20833333333348 71
Completed Iteration #14
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf281240> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2812b0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6d30> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 31.25000000000005 19
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 42.7083333333334 25
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 69.7916666666668 47
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 73.95833333333346 49
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 82.29166666666683 60
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 82.29166666666683 72
Completed Iteration #15
Best Reward: 2.0833333333333357
Completed Iteration #16
Best Reward: 2.0833333333333357
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f1daf281cf8> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281d68> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2810b8> 3.125000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a32e8> 10.416666666666686 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 19.7916666666667 13
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 32.29166666666672 20
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 43.75000000000007 26
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 70.83333333333347 48
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 75.00000000000013 50
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 83.3333333333335 61
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 83.3333333333335 73
Completed Iteration #17
Best Reward: 2.0833333333333357
Completed Iteration #18
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b518> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 34.37500000000006 21
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 45.83333333333341 27
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 72.9166666666668 49
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 77.08333333333346 51
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 85.41666666666683 62
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 85.41666666666683 74
Completed Iteration #19
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6710> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 21.875000000000036 14
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 36.45833333333339 22
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 47.91666666666674 28
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 75.00000000000014 50
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 79.1666666666668 52
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 87.50000000000017 63
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 87.50000000000017 75
Completed Iteration #20
Best Reward: 2.0833333333333357
Completed Iteration #21
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b2e8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b518> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 38.54166666666673 23
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 50.00000000000008 29
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 77.08333333333348 51
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 81.25000000000014 53
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 89.58333333333351 64
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 89.58333333333351 76
Completed Iteration #22
Best Reward: 2.0833333333333357
Completed Iteration #23
Best Reward: 2.0833333333333357
Completed Iteration #24
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dba8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a2e8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef748> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 40.625000000000064 24
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 52.083333333333414 30
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 79.16666666666683 52
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 83.33333333333348 54
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 91.66666666666686 65
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 91.66666666666686 77
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #5
root->1->17->2->11->0
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6940> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3e48> 7.2916666666666785 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 23.95833333333337 15
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 42.7083333333334 25
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 54.16666666666675 31
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 81.25000000000017 53
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 85.41666666666683 55
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 93.7500000000002 66
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 93.7500000000002 78
Completed Iteration #0
Best Reward: 2.0833333333333357
Completed Iteration #1
Best Reward: 2.0833333333333357
Completed Iteration #2
Best Reward: 2.0833333333333357
Completed Iteration #3
Best Reward: 2.0833333333333357
Completed Iteration #4
Best Reward: 2.0833333333333357
Completed Iteration #5
Best Reward: 2.0833333333333357
Completed Iteration #6
Best Reward: 2.0833333333333357
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b0f0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b470> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2810b8> 4.1666666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a32e8> 11.458333333333357 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 25.000000000000043 16
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 43.75000000000007 26
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 55.20833333333342 32
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 82.29166666666684 54
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 86.4583333333335 56
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 94.79166666666687 67
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 94.79166666666687 79
Completed Iteration #7
Best Reward: 2.0833333333333357
Completed Iteration #8
Best Reward: 2.0833333333333357
Completed Iteration #9
Best Reward: 2.0833333333333357
Completed Iteration #10
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef908> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 27.08333333333338 17
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 45.83333333333341 27
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 57.29166666666676 33
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 84.37500000000017 55
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 88.54166666666683 57
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 96.8750000000002 68
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 96.8750000000002 80
Completed Iteration #11
Best Reward: 2.0833333333333357
Completed Iteration #12
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6588> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b65f8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef908> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 8.333333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 29.166666666666714 18
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 47.91666666666674 28
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 59.37500000000009 34
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 86.45833333333351 56
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 90.62500000000017 58
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 98.95833333333354 69
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 98.95833333333354 81
Completed Iteration #13
Best Reward: 2.0833333333333357
Completed Iteration #14
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6c88> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6cf8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3e48> 9.375000000000014 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 31.25000000000005 19
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 50.00000000000008 29
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 61.45833333333343 35
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 88.54166666666686 57
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 92.70833333333351 59
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 101.04166666666688 70
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 101.04166666666688 82
Completed Iteration #15
Best Reward: 2.0833333333333357
Completed Iteration #16
Best Reward: 2.0833333333333357
Completed Iteration #17
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553588> 1.0416666666666714 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a35f8> 3.125000000000007 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3e48> 9.375000000000014 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 31.25000000000005 20
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 50.00000000000008 30
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 61.45833333333343 36
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 88.54166666666686 58
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 92.70833333333351 60
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 101.04166666666688 71
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 101.04166666666688 83
Completed Iteration #18
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf748> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf0f0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efda0> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 10.416666666666679 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 33.333333333333385 21
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 52.083333333333414 31
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 63.541666666666764 37
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 90.6250000000002 59
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 94.79166666666686 61
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 103.12500000000023 72
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 103.12500000000023 84
Completed Iteration #19
Best Reward: 2.0833333333333357
Completed Iteration #20
Best Reward: 2.0833333333333357
Completed Iteration #21
Best Reward: 2.0833333333333357
Completed Iteration #22
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e0f0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bff28> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf748> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf0f0> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efda0> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 12.500000000000014 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 35.41666666666672 22
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 54.16666666666675 32
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 65.6250000000001 38
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 92.70833333333354 60
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 96.8750000000002 62
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 105.20833333333357 73
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 105.20833333333357 85
Completed Iteration #23
Best Reward: 2.0833333333333357
Completed Iteration #24
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf563b38> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f69e8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6940> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3e48> 11.45833333333335 9
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 37.50000000000006 23
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 56.250000000000085 33
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 67.70833333333343 39
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 94.79166666666688 61
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 98.95833333333354 63
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 107.29166666666691 74
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 107.29166666666691 86
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #6
root->1->17->2->11->0->18
Best Reward: 2.0833333333333357
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f1daf586630> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281c88> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e0f0> 3.125000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bff28> 3.125000000000007 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf748> 5.208333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf0f0> 5.208333333333343 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efda0> 7.2916666666666785 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 13.541666666666686 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 38.54166666666673 24
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 57.29166666666676 34
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 68.7500000000001 40
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 95.83333333333356 62
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 100.00000000000021 64
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 108.33333333333358 75
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 108.33333333333358 87
Completed Iteration #0
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf5638d0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf0f0> 7.2916666666666785 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efda0> 9.375000000000014 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 15.625000000000021 9
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 40.625000000000064 25
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 59.37500000000009 35
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 70.83333333333343 41
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 97.91666666666688 63
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 102.08333333333354 65
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 110.41666666666691 76
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 110.41666666666691 88
Completed Iteration #1
Best Reward: 2.0833333333333357
Completed Iteration #2
Best Reward: 2.0833333333333357
Completed Iteration #3
Best Reward: 2.0833333333333357
Completed Iteration #4
Best Reward: 2.0833333333333357
Completed Iteration #5
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bcf8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bbe0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6588> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b65f8> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef908> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 17.708333333333357 10
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 42.7083333333334 26
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 61.45833333333343 36
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 72.91666666666677 42
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 100.00000000000023 64
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 104.16666666666688 66
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 112.50000000000026 77
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 112.50000000000026 89
Completed Iteration #6
Best Reward: 2.0833333333333357
Reward: 1.0416666666666714
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf2b0> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf438> 1.0416666666666714 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586630> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf281c88> 2.083333333333343 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e0f0> 4.1666666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bff28> 4.1666666666666785 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf748> 6.250000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf0f0> 8.33333333333335 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efda0> 10.416666666666686 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 18.75000000000003 11
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 43.75000000000007 27
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 62.5000000000001 37
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 73.95833333333344 43
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 101.0416666666669 65
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 105.20833333333356 67
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 113.54166666666693 78
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 113.54166666666693 90
Completed Iteration #7
Best Reward: 2.0833333333333357
Completed Iteration #8
Best Reward: 2.0833333333333357
Completed Iteration #9
Best Reward: 2.0833333333333357
coverage_call_count 2300
Completed Iteration #10
Best Reward: 2.0833333333333357
Completed Iteration #11
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e748> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bff28> 6.250000000000014 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf748> 8.33333333333335 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf0f0> 10.416666666666686 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efda0> 12.500000000000021 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 20.833333333333364 12
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 45.83333333333341 28
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 64.58333333333343 38
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 76.04166666666677 44
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 103.12500000000023 66
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 107.29166666666688 68
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 115.62500000000026 79
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 115.62500000000026 91
Completed Iteration #12
Best Reward: 2.0833333333333357
Completed Iteration #13
Best Reward: 2.0833333333333357
Completed Iteration #14
Best Reward: 2.0833333333333357
Completed Iteration #15
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf281b70> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24ea90> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6710> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 22.9166666666667 13
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 47.91666666666674 29
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 66.66666666666677 39
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 78.12500000000011 45
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 105.20833333333357 67
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 109.37500000000023 69
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 117.7083333333336 80
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 117.7083333333336 92
Completed Iteration #16
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6e80> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bff28> 8.33333333333335 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf748> 10.416666666666686 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf0f0> 12.500000000000021 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efda0> 14.583333333333357 9
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 25.000000000000036 14
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 50.00000000000008 30
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 68.75000000000011 40
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 80.20833333333346 46
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 107.29166666666691 68
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 111.45833333333357 70
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 119.79166666666694 81
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 119.79166666666694 93
Completed Iteration #17
Best Reward: 2.0833333333333357
Completed Iteration #18
Best Reward: 2.0833333333333357
Completed Iteration #19
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf828> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bff28> 10.416666666666686 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf748> 12.500000000000021 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf0f0> 14.583333333333357 9
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efda0> 16.666666666666693 10
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 27.08333333333337 15
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 52.083333333333414 31
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 70.83333333333346 41
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 82.2916666666668 47
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 109.37500000000026 69
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 113.54166666666691 71
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 121.87500000000028 82
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 121.87500000000028 94
Completed Iteration #20
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6860> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281b70> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf24ea90> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6710> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 29.166666666666707 16
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 54.16666666666675 32
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 72.9166666666668 42
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 84.37500000000014 48
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 111.4583333333336 70
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 115.62500000000026 72
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 123.95833333333363 83
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 123.95833333333363 95
Completed Iteration #21
Best Reward: 2.0833333333333357
Completed Iteration #22
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e4a8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e160> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6860> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf281b70> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf24ea90> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6710> 8.333333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 31.250000000000043 17
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 56.250000000000085 33
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 75.00000000000014 43
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 86.45833333333348 49
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 113.54166666666694 71
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 117.7083333333336 73
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 126.04166666666697 84
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 126.04166666666697 96
Completed Iteration #23
Best Reward: 2.0833333333333357
Completed Iteration #24
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf563c18> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf470> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e4a8> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e160> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6860> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf281b70> 8.333333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf24ea90> 8.333333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6710> 10.416666666666679 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 33.33333333333338 18
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 58.33333333333342 34
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 77.08333333333348 44
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 88.54166666666683 50
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 115.62500000000028 72
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 119.79166666666694 74
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 128.1250000000003 85
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 128.1250000000003 97
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #7
root->1->17->2->11->0->18->4
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf2605c0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24ea90> 10.416666666666679 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6710> 12.500000000000014 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 35.416666666666714 19
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 60.41666666666676 35
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 79.16666666666683 45
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 90.62500000000017 51
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 117.70833333333363 73
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 121.87500000000028 75
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 130.20833333333366 86
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 130.20833333333366 98
Completed Iteration #0
Best Reward: 2.0833333333333357
Completed Iteration #1
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf260c50> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260cc0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2605c0> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf24ea90> 12.500000000000014 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6710> 14.58333333333335 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 37.50000000000005 20
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 62.50000000000009 36
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 81.25000000000017 46
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 92.70833333333351 52
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 119.79166666666697 74
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 123.95833333333363 76
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 132.291666666667 87
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 132.291666666667 99
Completed Iteration #2
Best Reward: 2.0833333333333357
Completed Iteration #3
Best Reward: 2.0833333333333357
Completed Iteration #4
Best Reward: 2.0833333333333357
Completed Iteration #5
Best Reward: 2.0833333333333357
Completed Iteration #6
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6400> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e160> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6860> 8.333333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 8.333333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf281b70> 10.416666666666679 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf24ea90> 14.58333333333335 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6710> 16.666666666666686 9
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 39.583333333333385 21
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 64.58333333333343 37
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 83.33333333333351 47
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 94.79166666666686 53
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 121.87500000000031 75
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 126.04166666666697 77
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 134.37500000000034 88
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 134.37500000000034 100
Completed Iteration #7
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e358> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6898> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260c50> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf260cc0> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2605c0> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf24ea90> 16.666666666666686 9
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6710> 18.75000000000002 10
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 41.66666666666672 22
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 66.66666666666677 38
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 85.41666666666686 48
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 96.8750000000002 54
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 123.95833333333366 76
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 128.1250000000003 78
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 136.45833333333368 89
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 136.45833333333368 101
Completed Iteration #8
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf260160> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260cf8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6400> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e160> 8.333333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6860> 10.416666666666679 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 10.416666666666679 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf281b70> 12.500000000000014 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf24ea90> 18.75000000000002 10
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6710> 20.833333333333357 11
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 43.75000000000006 23
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 68.75000000000011 39
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 87.5000000000002 49
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 98.95833333333354 55
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 126.041666666667 77
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 130.20833333333366 79
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 138.54166666666703 90
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 138.54166666666703 102
Completed Iteration #9
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf260898> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260cc0> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf2605c0> 8.333333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf24ea90> 20.833333333333357 11
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6710> 22.916666666666693 12
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 45.83333333333339 24
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 70.83333333333346 40
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 89.58333333333354 50
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 101.04166666666688 56
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 128.12500000000034 78
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 132.291666666667 80
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 140.62500000000037 91
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 140.62500000000037 103
Completed Iteration #10
Best Reward: 2.0833333333333357
Completed Iteration #11
Best Reward: 2.0833333333333357
Completed Iteration #12
Best Reward: 2.0833333333333357
Completed Iteration #13
Best Reward: 2.0833333333333357
Completed Iteration #14
Best Reward: 2.0833333333333357
Completed Iteration #15
Best Reward: 2.0833333333333357
Completed Iteration #16
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf275ac8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275b38> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6710> 25.00000000000003 13
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 47.91666666666673 25
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 72.9166666666668 41
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 91.66666666666688 51
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 103.12500000000023 57
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 130.20833333333368 79
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 134.37500000000034 81
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 142.7083333333337 92
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 142.7083333333337 104
Completed Iteration #17
Best Reward: 2.0833333333333357
Completed Iteration #18
Best Reward: 2.0833333333333357
Completed Iteration #19
Best Reward: 2.0833333333333357
Completed Iteration #20
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf2047b8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf470> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e4a8> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e160> 10.416666666666679 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6860> 12.500000000000014 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 12.500000000000014 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf281b70> 14.58333333333335 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf24ea90> 22.916666666666693 12
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6710> 27.083333333333364 14
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 50.000000000000064 26
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 75.00000000000014 42
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 93.75000000000023 52
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 105.20833333333357 58
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 132.29166666666703 80
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 136.45833333333368 82
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 144.79166666666706 93
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 144.79166666666706 105
Completed Iteration #21
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b6a0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275b38> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6710> 29.1666666666667 15
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb38> 52.0833333333334 27
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 77.08333333333348 43
backprop <src.mcts.MCTS_Node object at 0x7f1daf542b38> 95.83333333333357 53
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 107.29166666666691 59
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 134.37500000000037 81
backprop <src.mcts.MCTS_Node object at 0x7f1daf533208> 138.54166666666703 83
backprop <src.mcts.MCTS_Node object at 0x7f1daf516eb8> 146.8750000000004 94
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6668> 146.8750000000004 106
Completed Iteration #22
Best Reward: 2.0833333333333357
Completed Iteration #23
Best Reward: 2.0833333333333357
Completed Iteration #24
Best Reward: 2.0833333333333357
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #8
root->1->17->2->11->0->18->4->19
Best Reward: 2.0833333333333357
iteration: 58
found coverage increase 2.0833333333333357
Current Total Coverage 18.75
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260fd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf275f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260fd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf260fd0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf275c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260fd0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf260fd0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf275c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260fd0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2750b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf204320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260fd0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf260fd0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260fd0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf204320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf260fd0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf260fd0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf260fd0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260fd0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf204320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf260fd0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2285f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf260fd0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf260fd0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf228b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf228b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228b70> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228b70> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf228b70> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228b70> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf281e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf228b70> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf228b70> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2758d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf228b70> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf228b70> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf228b70> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228b70> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228b70> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf228b70> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228b70> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2046d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf228b70> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf228b70> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf275358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf228b70> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf275c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf228b70> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2753c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2753c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf275400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf275400> 0.0 6
Completed Iteration #4
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf275400> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275400> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275400> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf275a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bfdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf228320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf275400> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2284a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf204d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275400> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf275400> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275400> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf275400> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf275400> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275400> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf204d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf275400> 0.0 17
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2289b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf275400> 0.0 18
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf275400> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf275400> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf275400> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23fda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf275400> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228860> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228860> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf275be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e26a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf228860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228860> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228860> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e22b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf228860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e26a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf228860> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228860> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e22b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf228860> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf228860> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228860> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e26a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf228860> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf228860> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf228860> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf228860> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf182208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf228860> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf182748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1826d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf182b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf182d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf182f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1826d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf182550> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf182550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1980b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182550> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1985c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf182550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf182550> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182550> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182550> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1826d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf182550> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182550> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf182550> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182550> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf182080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf182550> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf182550> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf182550> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1826d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf182550> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf182550> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 18.75
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198048> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf198048> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198048> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198048> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198048> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198048> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198048> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf198048> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198048> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf182860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf198048> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1829e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf198048> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf198048> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198048> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf198048> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf182f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf198048> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf182198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf198048> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf198048> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf198048> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf182e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 2500
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4fd0> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4fd0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4fd0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4fd0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4fd0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4fd0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1988d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4fd0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4fd0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1820b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4fd0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4fd0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1820b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4fd0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4fd0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4fd0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4fd0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1820b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4fd0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 18.75
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f1d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f1d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f1d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2287b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f1d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf275be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f1d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf275940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f1d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f1d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f1d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f1d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f1d0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f1d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f1d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f1d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f1d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f1d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f1d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2287b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f1d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f1d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfb38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfb38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfb38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf204e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfb38> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfb38> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfb38> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfb38> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23feb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfb38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfb38> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfb38> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfb38> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfb38> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182a20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfb38> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfb38> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfb38> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf204e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfb38> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfb38> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da4630048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da46302e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da461c390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da4630390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461cf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1da461c390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c390> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da461c390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2289b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c390> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c390> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf275f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da461c390> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf275400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c390> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2284a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c390> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da461c390> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c390> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1da461c390> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c390> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da461c390> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461cf98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1da461c390> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da461c390> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da461c390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 18.75
coverage_call_count 2600
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c898> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c898> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da461c898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da461c898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da461c898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf281ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da461c898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c898> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1da461c898> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1da461c898> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da461c898> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da461c898> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c898> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1da461c898> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1822e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da46302b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da46306a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da46306a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da46309b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da46306a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da4630c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da46302b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da46306a0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da4630dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da46306a0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da4630e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da46306a0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da46306a0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da46306a0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da46306a0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da4630be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da46306a0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da46306a0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1da46306a0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da46306a0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1da46306a0> 0.0 15
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da4630ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1da46306a0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1823c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da46302b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1da46306a0> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1da46306a0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da46306a0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1da46306a0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1da46306a0> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da46306a0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2ac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1da46306a0> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da46306a0> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 18.75
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c17b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c17b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c17b8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da4630da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c17b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d89b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c17b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c17b8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d89b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c17b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c17b8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c17b8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c17b8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c17b8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c17b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c17b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c17b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c17b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c17b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c17b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e85c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8748> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c12e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c12e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8748> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e85c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8748> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8748> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8748> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8748> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8748> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e85c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8748> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8748> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8748> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8748> 0.0 20
Completed Iteration #22
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1989e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c12e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8748> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8748> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8748> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf275470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198438> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2752b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198438> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf275710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198438> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf275048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2607b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf198438> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198438> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2607b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf198438> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2609e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2607b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf198438> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198438> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf198438> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf198438> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1982e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf198438> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8550> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d86a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8550> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8550> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf275908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8550> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2603c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8550> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8550> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2603c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8550> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8550> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8550> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8550> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f66a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8550> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8550> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf586da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8550> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8550> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5867f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5861d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf586c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5861d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf586a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5866d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf586a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf586a58> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5861d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf586a58> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf586a58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586a58> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586a58> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf586a58> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf586a58> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf586a58> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf586a58> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf586a58> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf586a58> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf586e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586a58> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf586f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf586a58> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf586a58> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f64a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f64a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f64a8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f64a8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f64a8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f64a8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2603c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f64a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f64a8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f64a8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f64a8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2605f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f64a8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf275208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f64a8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf275b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2605f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f64a8> 0.0 14
Completed Iteration #18
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf275550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f64a8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2605f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f64a8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f64a8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 18.75
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8e80> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8e80> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8e80> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8e80> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8e80> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8e80> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8e80> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8e80> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8e80> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8e80> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf553e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8e80> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf553908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8e80> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf563278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8e80> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf553c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8e80> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5539b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5635c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5539b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf563710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5539b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf563ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5539b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf563898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5539b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5539b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5637b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5539b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5539b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5539b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5539b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf504208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5539b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf504d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5040b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5539b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5539b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf504780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5637b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5539b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5049b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5539b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf504c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5539b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e9b2b17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5539b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5637b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5539b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf504b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5636a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5539b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 18.75
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5634a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5634a8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5634a8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf553588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5634a8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e9b2b10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5634a8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5535c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5634a8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf504630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5634a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45650b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5634a8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454c668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5634a8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4565240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45655f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5634a8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1de198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5634a8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf504a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454c668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf5634a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf504128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5634a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5535c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5634a8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5535c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf5634a8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1de198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5634a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5634a8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1de160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5535c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf5634a8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf504710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5535c0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf5634a8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf563e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5634a8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf563898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5636a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf553358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf553908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5638d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf563a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf54aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf563a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf563a90> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf563c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563a90> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf563a90> 0.0 12
Completed Iteration #15
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5636a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf563a90> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf563a90> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563a90> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf563a90> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5636a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf563a90> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5049b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563a90> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf54aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf563a90> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5630b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf563a90> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf553c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b00> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b00> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b00> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b00> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b00> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf542ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f67b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b00> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b00> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b00> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f67b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b00> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf542748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b00> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf542198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f67b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b00> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf542ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b00> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 18.75
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507ba8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45070b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507ba8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507ba8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45070b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4507ba8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf542780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45070b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db4507ba8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4507ba8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507ba8> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507ba8> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45077f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507ba8> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45072e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db4507ba8> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf542f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0889b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507ba8> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0889b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4507ba8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4507ba8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4507ba8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45072e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07de10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1db4507ba8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45071d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507ba8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf553fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088160> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088160> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088160> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088160> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088160> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088160> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088160> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088160> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088160> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088160> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088160> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088160> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf542710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088160> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf542ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088160> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf542908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088160> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088160> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d4a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf275470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d4a8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf275b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d4a8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d4a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d4a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d4a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5425c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bfe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d4a8> 0.0 9
Completed Iteration #11
Best Reward: 0
coverage_call_count 3000
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf275278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d4a8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d4a8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf563898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d4a8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d4a8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d4a8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d4a8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f67f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d4a8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d4a8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d4a8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 18.75
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf553780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf563710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a400> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a400> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a400> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a400> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a400> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a400> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a400> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a400> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a400> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a400> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a400> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a400> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a400> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a400> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a400> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e30f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088828> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0941d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088828> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a32e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088828> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088828> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf553d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0941d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088828> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088828> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088828> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088828> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088828> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088828> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088828> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088828> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088828> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 18.75
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8cf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8cf8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8cf8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0940f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8cf8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8cf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8cf8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1553c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8cf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8cf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8cf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155390> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8cf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8cf8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8cf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8cf8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d68> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf54af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d68> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d68> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d68> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d68> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d68> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf563898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d68> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d68> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d68> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf275278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d68> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45654e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d68> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d68> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5531d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d68> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d68> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d68> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d68> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d68> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf563400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5531d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082d68> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 18.75
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542eb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf542eb8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45072e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542eb8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542eb8> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf542eb8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542eb8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542eb8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542eb8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf542eb8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542eb8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542eb8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf542eb8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf542eb8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5044a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf542eb8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf542eb8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5426a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf542eb8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542eb8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cc18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cc18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cc18> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cc18> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4525d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cc18> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4525320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cc18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4525fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cc18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4525400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cc18> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4525588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cc18> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cc18> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4573be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cc18> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4573a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cc18> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4573eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cc18> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cc18> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cc18> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4573eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cc18> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45732e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cc18> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45736a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cc18> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cc18> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4525f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4573eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cc18> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4573320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4573588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf504470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4573588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453d4e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453d4e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45737b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d4e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d4e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45737b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453d4e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453d4e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16df28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db453d4e0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d4e0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d4e0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d74e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453d4e0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4573588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db453d4e0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d4e0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d4e0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16df28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1db453d4e0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf586dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16deb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453d4e0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453d4e0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4573588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1db453d4e0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0680f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d668> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db458d668> 0.0 5
Completed Iteration #7
Best Reward: 0
coverage_call_count 3200
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e4d3a2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d668> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5632b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db458d668> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4594780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d668> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45940f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d668> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45945c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d668> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db458d668> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db458d668> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db458d668> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e4d3a2390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db458d668> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e4d3a23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e4d3a2390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db458d668> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db458d668> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf275278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d668> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7a90> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7a90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7a90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7a90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7a90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc685f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7a90> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7a90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7a90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7a90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc684a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7a90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7a90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7a90> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7a90> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7a90> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7a90> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7a90> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7a90> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7a90> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7a90> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc339e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33e48> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1f1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33e48> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33e48> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33e48> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33e48> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33e48> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc689e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc333c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33e48> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33e48> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33e48> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33e48> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33e48> 0.0 13
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 18.75
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e4d3a2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e10> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e10> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4594ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e10> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4594390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e10> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e10> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e10> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf586dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e10> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e10> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4594860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e10> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45072e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e10> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e10> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e10> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e10> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf542c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e10> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45944e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e10> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e10> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e10> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45737b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e10> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5044a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5044a8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4594be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5044a8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5044a8> 0.0 5
Completed Iteration #6
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45654e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5044a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5044a8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45654e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5044a8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45654e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5044a8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5044a8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5044a8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5044a8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5044a8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc685f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45654e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf5044a8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf5044a8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5044a8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54af60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5044a8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5044a8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5044a8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf5044a8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 18.75
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e48> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc523c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e48> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc526a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e48> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e48> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce79b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e48> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e48> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e48> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc40b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e48> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce79b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e48> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e48> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e48> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e48> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e48> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e48> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e48> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc526a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52e48> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553780> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553780> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf553780> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf553780> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553780> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf553780> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553780> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553780> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf553780> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc40b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf553780> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf553780> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553780> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce79e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf553780> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553780> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf553780> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc525c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce79e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf553780> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07dd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07dd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07dd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07dd8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07dd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07dd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e4d3a23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07dd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07dd8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07dd8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07dd8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07dd8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45072e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07dd8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07dd8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07dd8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 18.75
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4594630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45945c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45947f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dba8> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e4d3a2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dba8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dba8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dba8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e4d3a2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dba8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dba8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dba8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dba8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dba8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dba8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dba8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dba8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dba8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0358> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dba8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef978> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef978> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef978> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef978> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef978> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5164e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef978> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5168d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef978> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf533cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef978> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db458dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf516e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef978> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf533518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef978> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf533320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3db38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef978> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5339b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef978> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef978> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58def0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf533eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5333c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58def0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf533940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58def0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5167f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf58def0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58def0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58def0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc904e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf58def0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5333c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf58def0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5332e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58def0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58de10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf58def0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf58def0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf58def0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58def0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf58def0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58def0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf58def0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf58def0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf58def0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf58def0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5333c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf58def0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 18.75
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516048> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516048> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5426a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516048> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516048> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e4d3a2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516048> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5426a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf516048> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e4d3a2198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf516048> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516048> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e4d3a2198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf516048> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf553a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516048> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516048> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf516048> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf516048> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf58de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516048> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf516048> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf516048> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d080> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 3500
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d080> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d080> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d080> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d080> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d080> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d080> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d080> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58dcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d080> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58dcf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d080> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d080> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d080> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d080> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d080> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d080> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c17f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1cc0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf24ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1cc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf24ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c17f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1cc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf24ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1cc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c17f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1cc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf24eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1cc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1cc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c17f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1cc0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1cc0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1cc0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1cc0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1cc0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1cc0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c68d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1cc0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1240> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1240> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf58db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1240> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e4d3a23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1240> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf24eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58db70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1240> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1240> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1240> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1240> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1240> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1240> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58db70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1240> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5335c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d4e0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1240> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4573b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07860> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07860> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf281518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07860> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07860> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07860> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2813c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07860> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf281048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07860> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf281b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07860> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07860> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07860> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2818d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07860> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2819b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07860> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07860> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07860> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07860> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07860> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dc50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dc50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dc50> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf281e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dc50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dc50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dc50> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4573080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dc50> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dc50> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dc50> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dc50> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2288d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dc50> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1827f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dc50> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dc50> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dc50> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dc50> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1822e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dc50> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1827b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dc50> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2284a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dc50> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2049b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2042b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf204a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2042b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf204b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2042b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2042b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf204b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2042b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf204a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2042b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2049b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2042b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2042b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2049b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf2042b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2049b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf2042b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2042b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b64a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2042b0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2042b0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf204b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf2042b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf2042b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf204b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf2042b0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf204b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf204dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf281748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf204dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf281c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf281710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2814e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf204358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2047b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6400> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf553a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6400> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf204dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b09e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b09e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2819e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b09e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b09e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2819e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b09e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf58de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b09e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b09e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b09e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b09e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2819e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b09e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b09e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b09e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b09e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b09e8> 0.0 15
Completed Iteration #20
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2819e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b09e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b09e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58db00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b09e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58db00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b09e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58db00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b09e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f42b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f42b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f42b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f42b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f42b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f42b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f42b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f42b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f42b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f42b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f42b0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f42b0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23fac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f42b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f42b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f42b0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f42b0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f42b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da46304a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f42b0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f42b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da4630048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23ff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f42b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da4630198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da4630fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630358> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da4630358> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630358> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da4630358> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1da4630358> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630358> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630358> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1da4630358> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf281710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630358> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf182a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da4630358> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1da4630358> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2047b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da4630358> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1da4630358> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf281860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630908> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f1da4630358> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d080> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d080> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d080> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf281b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d080> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d080> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d080> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d080> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d080> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d080> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d080> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d080> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d080> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d080> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d080> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d080> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281b00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d080> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d080> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d080> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d080> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf281518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182eb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da4630390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182eb8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da4630e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf182eb8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da4630be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182eb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da4630c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf182eb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf182eb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e20f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf182eb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182eb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf182eb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf182eb8> 0.0 15
Completed Iteration #17
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf182eb8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf182eb8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da4630630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf182eb8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf182eb8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182eb8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf182eb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c3c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c3c8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c3c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c3c8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86185048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c3c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c3c8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86185390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c3c8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c3c8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86185978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c3c8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86185b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c3c8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c3c8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c3c8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c3c8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c3c8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86185710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77cf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c3c8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861854e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c3c8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 18.75
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861856a0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861856a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861856a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861856a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861856a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861858d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861856a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861856a0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861856a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861856a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da4630978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861856a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d861856a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf281048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861856a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861856a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d861856a0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d861856a0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861858d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861856a0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861856a0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861856a0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 18.75
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2b70> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2b70> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2b70> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2b70> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2b70> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2b70> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86185d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2b70> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2b70> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2b70> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2b70> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2b70> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2b70> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2b70> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86185080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461cf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2b70> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2b70> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16fda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2b70> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2b70> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86185748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2b70> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861854e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461cf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2b70> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86185940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86185b00> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86185b00> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861bee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861beb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185b00> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861bef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185b00> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86185b00> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861bef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185b00> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185b00> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86185b00> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86185b00> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185b00> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861beef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86185b00> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86185b00> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861bec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86185b00> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86185b00> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86185b00> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86185b00> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861beb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86185b00> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861bed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86185240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861590f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861595f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861595c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861597f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86185e48> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185e48> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861595c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86185e48> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86185e48> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861590f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86185e48> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861bed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86185e48> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86185e48> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86185e48> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86185e48> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86185e48> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ae80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d86185e48> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d86185e48> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861590f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86185e48> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861595c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86185e48> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be0f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be0f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be0f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be0f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be0f0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be0f0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861be0f0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be0f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861be0f0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861be0f0> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861beef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861be0f0> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861854e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d861be0f0> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d861be0f0> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861852e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861852e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861852e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861852e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861beb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861852e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861852e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861852e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861852e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861120b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861852e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d861852e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861125c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d861852e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861852e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861126d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861852e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861852e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d861852e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861126d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d861852e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861852e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861852e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d861852e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f1d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f1d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f1d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86185d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f1d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f1d0> 0.0 11
Completed Iteration #12
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f1d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f1d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f1d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f1d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f1d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f1d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f1d0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da4630a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f1d0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f1d0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f1d0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f1d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 18.75
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ec18> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ec18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ec18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ec18> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ec18> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ec18> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ec18> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ec18> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ec18> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ec18> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ec18> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ec18> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ec18> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ec18> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ec18> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ec18> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ec18> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f0b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f0b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f0b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f0b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f0b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16fda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f0b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f0b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f0b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f0b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16fda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f0b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f0b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f0b8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f0b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf281c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f0b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f0b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f0b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16fda0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f0b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f0b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861596d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f0b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86185048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86159320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159320> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86159320> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86159320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86159320> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86159320> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159320> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86159320> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77ce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86159320> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86159320> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77ce48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d86159320> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159320> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ac18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ac18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ac18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ac18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ac18> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ac18> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ac18> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c98d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ac18> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ac18> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ac18> 0.0 11
Completed Iteration #9
Best Reward: 0
coverage_call_count 4100
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8608ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ac18> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86098048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c98d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ac18> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8608df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ac18> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ac18> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c98d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ac18> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86098198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ac18> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86098588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ac18> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86098748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ac18> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860987f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860987b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ac18> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86098b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ac18> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ac18> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86098cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ac18> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860984e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608dda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ac18> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 18.75
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098390> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098390> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86098be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098390> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86098898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86098390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86098940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860984e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098390> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86098860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86098390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86098390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8608dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86098390> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86098390> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86098390> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86098438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86098390> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860988d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098390> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86098e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86098390> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86098160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d86098390> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e4d3a2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860987f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098390> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86098390> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d86098390> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 18.75
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6898> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6898> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6898> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6898> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf182828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6898> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf182a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6898> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1820f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6898> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf182e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6898> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf24ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6898> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf24ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6898> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf24eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6898> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860986d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1822b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86098128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098128> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098128> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86098128> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86098128> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860986d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86098128> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098128> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098128> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098128> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098128> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860986d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86098128> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86098128> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86098128> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d86098128> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86098128> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86098128> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86098128> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86098128> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86098128> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 18.75
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf58dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf58dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf58ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5339e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5330b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5164a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a90> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1825c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b02e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a90> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86098780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a90> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b02e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a90> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a90> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a90> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf533ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a90> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf533358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58dfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a90> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a90> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5333c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a90> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5164a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a90> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5164a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a90> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58da58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a90> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 18.75
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a470> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf54aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a470> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf58db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a470> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc078d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a470> 0.0 5
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafce7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a470> 0.0 6
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5332e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a470> 0.0 7
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a470> 0.0 8
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a470> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a470> 0.0 10
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a470> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a470> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a470> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a470> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a470> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 18.75
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2358> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2358> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2358> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf533358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2358> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2358> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf54a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2358> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2358> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf516668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2358> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf260278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2358> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c16df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2358> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2358> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b07f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2358> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b07f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2358> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2358> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2358> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4594630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2358> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf182f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58df60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2358> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf182a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2358> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 18.75
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0d71d0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182c88> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 2.0833333333333357 2
Completed Iteration #0
Best Reward: 2.0833333333333357
Completed Iteration #1
Best Reward: 2.0833333333333357
Completed Iteration #2
Best Reward: 2.0833333333333357
Completed Iteration #3
Best Reward: 2.0833333333333357
Completed Iteration #4
Best Reward: 2.0833333333333357
Completed Iteration #5
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52eb8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182c88> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 4.166666666666671 3
Completed Iteration #6
Best Reward: 2.0833333333333357
Completed Iteration #7
Best Reward: 2.0833333333333357
Completed Iteration #8
Best Reward: 2.0833333333333357
Completed Iteration #9
Best Reward: 2.0833333333333357
Completed Iteration #10
Best Reward: 2.0833333333333357
Completed Iteration #11
Best Reward: 2.0833333333333357
Completed Iteration #12
Best Reward: 2.0833333333333357
Completed Iteration #13
Best Reward: 2.0833333333333357
Completed Iteration #14
Best Reward: 2.0833333333333357
Completed Iteration #15
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0f28> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0748> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52eb8> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf182c88> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 6.250000000000007 4
Completed Iteration #16
Best Reward: 2.0833333333333357
Completed Iteration #17
Best Reward: 2.0833333333333357
Completed Iteration #18
Best Reward: 2.0833333333333357
Completed Iteration #19
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 8.333333333333343 5
Completed Iteration #20
Best Reward: 2.0833333333333357
Completed Iteration #21
Best Reward: 2.0833333333333357
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb1d0> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182c88> 7.291666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 9.375000000000007 6
Completed Iteration #22
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb400> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 11.458333333333343 7
Completed Iteration #23
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cc88> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0748> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc52eb8> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf182c88> 9.375000000000007 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 13.541666666666679 8
Completed Iteration #24
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cc18> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 15.625000000000014 9
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #0
root
Best Reward: 2.0833333333333357
Completed Iteration #0
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc335c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 6.250000000000007 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 15.625000000000014 10
Completed Iteration #1
Best Reward: 2.0833333333333357
Completed Iteration #2
Best Reward: 2.0833333333333357
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33080> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 7.291666666666671 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 16.66666666666668 11
Completed Iteration #3
Best Reward: 2.0833333333333357
Completed Iteration #4
Best Reward: 2.0833333333333357
coverage_call_count 4300
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1daf1820f0> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098748> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33080> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 8.333333333333336 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 17.708333333333343 12
Completed Iteration #5
Best Reward: 2.0833333333333357
Completed Iteration #6
Best Reward: 2.0833333333333357
Completed Iteration #7
Best Reward: 2.0833333333333357
Completed Iteration #8
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 8.333333333333336 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 17.708333333333343 13
Completed Iteration #9
Best Reward: 2.0833333333333357
Completed Iteration #10
Best Reward: 2.0833333333333357
Completed Iteration #11
Best Reward: 2.0833333333333357
Completed Iteration #12
Best Reward: 2.0833333333333357
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbfd0> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb128> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1820f0> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86098748> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33080> 3.124999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 9.375 9
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 18.750000000000007 14
Completed Iteration #13
Best Reward: 2.0833333333333357
Completed Iteration #14
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 11.458333333333336 10
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 20.833333333333343 15
Completed Iteration #15
Best Reward: 2.0833333333333357
Completed Iteration #16
Best Reward: 2.0833333333333357
Completed Iteration #17
Best Reward: 2.0833333333333357
Completed Iteration #18
Best Reward: 2.0833333333333357
Completed Iteration #19
Best Reward: 2.0833333333333357
Completed Iteration #20
Best Reward: 2.0833333333333357
Completed Iteration #21
Best Reward: 2.0833333333333357
Completed Iteration #22
Best Reward: 2.0833333333333357
Completed Iteration #23
Best Reward: 2.0833333333333357
Completed Iteration #24
Best Reward: 2.0833333333333357
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c908> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 5.208333333333336 4
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 7.291666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 12.5 11
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 21.875000000000007 16
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #1
root->8
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86098320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c908> 1.0416666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 5.208333333333336 5
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 7.291666666666671 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 12.5 12
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 21.875000000000007 17
Completed Iteration #0
Best Reward: 2.0833333333333357
Completed Iteration #1
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1db4594630> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b62b0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 7.291666666666671 6
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 9.375000000000007 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 14.583333333333336 13
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 23.958333333333343 18
Completed Iteration #2
Best Reward: 2.0833333333333357
Completed Iteration #3
Best Reward: 2.0833333333333357
Completed Iteration #4
Best Reward: 2.0833333333333357
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1daf2288d0> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 8.333333333333336 7
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 10.416666666666671 8
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 15.625 14
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 25.000000000000007 19
Completed Iteration #5
Best Reward: 2.0833333333333357
Completed Iteration #6
Best Reward: 2.0833333333333357
Completed Iteration #7
Best Reward: 2.0833333333333357
Completed Iteration #8
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf98> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 10.416666666666671 8
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 12.500000000000007 9
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 17.708333333333336 15
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 27.083333333333343 20
Completed Iteration #9
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4525320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b62b0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 6.250000000000007 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 10.416666666666671 9
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 12.500000000000007 10
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 17.708333333333336 16
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 27.083333333333343 21
Completed Iteration #10
Best Reward: 2.0833333333333357
Completed Iteration #11
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b62b0> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 6.250000000000007 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 10.416666666666671 10
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 12.500000000000007 11
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 17.708333333333336 17
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 27.083333333333343 22
Completed Iteration #12
Best Reward: 2.0833333333333357
Completed Iteration #13
Best Reward: 2.0833333333333357
Completed Iteration #14
Best Reward: 2.0833333333333357
Completed Iteration #15
Best Reward: 2.0833333333333357
Completed Iteration #16
Best Reward: 2.0833333333333357
Completed Iteration #17
Best Reward: 2.0833333333333357
Completed Iteration #18
Best Reward: 2.0833333333333357
Completed Iteration #19
Best Reward: 2.0833333333333357
Completed Iteration #20
Best Reward: 2.0833333333333357
Completed Iteration #21
Best Reward: 2.0833333333333357
Completed Iteration #22
Best Reward: 2.0833333333333357
Completed Iteration #23
Best Reward: 2.0833333333333357
Completed Iteration #24
Best Reward: 2.0833333333333357
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #2
root->8->3
Best Reward: 2.0833333333333357
Completed Iteration #0
Best Reward: 2.0833333333333357
Completed Iteration #1
Best Reward: 2.0833333333333357
Completed Iteration #2
Best Reward: 2.0833333333333357
Completed Iteration #3
Best Reward: 2.0833333333333357
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33550> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 11.458333333333336 11
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 13.541666666666671 12
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 18.75 18
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 28.125000000000007 23
Completed Iteration #4
Best Reward: 2.0833333333333357
Completed Iteration #5
Best Reward: 2.0833333333333357
Completed Iteration #6
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c908> 1.0416666666666643 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 11.458333333333336 12
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 13.541666666666671 13
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 18.75 19
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 28.125000000000007 24
Completed Iteration #7
Best Reward: 2.0833333333333357
Completed Iteration #8
Best Reward: 2.0833333333333357
Completed Iteration #9
Best Reward: 2.0833333333333357
Completed Iteration #10
Best Reward: 2.0833333333333357
Completed Iteration #11
Best Reward: 2.0833333333333357
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1daf260278> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90f28> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2288d0> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 12.5 13
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 14.583333333333336 14
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 19.791666666666664 20
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 29.16666666666667 25
Completed Iteration #12
Best Reward: 2.0833333333333357
Completed Iteration #13
Best Reward: 2.0833333333333357
Completed Iteration #14
Best Reward: 2.0833333333333357
Completed Iteration #15
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1db45735c0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90f28> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2288d0> 4.166666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 14.583333333333336 14
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 16.66666666666667 15
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 21.875 21
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 31.250000000000007 26
Completed Iteration #16
Best Reward: 2.0833333333333357
Completed Iteration #17
Best Reward: 2.0833333333333357
Completed Iteration #18
Best Reward: 2.0833333333333357
Completed Iteration #19
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c908> 1.0416666666666643 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 14.583333333333336 15
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 16.66666666666667 16
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 21.875 22
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 31.250000000000007 27
Completed Iteration #20
Best Reward: 2.0833333333333357
Completed Iteration #21
Best Reward: 2.0833333333333357
Completed Iteration #22
Best Reward: 2.0833333333333357
Completed Iteration #23
Best Reward: 2.0833333333333357
Completed Iteration #24
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe518> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 8.333333333333343 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 16.66666666666667 16
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 18.750000000000007 17
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 23.958333333333336 23
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 33.33333333333334 28
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #3
root->8->3->8
Best Reward: 2.0833333333333357
Completed Iteration #0
Best Reward: 2.0833333333333357
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f5f8> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 5.208333333333336 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 9.375000000000007 8
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 17.708333333333336 17
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 19.79166666666667 18
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 25.0 24
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 34.37500000000001 29
Completed Iteration #1
Best Reward: 2.0833333333333357
Completed Iteration #2
Best Reward: 2.0833333333333357
Completed Iteration #3
Best Reward: 2.0833333333333357
Completed Iteration #4
Best Reward: 2.0833333333333357
Completed Iteration #5
Best Reward: 2.0833333333333357
Completed Iteration #6
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0688d0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11fac8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe518> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 7.291666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 11.458333333333343 9
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 19.79166666666667 18
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 21.875000000000007 19
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 27.083333333333336 25
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 36.45833333333334 30
Completed Iteration #7
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b62b0> 2.0833333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 11.458333333333343 10
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 19.79166666666667 19
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 21.875000000000007 20
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 27.083333333333336 26
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 36.45833333333334 31
Completed Iteration #8
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf542a20> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a6d8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f5f8> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 9.375000000000007 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 13.541666666666679 11
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 21.875000000000007 20
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 23.958333333333343 21
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 29.16666666666667 27
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 38.54166666666668 32
Completed Iteration #9
Best Reward: 2.0833333333333357
Completed Iteration #10
Best Reward: 2.0833333333333357
Completed Iteration #11
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5427f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b62b0> 2.0833333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 13.541666666666679 12
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 21.875000000000007 21
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 23.958333333333343 22
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 29.16666666666667 28
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 38.54166666666668 33
Completed Iteration #12
Best Reward: 2.0833333333333357
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1daf182f60> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11fac8> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe518> 5.208333333333336 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 10.416666666666671 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 14.583333333333343 13
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 22.91666666666667 22
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 25.000000000000007 23
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 30.208333333333336 29
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 39.58333333333334 34
Completed Iteration #13
Best Reward: 2.0833333333333357
Completed Iteration #14
Best Reward: 2.0833333333333357
Completed Iteration #15
Best Reward: 2.0833333333333357
Completed Iteration #16
Best Reward: 2.0833333333333357
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e32e8> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 11.458333333333336 8
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 15.625000000000007 14
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 23.958333333333336 23
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 26.04166666666667 24
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 31.25 30
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 40.62500000000001 35
Completed Iteration #17
Best Reward: 2.0833333333333357
Completed Iteration #18
Best Reward: 2.0833333333333357
Completed Iteration #19
Best Reward: 2.0833333333333357
Completed Iteration #20
Best Reward: 2.0833333333333357
Completed Iteration #21
Best Reward: 2.0833333333333357
Completed Iteration #22
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf542710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b62b0> 2.0833333333333357 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 15.625000000000007 15
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 23.958333333333336 24
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 26.04166666666667 25
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 31.25 31
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 40.62500000000001 36
Completed Iteration #23
Best Reward: 2.0833333333333357
Completed Iteration #24
Best Reward: 2.0833333333333357
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #4
root->8->3->8->8
Best Reward: 2.0833333333333357
Completed Iteration #0
Best Reward: 2.0833333333333357
Completed Iteration #1
Best Reward: 2.0833333333333357
coverage_call_count 4400
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1db4507ef0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f2b0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf98> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 13.541666666666671 9
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 17.708333333333343 16
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 26.04166666666667 25
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 28.125000000000007 26
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 33.333333333333336 32
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 42.70833333333334 37
Completed Iteration #2
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1db4507400> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f2b0> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf98> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 15.625000000000007 10
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 19.79166666666668 17
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 28.125000000000007 26
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 30.208333333333343 27
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 35.41666666666667 33
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 44.79166666666668 38
Completed Iteration #3
Best Reward: 2.0833333333333357
Completed Iteration #4
Best Reward: 2.0833333333333357
Completed Iteration #5
Best Reward: 2.0833333333333357
Completed Iteration #6
Best Reward: 2.0833333333333357
Completed Iteration #7
Best Reward: 2.0833333333333357
Completed Iteration #8
Best Reward: 2.0833333333333357
Completed Iteration #9
Best Reward: 2.0833333333333357
Completed Iteration #10
Best Reward: 2.0833333333333357
Completed Iteration #11
Best Reward: 2.0833333333333357
Completed Iteration #12
Best Reward: 2.0833333333333357
Completed Iteration #13
Best Reward: 2.0833333333333357
Completed Iteration #14
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf5631d0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f2b0> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf98> 8.333333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 17.708333333333343 11
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 21.875000000000014 18
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 30.208333333333343 27
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 32.29166666666668 28
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 37.50000000000001 34
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 46.875000000000014 39
Completed Iteration #15
Best Reward: 2.0833333333333357
Completed Iteration #16
Best Reward: 2.0833333333333357
Completed Iteration #17
Best Reward: 2.0833333333333357
Completed Iteration #18
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082fd0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3898> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0688d0> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11fac8> 5.208333333333336 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe518> 7.291666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 19.79166666666668 12
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 23.95833333333335 19
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 32.29166666666668 28
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 34.375000000000014 29
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 39.58333333333334 35
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 48.95833333333335 40
Completed Iteration #19
Best Reward: 2.0833333333333357
Completed Iteration #20
Best Reward: 2.0833333333333357
Completed Iteration #21
Best Reward: 2.0833333333333357
Completed Iteration #22
Best Reward: 2.0833333333333357
Completed Iteration #23
Best Reward: 2.0833333333333357
Completed Iteration #24
Best Reward: 2.0833333333333357
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #5
root->8->3->8->8->8
Best Reward: 2.0833333333333357
Completed Iteration #0
Best Reward: 2.0833333333333357
Completed Iteration #1
Best Reward: 2.0833333333333357
Completed Iteration #2
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1db454ccc0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f2b0> 8.333333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf98> 10.416666666666679 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 21.875000000000014 13
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 26.041666666666686 20
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 34.375000000000014 29
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 36.45833333333335 30
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 41.66666666666668 36
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 51.041666666666686 41
Completed Iteration #3
Best Reward: 2.0833333333333357
Completed Iteration #4
Best Reward: 2.0833333333333357
Completed Iteration #5
Best Reward: 2.0833333333333357
Completed Iteration #6
Best Reward: 2.0833333333333357
Completed Iteration #7
Best Reward: 2.0833333333333357
Completed Iteration #8
Best Reward: 2.0833333333333357
Completed Iteration #9
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1db4507860> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11ff28> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507400> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f2b0> 10.416666666666679 6
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf98> 12.500000000000014 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 23.95833333333335 14
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 28.12500000000002 21
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 36.45833333333335 30
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 38.541666666666686 31
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 43.750000000000014 37
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 53.12500000000002 42
Completed Iteration #10
Best Reward: 2.0833333333333357
Completed Iteration #11
Best Reward: 2.0833333333333357
Completed Iteration #12
Best Reward: 2.0833333333333357
Completed Iteration #13
Best Reward: 2.0833333333333357
Completed Iteration #14
Best Reward: 2.0833333333333357
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088160> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bda0> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507ef0> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f2b0> 11.458333333333343 7
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf98> 13.541666666666679 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 25.000000000000014 15
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 29.166666666666686 22
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 37.500000000000014 31
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 39.58333333333335 32
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 44.79166666666668 38
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 54.166666666666686 43
Completed Iteration #15
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33588> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f2b0> 13.541666666666679 8
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf98> 15.625000000000014 9
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 27.08333333333335 16
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 31.25000000000002 23
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 39.58333333333335 32
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 41.666666666666686 33
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 46.875000000000014 39
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 56.25000000000002 44
Completed Iteration #16
Best Reward: 2.0833333333333357
Completed Iteration #17
Best Reward: 2.0833333333333357
Completed Iteration #18
Best Reward: 2.0833333333333357
Completed Iteration #19
Best Reward: 2.0833333333333357
Completed Iteration #20
Best Reward: 2.0833333333333357
Completed Iteration #21
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4565080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454ccc0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f2b0> 13.541666666666679 9
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf98> 15.625000000000014 10
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 27.08333333333335 17
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 31.25000000000002 24
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 39.58333333333335 33
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 41.666666666666686 34
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 46.875000000000014 40
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 56.25000000000002 45
Completed Iteration #22
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3780> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2750b8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33588> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f2b0> 15.625000000000014 10
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf98> 17.70833333333335 11
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 29.166666666666686 18
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 33.33333333333336 25
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 41.666666666666686 34
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 43.75000000000002 35
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 48.95833333333335 41
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 58.33333333333336 46
Completed Iteration #23
Best Reward: 2.0833333333333357
Completed Iteration #24
Best Reward: 2.0833333333333357
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #6
root->8->3->8->8->8->0
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bfa58> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bda0> 3.125 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4507ef0> 5.208333333333336 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f2b0> 17.70833333333335 11
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf98> 19.791666666666686 12
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 31.25000000000002 19
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 35.41666666666669 26
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 43.75000000000002 35
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 45.83333333333336 36
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 51.041666666666686 42
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 60.41666666666669 47
Completed Iteration #0
Best Reward: 2.0833333333333357
Completed Iteration #1
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6ac8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f65f8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507860> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11ff28> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4507400> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f2b0> 19.791666666666686 12
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf98> 21.87500000000002 13
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 33.33333333333336 20
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 37.50000000000003 27
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 45.83333333333336 36
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 47.91666666666669 37
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 53.12500000000002 43
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 62.50000000000003 48
Completed Iteration #2
Best Reward: 2.0833333333333357
Completed Iteration #3
Best Reward: 2.0833333333333357
Completed Iteration #4
Best Reward: 2.0833333333333357
Completed Iteration #5
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f64a8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11ff28> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1db4507400> 8.333333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f2b0> 21.87500000000002 13
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf98> 23.958333333333357 14
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 35.41666666666669 21
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 39.583333333333364 28
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 47.91666666666669 37
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 50.00000000000003 38
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 55.20833333333336 44
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 64.58333333333337 49
Completed Iteration #6
Best Reward: 2.0833333333333357
Completed Iteration #7
Best Reward: 2.0833333333333357
Completed Iteration #8
Best Reward: 2.0833333333333357
Completed Iteration #9
Best Reward: 2.0833333333333357
Completed Iteration #10
Best Reward: 2.0833333333333357
Completed Iteration #11
Best Reward: 2.0833333333333357
Completed Iteration #12
Best Reward: 2.0833333333333357
Completed Iteration #13
Best Reward: 2.0833333333333357
Completed Iteration #14
Best Reward: 2.0833333333333357
Completed Iteration #15
Best Reward: 2.0833333333333357
Completed Iteration #16
Best Reward: 2.0833333333333357
Completed Iteration #17
Best Reward: 2.0833333333333357
Completed Iteration #18
Best Reward: 2.0833333333333357
Completed Iteration #19
Best Reward: 2.0833333333333357
Completed Iteration #20
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc33588> 4.166666666666671 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f2b0> 21.87500000000002 14
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf98> 23.958333333333357 15
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 35.41666666666669 22
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 39.583333333333364 29
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 47.91666666666669 38
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 50.00000000000003 39
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 55.20833333333336 45
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 64.58333333333337 50
Completed Iteration #21
Best Reward: 2.0833333333333357
Completed Iteration #22
Best Reward: 2.0833333333333357
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1daf586eb8> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f2b0> 22.916666666666686 15
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf98> 25.00000000000002 16
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 36.45833333333336 23
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 40.62500000000003 30
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 48.95833333333336 39
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 51.04166666666669 40
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 56.25000000000002 46
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 65.62500000000003 51
Completed Iteration #23
Best Reward: 2.0833333333333357
Completed Iteration #24
Best Reward: 2.0833333333333357
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #7
root->8->3->8->8->8->0->8
Best Reward: 2.0833333333333357
Completed Iteration #0
Best Reward: 2.0833333333333357
Completed Iteration #1
Best Reward: 2.0833333333333357
Completed Iteration #2
Best Reward: 2.0833333333333357
Completed Iteration #3
Best Reward: 2.0833333333333357
Completed Iteration #4
Best Reward: 2.0833333333333357
Completed Iteration #5
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8860> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f65f8> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4507860> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11ff28> 8.333333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f1db4507400> 10.416666666666679 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f2b0> 25.00000000000002 16
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf98> 27.083333333333357 17
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 38.54166666666669 24
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 42.708333333333364 31
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 51.04166666666669 40
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 53.12500000000003 41
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 58.33333333333336 47
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 67.70833333333337 52
Completed Iteration #6
Best Reward: 2.0833333333333357
Completed Iteration #7
Best Reward: 2.0833333333333357
Completed Iteration #8
Best Reward: 2.0833333333333357
Completed Iteration #9
Best Reward: 2.0833333333333357
Completed Iteration #10
Best Reward: 2.0833333333333357
Completed Iteration #11
Best Reward: 2.0833333333333357
Completed Iteration #12
Best Reward: 2.0833333333333357
Completed Iteration #13
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1e80> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f65f8> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1db4507860> 8.333333333333343 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11ff28> 10.416666666666679 6
backprop <src.mcts.MCTS_Node object at 0x7f1db4507400> 12.500000000000014 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f2b0> 27.083333333333357 17
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bf98> 29.166666666666693 18
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 40.62500000000003 25
backprop <src.mcts.MCTS_Node object at 0x7f1dafc337b8> 44.7916666666667 32
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbe10> 53.12500000000003 41
backprop <src.mcts.MCTS_Node object at 0x7f1db458d160> 55.208333333333364 42
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4b38> 60.41666666666669 48
backprop <src.mcts.MCTS_Node object at 0x7f1daf182668> 69.79166666666671 53
Completed Iteration #14
Best Reward: 2.0833333333333357
Completed Iteration #15
Best Reward: 2.0833333333333357
Completed Iteration #16
Best Reward: 2.0833333333333357
Completed Iteration #17
Best Reward: 2.0833333333333357
Completed Iteration #18
Best Reward: 2.0833333333333357
Completed Iteration #19
Best Reward: 2.0833333333333357
Completed Iteration #20
Best Reward: 2.0833333333333357
Completed Iteration #21
Best Reward: 2.0833333333333357
Completed Iteration #22
Best Reward: 2.0833333333333357
Completed Iteration #23
Best Reward: 2.0833333333333357
Completed Iteration #24
Best Reward: 2.0833333333333357
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #8
root->8->3->8->8->8->0->8->3
Best Reward: 2.0833333333333357
iteration: 134
found coverage increase 2.0833333333333357
Current Total Coverage 20.833333333333336
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608db00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608db00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8608df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608db00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8608db00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608db00> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8608df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8608db00> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8608db00> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8608db00> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8608db00> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608db00> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8608db00> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8608db00> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf586588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608db00> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf586080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8608db00> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608db00> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8608db00> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf586e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8608db00> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608df28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8608db00> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8608db00> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608df28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8608db00> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8608db00> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8898> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8608da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8898> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8898> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29ba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8898> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8898> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8898> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8898> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8898> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2042b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8898> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8898> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8898> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d84a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8898> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf504630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29ba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8898> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5866d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2042e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8e48> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8e48> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8e48> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5866d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8e48> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861beba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8e48> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ab70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8e48> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ab70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8e48> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8e48> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8e48> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8e48> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8e48> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8e48> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461ce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8e48> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8e48> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ab70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8e48> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 20.833333333333336
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be2b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be2b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be2b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be2b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be2b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861be2b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861bea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be2b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be2b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861be2b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861be2b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f82e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d861be2b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be2b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861bea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861be2b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d861be2b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861be2b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5867b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861be2b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be2b0> 0.0 18
Completed Iteration #22
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f82e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d861be2b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d861be2b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1d861be2b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da4630668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf275358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d898> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da46300b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d898> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d898> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e27f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d898> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d898> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d898> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d898> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da46300b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d898> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da46300b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d898> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861bee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d898> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50dcc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d898> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50de80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d898> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1989b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861bed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5866d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bfc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf204ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf204ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861beac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bfc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bfc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bfc50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1da461c748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1da4630358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da46307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1828> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1828> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1828> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1828> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1828> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf281e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1828> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2810f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1828> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1828> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1828> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1828> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1828> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf281438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a7b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a7b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da4630240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a7b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a7b8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86185ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a7b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86185d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a7b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a7b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a7b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a7b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86185b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a7b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a7b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a7b8> 0.0 15
Completed Iteration #20
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a7b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a7b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a7b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a7b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 20.833333333333336
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159668> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2819e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2814e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159668> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da4630fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159668> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf281e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da46300f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159668> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86159668> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da46300f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86159668> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159668> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159668> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf281550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159668> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2814e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86159668> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86159668> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86159668> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86159668> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf281668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86159668> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159668> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2814e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86159668> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da46308d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86159668> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d86159668> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861594a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86159668> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5867b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a940> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a940> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a940> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a940> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a940> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a940> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a940> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a940> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a940> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a940> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a940> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a940> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5867b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a940> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a940> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5867b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a940> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861590b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a940> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a940> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a940> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861124a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861121d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861121d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861121d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861122e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861121d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861121d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861121d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861121d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861121d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861121d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d861121d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861121d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d861121d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861121d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861bed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef6a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1d861121d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861121d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861121d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861121d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9898> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c95c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9898> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9898> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9898> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9898> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c95f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9898> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9898> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9898> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9898> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9898> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9898> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9898> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9898> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1e6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c95f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9898> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf504630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f978> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861125c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f978> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f978> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f978> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f978> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f978> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616fa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f978> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f978> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f978> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f978> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f978> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f978> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f978> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 20.833333333333336
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159f28> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf204748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159f28> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159f28> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159f28> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861859e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86159f28> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf281668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159f28> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861859b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86159f28> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da4630a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861594a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159f28> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86159f28> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159f28> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159f28> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861859b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86159f28> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861859e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86159f28> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86185fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861859b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d86159f28> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86159f28> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f47f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86159f28> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf204748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86159f28> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86159f28> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2819e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86159f28> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 20.833333333333336
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f400> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f400> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f400> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f400> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860aeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f400> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d858373c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f400> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f400> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860aee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f400> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85837710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f400> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d858377f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d858377b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f400> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85837d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f400> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85837f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f400> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85837cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f400> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85837780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f400> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d858372b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f400> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f400> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f400> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 20.833333333333336
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860aec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb5f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb5f8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb5f8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb5f8> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb5f8> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d858370f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb5f8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85837cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb5f8> 0.0 9
Completed Iteration #14
Best Reward: 0
coverage_call_count 4900
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85837470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb5f8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb5f8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85837be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb5f8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85837710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb5f8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860aec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb5f8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb5f8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da4630358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb5f8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d858379b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d858372b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae0b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae0b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d858372b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae0b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae0b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae0b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae0b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae0b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae0b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae0b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae0b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae0b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae0b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae0b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae0b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d858372b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae0b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae0b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae0b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861125f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d0b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d0b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2810f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d858370b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d0b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860aef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d858370b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453d0b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861bed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453d0b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d0b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d858370b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db453d0b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d0b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860aeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453d0b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853ddda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db453d0b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853ddf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861125f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1db453d0b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85391048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db453d0b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85391320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d858370b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1db453d0b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853ddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1db453d0b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861125f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1db453d0b8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85391a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85391278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85391160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85391d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85391b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85391160> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85391780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85391b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85391160> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853ddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853915f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85391160> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853915f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85391160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85391278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85391160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85391160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85391160> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85391160> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853919e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85391160> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d85391160> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85391278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d85391160> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85391278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d85391160> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85391160> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85391a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85391278> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1d85391160> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d85391160> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85391160> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85391908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d85391160> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0828> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0828> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853ddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0828> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853ddd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853ddef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0828> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0828> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853ddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853ddef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0828> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0828> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a07f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0828> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85391a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0828> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0828> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85391b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0828> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8608dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0828> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0828> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853917f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853917b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86185fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f828> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f828> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f828> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f828> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853ddba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f828> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f828> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853917b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f828> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f828> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f828> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f828> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f828> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f828> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f828> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860aec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f828> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85837278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f828> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85391978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f828> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2b0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2b0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2b0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2b0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2b0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b04e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2b0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2b0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2b0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2b0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2b0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2b0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2b0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2b0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0a20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef2b0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a5c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537ac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a5c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a5c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a5c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a5c0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a5c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537ac50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a5c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a5c0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853084a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853083c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a5c0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85308828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a5c0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853088d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a5c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85308dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a5c0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85308f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a5c0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85308d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a5c0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a5c0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a5c0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a5c0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c828> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c828> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c828> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 5100
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c828> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c828> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c828> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86185fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c828> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860aec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c828> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c828> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c828> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c828> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c828> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c828> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861594a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c828> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b05f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c828> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85308630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c828> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d858370b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0d30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0d30> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d858370b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0d30> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853ddba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0d30> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0d30> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853278d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0d30> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0d30> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853087f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0d30> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853ddba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0d30> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853271d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0d30> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853277b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0d30> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853ddba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0d30> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0d30> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0d30> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853276d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0d30> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0d30> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e940> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e940> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d42e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e940> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e940> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ea90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e940> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853ddda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d42e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e940> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ea90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e940> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e940> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e940> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e940> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e940> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ee48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e940> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533eef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e940> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853275c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e940> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 20.833333333333336
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e81d0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e81d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e81d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e81d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e81d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d852e81d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d852e81d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852851d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852850f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e81d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85285358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85285320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e81d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852856a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e81d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85285748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85285710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e81d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85285710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d852e81d0> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d852e81d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85285710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d852e81d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d852e81d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d852e81d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d852e81d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ed30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ed30> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ed30> 0.0 4
Completed Iteration #4
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ed30> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853279e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ed30> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ed30> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ed30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ed30> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ed30> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ed30> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ed30> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ed30> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ed30> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ed30> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ed30> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ed30> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ed30> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 20.833333333333336
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308358> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf281550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85308358> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853273c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308358> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308358> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85308358> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85285518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308358> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308358> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853273c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85308358> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85285da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d85308358> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85285f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85285a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308358> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85285908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d85308358> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308358> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308358> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1d85308358> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308358> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85285518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85308358> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c390> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f1d85308358> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 20.833333333333336
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5c50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85308da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5c50> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5c50> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5c50> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85285e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5c50> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5c50> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852466d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5c50> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852462b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5c50> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85246dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5c50> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5c50> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852467f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5c50> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5c50> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c518> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85246b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c518> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85246898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c518> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c518> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85246f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c518> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85246278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c518> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c518> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85285ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c518> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85285240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c518> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85246080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c518> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c518> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c518> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 20.833333333333336
Completed Iteration #0
Best Reward: 0
coverage_call_count 5300
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85246ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c2e8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85246f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c2e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c2e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85285da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c2e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c2e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c2e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853087f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c2e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85391390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c2e8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c2e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852854e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c2e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c2e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85246128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c2e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853ddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c2e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c2e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85285da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c2e8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c2e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853278d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c2e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853277b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e0b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e0b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e0b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e0b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e0b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e0b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e0b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e0b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e0b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e0b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e0b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e0b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e0b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e0b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e0b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e0b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e0b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526eda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853279b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526eda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8526eda0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526eda0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526eda0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526eda0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8526eda0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852335f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526eda0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852336a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85233668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526eda0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852339e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8526eda0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85233ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8526eda0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8526eda0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852337f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526eda0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85233780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8526eda0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852331d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526eda0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8526eda0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85233f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8526eda0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d858372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8526eda0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85233320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85233438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85233438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85233438> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85233438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85233438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85233438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85233438> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85233438> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852333c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85233438> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85233b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852330b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85233438> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85233eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85233438> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85233438> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85233438> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d85233438> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852333c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85233438> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853cba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d85233438> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852330b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85233438> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d85233438> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d85233438> 0.0 20
Completed Iteration #23
Best Reward: 0
coverage_call_count 5400
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852333c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d85233438> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 20.833333333333336
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852465c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327160> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327160> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85327160> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327160> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327160> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327160> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85327160> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85246048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327160> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327160> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85327160> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d85327160> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85327160> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852465c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d852b55f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85327160> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852852b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85327160> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d85327160> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84debc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85327160> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84debe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85327160> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 20.833333333333336
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84debf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84debba8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853087f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84debba8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84debba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85233588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84debba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84debba8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84debba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84debba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84debba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84debf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84debba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84debba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84df80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84debba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84df88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84debba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84debba8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84debba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84debba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d940b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84debba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d942e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84debba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84debba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84debba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d946a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94710> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94710> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84da13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94710> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94710> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d946a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94710> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94710> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94710> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94710> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94710> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94710> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94710> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94710> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94710> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84da11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94710> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94710> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d947f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df89e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94710> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94710> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84df81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84df86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84df85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1978> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1978> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1978> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1978> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1978> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1978> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1978> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853278d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1978> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1978> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1978> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84df86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1978> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1978> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84debfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb080> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85233eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852330b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85308278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb080> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb080> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85233eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb080> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85233eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb080> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc53c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb080> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb080> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85285dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb080> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb080> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb080> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc53c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb080> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb080> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84debfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb080> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852330b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb080> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85246048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb080> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb080> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85233eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb080> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 20.833333333333336
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db63c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84db63c8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db63c8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db63c8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db63c8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db63c8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db63c8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84db63c8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84db63c8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84db63c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db63c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db63c8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db63c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6bbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84db63c8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84db63c8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84db63c8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84db63c8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6bbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84db63c8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 20.833333333333336
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c710> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c710> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c710> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84debe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c710> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c710> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c710> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c710> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c710> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c710> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c710> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6be48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c710> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c710> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c710> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7cd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c710> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c710> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c710> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c710> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7cd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c710> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c710> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 20.833333333333336
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85233eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e208> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e208> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84debfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e208> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84debfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e208> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e208> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e208> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e208> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e208> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e208> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e208> 0.0 13
Completed Iteration #17
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e208> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e208> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84debfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e208> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85246d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e208> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e208> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85285dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84debe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e2b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e2b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e2b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e2b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e2b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e2b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e2b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e2b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e2b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e2b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e2b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e2b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc59b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e2b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e2b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e2b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e2b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e2b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0550> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0550> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0550> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0550> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0550> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0550> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0550> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0550> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0550> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0550> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0550> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0550> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0550> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0550> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0a58> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0550> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0550> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0550> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 20.833333333333336
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee198> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee198> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee198> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee198> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee198> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee198> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee198> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee198> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee198> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee198> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc09b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee198> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee198> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee198> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee198> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d940b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee198> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee198> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee198> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84debc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84debfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb208> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb208> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb208> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84debfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb208> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb208> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb208> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6bb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb208> 0.0 14
Completed Iteration #13
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84df80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb208> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853ddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb208> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df86d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb208> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb208> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb208> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb208> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6bb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb208> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb208> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb208> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8ba8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8ba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8ba8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8ba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8ba8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8ba8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c967f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8ba8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8ba8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceeef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceeeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8ba8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8ba8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ba8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ba8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca86a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ba8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ba8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca88d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ba8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ba8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 20.833333333333336
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ef0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c968d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ef0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85285dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ef0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85233c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ef0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ef0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ef0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ef0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ef0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c448d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ef0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ef0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ef0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85246ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ef0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ef0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c965c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ef0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ef0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c965c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96ef0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 20.833333333333336
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc59b0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc59b0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc59b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84debf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526ecf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc59b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc59b0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c533c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc59b0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c537f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc59b0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 5800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c533c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc59b0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c535f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc59b0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc59b0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc59b0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c772b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc59b0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526ecf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc59b0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c537f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc59b0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c533c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc59b0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77908> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84debdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77908> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77908> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77908> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77908> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c775c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77908> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77908> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77908> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77908> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c085c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77b38> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77908> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77908> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77908> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c080f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceeb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77908> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77908> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77908> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c778d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77908> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c242e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77b38> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77908> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24160> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c246d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24160> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c240b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24160> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24160> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c240b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c240b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24160> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c246d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24160> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24160> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24160> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c367f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24160> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c369b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c240b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24160> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c246a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c240b8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24160> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24160> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c080f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24160> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24160> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c246d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24160> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c249b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24160> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24160> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24160> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efa20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c089b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efa20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efa20> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c089b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efa20> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efa20> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efa20> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efa20> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efa20> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efa20> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efa20> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d944e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efa20> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efa20> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efa20> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efa20> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7cd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efa20> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7cd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efa20> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853279e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327cc0> 0.0 6
Completed Iteration #9
Best Reward: 0
coverage_call_count 5900
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85327cc0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85327cc0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d85327cc0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327cc0> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327cc0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d85327cc0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85327cc0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d85327cc0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853279e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85327cc0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1d85327cc0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85327cc0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85327cc0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 20.833333333333336
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327be0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327be0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327be0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327be0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85327be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85327be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327be0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327be0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85327be0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d85327be0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d85327be0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d85327be0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327be0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85308160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327be0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853084a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85327be0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85308a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1d85327be0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85308ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308978> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308978> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85391ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308978> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85308978> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853080b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85391ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85308978> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85391ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d85308978> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85308978> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853084e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85308978> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85308a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853084e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d85308978> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d85308978> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308978> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85391ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d85308978> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853084e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d85308978> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85308320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8536cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85308978> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308c50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e85f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85308c50> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537ac88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85308c50> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308c50> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85308c50> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308c50> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85308c50> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308c50> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85308c50> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b57b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85308c50> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d85308c50> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d85308c50> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d85308c50> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85308c50> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d85308c50> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85308c50> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c241d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85308358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94c18> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94c18> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
coverage_call_count 6000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94c18> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94c18> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94c18> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85391c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94c18> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94c18> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94c18> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85391f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c244e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94c18> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853919e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94c18> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85391588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94c18> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94c18> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8537aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94c18> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853917f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94c18> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c244e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94c18> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85837a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b04e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85837c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b04e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85837080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d858378d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b04e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b04e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85391ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b07b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853b04e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85837518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d858377f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b04e0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d858370f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b07b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d853b04e0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b04e0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853b04e0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853b04e0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853cba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b04e0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85837d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d858378d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853b04e0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85837be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d853b04e0> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853b04e0> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d853b04e0> 0.0 16
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d853b04e0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b04e0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853b04e0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d853b04e0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d853b04e0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85391eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b04e0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbcc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbcc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8536ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbcc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbcc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbcc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbcc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbcc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbcc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbcc0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbcc0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db453df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbcc0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbcc0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853cba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbcc0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbcc0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb7b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbcc0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85837978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbcc0> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbcc0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbcc0> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85837d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbcc0> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d858372e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbcc0> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbcc0> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db453d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbcc0> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85391978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb7b8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbcc0> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85391eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85391a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0588> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85391c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0588> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0588> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0588> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0588> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0588> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c241d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0588> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4efcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85391f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85391eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0588> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0588> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0588> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4ef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85327dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0588> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0588> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85837588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0588> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c241d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0588> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85837a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0588> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0588> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c828> 0.0 6
Completed Iteration #4
Best Reward: 0
coverage_call_count 6100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c828> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85837828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c828> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c828> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e82b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c828> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c828> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c828> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c828> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c828> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c828> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c828> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c828> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c828> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c828> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861125f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c828> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c828> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85837080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c828> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112048> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86112048> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112048> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86112048> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112048> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf281ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86112048> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861121d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112048> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86112048> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86112048> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112048> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d86112048> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614aa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86112048> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86112048> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86112048> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c99e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86112048> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86185ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf281710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f60> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86185828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f60> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f60> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f60> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f60> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f60> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf281048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f60> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f60> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1f43c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f60> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86159e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f60> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f60> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf281518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f60> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f60> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86185f60> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 20.833333333333336
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112b38> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112b38> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112b38> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112b38> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112b38> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112b38> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86112b38> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853cb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86112b38> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86112b38> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86112b38> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85308710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86112b38> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86112b38> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85391cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d86112b38> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85837828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86112b38> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85837a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112b38> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86185da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86112b38> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861beac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861bedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be898> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 6200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861bed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be898> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be898> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d858370f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be898> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85327dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2814a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be898> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861be898> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861be898> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be898> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852e81d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861be898> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be898> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861be898> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be898> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d861be898> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d861be898> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2814a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861be898> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2814a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d861be898> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2390> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2390> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2390> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da46301d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2390> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2041d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da4630080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2390> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da46304a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2390> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2390> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2390> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da46304a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2390> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2390> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e4f66b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da46304a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2390> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2390> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf204748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2390> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da46302b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d4a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da4630b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d4a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461cf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d4a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d4a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d4a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d4a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d4a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d4a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d4a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d4a8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d4a8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461cf28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d4a8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85837550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85308400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d4a8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85308c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d4a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d4a8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853cbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1da461cf28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d4a8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d4a8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 20.833333333333336
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c08cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c9b0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c9b0> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c9b0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c9b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c9b0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c9b0> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c9b0> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c9b0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c9b0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7cdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c9b0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1989b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c9b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c9b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf50da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c9b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c9b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1bf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c9b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c9b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7cdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c9b0> 0.0 18
Completed Iteration #24
Best Reward: 0
coverage_call_count 6300
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85391cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf198dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f63c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85391cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f63c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45659b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45651d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1de160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf563e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85391cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e9b2b17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0684a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf563b38> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c068b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563b38> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861855c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563b38> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4565b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf563b38> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563b38> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf563b38> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf563710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563b38> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf563b38> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e4d390dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf563b38> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852b5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563b38> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf563b38> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf563cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf563b38> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c030160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf563b38> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861855c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf563b38> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1de198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf563b38> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf9b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf275fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf9b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf9b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf198dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf9b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf9b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf9b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7c1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf9b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf9b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4565e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf9b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf9b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853913c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf9b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86112748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf9b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf9b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf9b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf9b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf9b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852e8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85837550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1989b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8616f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853b0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4565f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85308400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
coverage_call_count 6400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5049b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf504128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf504400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf50d7b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf553940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05da20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05da20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05da20> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1553c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05da20> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05da20> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05da20> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05da20> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11ff98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05da20> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11ff98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05da20> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db454c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05da20> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05da20> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05da20> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05da20> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05da20> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05da20> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05da20> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155470> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0e3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155470> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4507860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155470> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155470> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155470> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155470> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d94a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155470> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4507588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155470> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c11f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155470> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155470> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1da461c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155470> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155470> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf553e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155470> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155470> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf586f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155470> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155470> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155470> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c12f748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c155470> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8537a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8525cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504860> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf504358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504860> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db454c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf504860> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc04e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf23f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504860> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c24b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504860> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf504860> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860c9a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf504860> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504860> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf275fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504860> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc03b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860f8048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf504860> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5a3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf504860> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2756a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf504860> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4565f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504860> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860c92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1fe2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf504860> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5867f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c147400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf504860> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c1553c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf586a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504860> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c05d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0a8080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf504860> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf2f6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf504630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf504860> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 20.833333333333336
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf198358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d858370f0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d858370f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc09f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d858370f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c0940f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d858370f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d858370f0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d858370f0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d858370f0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d858370f0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d858370f0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf542908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d858370f0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf542400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8614a9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d858370f0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc05bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d858370f0> 0.0 13
Completed Iteration #19
Best Reward: 0
coverage_call_count 6500
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf542208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d858370f0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d858370f0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c77c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d858370f0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d858370f0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2285f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2285f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc90320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2285f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf182518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2285f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf182ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2285f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7e80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2285f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2285f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf563e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2285f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf182208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2285f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf16f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2285f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf182c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2285f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45252e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf2285f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf2285f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d861be128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf542dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2285f8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 20.833333333333336
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dcc0a6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf182898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db4525438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4573dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf228160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf228470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 2.0833333333333286 9
Completed Iteration #12
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c082550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 2.0833333333333286 10
Completed Iteration #13
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc902b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 2.0833333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 2.0833333333333286 11
Completed Iteration #14
Best Reward: 2.0833333333333286
Completed Iteration #15
Best Reward: 2.0833333333333286
Completed Iteration #16
Best Reward: 2.0833333333333286
Completed Iteration #17
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf29b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf563c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 2.0833333333333286 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 2.0833333333333286 12
Completed Iteration #18
Best Reward: 2.0833333333333286
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf542588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 2.0833333333333286 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 2.0833333333333286 13
Completed Iteration #19
Best Reward: 2.0833333333333286
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 5.208333333333329 4
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 5.208333333333329 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 5.208333333333329 14
Completed Iteration #20
Best Reward: 3.125
Completed Iteration #21
Best Reward: 3.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4573dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 5.208333333333329 15
Completed Iteration #22
Best Reward: 3.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c645860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 5.208333333333329 8
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 5.208333333333329 16
Completed Iteration #23
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8278> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 8.333333333333329 9
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 8.333333333333329 17
Completed Iteration #24
Best Reward: 3.125
Completed Iteration #25
Best Reward: 3.125
Completed MCTS Level/Depth: #0
root
Best Reward: 3.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf1e2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 8.333333333333329 10
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 8.333333333333329 18
Completed Iteration #0
Best Reward: 3.125
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f1daf553550> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1822b0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8278> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 11.458333333333329 6
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 11.458333333333329 11
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 11.458333333333329 19
Completed Iteration #1
Best Reward: 3.125
Completed Iteration #2
Best Reward: 3.125
Completed Iteration #3
Best Reward: 3.125
Completed Iteration #4
Best Reward: 3.125
Completed Iteration #5
Best Reward: 3.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf542c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 11.458333333333329 12
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 11.458333333333329 20
Completed Iteration #6
Best Reward: 3.125
Completed Iteration #7
Best Reward: 3.125
Completed Iteration #8
Best Reward: 3.125
Completed Iteration #9
Best Reward: 3.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 11.458333333333329 13
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 11.458333333333329 21
Completed Iteration #10
Best Reward: 3.125
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1db45737b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 11.458333333333329 14
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 11.458333333333329 22
Completed Iteration #11
Best Reward: 3.125
Completed Iteration #12
Best Reward: 3.125
Completed Iteration #13
Best Reward: 3.125
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7f1d861be128> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45075f8> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf553550> 7.291666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1822b0> 7.291666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8278> 10.416666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 10.416666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 13.541666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 13.541666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 15.624999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 15.624999999999993 15
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 15.624999999999993 23
Completed Iteration #14
Best Reward: 4.166666666666664
Completed Iteration #15
Best Reward: 4.166666666666664
Completed Iteration #16
Best Reward: 4.166666666666664
Completed Iteration #17
Best Reward: 4.166666666666664
Completed Iteration #18
Best Reward: 4.166666666666664
Completed Iteration #19
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 14.583333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 17.70833333333333 6
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 17.70833333333333 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 19.791666666666657 8
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 19.791666666666657 16
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 19.791666666666657 24
Completed Iteration #20
Best Reward: 4.166666666666664
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68ba8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 7.291666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 17.70833333333333 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 20.83333333333333 7
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 20.83333333333333 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 22.916666666666657 9
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 22.916666666666657 17
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 22.916666666666657 25
Completed Iteration #21
Best Reward: 4.166666666666664
Completed Iteration #22
Best Reward: 4.166666666666664
Completed Iteration #23
Best Reward: 4.166666666666664
Completed Iteration #24
Best Reward: 4.166666666666664
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c6a0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 23.95833333333333 8
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 26.041666666666657 10
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 26.041666666666657 18
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 26.041666666666657 26
Completed Iteration #25
Best Reward: 4.166666666666664
Completed MCTS Level/Depth: #1
root->2
Best Reward: 4.166666666666664
Completed Iteration #0
Best Reward: 4.166666666666664
Completed Iteration #1
Best Reward: 4.166666666666664
Completed Iteration #2
Best Reward: 4.166666666666664
Completed Iteration #3
Best Reward: 4.166666666666664
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d588> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 20.83333333333333 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 23.95833333333333 8
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 27.08333333333333 9
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 29.166666666666657 11
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 29.166666666666657 19
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 29.166666666666657 27
Completed Iteration #4
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d1d0> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d7b8> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be128> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7f1db45075f8> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf553550> 11.458333333333329 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf1822b0> 11.458333333333329 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8278> 14.583333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 24.999999999999993 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 28.124999999999993 9
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 31.249999999999993 10
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 33.33333333333332 12
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 33.33333333333332 20
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 33.33333333333332 28
Completed Iteration #5
Best Reward: 4.166666666666664
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e898> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d7b8> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7f1d861be128> 12.499999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f1db45075f8> 12.499999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf553550> 15.624999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf1822b0> 15.624999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8278> 18.749999999999993 6
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 29.166666666666657 9
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 32.29166666666666 10
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 35.41666666666666 11
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 37.499999999999986 13
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 37.499999999999986 21
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 37.499999999999986 29
Completed Iteration #6
Best Reward: 4.166666666666664
Completed Iteration #7
Best Reward: 4.166666666666664
Completed Iteration #8
Best Reward: 4.166666666666664
Completed Iteration #9
Best Reward: 4.166666666666664
Completed Iteration #10
Best Reward: 4.166666666666664
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f1daf5f2a90> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 37.499999999999986 12
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 39.583333333333314 14
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 39.583333333333314 22
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 39.583333333333314 30
Completed Iteration #11
Best Reward: 4.166666666666664
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7cdd8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c3c8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c6a0> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 40.624999999999986 13
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 42.708333333333314 15
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 42.708333333333314 23
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 42.708333333333314 31
Completed Iteration #12
Best Reward: 4.166666666666664
Completed Iteration #13
Best Reward: 4.166666666666664
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c198> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094f28> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d588> 8.333333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 34.374999999999986 10
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 37.499999999999986 11
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 45.833333333333314 14
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 47.91666666666664 16
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 47.91666666666664 24
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 47.91666666666664 32
Completed Iteration #14
Best Reward: 5.208333333333332
Completed Iteration #15
Best Reward: 5.208333333333332
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d780> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dc88> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7cdd8> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c3c8> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c6a0> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 48.958333333333314 15
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 51.04166666666664 17
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 51.04166666666664 25
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 51.04166666666664 33
Completed Iteration #16
Best Reward: 5.208333333333332
Completed Iteration #17
Best Reward: 5.208333333333332
Completed Iteration #18
Best Reward: 5.208333333333332
Completed Iteration #19
Best Reward: 5.208333333333332
Completed Iteration #20
Best Reward: 5.208333333333332
coverage_call_count 6600
Completed Iteration #21
Best Reward: 5.208333333333332
Completed Iteration #22
Best Reward: 5.208333333333332
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6940> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e64e0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8278> 21.874999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 37.499999999999986 11
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 40.624999999999986 12
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 52.083333333333314 16
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 54.16666666666664 18
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 54.16666666666664 26
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 54.16666666666664 34
Completed Iteration #23
Best Reward: 5.208333333333332
Completed Iteration #24
Best Reward: 5.208333333333332
Completed Iteration #25
Best Reward: 5.208333333333332
Completed MCTS Level/Depth: #2
root->2->18
Best Reward: 5.208333333333332
Completed Iteration #0
Best Reward: 5.208333333333332
Completed Iteration #1
Best Reward: 5.208333333333332
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0080> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dc88> 7.291666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7cdd8> 10.416666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c3c8> 10.416666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c6a0> 13.541666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 56.24999999999998 17
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 58.33333333333331 19
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 58.33333333333331 27
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 58.33333333333331 35
Completed Iteration #2
Best Reward: 5.208333333333332
Completed Iteration #3
Best Reward: 5.208333333333332
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1daf260550> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2608d0> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0080> 9.374999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dc88> 12.499999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7cdd8> 15.624999999999996 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c3c8> 15.624999999999996 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c6a0> 18.749999999999996 6
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 61.458333333333314 18
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 63.54166666666664 20
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 63.54166666666664 28
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 63.54166666666664 36
Completed Iteration #4
Best Reward: 5.208333333333332
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0a90> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d518> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d1d0> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d7b8> 12.499999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f1d861be128> 16.666666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f1db45075f8> 16.666666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf553550> 19.791666666666657 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf1822b0> 19.791666666666657 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8278> 26.041666666666657 8
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 41.66666666666665 12
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 44.79166666666665 13
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 65.62499999999997 19
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 67.70833333333331 21
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 67.70833333333331 29
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 67.70833333333331 37
Completed Iteration #5
Best Reward: 5.208333333333332
Completed Iteration #6
Best Reward: 5.208333333333332
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1db458dbe0> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54ab00> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68ba8> 8.333333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 8.333333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 12.499999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 46.874999999999986 13
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 49.999999999999986 14
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 70.8333333333333 20
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 72.91666666666664 22
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 72.91666666666664 30
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 72.91666666666664 38
Completed Iteration #7
Best Reward: 5.208333333333332
Completed Iteration #8
Best Reward: 5.208333333333332
Completed Iteration #9
Best Reward: 5.208333333333332
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f1daf533898> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 53.124999999999986 15
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 73.9583333333333 21
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 76.04166666666664 23
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 76.04166666666664 31
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 76.04166666666664 39
Completed Iteration #10
Best Reward: 5.208333333333332
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f1daf5867f0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a550> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d780> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dc88> 15.624999999999996 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7cdd8> 18.749999999999996 6
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c3c8> 18.749999999999996 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c6a0> 21.874999999999996 7
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 77.0833333333333 22
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 79.16666666666664 24
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 79.16666666666664 32
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 79.16666666666664 40
Completed Iteration #11
Best Reward: 5.208333333333332
Completed Iteration #12
Best Reward: 5.208333333333332
Completed Iteration #13
Best Reward: 5.208333333333332
Completed Iteration #14
Best Reward: 5.208333333333332
Completed Iteration #15
Best Reward: 5.208333333333332
Completed Iteration #16
Best Reward: 5.208333333333332
Completed Iteration #17
Best Reward: 5.208333333333332
Completed Iteration #18
Best Reward: 5.208333333333332
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d550> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260e48> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 56.249999999999986 16
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 80.2083333333333 23
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 82.29166666666664 25
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 82.29166666666664 33
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 82.29166666666664 41
Completed Iteration #19
Best Reward: 5.208333333333332
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0908> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 12.499999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 16.66666666666666 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 51.04166666666665 14
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 60.41666666666665 17
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 84.37499999999997 24
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 86.45833333333331 26
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 86.45833333333331 34
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 86.45833333333331 42
Completed Iteration #20
Best Reward: 5.208333333333332
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6a20> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d518> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d1d0> 12.499999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d7b8> 16.666666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f1d861be128> 20.83333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f1db45075f8> 20.83333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf553550> 23.95833333333332 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf1822b0> 23.95833333333332 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8278> 30.20833333333332 9
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 55.208333333333314 15
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 64.58333333333331 18
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 88.54166666666663 25
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 90.62499999999997 27
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 90.62499999999997 35
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 90.62499999999997 43
Completed Iteration #21
Best Reward: 5.208333333333332
Completed Iteration #22
Best Reward: 5.208333333333332
Completed Iteration #23
Best Reward: 5.208333333333332
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1daf260320> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516b38> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5867f0> 8.333333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02a550> 8.333333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d780> 11.458333333333332 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3dc88> 20.83333333333333 6
backprop <src.mcts.MCTS_Node object at 0x7f1d84d7cdd8> 23.95833333333333 7
backprop <src.mcts.MCTS_Node object at 0x7f1e0c17c3c8> 23.95833333333333 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c6a0> 27.08333333333333 8
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 93.74999999999996 26
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 95.8333333333333 28
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 95.8333333333333 36
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 95.8333333333333 44
Completed Iteration #24
Best Reward: 5.208333333333332
Reward: 2.0833333333333286
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb630> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b02b0> 2.0833333333333286 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d550> 5.208333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf260e48> 5.208333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 66.66666666666664 19
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 95.83333333333329 27
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 97.91666666666663 29
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 97.91666666666663 37
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 97.91666666666663 45
Completed Iteration #25
Best Reward: 5.208333333333332
Completed MCTS Level/Depth: #3
root->2->18->0
Best Reward: 5.208333333333332
Completed Iteration #0
Best Reward: 5.208333333333332
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1daf516c50> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094cc0> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c198> 10.416666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094f28> 10.416666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d588> 13.541666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 60.41666666666664 16
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 71.87499999999997 20
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 101.04166666666661 28
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 103.12499999999996 30
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 103.12499999999996 38
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 103.12499999999996 46
Completed Iteration #1
Best Reward: 5.208333333333332
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6b00> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 63.54166666666664 17
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 74.99999999999997 21
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 104.16666666666661 29
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 106.24999999999996 31
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 106.24999999999996 39
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 106.24999999999996 47
Completed Iteration #2
Best Reward: 5.208333333333332
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f1dafc078d0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf260e48> 8.333333333333329 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 78.12499999999997 22
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 107.29166666666661 30
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 109.37499999999996 32
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 109.37499999999996 40
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 109.37499999999996 48
Completed Iteration #3
Best Reward: 5.208333333333332
Completed Iteration #4
Best Reward: 5.208333333333332
Completed Iteration #5
Best Reward: 5.208333333333332
Completed Iteration #6
Best Reward: 5.208333333333332
Completed Iteration #7
Best Reward: 5.208333333333332
Completed Iteration #8
Best Reward: 5.208333333333332
Completed Iteration #9
Best Reward: 5.208333333333332
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7f1dafca0cc0> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f28> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b0a90> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d518> 12.499999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d1d0> 16.666666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d7b8> 20.83333333333332 6
backprop <src.mcts.MCTS_Node object at 0x7f1d861be128> 24.999999999999986 7
backprop <src.mcts.MCTS_Node object at 0x7f1db45075f8> 24.999999999999986 7
backprop <src.mcts.MCTS_Node object at 0x7f1daf553550> 28.124999999999986 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf1822b0> 28.124999999999986 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8278> 34.374999999999986 10
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 67.70833333333331 18
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 82.29166666666663 23
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 111.45833333333329 31
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 113.54166666666663 33
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 113.54166666666663 41
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 113.54166666666663 49
Completed Iteration #10
Best Reward: 5.208333333333332
Completed Iteration #11
Best Reward: 5.208333333333332
Completed Iteration #12
Best Reward: 5.208333333333332
Completed Iteration #13
Best Reward: 5.208333333333332
Completed Iteration #14
Best Reward: 5.208333333333332
Completed Iteration #15
Best Reward: 5.208333333333332
Completed Iteration #16
Best Reward: 5.208333333333332
Completed Iteration #17
Best Reward: 5.208333333333332
Completed Iteration #18
Best Reward: 5.208333333333332
Completed Iteration #19
Best Reward: 5.208333333333332
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f1db4594630> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf533f60> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 85.41666666666663 24
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 114.58333333333329 32
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 116.66666666666663 34
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 116.66666666666663 42
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 116.66666666666663 50
Completed Iteration #20
Best Reward: 5.208333333333332
Completed Iteration #21
Best Reward: 5.208333333333332
Completed Iteration #22
Best Reward: 5.208333333333332
Completed Iteration #23
Best Reward: 5.208333333333332
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07518> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf5c0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb630> 5.208333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b02b0> 5.208333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d550> 8.333333333333329 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf260e48> 11.458333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 88.54166666666663 25
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 117.70833333333329 33
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 119.79166666666663 35
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 119.79166666666663 43
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 119.79166666666663 51
Completed Iteration #24
Best Reward: 5.208333333333332
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f1d8608de48> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608db70> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07518> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf2bf5c0> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfb630> 8.333333333333329 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf1b02b0> 8.333333333333329 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d550> 11.458333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf260e48> 14.583333333333329 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 91.66666666666663 26
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 120.83333333333329 34
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 122.91666666666663 36
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 122.91666666666663 44
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 122.91666666666663 52
Completed Iteration #25
Best Reward: 5.208333333333332
Completed MCTS Level/Depth: #4
root->2->18->0->13
Best Reward: 5.208333333333332
Completed Iteration #0
Best Reward: 5.208333333333332
Completed Iteration #1
Best Reward: 5.208333333333332
Completed Iteration #2
Best Reward: 5.208333333333332
Completed Iteration #3
Best Reward: 5.208333333333332
Completed Iteration #4
Best Reward: 5.208333333333332
Completed Iteration #5
Best Reward: 5.208333333333332
Completed Iteration #6
Best Reward: 5.208333333333332
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae240> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7f1db45075f8> 29.16666666666665 8
backprop <src.mcts.MCTS_Node object at 0x7f1daf553550> 32.29166666666665 9
backprop <src.mcts.MCTS_Node object at 0x7f1daf1822b0> 32.29166666666665 9
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8278> 38.54166666666665 11
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 71.87499999999997 19
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 95.83333333333329 27
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 124.99999999999994 35
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 127.08333333333329 37
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 127.08333333333329 45
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 127.08333333333329 53
Completed Iteration #7
Best Reward: 5.208333333333332
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f1d86098320> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860aeb38> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6b00> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 74.99999999999997 20
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 98.95833333333329 28
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 128.12499999999994 36
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 130.2083333333333 38
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 130.2083333333333 46
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 130.2083333333333 54
Completed Iteration #8
Best Reward: 5.208333333333332
Completed Iteration #9
Best Reward: 5.208333333333332
Completed Iteration #10
Best Reward: 5.208333333333332
Completed Iteration #11
Best Reward: 5.208333333333332
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07deb8> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098d68> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458dbe0> 9.374999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf54ab00> 9.374999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68ba8> 12.499999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 16.66666666666666 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 20.833333333333325 6
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 79.16666666666663 21
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 103.12499999999994 29
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 132.2916666666666 37
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 134.37499999999994 39
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 134.37499999999994 47
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 134.37499999999994 55
Completed Iteration #12
Best Reward: 5.208333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf58d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d861be7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d588> 13.541666666666664 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 79.16666666666663 22
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 103.12499999999994 30
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 132.2916666666666 38
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 134.37499999999994 40
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 134.37499999999994 48
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 134.37499999999994 56
Completed Iteration #13
Best Reward: 5.208333333333332
Completed Iteration #14
Best Reward: 5.208333333333332
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6630> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbac8> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf516c50> 10.416666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094cc0> 10.416666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c198> 15.624999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094f28> 15.624999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d588> 18.749999999999996 6
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 84.37499999999996 23
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 108.33333333333327 31
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 137.49999999999994 39
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 139.5833333333333 41
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 139.5833333333333 49
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 139.5833333333333 57
Completed Iteration #15
Best Reward: 5.208333333333332
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f1db45940b8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf1822b0> 35.41666666666665 10
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8278> 41.66666666666665 12
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 87.49999999999996 24
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 111.45833333333327 32
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 140.62499999999994 40
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 142.7083333333333 42
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 142.7083333333333 50
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 142.7083333333333 58
Completed Iteration #16
Best Reward: 5.208333333333332
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d86098390> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07def0> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e6940> 8.333333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5e64e0> 8.333333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8278> 46.874999999999986 13
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 92.70833333333329 25
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 116.6666666666666 33
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 145.8333333333333 41
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 147.91666666666663 43
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 147.91666666666663 51
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 147.91666666666663 59
Completed Iteration #17
Best Reward: 5.208333333333332
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f1d86098710> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098be0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098320> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f1d860aeb38> 6.25 3
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6b00> 9.375 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 95.83333333333329 26
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 119.7916666666666 34
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 148.9583333333333 42
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 151.04166666666663 44
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 151.04166666666663 52
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 151.04166666666663 60
Completed Iteration #18
Best Reward: 5.208333333333332
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae7f0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae2e8> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07deb8> 7.291666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86098d68> 7.291666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1db458dbe0> 12.499999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f1daf54ab00> 12.499999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68ba8> 15.624999999999996 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 19.79166666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 23.958333333333325 7
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 98.95833333333329 27
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 122.9166666666666 35
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 152.0833333333333 43
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 154.16666666666663 45
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 154.16666666666663 53
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 154.16666666666663 61
Completed Iteration #19
Best Reward: 5.208333333333332
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68198> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 24.999999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 29.166666666666657 8
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 104.16666666666661 28
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 128.12499999999994 36
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 157.29166666666663 44
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 159.37499999999997 46
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 159.37499999999997 54
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 159.37499999999997 62
Completed Iteration #20
Best Reward: 5.208333333333332
Completed Iteration #21
Best Reward: 5.208333333333332
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07beb8> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d198> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf24e898> 8.333333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d7b8> 24.999999999999986 7
backprop <src.mcts.MCTS_Node object at 0x7f1d861be128> 29.16666666666665 8
backprop <src.mcts.MCTS_Node object at 0x7f1db45075f8> 33.333333333333314 9
backprop <src.mcts.MCTS_Node object at 0x7f1daf553550> 36.458333333333314 10
backprop <src.mcts.MCTS_Node object at 0x7f1daf1822b0> 39.583333333333314 11
backprop <src.mcts.MCTS_Node object at 0x7f1daf5c8278> 51.04166666666665 14
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 108.33333333333329 29
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 132.2916666666666 37
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 161.4583333333333 45
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 163.54166666666663 47
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 163.54166666666663 55
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 163.54166666666663 63
Completed Iteration #22
Best Reward: 5.208333333333332
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77710> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c777f0> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1db44f6630> 8.333333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafcfbac8> 8.333333333333332 3
backprop <src.mcts.MCTS_Node object at 0x7f1daf516c50> 13.541666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094cc0> 13.541666666666664 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc7c198> 18.749999999999996 5
backprop <src.mcts.MCTS_Node object at 0x7f1e0c094f28> 18.749999999999996 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc3d588> 21.874999999999996 7
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 111.45833333333329 30
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 135.4166666666666 38
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 164.5833333333333 46
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 166.66666666666663 48
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 166.66666666666663 56
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 166.66666666666663 64
Completed Iteration #23
Best Reward: 5.208333333333332
Completed Iteration #24
Best Reward: 5.208333333333332
Completed Iteration #25
Best Reward: 5.208333333333332
Completed MCTS Level/Depth: #5
root->2->18->0->13->7
Best Reward: 5.208333333333332
Completed Iteration #0
Best Reward: 5.208333333333332
Completed Iteration #1
Best Reward: 5.208333333333332
Completed Iteration #2
Best Reward: 5.208333333333332
Completed Iteration #3
Best Reward: 5.208333333333332
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1db4594e80> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1db458dda0> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68198> 10.416666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 30.208333333333325 8
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 34.374999999999986 9
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 116.66666666666661 31
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 140.62499999999994 39
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 169.79166666666663 47
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 171.87499999999997 49
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 171.87499999999997 57
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 171.87499999999997 65
Completed Iteration #4
Best Reward: 5.208333333333332
Completed Iteration #5
Best Reward: 5.208333333333332
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b5c0> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608dd30> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68198> 15.624999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 35.41666666666666 9
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 39.583333333333314 10
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 121.87499999999994 32
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 145.8333333333333 40
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 174.99999999999997 48
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 177.08333333333331 50
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 177.08333333333331 58
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 177.08333333333331 66
Completed Iteration #6
Best Reward: 5.208333333333332
Completed Iteration #7
Best Reward: 5.208333333333332
Completed Iteration #8
Best Reward: 5.208333333333332
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77d68> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77f28> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1db4594e80> 10.416666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1db458dda0> 10.416666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68198> 20.83333333333333 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 40.624999999999986 10
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 44.79166666666664 11
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 127.08333333333327 33
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 151.04166666666663 41
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 180.20833333333331 49
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 182.29166666666666 51
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 182.29166666666666 59
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 182.29166666666666 67
Completed Iteration #9
Best Reward: 5.208333333333332
Completed Iteration #10
Best Reward: 5.208333333333332
Completed Iteration #11
Best Reward: 5.208333333333332
Completed Iteration #12
Best Reward: 5.208333333333332
Completed Iteration #13
Best Reward: 5.208333333333332
Completed Iteration #14
Best Reward: 5.208333333333332
Reward: 6.2499999999999964
backprop <src.mcts.MCTS_Node object at 0x7f1d8526eb00> 6.2499999999999964 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098d68> 13.54166666666666 4
backprop <src.mcts.MCTS_Node object at 0x7f1db458dbe0> 18.749999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7f1daf54ab00> 18.749999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68ba8> 21.874999999999993 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 46.874999999999986 11
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 51.04166666666664 12
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 133.33333333333326 34
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 157.29166666666663 42
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 186.45833333333331 50
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 188.54166666666666 52
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 188.54166666666666 60
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 188.54166666666666 68
Completed Iteration #15
Best Reward: 6.2499999999999964
Completed Iteration #16
Best Reward: 6.2499999999999964
Completed Iteration #17
Best Reward: 6.2499999999999964
coverage_call_count 6700
Completed Iteration #18
Best Reward: 6.2499999999999964
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d86098b70> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8978> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b5c0> 10.416666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8608dd30> 10.416666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68198> 26.04166666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 52.083333333333314 12
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 56.24999999999997 13
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 138.5416666666666 35
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 162.49999999999997 43
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 191.66666666666666 51
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 193.75 53
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 193.75 61
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 193.75 69
Completed Iteration #19
Best Reward: 6.2499999999999964
Completed Iteration #20
Best Reward: 6.2499999999999964
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb748> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb4e0> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098b70> 10.416666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8978> 10.416666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b5c0> 15.624999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8608dd30> 15.624999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68198> 31.249999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 57.29166666666664 13
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 61.4583333333333 14
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 143.74999999999994 36
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 167.70833333333331 44
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 196.875 52
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 198.95833333333334 54
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 198.95833333333334 62
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 198.95833333333334 70
Completed Iteration #21
Best Reward: 6.2499999999999964
Completed Iteration #22
Best Reward: 6.2499999999999964
Completed Iteration #23
Best Reward: 6.2499999999999964
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc09b0> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb4e0> 10.416666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86098b70> 15.624999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8978> 15.624999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b5c0> 20.83333333333333 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8608dd30> 20.83333333333333 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68198> 36.45833333333333 8
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 62.49999999999997 14
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 66.66666666666663 15
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 148.9583333333333 37
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 172.91666666666666 45
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 202.08333333333334 53
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 204.16666666666669 55
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 204.16666666666669 63
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 204.16666666666669 71
Completed Iteration #24
Best Reward: 6.2499999999999964
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bfd0> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608dd30> 26.04166666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68198> 41.66666666666666 9
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 67.7083333333333 15
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 71.87499999999996 16
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 154.16666666666663 38
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 178.125 46
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 207.29166666666669 54
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 209.37500000000003 56
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 209.37500000000003 64
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 209.37500000000003 72
Completed Iteration #25
Best Reward: 6.2499999999999964
Completed MCTS Level/Depth: #6
root->2->18->0->13->7->2
Best Reward: 6.2499999999999964
Completed Iteration #0
Best Reward: 6.2499999999999964
Completed Iteration #1
Best Reward: 6.2499999999999964
Completed Iteration #2
Best Reward: 6.2499999999999964
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8eb8> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8a90> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc09b0> 10.416666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb4e0> 15.624999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f1d86098b70> 20.83333333333333 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8978> 20.83333333333333 5
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b5c0> 26.04166666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f1d8608dd30> 31.249999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68198> 46.874999999999986 10
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 72.91666666666663 16
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 77.08333333333329 17
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 159.37499999999997 39
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 183.33333333333334 47
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 212.50000000000003 55
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 214.58333333333337 57
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 214.58333333333337 65
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 214.58333333333337 73
Completed Iteration #3
Best Reward: 6.2499999999999964
Completed Iteration #4
Best Reward: 6.2499999999999964
Completed Iteration #5
Best Reward: 6.2499999999999964
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d84c776d8> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77c88> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77d68> 10.416666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77f28> 10.416666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1db4594e80> 15.624999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f1db458dda0> 15.624999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68198> 52.083333333333314 11
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 78.12499999999996 17
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 82.29166666666661 18
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 164.58333333333331 40
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 188.54166666666669 48
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 217.70833333333337 56
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 219.7916666666667 58
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 219.7916666666667 66
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 219.7916666666667 74
Completed Iteration #6
Best Reward: 6.2499999999999964
Completed Iteration #7
Best Reward: 6.2499999999999964
Completed Iteration #8
Best Reward: 6.2499999999999964
Completed Iteration #9
Best Reward: 6.2499999999999964
Completed Iteration #10
Best Reward: 6.2499999999999964
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0860> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0ba8> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526eb00> 11.458333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7f1d86098d68> 18.749999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7f1db458dbe0> 23.958333333333325 6
backprop <src.mcts.MCTS_Node object at 0x7f1daf54ab00> 23.958333333333325 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68ba8> 27.083333333333325 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 83.33333333333329 18
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 87.49999999999994 19
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 169.79166666666666 41
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 193.75000000000003 49
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 222.9166666666667 57
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 225.00000000000006 59
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 225.00000000000006 67
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 225.00000000000006 75
Completed Iteration #11
Best Reward: 6.2499999999999964
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53048> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf54ab00> 29.166666666666657 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68ba8> 32.29166666666666 8
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 88.54166666666661 19
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 92.70833333333327 20
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 175.0 42
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 198.95833333333337 50
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 228.12500000000006 58
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 230.2083333333334 60
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 230.2083333333334 68
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 230.2083333333334 76
Completed Iteration #12
Best Reward: 6.2499999999999964
Completed Iteration #13
Best Reward: 6.2499999999999964
Completed Iteration #14
Best Reward: 6.2499999999999964
Completed Iteration #15
Best Reward: 6.2499999999999964
Completed Iteration #16
Best Reward: 6.2499999999999964
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8be0> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 92.70833333333329 20
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 96.87499999999994 21
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 179.16666666666666 43
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 203.12500000000003 51
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 232.2916666666667 59
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 234.37500000000006 61
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 234.37500000000006 69
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 234.37500000000006 77
Completed Iteration #17
Best Reward: 6.2499999999999964
Completed Iteration #18
Best Reward: 6.2499999999999964
Completed Iteration #19
Best Reward: 6.2499999999999964
Completed Iteration #20
Best Reward: 6.2499999999999964
Completed Iteration #21
Best Reward: 6.2499999999999964
Completed Iteration #22
Best Reward: 6.2499999999999964
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d84c530f0> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b978> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8be0> 9.374999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 97.91666666666661 21
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 102.08333333333327 22
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 184.375 44
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 208.33333333333337 52
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 237.50000000000006 60
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 239.5833333333334 62
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 239.5833333333334 70
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 239.5833333333334 78
Completed Iteration #23
Best Reward: 6.2499999999999964
Completed Iteration #24
Best Reward: 6.2499999999999964
Completed Iteration #25
Best Reward: 6.2499999999999964
Completed MCTS Level/Depth: #7
root->2->18->0->13->7->2->6
Best Reward: 6.2499999999999964
Completed Iteration #0
Best Reward: 6.2499999999999964
Completed Iteration #1
Best Reward: 6.2499999999999964
Completed Iteration #2
Best Reward: 6.2499999999999964
Completed Iteration #3
Best Reward: 6.2499999999999964
Completed Iteration #4
Best Reward: 6.2499999999999964
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d550> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e390> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c776d8> 10.416666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77c88> 10.416666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77d68> 15.624999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77f28> 15.624999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f1db4594e80> 20.83333333333333 5
backprop <src.mcts.MCTS_Node object at 0x7f1db458dda0> 20.83333333333333 5
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68198> 57.29166666666664 12
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 103.12499999999994 22
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 107.2916666666666 23
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 189.58333333333334 45
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 213.5416666666667 53
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 242.7083333333334 61
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 244.79166666666674 63
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 244.79166666666674 71
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 244.79166666666674 79
Completed Iteration #5
Best Reward: 6.2499999999999964
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e128> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d860aec50> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d550> 10.416666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e390> 10.416666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c776d8> 15.624999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77c88> 15.624999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77d68> 20.83333333333333 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77f28> 20.83333333333333 5
backprop <src.mcts.MCTS_Node object at 0x7f1db4594e80> 26.04166666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f1db458dda0> 26.04166666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68198> 62.49999999999997 13
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 108.33333333333327 23
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 112.49999999999993 24
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 194.79166666666669 46
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 218.75000000000006 54
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 247.91666666666674 62
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 250.00000000000009 64
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 250.00000000000009 72
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 250.00000000000009 80
Completed Iteration #6
Best Reward: 6.2499999999999964
Reward: 3.125
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0e860> 3.125 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8978> 23.95833333333333 6
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b5c0> 29.16666666666666 7
backprop <src.mcts.MCTS_Node object at 0x7f1d8608dd30> 34.37499999999999 8
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68198> 65.62499999999997 14
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 111.45833333333327 24
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 115.62499999999993 25
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 197.91666666666669 47
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 221.87500000000006 55
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 251.04166666666674 63
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 253.12500000000009 65
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 253.12500000000009 73
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 253.12500000000009 81
Completed Iteration #7
Best Reward: 6.2499999999999964
Completed Iteration #8
Best Reward: 6.2499999999999964
Completed Iteration #9
Best Reward: 6.2499999999999964
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5978> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0eb00> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb748> 10.416666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb4e0> 20.83333333333333 5
backprop <src.mcts.MCTS_Node object at 0x7f1d86098b70> 26.04166666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8978> 29.16666666666666 7
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b5c0> 34.37499999999999 8
backprop <src.mcts.MCTS_Node object at 0x7f1d8608dd30> 39.58333333333333 9
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68198> 70.8333333333333 15
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 116.6666666666666 25
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 120.83333333333326 26
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 203.12500000000003 48
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 227.0833333333334 56
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 256.25000000000006 64
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 258.3333333333334 66
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 258.3333333333334 74
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 258.3333333333334 82
Completed Iteration #10
Best Reward: 6.2499999999999964
Completed Iteration #11
Best Reward: 6.2499999999999964
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc50b8> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc59b0> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e128> 10.416666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d860aec50> 10.416666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8608d550> 15.624999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e390> 15.624999999999996 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84c776d8> 20.83333333333333 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77c88> 20.83333333333333 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77d68> 26.04166666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77f28> 26.04166666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f1db4594e80> 31.249999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7f1db458dda0> 31.249999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68198> 76.04166666666663 16
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 121.87499999999993 26
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 126.04166666666659 27
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 208.33333333333337 49
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 232.29166666666674 57
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 261.45833333333337 65
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 263.54166666666674 67
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 263.54166666666674 75
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 263.54166666666674 83
Completed Iteration #12
Best Reward: 6.2499999999999964
Completed Iteration #13
Best Reward: 6.2499999999999964
Completed Iteration #14
Best Reward: 6.2499999999999964
Completed Iteration #15
Best Reward: 6.2499999999999964
Completed Iteration #16
Best Reward: 6.2499999999999964
Completed Iteration #17
Best Reward: 6.2499999999999964
Reward: 6.2499999999999964
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53710> 6.2499999999999964 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0390> 6.2499999999999964 2
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bfd0> 11.458333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8608dd30> 45.83333333333333 10
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68198> 82.29166666666663 17
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 128.12499999999991 27
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 132.29166666666657 28
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 214.58333333333337 50
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 238.54166666666674 58
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 267.70833333333337 66
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 269.79166666666674 68
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 269.79166666666674 76
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 269.79166666666674 84
Completed Iteration #18
Best Reward: 6.2499999999999964
Completed Iteration #19
Best Reward: 6.2499999999999964
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0ea58> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0e0f0> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53710> 11.458333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0390> 11.458333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bfd0> 16.66666666666666 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8608dd30> 51.04166666666666 11
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68198> 87.49999999999996 18
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 133.33333333333326 28
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 137.49999999999991 29
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 219.7916666666667 51
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 243.75000000000009 59
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 272.9166666666667 67
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 275.00000000000006 69
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 275.00000000000006 77
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 275.00000000000006 85
Completed Iteration #20
Best Reward: 6.2499999999999964
Reward: 6.2499999999999964
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5908> 6.2499999999999964 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5a58> 6.2499999999999964 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0ea58> 11.458333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0e0f0> 11.458333333333329 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53710> 17.708333333333325 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0390> 17.708333333333325 4
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07bfd0> 22.916666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8608dd30> 57.29166666666666 12
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68198> 93.74999999999996 19
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 139.58333333333326 29
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 143.74999999999991 30
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 226.0416666666667 52
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 250.00000000000009 60
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 279.1666666666667 68
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 281.25000000000006 70
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 281.25000000000006 78
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 281.25000000000006 86
Completed Iteration #21
Best Reward: 6.2499999999999964
Reward: 4.166666666666664
backprop <src.mcts.MCTS_Node object at 0x7f1daf2b6d68> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53e80> 4.166666666666664 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8eb8> 9.374999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8a90> 9.374999999999996 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc09b0> 14.583333333333329 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb4e0> 24.999999999999993 6
backprop <src.mcts.MCTS_Node object at 0x7f1d86098b70> 30.208333333333325 7
backprop <src.mcts.MCTS_Node object at 0x7f1d84df8978> 33.33333333333333 8
backprop <src.mcts.MCTS_Node object at 0x7f1dcc07b5c0> 38.54166666666666 9
backprop <src.mcts.MCTS_Node object at 0x7f1d8608dd30> 61.45833333333332 13
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68198> 97.91666666666663 20
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 143.74999999999991 30
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 147.91666666666657 31
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 230.20833333333337 53
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 254.16666666666674 61
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 283.33333333333337 69
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 285.41666666666674 71
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 285.41666666666674 79
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 285.41666666666674 87
Completed Iteration #22
Best Reward: 6.2499999999999964
Completed Iteration #23
Best Reward: 6.2499999999999964
Reward: 5.208333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0e48> 5.208333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c77f28> 31.249999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7f1db4594e80> 36.45833333333333 8
backprop <src.mcts.MCTS_Node object at 0x7f1db458dda0> 36.45833333333333 8
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68198> 103.12499999999996 21
backprop <src.mcts.MCTS_Node object at 0x7f1dafc68978> 148.95833333333326 31
backprop <src.mcts.MCTS_Node object at 0x7f1d8612e128> 153.12499999999991 32
backprop <src.mcts.MCTS_Node object at 0x7f1d8c7d8550> 235.4166666666667 54
backprop <src.mcts.MCTS_Node object at 0x7f1daf29bb38> 259.37500000000006 62
backprop <src.mcts.MCTS_Node object at 0x7f1dcc088630> 288.5416666666667 70
backprop <src.mcts.MCTS_Node object at 0x7f1e0c02ac88> 290.62500000000006 72
backprop <src.mcts.MCTS_Node object at 0x7f1db4525390> 290.62500000000006 80
backprop <src.mcts.MCTS_Node object at 0x7f1dafcc4940> 290.62500000000006 88
Completed Iteration #24
Best Reward: 6.2499999999999964
Completed Iteration #25
Best Reward: 6.2499999999999964
Completed MCTS Level/Depth: #8
root->2->18->0->13->7->2->6->15
Best Reward: 6.2499999999999964
iteration: 214
found coverage increase 6.2499999999999964
Current Total Coverage 27.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e828> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e828> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e828> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e828> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e828> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ef28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e828> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e828> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e828> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ef28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e828> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e828> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e828> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86112be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e828> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ef28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e828> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e828> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e828> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e828> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e828> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85246390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e828> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 27.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c539e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85246e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852337f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85233a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246dd8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85246dd8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85233048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85246dd8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85233a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246dd8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85233dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246dd8> 0.0 9
Completed Iteration #12
Best Reward: 0
coverage_call_count 6800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d85246dd8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d85246dd8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d85246dd8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85233f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246dd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85233978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85233a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85246dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246dd8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85246dd8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d860ae908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85246dd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521ee80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d85246dd8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85246a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85233dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d85246dd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 27.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85233780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852330f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852330f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85233780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d852330f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852330f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d852330f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d852330f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852330f0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852330f0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d852330f0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d852330f0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852339b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85233198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852330f0> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1dafc07710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d852330f0> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85233048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d852330f0> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852330f0> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85233748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852330f0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d852330f0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85246a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d852330f0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852461d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1d852330f0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d0e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852330f0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d852330f0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cc0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85233748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d852330f0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 27.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ee10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ee10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ee10> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ee10> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ee10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85246e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ee10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ee10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ee10> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85246400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ee10> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a03c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ee10> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ee10> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ee10> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ee10> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ee10> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ee10> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ee10> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ee10> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85246d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852337b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ee10> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ee10> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ee10> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ee10> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 27.083333333333332
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85285550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85285748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceed30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852858d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852853c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da15c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85285f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da10b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85285c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 27.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852856a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd6a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85246a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85285668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd6a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd6a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd6a0> 0.0 7
Completed Iteration #8
Best Reward: 0
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd6a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd6a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853ddeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd6a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853ddd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd6a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd6a0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd6a0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5470> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd6a0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd6a0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd6a0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd6a0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db62e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd6a0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd6a0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd6a0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 27.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44400> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85285c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85285898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85285f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44400> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44400> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85285470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44400> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85285828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44400> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44400> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44400> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85285f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44400> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44400> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85233e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44400> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44400> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db64e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44400> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d85285828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44400> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44400> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852850b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44400> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 27.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853ddb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceed30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceed30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceed30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceed30> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceed30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d86098eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceed30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853ddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceed30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c440f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceed30> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceed30> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceed30> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceed30> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceed30> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84dc5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceed30> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c440f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceed30> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceed30> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceed30> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceed30> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee6a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceed30> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceed30> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85285b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da19b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceed30> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee6a0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceed30> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceed30> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 27.083333333333332
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b198> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b198> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b198> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b198> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b198> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b198> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b198> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c962e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b198> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b198> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b198> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b198> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6beb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b198> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b198> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b198> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d45f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b198> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b198> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b198> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b198> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b198> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b198> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d45f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b198> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 27.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96400> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96400> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96400> 0.0 5
Completed Iteration #6
Best Reward: 0
coverage_call_count 7000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c366a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96400> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96400> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96400> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96400> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96400> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96400> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96400> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96400> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96400> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96400> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96400> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96400> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8526e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96400> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 27.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c962e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96668> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c969e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4dfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c962e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96668> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96668> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96668> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c969e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96668> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96668> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96668> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96668> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84deb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96668> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85233e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96668> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c440f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96668> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c969e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96668> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96668> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 27.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e8d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852853c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e8d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85285550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d42b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e8d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e8d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853ddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e8d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e8d0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e8d0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d42b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e8d0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85285470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e8d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceeb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e8d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e8d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e8d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1e0c07d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceeb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e8d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c449b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e8d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e8d0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c449b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e8d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e8d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85246860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8533e8d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 27.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84ceeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe353c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1cf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 27.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0be0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0be0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0be0> 0.0 5
Completed Iteration #5
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d85285278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0be0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d34e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0be0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0be0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0be0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0be0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0be0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0be0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d34e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0be0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d32b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0be0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe356a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0be0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe353c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0be0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0be0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0be0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0be0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0be0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 27.083333333333332
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f710> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8521ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f710> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d853dd198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f710> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853ddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f710> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f710> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f710> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f710> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f710> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f710> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f710> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f710> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d8611f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f710> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c53208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c44cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f710> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853ddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7f710> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 27.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d86098ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35a58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35a58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35a58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35a58> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35a58> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c961d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35a58> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c961d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35a58> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35a58> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84d6b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35a58> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35a58> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35a58> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c961d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35a58> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7899e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35a58> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35a58> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 27.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7982e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7984a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f798550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f798518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789c18> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f798ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789c18> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f798b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789c18> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f798d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f798518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789c18> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789c18> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f798748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789c18> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f798e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f798518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789c18> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f798518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789c18> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84ca8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789c18> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a07f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f798978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789c18> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7897f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f798518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789c18> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7981d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789c18> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f798630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789c18> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 27.083333333333332
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 7200
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f798908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7985f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f798d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f798438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f798160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1daf4df780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f798780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f798160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a79b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d853a0630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f798320> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a79b0> 1.0416666666666679 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 1.0416666666666679 13
Completed Iteration #15
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a79b0> 1.0416666666666679 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 1.0416666666666679 14
Completed Iteration #16
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 2.0833333333333357 15
Completed Iteration #17
Best Reward: 1.0416666666666679
Completed Iteration #18
Best Reward: 1.0416666666666679
Completed Iteration #19
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3e10> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 3.1250000000000036 16
Completed Iteration #20
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a79b0> 1.0416666666666679 6
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 3.1250000000000036 17
Completed Iteration #21
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3390> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3ac8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3e10> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 4.166666666666671 18
Completed Iteration #22
Best Reward: 1.0416666666666679
Completed Iteration #23
Best Reward: 1.0416666666666679
Completed Iteration #24
Best Reward: 1.0416666666666679
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #0
root
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84cee898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 3.1250000000000036 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 3.1250000000000036 5
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 4.166666666666671 19
Completed Iteration #0
Best Reward: 1.0416666666666679
Completed Iteration #1
Best Reward: 1.0416666666666679
Completed Iteration #2
Best Reward: 1.0416666666666679
Completed Iteration #3
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 3.1250000000000036 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 3.1250000000000036 6
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 4.166666666666671 20
Completed Iteration #4
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c05c0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789518> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 4.166666666666671 7
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 4.166666666666671 7
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 5.208333333333339 21
Completed Iteration #5
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 4.166666666666671 8
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 5.208333333333339 22
Completed Iteration #6
Best Reward: 1.0416666666666679
Completed Iteration #7
Best Reward: 1.0416666666666679
Completed Iteration #8
Best Reward: 1.0416666666666679
Completed Iteration #9
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84db6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 4.166666666666671 9
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 5.208333333333339 23
Completed Iteration #10
Best Reward: 1.0416666666666679
Completed Iteration #11
Best Reward: 1.0416666666666679
Completed Iteration #12
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 2.0833333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 4.166666666666671 8
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 4.166666666666671 10
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 5.208333333333339 24
Completed Iteration #13
Best Reward: 1.0416666666666679
Completed Iteration #14
Best Reward: 1.0416666666666679
Completed Iteration #15
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 3.1250000000000036 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 5.208333333333339 9
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 5.208333333333339 11
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 6.250000000000007 25
Completed Iteration #16
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 5.208333333333339 12
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 6.250000000000007 26
Completed Iteration #17
Best Reward: 1.0416666666666679
Completed Iteration #18
Best Reward: 1.0416666666666679
Completed Iteration #19
Best Reward: 1.0416666666666679
Completed Iteration #20
Best Reward: 1.0416666666666679
Completed Iteration #21
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4da0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1278> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 4.166666666666671 7
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 6.250000000000007 10
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 6.250000000000007 13
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 7.291666666666675 27
Completed Iteration #22
Best Reward: 1.0416666666666679
Completed Iteration #23
Best Reward: 1.0416666666666679
Completed Iteration #24
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7424a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3e10> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 4.166666666666671 8
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 6.250000000000007 11
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 6.250000000000007 14
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 7.291666666666675 28
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #1
root->7
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 5.208333333333339 9
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 7.291666666666675 12
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 7.291666666666675 15
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 8.333333333333343 29
Completed Iteration #0
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742d30> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742b70> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3390> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3ac8> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3e10> 3.1250000000000036 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 6.250000000000007 10
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 8.333333333333343 13
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 8.333333333333343 16
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 9.37500000000001 30
Completed Iteration #1
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f765198> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789fd0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 7.291666666666675 11
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 9.37500000000001 14
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 9.37500000000001 17
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 10.416666666666679 31
Completed Iteration #2
Best Reward: 1.0416666666666679
Completed Iteration #3
Best Reward: 1.0416666666666679
Completed Iteration #4
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742828> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 8.333333333333343 12
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 10.416666666666679 15
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 10.416666666666679 18
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 11.458333333333346 32
Completed Iteration #5
Best Reward: 1.0416666666666679
Completed Iteration #6
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f765b70> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 9.37500000000001 13
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 11.458333333333346 16
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 11.458333333333346 19
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 12.500000000000014 33
Completed Iteration #7
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f765dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 9.37500000000001 14
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 11.458333333333346 17
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 11.458333333333346 20
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 12.500000000000014 34
Completed Iteration #8
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f76c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f765e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 11.458333333333346 18
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 11.458333333333346 21
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 12.500000000000014 35
Completed Iteration #9
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f76c470> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d8521ed68> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 12.500000000000014 19
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 12.500000000000014 22
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 13.541666666666682 36
Completed Iteration #10
Best Reward: 1.0416666666666679
Completed Iteration #11
Best Reward: 1.0416666666666679
Completed Iteration #12
Best Reward: 1.0416666666666679
Completed Iteration #13
Best Reward: 1.0416666666666679
Completed Iteration #14
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 9.37500000000001 15
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 12.500000000000014 20
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 12.500000000000014 23
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 13.541666666666682 37
Completed Iteration #15
Best Reward: 1.0416666666666679
Completed Iteration #16
Best Reward: 1.0416666666666679
Completed Iteration #17
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7426d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f76c470> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f1d8521ed68> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 12.500000000000014 21
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 12.500000000000014 24
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 13.541666666666682 38
Completed Iteration #18
Best Reward: 1.0416666666666679
Completed Iteration #19
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f76c470> 1.0416666666666679 4
backprop <src.mcts.MCTS_Node object at 0x7f1d8521ed68> 1.0416666666666679 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 12.500000000000014 22
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 12.500000000000014 25
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 13.541666666666682 39
Completed Iteration #20
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789518> 1.0416666666666679 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 12.500000000000014 23
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 12.500000000000014 26
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 13.541666666666682 40
Completed Iteration #21
Best Reward: 1.0416666666666679
Completed Iteration #22
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7654a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3ac8> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3e10> 3.1250000000000036 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 9.37500000000001 16
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 12.500000000000014 24
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 12.500000000000014 27
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 13.541666666666682 41
Completed Iteration #23
Best Reward: 1.0416666666666679
Completed Iteration #24
Best Reward: 1.0416666666666679
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #2
root->7->3
Best Reward: 1.0416666666666679
Completed Iteration #0
Best Reward: 1.0416666666666679
Completed Iteration #1
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f76c7f0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f76c4e0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4da0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1278> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 5.208333333333339 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 10.416666666666679 17
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 13.541666666666682 25
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 13.541666666666682 28
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 14.58333333333335 42
Completed Iteration #2
Best Reward: 1.0416666666666679
Completed Iteration #3
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789240> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f765748> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f765198> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789fd0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 6.250000000000007 7
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 11.458333333333346 18
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 14.58333333333335 26
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 14.58333333333335 29
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 15.625000000000018 43
Completed Iteration #4
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f76cf98> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f76c128> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742828> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 12.500000000000014 19
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 15.625000000000018 27
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 15.625000000000018 30
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 16.666666666666686 44
Completed Iteration #5
Best Reward: 1.0416666666666679
Completed Iteration #6
Best Reward: 1.0416666666666679
Completed Iteration #7
Best Reward: 1.0416666666666679
Completed Iteration #8
Best Reward: 1.0416666666666679
Completed Iteration #9
Best Reward: 1.0416666666666679
Completed Iteration #10
Best Reward: 1.0416666666666679
Completed Iteration #11
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708668> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f76c4e0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4da0> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1278> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 7.291666666666675 8
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 13.541666666666682 20
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 16.666666666666686 28
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 16.666666666666686 31
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 17.708333333333353 45
Completed Iteration #12
Best Reward: 1.0416666666666679
Completed Iteration #13
Best Reward: 1.0416666666666679
Completed Iteration #14
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f714518> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f714588> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f765b70> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 14.58333333333335 21
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 17.708333333333353 29
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 17.708333333333353 32
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 18.75000000000002 46
Completed Iteration #15
Best Reward: 1.0416666666666679
Completed Iteration #16
Best Reward: 1.0416666666666679
Completed Iteration #17
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f714e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f714e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742d30> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742b70> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3390> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3ac8> 2.0833333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3e10> 3.1250000000000036 7
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 14.58333333333335 22
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 17.708333333333353 30
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 17.708333333333353 33
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 18.75000000000002 47
Completed Iteration #18
Best Reward: 1.0416666666666679
Completed Iteration #19
Best Reward: 1.0416666666666679
Completed Iteration #20
Best Reward: 1.0416666666666679
Completed Iteration #21
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f765400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742b70> 1.0416666666666679 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84cd3390> 2.0833333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3ac8> 2.0833333333333357 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7d3e10> 3.1250000000000036 8
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 14.58333333333335 23
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 17.708333333333353 31
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 17.708333333333353 34
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 18.75000000000002 48
Completed Iteration #22
Best Reward: 1.0416666666666679
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789240> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f765748> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f765198> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789fd0> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 7.291666666666675 9
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 14.58333333333335 24
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 17.708333333333353 32
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 17.708333333333353 35
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 18.75000000000002 49
Completed Iteration #23
Best Reward: 1.0416666666666679
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708320> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f714588> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f765b70> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 15.625000000000018 25
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 18.75000000000002 33
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 18.75000000000002 36
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 19.79166666666669 50
Completed Iteration #24
Best Reward: 1.0416666666666679
Completed Iteration #25
Best Reward: 1.0416666666666679
Completed MCTS Level/Depth: #3
root->7->3->3
Best Reward: 1.0416666666666679
Completed Iteration #0
Best Reward: 1.0416666666666679
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708e48> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 3.1250000000000036 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 3.1250000000000036 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 9.37500000000001 10
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 17.708333333333353 26
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 20.833333333333357 34
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 20.833333333333357 37
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 21.875000000000025 51
Completed Iteration #1
Best Reward: 2.0833333333333357
coverage_call_count 7300
Completed Iteration #2
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fd68> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 5.208333333333339 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 5.208333333333339 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 11.458333333333346 11
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 19.79166666666669 27
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 22.916666666666693 35
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 22.916666666666693 38
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 23.95833333333336 52
Completed Iteration #3
Best Reward: 2.0833333333333357
Completed Iteration #4
Best Reward: 2.0833333333333357
Completed Iteration #5
Best Reward: 2.0833333333333357
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7143c8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7140f0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f76c7f0> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f76c4e0> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4da0> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1278> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 12.500000000000014 12
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 20.833333333333357 28
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 23.95833333333336 36
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 23.95833333333336 39
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 25.00000000000003 53
Completed Iteration #6
Best Reward: 2.0833333333333357
Completed Iteration #7
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1d7f72e2b0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f72e198> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f765198> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789fd0> 4.166666666666671 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 14.58333333333335 13
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 22.916666666666693 29
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 26.041666666666696 37
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 26.041666666666696 40
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 27.083333333333364 54
Completed Iteration #8
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d84c96d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f72e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708668> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f76c4e0> 3.1250000000000036 5
backprop <src.mcts.MCTS_Node object at 0x7f1d852d4da0> 4.166666666666671 6
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1278> 4.166666666666671 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 14.58333333333335 14
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 22.916666666666693 30
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 26.041666666666696 38
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 26.041666666666696 41
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 27.083333333333364 55
Completed Iteration #9
Best Reward: 2.0833333333333357
Completed Iteration #10
Best Reward: 2.0833333333333357
Completed Iteration #11
Best Reward: 2.0833333333333357
Completed Iteration #12
Best Reward: 2.0833333333333357
Completed Iteration #13
Best Reward: 2.0833333333333357
Completed Iteration #14
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1d7f735198> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f72e908> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fd68> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 6.250000000000007 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 7.291666666666675 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 7.291666666666675 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 16.666666666666686 15
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 25.00000000000003 31
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 28.125000000000032 39
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 28.125000000000032 42
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 29.1666666666667 56
Completed Iteration #15
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fd68> 4.166666666666671 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 6.250000000000007 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 7.291666666666675 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 7.291666666666675 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 16.666666666666686 16
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 25.00000000000003 32
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 28.125000000000032 40
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 28.125000000000032 43
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 29.1666666666667 57
Completed Iteration #16
Best Reward: 2.0833333333333357
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7089b0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f76c9b0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 17.708333333333353 17
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 26.041666666666696 33
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 29.1666666666667 41
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 29.1666666666667 44
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 30.208333333333368 58
Completed Iteration #17
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f76c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 7.291666666666675 7
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 17.708333333333353 18
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 26.041666666666696 34
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 29.1666666666667 42
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 29.1666666666667 45
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 30.208333333333368 59
Completed Iteration #18
Best Reward: 2.0833333333333357
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f798f28> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1278> 5.208333333333339 7
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 18.75000000000002 19
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 27.083333333333364 35
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 30.208333333333368 43
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 30.208333333333368 46
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 31.250000000000036 60
Completed Iteration #19
Best Reward: 2.0833333333333357
Completed Iteration #20
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7146d8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7145f8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fd68> 6.250000000000007 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 8.333333333333343 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 9.37500000000001 7
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 9.37500000000001 8
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 20.833333333333357 20
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 29.1666666666667 36
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 32.2916666666667 44
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 32.2916666666667 47
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 33.33333333333337 61
Completed Iteration #21
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f72ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f798f28> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1278> 5.208333333333339 8
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 20.833333333333357 21
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 29.1666666666667 37
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 32.2916666666667 45
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 32.2916666666667 48
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 33.33333333333337 62
Completed Iteration #22
Best Reward: 2.0833333333333357
Completed Iteration #23
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f72e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f72e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7089b0> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f76c9b0> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 20.833333333333357 22
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 29.1666666666667 38
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 32.2916666666667 46
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 32.2916666666667 49
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 33.33333333333337 63
Completed Iteration #24
Best Reward: 2.0833333333333357
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f714438> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7352b0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f798f28> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84da1278> 6.250000000000007 9
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 21.875000000000025 23
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 30.208333333333368 39
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 33.33333333333337 47
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 33.33333333333337 50
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 34.37500000000004 64
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #4
root->7->3->3->2
Best Reward: 2.0833333333333357
Completed Iteration #0
Best Reward: 2.0833333333333357
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7355f8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f76c438> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708e48> 3.1250000000000036 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 9.37500000000001 7
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 10.416666666666679 8
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 10.416666666666679 9
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 22.916666666666693 24
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 31.250000000000036 40
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 34.37500000000004 48
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 34.37500000000004 51
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 35.416666666666714 65
Completed Iteration #1
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f735a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f735940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 10.416666666666679 9
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 10.416666666666679 10
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 22.916666666666693 25
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 31.250000000000036 41
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 34.37500000000004 49
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 34.37500000000004 52
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 35.416666666666714 66
Completed Iteration #2
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f735e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f735ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7355f8> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f76c438> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708e48> 3.1250000000000036 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 9.37500000000001 8
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 10.416666666666679 10
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 10.416666666666679 11
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 22.916666666666693 26
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 31.250000000000036 42
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 34.37500000000004 50
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 34.37500000000004 53
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 35.416666666666714 67
Completed Iteration #3
Best Reward: 2.0833333333333357
Completed Iteration #4
Best Reward: 2.0833333333333357
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742cf8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 10.416666666666679 9
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 11.458333333333346 11
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 11.458333333333346 12
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 23.95833333333336 27
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 32.2916666666667 43
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 35.416666666666714 51
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 35.416666666666714 54
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 36.458333333333385 68
Completed Iteration #5
Best Reward: 2.0833333333333357
Completed Iteration #6
Best Reward: 2.0833333333333357
Completed Iteration #7
Best Reward: 2.0833333333333357
Completed Iteration #8
Best Reward: 2.0833333333333357
Completed Iteration #9
Best Reward: 2.0833333333333357
Completed Iteration #10
Best Reward: 2.0833333333333357
Completed Iteration #11
Best Reward: 2.0833333333333357
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f765a90> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 12.500000000000014 13
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 25.00000000000003 28
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 33.33333333333337 44
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 36.458333333333385 52
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 36.458333333333385 55
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 37.50000000000006 69
Completed Iteration #12
Best Reward: 2.0833333333333357
Completed Iteration #13
Best Reward: 2.0833333333333357
Completed Iteration #14
Best Reward: 2.0833333333333357
Completed Iteration #15
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f735fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7355f8> 1.0416666666666679 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f76c438> 1.0416666666666679 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708e48> 3.1250000000000036 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 10.416666666666679 10
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 11.458333333333346 12
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 12.500000000000014 14
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 25.00000000000003 29
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 33.33333333333337 45
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 36.458333333333385 53
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 36.458333333333385 56
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 37.50000000000006 70
Completed Iteration #16
Best Reward: 2.0833333333333357
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f735cf8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 13.541666666666682 15
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 26.041666666666696 30
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 34.37500000000004 46
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 37.50000000000006 54
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 37.50000000000006 57
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 38.54166666666673 71
Completed Iteration #17
Best Reward: 2.0833333333333357
Completed Iteration #18
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6c14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6c1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708e48> 3.1250000000000036 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 10.416666666666679 11
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 11.458333333333346 13
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 13.541666666666682 16
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 26.041666666666696 31
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 34.37500000000004 47
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 37.50000000000006 55
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 37.50000000000006 58
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 38.54166666666673 72
Completed Iteration #19
Best Reward: 2.0833333333333357
Completed Iteration #20
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6c1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f76c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 11.458333333333346 14
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 13.541666666666682 17
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 26.041666666666696 32
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 34.37500000000004 48
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 37.50000000000006 56
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 37.50000000000006 59
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 38.54166666666673 73
Completed Iteration #21
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6d90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6c1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f735198> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f72e908> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fd68> 6.250000000000007 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 10.416666666666679 12
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 11.458333333333346 15
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 13.541666666666682 18
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 26.041666666666696 33
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 34.37500000000004 49
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 37.50000000000006 57
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 37.50000000000006 60
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 38.54166666666673 74
Completed Iteration #22
Best Reward: 2.0833333333333357
Completed Iteration #23
Best Reward: 2.0833333333333357
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6d98d0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 14.58333333333335 19
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 27.083333333333364 34
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 35.416666666666714 50
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 38.54166666666673 58
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 38.54166666666673 61
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 39.5833333333334 75
Completed Iteration #24
Best Reward: 2.0833333333333357
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #5
root->7->3->3->2->2
Best Reward: 2.0833333333333357
Completed Iteration #0
Best Reward: 2.0833333333333357
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6d96a0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6d9c88> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7146d8> 3.1250000000000036 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7145f8> 3.1250000000000036 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fd68> 7.291666666666675 7
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 11.458333333333346 13
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 12.500000000000014 16
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 15.625000000000018 20
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 28.125000000000032 35
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 36.458333333333385 51
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 39.5833333333334 59
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 39.5833333333334 62
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 40.62500000000007 76
Completed Iteration #1
Best Reward: 2.0833333333333357
Completed Iteration #2
Best Reward: 2.0833333333333357
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f735c88> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 12.500000000000014 14
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 13.541666666666682 17
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 16.666666666666686 21
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 29.1666666666667 36
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 37.50000000000006 52
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 40.62500000000007 60
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 40.62500000000007 63
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 41.66666666666674 77
Completed Iteration #3
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1d7f765128> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7356d8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f735198> 4.166666666666671 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f72e908> 4.166666666666671 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fd68> 9.37500000000001 8
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 14.58333333333335 15
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 15.625000000000018 18
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 18.75000000000002 22
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 31.250000000000036 37
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 39.58333333333339 53
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 42.70833333333341 61
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 42.70833333333341 64
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 43.75000000000008 78
Completed Iteration #4
Best Reward: 2.0833333333333357
Completed Iteration #5
Best Reward: 2.0833333333333357
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6c1cf8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6c1908> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 16.666666666666686 19
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 19.79166666666669 23
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 32.2916666666667 38
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 40.62500000000006 54
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 43.75000000000007 62
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 43.75000000000007 65
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 44.79166666666674 79
Completed Iteration #6
Best Reward: 2.0833333333333357
Completed Iteration #7
Best Reward: 2.0833333333333357
Completed Iteration #8
Best Reward: 2.0833333333333357
Completed Iteration #9
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6d9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6d9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 16.666666666666686 20
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 19.79166666666669 24
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 32.2916666666667 39
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 40.62500000000006 55
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 43.75000000000007 63
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 43.75000000000007 66
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 44.79166666666674 80
Completed Iteration #10
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6d94e0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7145f8> 5.208333333333339 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fd68> 11.458333333333346 9
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 16.666666666666686 16
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 18.75000000000002 21
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 21.875000000000025 25
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 34.375000000000036 40
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 42.70833333333339 56
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 45.83333333333341 64
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 45.83333333333341 67
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 46.87500000000008 81
Completed Iteration #11
Best Reward: 2.0833333333333357
Completed Iteration #12
Best Reward: 2.0833333333333357
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6f2518> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f72e908> 5.208333333333339 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fd68> 12.500000000000014 10
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 17.708333333333353 17
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 19.79166666666669 22
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 22.916666666666693 26
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 35.4166666666667 41
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 43.75000000000006 57
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 46.87500000000007 65
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 46.87500000000007 68
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 47.91666666666674 82
Completed Iteration #13
Best Reward: 2.0833333333333357
Completed Iteration #14
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6d9be0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f76c438> 3.1250000000000036 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708e48> 5.208333333333339 7
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 19.79166666666669 18
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 21.875000000000025 23
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 25.00000000000003 27
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 37.500000000000036 42
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 45.83333333333339 58
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 48.95833333333341 66
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 48.95833333333341 69
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 50.00000000000008 83
Completed Iteration #15
Best Reward: 2.0833333333333357
Completed Iteration #16
Best Reward: 2.0833333333333357
Completed Iteration #17
Best Reward: 2.0833333333333357
Completed Iteration #18
Best Reward: 2.0833333333333357
Completed Iteration #19
Best Reward: 2.0833333333333357
Completed Iteration #20
Best Reward: 2.0833333333333357
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6fc6a0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6fc710> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6d94e0> 3.1250000000000036 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7145f8> 6.250000000000007 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fd68> 13.541666666666682 11
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 20.833333333333357 19
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 22.916666666666693 24
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 26.041666666666696 28
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 38.5416666666667 43
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 46.87500000000006 59
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 50.00000000000007 67
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 50.00000000000007 70
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 51.04166666666674 84
Completed Iteration #21
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f735c88> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 20.833333333333357 20
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 22.916666666666693 25
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 26.041666666666696 29
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 38.5416666666667 44
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 46.87500000000006 60
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 50.00000000000007 68
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 50.00000000000007 71
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 51.04166666666674 85
Completed Iteration #22
Best Reward: 2.0833333333333357
Completed Iteration #23
Best Reward: 2.0833333333333357
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6d9630> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 21.875000000000025 21
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 23.95833333333336 26
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 27.083333333333364 30
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 39.58333333333337 45
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 47.91666666666673 61
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 51.04166666666674 69
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 51.04166666666674 72
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 52.083333333333414 86
Completed Iteration #24
Best Reward: 2.0833333333333357
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #6
root->7->3->3->2->2->4
Best Reward: 2.0833333333333357
Completed Iteration #0
Best Reward: 2.0833333333333357
Completed Iteration #1
Best Reward: 2.0833333333333357
Completed Iteration #2
Best Reward: 2.0833333333333357
Completed Iteration #3
Best Reward: 2.0833333333333357
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6f2748> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7145f8> 7.291666666666675 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fd68> 14.58333333333335 12
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 22.916666666666693 22
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 25.00000000000003 27
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 28.125000000000032 31
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 40.62500000000004 46
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 48.9583333333334 62
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 52.083333333333414 70
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 52.083333333333414 73
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 53.125000000000085 87
Completed Iteration #4
Best Reward: 2.0833333333333357
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6f2080> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6fc3c8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7355f8> 2.0833333333333357 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f76c438> 4.166666666666671 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708e48> 6.250000000000007 8
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 23.95833333333336 23
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 26.041666666666696 28
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 29.1666666666667 32
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 41.666666666666714 47
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 50.00000000000007 63
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 53.125000000000085 71
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 53.125000000000085 74
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 54.16666666666676 88
Completed Iteration #5
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6fc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7c0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742cf8> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 23.95833333333336 24
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 26.041666666666696 29
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 29.1666666666667 33
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 41.666666666666714 48
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 50.00000000000007 64
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 53.125000000000085 72
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 53.125000000000085 75
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 54.16666666666676 89
Completed Iteration #6
Best Reward: 2.0833333333333357
Completed Iteration #7
Best Reward: 2.0833333333333357
Completed Iteration #8
Best Reward: 2.0833333333333357
Completed Iteration #9
Best Reward: 2.0833333333333357
Completed Iteration #10
Best Reward: 2.0833333333333357
Completed Iteration #11
Best Reward: 2.0833333333333357
Completed Iteration #12
Best Reward: 2.0833333333333357
Completed Iteration #13
Best Reward: 2.0833333333333357
Completed Iteration #14
Best Reward: 2.0833333333333357
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6fcf98> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f76c438> 5.208333333333339 7
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708e48> 7.291666666666675 9
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 25.00000000000003 25
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 27.083333333333364 30
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 30.208333333333368 34
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 42.708333333333385 49
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 51.04166666666674 65
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 54.16666666666676 73
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 54.16666666666676 76
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 55.20833333333343 90
Completed Iteration #15
Best Reward: 2.0833333333333357
Completed Iteration #16
Best Reward: 2.0833333333333357
Completed Iteration #17
Best Reward: 2.0833333333333357
Completed Iteration #18
Best Reward: 2.0833333333333357
Completed Iteration #19
Best Reward: 2.0833333333333357
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6a3278> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6a32e8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742cf8> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 26.041666666666696 26
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 28.125000000000032 31
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 31.250000000000036 35
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 43.75000000000006 50
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 52.083333333333414 66
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 55.20833333333343 74
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 55.20833333333343 77
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 56.2500000000001 91
Completed Iteration #20
Best Reward: 2.0833333333333357
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6a37f0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe35cc0> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f735c88> 2.0833333333333357 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 27.083333333333364 27
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 29.1666666666667 32
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 32.2916666666667 36
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 44.79166666666673 51
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 53.125000000000085 67
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 56.2500000000001 75
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 56.2500000000001 78
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 57.29166666666677 92
Completed Iteration #21
Best Reward: 2.0833333333333357
Completed Iteration #22
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f714908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6f2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6d9630> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 27.083333333333364 28
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 29.1666666666667 33
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 32.2916666666667 37
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 44.79166666666673 52
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 53.125000000000085 68
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 56.2500000000001 76
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 56.2500000000001 79
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 57.29166666666677 93
Completed Iteration #23
Best Reward: 2.0833333333333357
Completed Iteration #24
Best Reward: 2.0833333333333357
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #7
root->7->3->3->2->2->4->6
Best Reward: 2.0833333333333357
Completed Iteration #0
Best Reward: 2.0833333333333357
Completed Iteration #1
Best Reward: 2.0833333333333357
coverage_call_count 7400
Completed Iteration #2
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6fc550> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f735400> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6f2518> 3.1250000000000036 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f72e908> 7.291666666666675 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fd68> 16.666666666666686 13
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 29.1666666666667 29
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 31.250000000000036 34
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 34.375000000000036 38
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 46.875000000000064 53
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 55.20833333333342 69
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 58.333333333333435 77
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 58.333333333333435 80
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 59.37500000000011 94
Completed Iteration #3
Best Reward: 2.0833333333333357
Completed Iteration #4
Best Reward: 2.0833333333333357
Completed Iteration #5
Best Reward: 2.0833333333333357
Completed Iteration #6
Best Reward: 2.0833333333333357
Completed Iteration #7
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6970b8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7145f8> 9.37500000000001 7
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fd68> 18.75000000000002 14
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 31.250000000000036 30
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 33.33333333333337 35
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 36.45833333333337 39
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 48.9583333333334 54
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 57.29166666666676 70
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 60.41666666666677 78
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 60.41666666666677 81
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 61.45833333333344 95
Completed Iteration #8
Best Reward: 2.0833333333333357
Completed Iteration #9
Best Reward: 2.0833333333333357
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6a3128> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f72e908> 8.333333333333343 7
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fd68> 19.79166666666669 15
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 32.2916666666667 31
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 34.37500000000004 36
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 37.50000000000004 40
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 50.00000000000007 55
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 58.33333333333343 71
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 61.45833333333344 79
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 61.45833333333344 82
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 62.500000000000114 96
Completed Iteration #10
Best Reward: 2.0833333333333357
Completed Iteration #11
Best Reward: 2.0833333333333357
Completed Iteration #12
Best Reward: 2.0833333333333357
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6a3da0> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6a3e10> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6970b8> 3.1250000000000036 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7145f8> 10.416666666666679 8
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fd68> 20.833333333333357 16
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 33.33333333333337 32
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 35.416666666666714 37
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 38.541666666666714 41
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 51.04166666666674 56
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 59.3750000000001 72
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 62.500000000000114 80
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 62.500000000000114 83
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 63.541666666666785 97
Completed Iteration #13
Best Reward: 2.0833333333333357
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6f29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6979b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6a3128> 1.0416666666666679 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f72e908> 8.333333333333343 8
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fd68> 20.833333333333357 17
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 33.33333333333337 33
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 35.416666666666714 38
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 38.541666666666714 42
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 51.04166666666674 57
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 59.3750000000001 73
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 62.500000000000114 81
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 62.500000000000114 84
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 63.541666666666785 98
Completed Iteration #14
Best Reward: 2.0833333333333357
Completed Iteration #15
Best Reward: 2.0833333333333357
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bb588> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bb5f8> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f765128> 3.1250000000000036 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7356d8> 3.1250000000000036 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f735198> 5.208333333333339 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f72e908> 9.37500000000001 9
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fd68> 21.875000000000025 18
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 34.37500000000004 34
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 36.458333333333385 39
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 39.583333333333385 43
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 52.083333333333414 58
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 60.41666666666677 74
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 63.541666666666785 82
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 63.541666666666785 85
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 64.58333333333346 99
Completed Iteration #16
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1d7f72e6a0> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f76c908> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6fc550> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f735400> 4.166666666666671 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6f2518> 5.208333333333339 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f72e908> 11.458333333333346 10
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fd68> 23.95833333333336 19
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 36.45833333333338 35
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 38.54166666666672 40
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 41.66666666666672 44
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 54.16666666666675 59
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 62.50000000000011 75
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 65.62500000000011 83
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 65.62500000000011 86
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 66.6666666666668 100
Completed Iteration #17
Best Reward: 2.0833333333333357
Completed Iteration #18
Best Reward: 2.0833333333333357
Completed Iteration #19
Best Reward: 2.0833333333333357
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6a3e80> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f72e908> 12.500000000000014 11
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fd68> 25.00000000000003 20
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 37.50000000000004 36
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 39.583333333333385 41
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 42.708333333333385 45
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 55.208333333333414 60
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 63.54166666666677 76
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 66.66666666666679 84
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 66.66666666666679 87
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 67.70833333333347 101
Completed Iteration #20
Best Reward: 2.0833333333333357
Completed Iteration #21
Best Reward: 2.0833333333333357
Completed Iteration #22
Best Reward: 2.0833333333333357
Reward: 2.0833333333333357
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6976d8> 2.0833333333333357 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708128> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fd68> 27.083333333333364 21
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 39.58333333333338 37
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 41.66666666666672 42
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 44.79166666666672 46
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 57.29166666666675 61
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 65.62500000000011 77
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 68.75000000000011 85
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 68.75000000000011 88
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 69.7916666666668 102
Completed Iteration #23
Best Reward: 2.0833333333333357
Reward: 1.0416666666666679
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bb630> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6d9940> 1.0416666666666679 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6a3e80> 2.0833333333333357 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f72e908> 13.541666666666682 12
backprop <src.mcts.MCTS_Node object at 0x7f1d7fe7fd68> 28.125000000000032 22
backprop <src.mcts.MCTS_Node object at 0x7f1d7f708208> 40.62500000000004 38
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7428d0> 42.708333333333385 43
backprop <src.mcts.MCTS_Node object at 0x7f1d7f742780> 45.833333333333385 47
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7898d0> 58.333333333333414 62
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789828> 66.66666666666679 78
backprop <src.mcts.MCTS_Node object at 0x7f1d7f789e10> 69.79166666666679 86
backprop <src.mcts.MCTS_Node object at 0x7f1d7f7a7be0> 69.79166666666679 89
backprop <src.mcts.MCTS_Node object at 0x7f1d8611ffd0> 70.83333333333347 103
Completed Iteration #24
Best Reward: 2.0833333333333357
Completed Iteration #25
Best Reward: 2.0833333333333357
Completed MCTS Level/Depth: #8
root->7->3->3->2->2->4->6->17
Best Reward: 2.0833333333333357
iteration: 232
found coverage increase 2.0833333333333357
Current Total Coverage 29.166666666666668
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6470b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f697278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6474a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f647470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f647668> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 1.0416666666666643 7
Completed Iteration #7
Best Reward: 1.0416666666666643
Completed Iteration #8
Best Reward: 1.0416666666666643
Completed Iteration #9
Best Reward: 1.0416666666666643
Completed Iteration #10
Best Reward: 1.0416666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f647eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 1.0416666666666643 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 1.0416666666666643 8
Completed Iteration #11
Best Reward: 1.0416666666666643
Completed Iteration #12
Best Reward: 1.0416666666666643
Completed Iteration #13
Best Reward: 1.0416666666666643
Completed Iteration #14
Best Reward: 1.0416666666666643
Completed Iteration #15
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 2.0833333333333286 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 2.0833333333333286 9
Completed Iteration #16
Best Reward: 1.0416666666666643
Completed Iteration #17
Best Reward: 1.0416666666666643
Completed Iteration #18
Best Reward: 1.0416666666666643
Completed Iteration #19
Best Reward: 1.0416666666666643
Completed Iteration #20
Best Reward: 1.0416666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f659d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 2.0833333333333286 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 2.0833333333333286 10
Completed Iteration #21
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f798c50> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 3.124999999999993 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 3.124999999999993 11
Completed Iteration #22
Best Reward: 1.0416666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6fc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6fc860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f647eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 3.124999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 3.124999999999993 12
Completed Iteration #23
Best Reward: 1.0416666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f697fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 3.124999999999993 8
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 3.124999999999993 13
Completed Iteration #24
Best Reward: 1.0416666666666643
Completed Iteration #25
Best Reward: 1.0416666666666643
Completed MCTS Level/Depth: #0
root
Best Reward: 1.0416666666666643
Completed Iteration #0
Best Reward: 1.0416666666666643
Completed Iteration #1
Best Reward: 1.0416666666666643
Completed Iteration #2
Best Reward: 1.0416666666666643
Completed Iteration #3
Best Reward: 1.0416666666666643
Completed Iteration #4
Best Reward: 1.0416666666666643
Completed Iteration #5
Best Reward: 1.0416666666666643
Completed Iteration #6
Best Reward: 1.0416666666666643
Completed Iteration #7
Best Reward: 1.0416666666666643
Completed Iteration #8
Best Reward: 1.0416666666666643
Completed Iteration #9
Best Reward: 1.0416666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 3.124999999999993 9
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 3.124999999999993 14
Completed Iteration #10
Best Reward: 1.0416666666666643
Completed Iteration #11
Best Reward: 1.0416666666666643
Completed Iteration #12
Best Reward: 1.0416666666666643
Completed Iteration #13
Best Reward: 1.0416666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f659d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 3.124999999999993 10
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 3.124999999999993 15
Completed Iteration #14
Best Reward: 1.0416666666666643
Completed Iteration #15
Best Reward: 1.0416666666666643
Completed Iteration #16
Best Reward: 1.0416666666666643
Completed Iteration #17
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666630> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 3.124999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 4.166666666666657 11
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 4.166666666666657 16
Completed Iteration #18
Best Reward: 1.0416666666666643
Completed Iteration #19
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 3.124999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 4.166666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 5.2083333333333215 12
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 5.2083333333333215 17
Completed Iteration #20
Best Reward: 1.0416666666666643
Completed Iteration #21
Best Reward: 1.0416666666666643
Completed Iteration #22
Best Reward: 1.0416666666666643
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 5.2083333333333215 13
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 5.2083333333333215 18
Completed Iteration #23
Best Reward: 1.0416666666666643
Completed Iteration #24
Best Reward: 1.0416666666666643
Completed Iteration #25
Best Reward: 1.0416666666666643
Completed MCTS Level/Depth: #1
root->2
Best Reward: 1.0416666666666643
Completed Iteration #0
Best Reward: 1.0416666666666643
Completed Iteration #1
Best Reward: 1.0416666666666643
Completed Iteration #2
Best Reward: 1.0416666666666643
Completed Iteration #3
Best Reward: 1.0416666666666643
Completed Iteration #4
Best Reward: 1.0416666666666643
Completed Iteration #5
Best Reward: 1.0416666666666643
Completed Iteration #6
Best Reward: 1.0416666666666643
Completed Iteration #7
Best Reward: 1.0416666666666643
Completed Iteration #8
Best Reward: 1.0416666666666643
Completed Iteration #9
Best Reward: 1.0416666666666643
Completed Iteration #10
Best Reward: 1.0416666666666643
Completed Iteration #11
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6240b8> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 4.166666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 5.2083333333333215 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 6.249999999999986 14
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 6.249999999999986 19
Completed Iteration #12
Best Reward: 1.0416666666666643
Completed Iteration #13
Best Reward: 1.0416666666666643
Completed Iteration #14
Best Reward: 1.0416666666666643
Completed Iteration #15
Best Reward: 1.0416666666666643
Completed Iteration #16
Best Reward: 1.0416666666666643
Completed Iteration #17
Best Reward: 1.0416666666666643
Completed Iteration #18
Best Reward: 1.0416666666666643
Completed Iteration #19
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f624518> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 5.2083333333333215 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 6.249999999999986 7
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 7.29166666666665 15
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 7.29166666666665 20
Completed Iteration #20
Best Reward: 1.0416666666666643
Completed Iteration #21
Best Reward: 1.0416666666666643
Completed Iteration #22
Best Reward: 1.0416666666666643
Completed Iteration #23
Best Reward: 1.0416666666666643
coverage_call_count 7500
Completed Iteration #24
Best Reward: 1.0416666666666643
Completed Iteration #25
Best Reward: 1.0416666666666643
Completed MCTS Level/Depth: #2
root->2->7
Best Reward: 1.0416666666666643
Completed Iteration #0
Best Reward: 1.0416666666666643
Completed Iteration #1
Best Reward: 1.0416666666666643
Completed Iteration #2
Best Reward: 1.0416666666666643
Completed Iteration #3
Best Reward: 1.0416666666666643
Completed Iteration #4
Best Reward: 1.0416666666666643
Completed Iteration #5
Best Reward: 1.0416666666666643
Completed Iteration #6
Best Reward: 1.0416666666666643
Completed Iteration #7
Best Reward: 1.0416666666666643
Completed Iteration #8
Best Reward: 1.0416666666666643
Completed Iteration #9
Best Reward: 1.0416666666666643
Completed Iteration #10
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f63c518> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 6.249999999999986 7
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 7.29166666666665 8
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 8.333333333333314 16
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 8.333333333333314 21
Completed Iteration #11
Best Reward: 1.0416666666666643
Completed Iteration #12
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6354e0> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 7.29166666666665 8
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 8.333333333333314 9
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 9.374999999999979 17
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 9.374999999999979 22
Completed Iteration #13
Best Reward: 1.0416666666666643
Completed Iteration #14
Best Reward: 1.0416666666666643
Completed Iteration #15
Best Reward: 1.0416666666666643
Completed Iteration #16
Best Reward: 1.0416666666666643
Completed Iteration #17
Best Reward: 1.0416666666666643
Completed Iteration #18
Best Reward: 1.0416666666666643
Completed Iteration #19
Best Reward: 1.0416666666666643
Completed Iteration #20
Best Reward: 1.0416666666666643
Completed Iteration #21
Best Reward: 1.0416666666666643
Completed Iteration #22
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f72ee48> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 8.333333333333314 9
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 9.374999999999979 10
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 10.416666666666643 18
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 10.416666666666643 23
Completed Iteration #23
Best Reward: 1.0416666666666643
Completed Iteration #24
Best Reward: 1.0416666666666643
Completed Iteration #25
Best Reward: 1.0416666666666643
Completed MCTS Level/Depth: #3
root->2->7->0
Best Reward: 1.0416666666666643
Completed Iteration #0
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f98> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6665c0> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f72ee48> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 3.124999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 9.374999999999979 10
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 10.416666666666643 11
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 11.458333333333307 19
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 11.458333333333307 24
Completed Iteration #1
Best Reward: 1.0416666666666643
Completed Iteration #2
Best Reward: 1.0416666666666643
Completed Iteration #3
Best Reward: 1.0416666666666643
Completed Iteration #4
Best Reward: 1.0416666666666643
Completed Iteration #5
Best Reward: 1.0416666666666643
Completed Iteration #6
Best Reward: 1.0416666666666643
Completed Iteration #7
Best Reward: 1.0416666666666643
Completed Iteration #8
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f63c320> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6665c0> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f72ee48> 3.124999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 3.124999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 4.166666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 10.416666666666643 11
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 11.458333333333307 12
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 12.499999999999972 20
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 12.499999999999972 25
Completed Iteration #9
Best Reward: 1.0416666666666643
Completed Iteration #10
Best Reward: 1.0416666666666643
Completed Iteration #11
Best Reward: 1.0416666666666643
Completed Iteration #12
Best Reward: 1.0416666666666643
Completed Iteration #13
Best Reward: 1.0416666666666643
Completed Iteration #14
Best Reward: 1.0416666666666643
Completed Iteration #15
Best Reward: 1.0416666666666643
Completed Iteration #16
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f635160> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6665c0> 3.124999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f72ee48> 4.166666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 4.166666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 5.2083333333333215 6
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 11.458333333333307 12
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 12.499999999999972 13
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 13.541666666666636 21
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 13.541666666666636 26
Completed Iteration #17
Best Reward: 1.0416666666666643
Completed Iteration #18
Best Reward: 1.0416666666666643
Completed Iteration #19
Best Reward: 1.0416666666666643
Completed Iteration #20
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3dea20> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3dea90> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f63c320> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6665c0> 4.166666666666657 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f72ee48> 5.2083333333333215 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 5.2083333333333215 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 6.249999999999986 7
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 12.499999999999972 13
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 13.541666666666636 14
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 14.5833333333333 22
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 14.5833333333333 27
Completed Iteration #21
Best Reward: 1.0416666666666643
Completed Iteration #22
Best Reward: 1.0416666666666643
Completed Iteration #23
Best Reward: 1.0416666666666643
Completed Iteration #24
Best Reward: 1.0416666666666643
Completed Iteration #25
Best Reward: 1.0416666666666643
Completed MCTS Level/Depth: #4
root->2->7->0->2
Best Reward: 1.0416666666666643
Completed Iteration #0
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e6748> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6665c0> 5.2083333333333215 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f72ee48> 6.249999999999986 7
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 6.249999999999986 7
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 7.29166666666665 8
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 13.541666666666636 14
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 14.5833333333333 15
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 15.624999999999964 23
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 15.624999999999964 28
Completed Iteration #1
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e6b00> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 7.29166666666665 8
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 8.333333333333314 9
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 14.5833333333333 15
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 15.624999999999964 16
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 16.66666666666663 24
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 16.66666666666663 29
Completed Iteration #2
Best Reward: 1.0416666666666643
Completed Iteration #3
Best Reward: 1.0416666666666643
Completed Iteration #4
Best Reward: 1.0416666666666643
Completed Iteration #5
Best Reward: 1.0416666666666643
Completed Iteration #6
Best Reward: 1.0416666666666643
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3de9b0> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e69e8> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e6b00> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 8.333333333333314 9
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 9.374999999999979 10
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 15.624999999999964 16
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 16.66666666666663 17
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 17.708333333333293 25
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 17.708333333333293 30
Completed Iteration #7
Best Reward: 1.0416666666666643
Completed Iteration #8
Best Reward: 1.0416666666666643
Completed Iteration #9
Best Reward: 1.0416666666666643
Completed Iteration #10
Best Reward: 1.0416666666666643
Completed Iteration #11
Best Reward: 1.0416666666666643
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d7f63c860> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607b38> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3de9b0> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e69e8> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e6b00> 4.166666666666661 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 10.416666666666647 10
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 11.45833333333331 11
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 17.708333333333297 17
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 18.74999999999996 18
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 19.791666666666625 26
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 19.791666666666625 31
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f63ce48> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 11.45833333333331 11
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 12.499999999999975 12
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 18.74999999999996 18
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 19.791666666666625 19
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 20.83333333333329 27
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 20.83333333333329 32
Completed Iteration #14
Best Reward: 2.083333333333332
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666748> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3dea90> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f63c320> 3.124999999999993 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6665c0> 6.249999999999986 7
backprop <src.mcts.MCTS_Node object at 0x7f1d7f72ee48> 7.29166666666665 8
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 12.499999999999975 12
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 13.54166666666664 13
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 19.791666666666625 19
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 20.83333333333329 20
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 21.874999999999954 28
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 21.874999999999954 33
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Completed Iteration #17
Best Reward: 2.083333333333332
Completed Iteration #18
Best Reward: 2.083333333333332
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3deac8> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 13.54166666666664 13
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 14.583333333333304 14
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 20.83333333333329 20
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 21.874999999999954 21
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 22.916666666666618 29
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 22.916666666666618 34
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f29b0> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e69e8> 4.166666666666661 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e6b00> 5.208333333333325 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 14.583333333333304 14
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 15.624999999999968 15
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 21.874999999999954 21
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 22.916666666666618 22
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 23.958333333333282 30
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 23.958333333333282 35
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #5
root->2->7->0->2->0
Best Reward: 2.083333333333332
Completed Iteration #0
Best Reward: 2.083333333333332
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3963c8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f396438> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f63c860> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607b38> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3de9b0> 5.208333333333329 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e69e8> 6.249999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e6b00> 7.291666666666657 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 16.666666666666636 15
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 17.7083333333333 16
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 23.958333333333286 22
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 24.99999999999995 23
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 26.041666666666615 31
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 26.041666666666615 36
Completed Iteration #3
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f2fd0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f396860> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f29b0> 3.1249999999999964 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e69e8> 8.333333333333325 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e6b00> 9.37499999999999 7
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 18.749999999999968 16
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 19.791666666666632 17
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 26.041666666666618 23
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 27.083333333333282 24
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 28.124999999999947 32
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 28.124999999999947 37
Completed Iteration #4
Best Reward: 2.083333333333332
Completed Iteration #5
Best Reward: 2.083333333333332
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f396c88> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e69e8> 9.37499999999999 7
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e6b00> 10.416666666666654 8
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 19.791666666666632 17
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 20.833333333333297 18
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 27.083333333333282 24
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 28.124999999999947 25
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 29.16666666666661 33
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 29.16666666666661 38
Completed Iteration #6
Best Reward: 2.083333333333332
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3a0080> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e69e8> 10.416666666666654 8
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e6b00> 11.458333333333318 9
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 20.833333333333297 18
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 21.87499999999996 19
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 28.124999999999947 25
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 29.16666666666661 26
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 30.208333333333275 34
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 30.208333333333275 39
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607898> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3de0b8> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3de9b0> 6.249999999999993 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e69e8> 11.458333333333318 9
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e6b00> 12.499999999999982 10
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 21.87499999999996 19
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 22.916666666666625 20
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 29.16666666666661 26
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 30.208333333333275 27
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 31.24999999999994 35
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 31.24999999999994 40
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Completed Iteration #17
Best Reward: 2.083333333333332
Completed Iteration #18
Best Reward: 2.083333333333332
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d7f635ba8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f26d8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f2fd0> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f396860> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f29b0> 5.208333333333329 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e69e8> 13.54166666666665 10
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e6b00> 14.583333333333314 11
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 23.958333333333293 20
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 24.999999999999957 21
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 31.249999999999943 27
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 32.29166666666661 28
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 33.33333333333327 36
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 33.33333333333327 41
Completed Iteration #22
Best Reward: 2.083333333333332
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f396518> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e69e8> 14.583333333333314 11
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e6b00> 15.624999999999979 12
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 24.999999999999957 21
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 26.04166666666662 22
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 32.29166666666661 28
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 33.33333333333327 29
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 34.374999999999936 37
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 34.374999999999936 42
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #6
root->2->7->0->2->0->9
Best Reward: 2.083333333333332
coverage_call_count 7600
Completed Iteration #0
Best Reward: 2.083333333333332
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Completed Iteration #3
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f2208> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3a05f8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f635ba8> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f26d8> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f2fd0> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f396860> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f29b0> 7.291666666666661 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e69e8> 16.666666666666647 12
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e6b00> 17.70833333333331 13
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 27.08333333333329 22
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 28.124999999999954 23
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 34.37499999999994 29
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 35.4166666666666 30
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 36.45833333333327 38
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 36.45833333333327 43
Completed Iteration #4
Best Reward: 2.083333333333332
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3b9d30> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3b9da0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3963c8> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f396438> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f63c860> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607b38> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3de9b0> 8.333333333333325 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e69e8> 18.74999999999998 13
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e6b00> 19.791666666666643 14
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 29.16666666666662 23
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 30.208333333333286 24
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 36.45833333333327 30
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 37.49999999999993 31
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 38.5416666666666 39
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 38.5416666666666 44
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3466a0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f26d8> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f2fd0> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f396860> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f29b0> 9.374999999999993 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e69e8> 20.83333333333331 14
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e6b00> 21.874999999999975 15
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 31.249999999999954 24
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 32.291666666666615 25
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 38.5416666666666 31
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 39.58333333333326 32
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 40.62499999999993 40
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 40.62499999999993 45
Completed Iteration #16
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666978> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f396860> 10.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f29b0> 11.458333333333325 7
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e69e8> 22.916666666666643 15
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e6b00> 23.958333333333307 16
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 33.333333333333286 25
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 34.37499999999994 26
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 40.62499999999993 32
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 41.666666666666586 33
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 42.70833333333326 41
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 42.70833333333326 46
Completed Iteration #17
Best Reward: 2.083333333333332
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f635278> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f63cf28> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f396518> 2.0833333333333286 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e69e8> 23.958333333333307 16
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e6b00> 24.99999999999997 17
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 34.37499999999995 26
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 35.41666666666661 27
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 41.66666666666659 33
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 42.70833333333325 34
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 43.74999999999992 42
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 43.74999999999992 47
Completed Iteration #18
Best Reward: 2.083333333333332
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f2ac8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3965c0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666978> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f396860> 12.499999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f29b0> 13.541666666666657 8
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e69e8> 26.04166666666664 17
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e6b00> 27.083333333333304 18
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 36.458333333333286 27
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 37.49999999999994 28
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 43.74999999999993 34
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 44.791666666666586 35
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 45.83333333333326 43
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 45.83333333333326 48
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3a0358> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607b38> 7.291666666666661 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3de9b0> 9.37499999999999 7
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e69e8> 27.083333333333304 18
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e6b00> 28.124999999999968 19
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 37.49999999999995 28
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 38.54166666666661 29
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 44.79166666666659 35
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 45.83333333333325 36
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 46.87499999999992 44
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 46.87499999999992 49
Completed Iteration #23
Best Reward: 2.083333333333332
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #7
root->2->7->0->2->0->9->2
Best Reward: 2.083333333333332
Completed Iteration #0
Best Reward: 2.083333333333332
Completed Iteration #1
Best Reward: 2.083333333333332
Completed Iteration #2
Best Reward: 2.083333333333332
Reward: 1.0416666666666643
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3460b8> 1.0416666666666643 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f396860> 13.541666666666657 8
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f29b0> 14.583333333333321 9
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e69e8> 28.124999999999968 19
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e6b00> 29.166666666666632 20
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 38.541666666666615 29
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 39.58333333333327 30
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 45.83333333333326 36
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 46.874999999999915 37
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 47.916666666666586 45
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 47.916666666666586 50
Completed Iteration #3
Best Reward: 2.083333333333332
Completed Iteration #4
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346be0> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346c50> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f2208> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3a05f8> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f635ba8> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f26d8> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f2fd0> 10.41666666666666 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f396860> 15.62499999999999 9
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f29b0> 16.666666666666654 10
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e69e8> 30.2083333333333 20
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e6b00> 31.249999999999964 21
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 40.62499999999994 30
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 41.6666666666666 31
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 47.916666666666586 37
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 48.95833333333324 38
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 49.999999999999915 46
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 49.999999999999915 51
Completed Iteration #5
Best Reward: 2.083333333333332
Completed Iteration #6
Best Reward: 2.083333333333332
Completed Iteration #7
Best Reward: 2.083333333333332
Completed Iteration #8
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3966d8> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f35c198> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f2ac8> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3965c0> 4.166666666666664 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666978> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f396860> 17.70833333333332 10
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f29b0> 18.749999999999986 11
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e69e8> 32.29166666666663 21
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e6b00> 33.3333333333333 22
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 42.70833333333327 31
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 43.74999999999993 32
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 49.999999999999915 38
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 51.04166666666657 39
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 52.08333333333324 47
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 52.08333333333324 52
Completed Iteration #9
Best Reward: 2.083333333333332
Completed Iteration #10
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6f2710> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f35cd68> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f2fd0> 12.499999999999993 7
backprop <src.mcts.MCTS_Node object at 0x7f1d7f396860> 19.791666666666654 11
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f29b0> 20.833333333333318 12
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e69e8> 34.37499999999996 22
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e6b00> 35.41666666666663 23
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 44.7916666666666 32
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 45.83333333333326 33
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 52.08333333333324 39
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 53.1249999999999 40
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 54.16666666666657 48
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 54.16666666666657 53
Completed Iteration #11
Best Reward: 2.083333333333332
Completed Iteration #12
Best Reward: 2.083333333333332
Completed Iteration #13
Best Reward: 2.083333333333332
Completed Iteration #14
Best Reward: 2.083333333333332
Completed Iteration #15
Best Reward: 2.083333333333332
Completed Iteration #16
Best Reward: 2.083333333333332
Completed Iteration #17
Best Reward: 2.083333333333332
Completed Iteration #18
Best Reward: 2.083333333333332
Completed Iteration #19
Best Reward: 2.083333333333332
Completed Iteration #20
Best Reward: 2.083333333333332
Completed Iteration #21
Best Reward: 2.083333333333332
Completed Iteration #22
Best Reward: 2.083333333333332
Completed Iteration #23
Best Reward: 2.083333333333332
Reward: 2.083333333333332
backprop <src.mcts.MCTS_Node object at 0x7f1d7f35c940> 2.083333333333332 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3965c0> 6.2499999999999964 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666978> 8.333333333333329 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f396860> 21.874999999999986 12
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f29b0> 22.91666666666665 13
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e69e8> 36.458333333333286 23
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3e6b00> 37.49999999999996 24
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607128> 46.87499999999993 33
backprop <src.mcts.MCTS_Node object at 0x7f1d7f666f60> 47.916666666666586 34
backprop <src.mcts.MCTS_Node object at 0x7f1d84c36128> 54.16666666666657 40
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6597f0> 55.20833333333323 41
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6476a0> 56.2499999999999 49
backprop <src.mcts.MCTS_Node object at 0x7f1d7f6bbc88> 56.2499999999999 54
Completed Iteration #24
Best Reward: 2.083333333333332
Completed Iteration #25
Best Reward: 2.083333333333332
Completed MCTS Level/Depth: #8
root->2->7->0->2->0->9->2->1
Best Reward: 2.083333333333332
iteration: 233
found coverage increase 2.083333333333332
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346668> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346668> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346668> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f35cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346668> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346668> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346668> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f30c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346668> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f30c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346668> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f30c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346668> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f30c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346668> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f30c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37ca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346668> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f30c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346668> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f30cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346668> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f30cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346668> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f30cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f30cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f30c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37ca20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346668> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f31a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f30c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346668> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f30c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37ca20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346668> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f30cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346668> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f31a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346668> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3f2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f63c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3a0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f35c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f396940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f35cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f35cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f63c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3a0f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607588> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f35ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f63c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607588> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3b9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f35c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607588> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f396208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607588> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f396208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607588> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f63c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607588> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f30c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f396940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607588> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f35c7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607588> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f35ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3b9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607588> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f30c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607588> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f30c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607588> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3b9a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607588> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f30cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607588> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 7700
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f346898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3b9a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607588> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f63c438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f607588> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f31a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c2e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f31a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c2e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f31a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c2e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f30c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c2e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f31a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c2e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f31a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f31a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c2e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f31aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f31aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c2e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f31afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f31ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c2e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f31af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c2e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f30cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f31a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c2e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f31a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f31a470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c2e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f31a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c2e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f30cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f31aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c2e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f30ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c2e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f3a0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c2e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f63c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f31aa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c2e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f31a470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c2e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f31a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f31ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c2e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f647400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f35ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2518> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2db128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2db160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2518> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2db6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2518> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2db358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2518> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f31a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2518> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2db9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2518> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2dbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2db358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2518> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2dbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c26d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2518> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2dbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c28d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2518> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2dbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c26d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2518> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2db358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2518> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2518> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2518> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2518> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 237
found coverage increase 0
Current Total Coverage 31.25
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2dbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2db940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2fc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8b00> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2fc390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2db940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8b00> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2fc438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2fc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8b00> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f37c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f396908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8b00> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2c2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2db940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8b00> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2fc400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8b00> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2fc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8b00> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2db2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8b00> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8b00> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2fc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8b00> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2fcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8b00> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2fce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2dba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8b00> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f297160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8b00> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2fc6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f396908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8b00> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2fc978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7f1d7f2e8b00> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 238
found coverage increase 0
Current Total Coverage 31.25
initial coverage: 5.20833
time passed (minutes): 60.3907
iterations: 239
number of new inputs: 512
final coverage: 31.25
total coverage increase: 26.0417
