Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='nbc', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet4', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet4', 'mcts', 'nbc'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7fbee03eef28>, tc2=<function tc2 at 0x7fbee03ff048>, tc3=<function tc3 at 0x7fbee03ff158>, tfc_threshold=169, time_period=3600, verbose=True)
initial coverage: 13.3803
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645908> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645908> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645908> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7814e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645908> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645908> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645908> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645908> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645908> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645908> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645908> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645908> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645908> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645908> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645908> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645908> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645908> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645908> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaba8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645908> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dc18> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6457b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dc18> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dc18> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dc18> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dc18> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6457b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dc18> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dc18> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dc18> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dc18> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6457b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dc18> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dc18> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dc18> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6457b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dc18> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dc18> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dc18> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dc18> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dc18> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dc18> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dc18> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f550> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f550> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f550> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f550> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f550> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f550> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f550> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f550> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f550> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f550> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f550> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f550> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f550> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7814a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f550> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f550> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f550> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abd30> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abd30> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abd30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abd30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abd30> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abd30> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ead30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abd30> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abd30> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abd30> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abd30> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abd30> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ead30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abd30> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abd30> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abd30> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abd30> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abd30> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ead30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abd30> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c18> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7040f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7045c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c18> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c18> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c18> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c18> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c18> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c18> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c18> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c18> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c18> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c18> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c18> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c18> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7232e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c18> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723710> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723710> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723710> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723710> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7364e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723710> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723710> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723710> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7366a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723710> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7369e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723710> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7369e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723710> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723710> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7364e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723710> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723710> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723710> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723710> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723710> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723710> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7364e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723710> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7230f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7368d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7237f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7368d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7048d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7368d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7040f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7368d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7368d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7040f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7368d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7365f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7368d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7365f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7368d0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7368d0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7368d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7368d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7368d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7368d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7368d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7368d0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7763c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7365f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7368d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7365f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7368d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7368d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7368d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7368d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7764e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7763c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7365f8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7368d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea588> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea588> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea588> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea588> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7760b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea588> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea588> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea588> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eabe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea588> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea588> 0.0 12
Completed Iteration #15
Best Reward: 0
coverage_call_count 200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea588> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea588> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea588> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e27b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea588> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7816d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea588> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7816d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea588> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7760b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea588> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb748> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb748> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb748> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb748> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb748> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb748> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb748> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb748> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb748> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb748> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebeb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb748> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb748> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb748> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695c88> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695c88> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695c88> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695c88> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e24e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695c88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695c88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695c88> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695c88> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695c88> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695c88> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695c88> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e24e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695c88> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695c88> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695c88> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695c88> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695c88> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695c88> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695c88> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e24e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695c88> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea550> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea550> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea550> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea550> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea550> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea550> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea550> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea550> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea550> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea550> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea550> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea550> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea550> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea550> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776080> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6845c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776080> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776080> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776080> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776080> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776080> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6956d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776080> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6952b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776080> 0.0 10
Completed Iteration #12
Best Reward: 0
coverage_call_count 300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776080> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776080> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6aba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7366d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776080> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6956d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776080> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6846a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776080> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776080> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6956d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776080> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7366d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776080> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6846a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776080> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6715c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6717f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6717f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a20> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a20> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a20> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a20> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a20> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6712e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a20> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6714a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a20> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6717f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a20> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a20> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a20> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a20> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a20> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6957b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6958d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6958d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671ac8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671ac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671ac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671ac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671ac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671ac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671ac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671ac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671ac8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6840b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671ac8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671ac8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671ac8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671ac8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6958d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671ac8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671ac8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaef0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6952b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaef0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaef0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7230f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd14a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaef0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaef0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaef0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd14a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaef0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaef0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaef0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaef0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaef0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abe10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b00> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b00> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b00> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b00> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af856a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b00> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b00> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b00> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b00> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b00> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b00> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b00> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6616d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b00> 0.0 18
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b00> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b00> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b00> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b00> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af954a8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af954a8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af954a8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af954a8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af954a8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af954a8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af853c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af954a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af954a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af954a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff38d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af954a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af954a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af954a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af957b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af954a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af954a8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af954a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af954a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af855f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af954a8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af954a8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95080> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95080> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95080> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95080> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95080> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95080> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95080> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af955f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95080> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95080> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95080> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95080> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95080> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95080> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95080> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95080> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6955c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6957b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7230f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6957b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6957b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6957b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6616d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6957b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6616d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6957b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6957b8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6957b8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6957b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6957b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6957b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6616d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6957b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6957b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6957b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6957b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6955c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6957b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af622e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6957b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af625f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6957b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6957b8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6955c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6957b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af951d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af629b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 500
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695dd8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695dd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695dd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af762e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af626a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695dd8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695dd8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af764e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695dd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695dd8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695dd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695dd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695dd8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af092e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695dd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695dd8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62b00> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695dd8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af096d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09860> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af192b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09860> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af098d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09860> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09860> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09860> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6455f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09860> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af192b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09860> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbf0791c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09860> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09860> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeae8b0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af096d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09860> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbefa89aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09860> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbefa8a0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af096d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09860> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c7327b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af192b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09860> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09860> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af766d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09860> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c71ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5f60> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5f60> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5f60> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5f60> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5f60> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5f60> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5f60> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5f60> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5f60> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5f60> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5f60> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5f60> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5f60> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abb38> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abb38> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abb38> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abb38> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeae94c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abb38> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abb38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abb38> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6aba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abb38> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abb38> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abb38> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abb38> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbefa89aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abb38> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abb38> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abb38> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abb38> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeae91e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abb38> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeac5ee6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbeac5ee7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df438> 0.0 2
Completed Iteration #1
Best Reward: 0
coverage_call_count 600
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeac5eea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbeac5eed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df438> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df438> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df438> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbeac5eed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df438> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbeac5ee7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df438> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbeac5ee7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df438> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df438> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbeac5ee9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df438> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7362b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df438> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df438> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbeac5ee6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbeac5ee7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df438> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df438> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df438> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbeac5ee7b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df438> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df438> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbeae94c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b50f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbeae94c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b50f0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b50f0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b50f0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c71eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b50f0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af092b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b50f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b50f0> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af092b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b50f0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b50f0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b50f0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b50f0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b50f0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af092b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b50f0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c71eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b50f0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b50f0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b58d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b58d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeac5ee6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b58d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbeac5eecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b58d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b58d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbeac5eecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b58d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b58d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b58d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b58d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b58d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b58d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7762e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbeac5eecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b58d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7763c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b58d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeac5ee630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b58d0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b58d0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b58d0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfc50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfc50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7aba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfc50> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfc50> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfc50> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfc50> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfc50> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfc50> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af624e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfc50> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfc50> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfc50> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfc50> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfc50> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7364e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfc50> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfc50> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5ef0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfc50> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfc50> 0.0 19
Completed Iteration #23
Best Reward: 0
coverage_call_count 700
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c71ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ff28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ff28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7236d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ff28> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ff28> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ff28> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ff28> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ff28> 0.0 8
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7765f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ff28> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ff28> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ff28> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ff28> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeac5ee630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ff28> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbefa89aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fe10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ff28> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ff28> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fe10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ff28> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b57f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b57f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6844e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b57f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b57f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b57f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7813c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b57f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7819b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b57f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b57f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b57f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7814a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b57f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b57f0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7369e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b57f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b57f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b57f0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b57f0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b57f0> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b57f0> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b57f0> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b57f0> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b57f0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b57f0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b57f0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6710f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6719e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6719e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7044e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6719e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6719e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6719e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6719e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6719e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6719e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6719e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6719e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6719e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6719e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6719e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6719e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6719e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6719e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6719e8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6719e8> 0.0 19
Completed Iteration #20
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6954a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6719e8> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6719e8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6719e8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbeac5eecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6719e8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704b38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704b38> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e26d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704b38> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7043c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704b38> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704b38> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704b38> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704b38> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704b38> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704b38> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704b38> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704b38> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704b38> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704b38> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6714e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6710b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6710b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6710b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6710b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6716d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6710b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6710b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbeac5ee860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6710b8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbeac5ee860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6710b8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6710b8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6710b8> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6710b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6710b8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6710b8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e21d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6710b8> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e21d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6710b8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6710b8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6716d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6710b8> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6710b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaff60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6710b8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6710b8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6716d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6710b8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af763c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76128> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76128> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76128> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76128> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76128> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7365f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76128> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76128> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76128> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76128> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76128> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af763c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76128> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af954a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76128> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af763c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76128> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76128> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af955c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95908> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95908> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95908> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af852e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95908> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95908> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95908> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af953c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95908> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95908> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95908> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95908> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af955c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95908> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af955c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95908> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af953c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95908> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af955c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95908> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95908> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dd30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dd30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dd30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dd30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dd30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dd30> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dd30> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af952b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dd30> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dd30> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dd30> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dd30> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbefa89aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af954e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dd30> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dd30> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dd30> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dd30> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dd30> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af854e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dd30> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebe10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dd30> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b38> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7046d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b38> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b38> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79da58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b38> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b38> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79da58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b38> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b38> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff36a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b38> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b38> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b38> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b38> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af197b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af196a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af198d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19208> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19208> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19208> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af198d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19208> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19208> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19208> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19208> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19208> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19208> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19208> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af196a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19208> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19208> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19208> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af198d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19208> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19208> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcc88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcc88> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcc88> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcc88> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcc88> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcc88> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcc88> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcc88> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcc88> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcc88> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcc88> 0.0 13
Completed Iteration #15
Best Reward: 0
coverage_call_count 1000
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcc88> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcc88> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcc88> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcc88> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcc88> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcc88> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcc88> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19be0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19be0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19be0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19be0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19be0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19be0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19be0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19be0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19be0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af199b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19be0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19be0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19be0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19be0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19be0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19be0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19be0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19be0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafa90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafa90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafa90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafa90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafa90> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafa90> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7237b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafa90> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafa90> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafa90> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafa90> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafa90> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280abba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafa90> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280abfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7360b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafa90> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafa90> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafa90> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafa90> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e21d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e21d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af952b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e21d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280abb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e21d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e21d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e21d0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e21d0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e21d0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e21d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e21d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff34e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e21d0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e21d0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e21d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e21d0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e21d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e21d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff34e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e21d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e21d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f60> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280736a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f60> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280736a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f60> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f60> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280734a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f60> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f60> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f60> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f60> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f60> 0.0 13
Completed Iteration #13
Best Reward: 0
coverage_call_count 1100
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f60> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f60> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f60> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f60> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280734e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f60> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280736d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f60> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f60> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280736d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f60> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280abb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280aba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28073128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280abfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073128> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073128> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280abc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073128> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28073128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28073128> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28073128> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280abc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28073128> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280abbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073128> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280abc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28073128> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280abb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28073128> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe28073128> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe28073128> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28073128> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d748> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fbe28073128> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c18> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280849b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c18> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeac5eecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c18> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280739e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c18> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c18> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c18> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c18> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c18> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280849b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c18> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c18> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280375c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c18> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037cf8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037cf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037cf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037cf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037cf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28037cf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037cf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe140502b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28037cf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140505f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037cf8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037cf8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037cf8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037cf8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe140501d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28037cf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe140504e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037cf8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037cf8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140500b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140507b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140507b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140500b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037748> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbefa89aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037748> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037748> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037748> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037748> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037748> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28037748> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037748> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe28037748> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037748> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037748> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28037748> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28037748> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbefa89aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037748> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cf98> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280730f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cf98> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cf98> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cf98> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cf98> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cf98> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cf98> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cf98> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cf98> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cf98> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cf98> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cf98> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cf98> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cf98> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cf98> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e320> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e320> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e320> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e320> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e320> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e320> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e320> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e320> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e320> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e320> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e320> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e320> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e320> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e320> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6955c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e320> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084898> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084898> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084898> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084898> 0.0 5
Completed Iteration #7
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28084898> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084898> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084898> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28084898> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084898> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28084898> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe140509b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28084898> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28084898> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dfd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe28084898> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28084898> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28084898> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084898> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28084898> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28084898> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dfd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe28084898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f198> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f198> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f198> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f198> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f198> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f198> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f198> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f198> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f198> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f198> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee480f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f198> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f198> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f198> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f198> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f198> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee483c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f198> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f198> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d1d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d1d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d1d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d1d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d1d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d1d0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d1d0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d1d0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d1d0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d1d0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d1d0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d1d0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe041310b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d1d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d4a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d1d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d1d0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48160> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48160> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe041312e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48160> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe041315f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48160> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48160> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48160> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe041312e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48160> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48160> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48160> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48160> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48160> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48160> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48160> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe041312e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48160> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe041312e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48160> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d240> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 1400
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee487f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d240> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d240> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d240> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d240> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d240> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d240> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d240> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d240> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d240> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140504a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d240> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d240> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d240> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d240> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d240> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f6a0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d240> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f668> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f668> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f668> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f668> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f668> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f668> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f668> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f668> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f668> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f668> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f668> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f668> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040eae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f668> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040eaa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f668> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f668> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa470> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa470> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040faf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa470> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ead68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa470> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe041086a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa470> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa470> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa470> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa470> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe041082b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa470> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040faba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa470> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe041084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa470> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108cf8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108cf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108cf8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108cf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108cf8> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108cf8> 0.0 7
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280abb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108cf8> 0.0 8
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108cf8> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04108cf8> 0.0 10
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04108cf8> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04108cf8> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04108cf8> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108cf8> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04108cf8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fa20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fa20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fa20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fa20> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fa20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fa20> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fa20> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe041085f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fa20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe041084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fa20> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fa20> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fa20> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fa20> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fa20> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee487f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fa20> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee487f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fa20> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fa20> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fa20> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d978> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d978> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d978> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d978> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d978> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d978> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d978> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d978> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d978> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d978> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040555c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d978> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d978> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040553c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d978> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d978> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040647b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040646a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055e48> 0.0 2
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055e48> 0.0 3
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055e48> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04055e48> 0.0 5
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040642b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055e48> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040762e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055e48> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe041318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055e48> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04055e48> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04055e48> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055e48> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe04055e48> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040642b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04055e48> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04055e48> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055e48> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040642e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe04055e48> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040642b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe04055e48> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040761d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04055e48> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af197f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04055320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040552e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040552e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04055320> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04055320> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040552e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe04055320> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04055320> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe04055320> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040550f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04055320> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055320> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055320> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040645c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055320> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe04055320> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04055320> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeac5eed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04055320> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeac5ee710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe04055320> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280373c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c97b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04055320> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeac5ee8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037da0> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040640f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280374a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28037da0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040556d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037da0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037da0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037da0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037da0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037da0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037da0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28037da0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28037da0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe28037da0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037da0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe28037da0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fa90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fa90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fa90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fa90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fa90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6615c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fa90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fa90> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fa90> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fa90> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fa90> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fa90> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fa90> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fa90> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fa90> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fa90> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fa90> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280844e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d898> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280844e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280734e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d898> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d898> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d898> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d898> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe280844e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d898> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280abb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280734e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d898> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d898> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d898> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d898> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d898> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d898> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d898> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280abef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d898> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d898> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d898> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d898> 0.0 24
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d898> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805df98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805df98> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6615c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805df98> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeac5ee860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6614a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805df98> 0.0 5
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805df98> 0.0 6
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805df98> 0.0 7
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805df98> 0.0 8
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805df98> 0.0 9
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6614a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805df98> 0.0 10
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805df98> 0.0 11
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280374e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6615c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805df98> 0.0 12
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280374a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805df98> 0.0 13
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055978> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055978> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055978> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055978> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040649e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055978> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04055978> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055978> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04055978> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04055978> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04055978> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe04055978> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055978> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04055978> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe04055978> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040649e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04055978> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04055978> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc6a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7360b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc6a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc6a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc6a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc6a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc6a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc6a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc6a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6611d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc6a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc6a0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc6a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc6a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc6a0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc6a0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc6a0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc6a0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79df98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79df98> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79df98> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af855c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79df98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79df98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af952e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79df60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79df98> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79df98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79df98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79df98> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af850b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79df98> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79df98> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af952b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79df98> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af856d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79df98> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79df60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79df98> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79df98> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af855c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79df98> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af855c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79df98> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79df98> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79df98> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af856d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79df98> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af854e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af953c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85278> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85278> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040649e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85278> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85278> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85278> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85278> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85278> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85278> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85278> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280374e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85278> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85278> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85278> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85278> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85278> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280733c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85278> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 13.380281690140844
coverage_call_count 1800
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280738d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671cf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af620f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af624a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723ba8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723ba8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723ba8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723ba8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723ba8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723ba8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6951d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723ba8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723ba8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723ba8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723ba8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7239e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723320> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723ba8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723ba8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723320> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723ba8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723ba8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723ba8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723320> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723ba8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723ba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723ba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805de80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805de80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805de80> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeac5ee860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805de80> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805de80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280738d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6611d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805de80> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805de80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805de80> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805de80> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2805de80> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2805de80> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671cf8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe2805de80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805de80> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805de80> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671cf8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fbe2805de80> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805de80> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671cf8> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7fbe2805de80> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af624a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af624a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af622b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af624a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af624a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af624a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af624a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af622b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af624a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af624a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af624a8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af622b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af624a8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af854e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af624a8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af624a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af624a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2af624a8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe2af624a8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af624a8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af624a8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af624a8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af624a8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c71eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeac57c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbefa89add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbefa89a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af629b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbefa89add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbefa89aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f710> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f710> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f710> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f710> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f710> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f710> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ffd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f710> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f710> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f710> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f710> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7043c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f710> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f710> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7812e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af191d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7812e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7812e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbf0791c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7812e8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeac5ee860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7812e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7812e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7812e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7812e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7812e8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6457b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7812e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7812e8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7812e8> 0.0 13
Completed Iteration #19
Best Reward: 0
coverage_call_count 2000
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7812e8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af763c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7812e8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7812e8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7812e8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbefa8a0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af094a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d128> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d128> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d128> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d128> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d128> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d128> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d128> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d128> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af094a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d128> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d128> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d128> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af766d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d128> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe140504a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d128> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe140507b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d128> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d128> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d128> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d128> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe140509b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09668> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09668> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09668> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09668> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09668> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe041086a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09668> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09668> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe041082b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09668> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09668> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeae8b0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09668> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09668> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe041086d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe041082b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09668> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbefa8a0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09668> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09668> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09668> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09668> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09668> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09668> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09668> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af092e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9198> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09668> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe140502b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe041084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeac5ee860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af769b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb550> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb550> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb550> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7362b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb550> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb550> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb550> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb550> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb550> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb550> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7362b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb550> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280abe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb550> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7362b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb550> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb550> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb550> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f6d8> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f6d8> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f6d8> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe140502e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f6d8> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f6d8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f6d8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280735c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f6d8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f6d8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f6d8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f6d8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f6d8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f6d8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f6d8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f6d8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040eaa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f6d8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f6d8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040eafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040eaf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1668> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040eaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1668> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1668> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1668> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1668> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040eaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1668> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040eaf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1668> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ead30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1668> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040eaf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1668> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040eaf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1668> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1668> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1668> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1668> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1668> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1668> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ead30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1668> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1668> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd15f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd15f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040eae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd15f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd15f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd15f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd15f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd15f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd15f8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd15f8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd15f8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd15f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe041084e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd15f8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd15f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd15f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd15f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd15f8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd15f8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd15f8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd15f8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd15f8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410de80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd15f8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe140502e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f98> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f98> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f98> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f98> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f98> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f98> 0.0 15
Completed Iteration #16
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f98> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f98> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f98> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f98> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f98> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f98> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f9b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f9b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe041310f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f9b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f9b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe041310f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f9b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f9b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f9b0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f9b0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe041318d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f9b0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f9b0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f9b0> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f9b0> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f9b0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee485f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa58> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa58> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040faeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa58> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa58> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa58> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa58> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa58> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa58> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa58> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa58> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe041316a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa58> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa58> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c50> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c50> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040768d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c50> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040768d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c50> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c50> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c50> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c50> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c50> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c50> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c50> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c50> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c50> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678beb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde678beb8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678beb8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678beb8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678beb8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678beb8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678beb8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04076c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678beb8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde678beb8> 0.0 10
Completed Iteration #13
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678bf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678beb8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678beb8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678bac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde678beb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde678beb8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04076c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde678beb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678bd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde678beb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde678beb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde678beb8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67996d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde678beb8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde678beb8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b77b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b77b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b77b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67b77b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b77b8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b77b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67b77b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b77b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde67b77b8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b77b8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67b77b8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67b77b8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67469e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67468d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6799eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67b77b8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde67b77b8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b77b8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b73c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde67b77b8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b77b8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbf0791c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67b77b8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde67b77b8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67b77b8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67997b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799780> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799780> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67997b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6799780> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799780> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799780> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6799780> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799780> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6799780> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67990b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799780> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280733c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67990b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6799780> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799780> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6799780> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678b898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6799780> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67997b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6799780> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678bc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6799780> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678b898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6799780> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67990b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6799780> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6799780> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04076908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67790f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67795c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67795c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67795c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67795c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678be80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67795c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67795c0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67795c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67795c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67795c0> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67795c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67795c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670e470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde67795c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67795c0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67795c0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670e240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67795c0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67795c0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671ec50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671ec50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671ec50> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671ec50> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671ec50> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671ec50> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671ec50> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde671ec50> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde671ec50> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde671ec50> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde671ec50> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671ec50> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde671ec50> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde671ec50> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670e390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde671ec50> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde671ec50> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779cc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779cc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6779cc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6779cc0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6779cc0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280733c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6779cc0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6779cc0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6779cc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779cc0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeae8c8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6779cc0> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde6779cc0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779cc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6779cc0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6779cc0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6779cc0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6779cc0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678b898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678b898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678b898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678b898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde678b898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678b898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04076b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678b898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde678b898> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67996d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678b898> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670e198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde678b898> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67324a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678b898> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde678b898> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde678b898> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde678b898> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67324a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde678b898> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67324a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde678b898> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67324a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde678b898> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde678b898> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b76d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde678b898> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbde678b898> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9a90> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67320f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9a90> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9a90> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e96a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9a90> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9a90> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9a90> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66faef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9a90> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9a90> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66faef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9a90> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6732be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6732be0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde6732be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732be0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67326d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732be0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732be0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6732be0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67326d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6732be0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040761d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6732be0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732be0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670ee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6732be0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67799b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6732be0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6732be0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732be0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040761d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6732be0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6732be0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6732be0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67326d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6732be0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66faeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e92e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e92e8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e92e8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e92e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66e92e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66e92e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66e92e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e92e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66e92e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e92e8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66e92e8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e92e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668a5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66e92e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66e92e8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66e92e8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66e92e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e92e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66e92e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b89b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b89b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b89b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b89b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b89b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b89b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b89b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66b89b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde66b89b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b89b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b85c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b89b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b89b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbde66b89b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668aa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66b89b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b89b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665a278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b89b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b89b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66b89b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668aa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde66b89b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b89b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6746a20> 0.0 6
Completed Iteration #4
Best Reward: 0
coverage_call_count 2600
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6746a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746a20> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6676320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746a20> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6746a20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6676320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6746a20> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6746a20> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6746a20> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746a20> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6676320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6746a20> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6746a20> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6746a20> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde6746a20> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66486a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66487b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6746a20> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746a20> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6746a20> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8438> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8438> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b84e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8438> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8438> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8438> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8438> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8438> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8438> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8438> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8438> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8438> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8438> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8438> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8438> 0.0 19
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b84e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8438> 0.0 20
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8438> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8438> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8438> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67990b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8438> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671eeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671eeb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671eeb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671eeb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671eeb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde671eeb8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6676630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671eeb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6676630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde671eeb8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671eeb8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6676780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671eeb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6676780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde671eeb8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6676630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde671eeb8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde671eeb8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde671eeb8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde671eeb8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde671eeb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671eeb8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde671eeb8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6676780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde671eeb8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6676780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde671eeb8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6676cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5581358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55811d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5581748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55814e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5581400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5581198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5581d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5590358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55903c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590630> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 2700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5590748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5590c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590630> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5581dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5590630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55814a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5590630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55903c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5590630> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5581c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde5590630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5590c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55812b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590630> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590630> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55900b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590630> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5581390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590630> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55816a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590630> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5590630> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5590630> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55900b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5590630> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67326d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde5590630> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55907b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55812b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5590630> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55810f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55900b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde5590630> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55900b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde5590630> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5581780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55903c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde5590630> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6676f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779630> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5590048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779630> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779630> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779630> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6779630> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779630> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5590390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67799e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6779630> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779630> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6779630> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6779630> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66facf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6779630> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde6779630> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6779630> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6779630> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6779630> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6676198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779630> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66484a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66484a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66484a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66484a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66484a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66484a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66484a8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66484a8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66484a8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66484a8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66484a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b82e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66484a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66484a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66faeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66484a8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66484a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66484a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66484a8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558588> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5566048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5558588> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558588> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55662e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5558588> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5566828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5566710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558588> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55664e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558588> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5566978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55664e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5558588> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5566cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558588> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5566208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde5558588> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5566eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5566710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5558588> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558588> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde5558588> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5558588> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5566630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5566cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5558588> 0.0 17
Completed Iteration #22
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5566860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde5558588> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5566cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde5558588> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1198> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5566940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1198> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55668d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55660f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1198> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55667f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1198> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5566898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55660f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1198> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55663c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5566eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1198> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5566358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1198> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5566b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1198> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5566a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5566320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1198> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55589e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55667f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1198> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1198> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55589b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1198> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1198> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55667f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1198> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55662b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55667f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1198> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5566320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1198> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1198> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55667f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1198> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1d30> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1d30> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1d30> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1d30> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1d30> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1d30> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1d30> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1d30> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1d30> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1d30> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1d30> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1d30> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1d30> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5566dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1d30> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55581d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55581d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55581d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67329e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55581d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55581d0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55581d0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55581d0> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde55581d0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55581d0> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55581d0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55581d0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55581d0> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55581d0> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55581d0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7630> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7630> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7630> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7630> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7630> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7630> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7630> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7630> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7630> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7630> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7630> 0.0 15
Completed Iteration #19
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67b75c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7630> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7630> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7630> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b75c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7630> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799a90> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6799a90> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799a90> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6799a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67329e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6799a90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67329e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde671e198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6799a90> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799a90> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6799a90> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799a90> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6799a90> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6799a90> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67324a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6799a90> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6799a90> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde6799a90> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde6799a90> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6799a90> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6648ef0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbde6799a90> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648ef0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fbde6799a90> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5566ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55660b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee484e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee484e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55660b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe041317f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55660b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe041317f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee485f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67996a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe041317f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe041317f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5566c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67996a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe041317f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040765c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040762e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040762e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04076ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040762e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040762e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040762e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040762e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeae8b0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040769b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe040762e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe040762e8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040762e8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040762e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040762e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd19b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe040762e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe040762e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd19b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe040762e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af760b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe040762e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8ecc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe040762e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6d8080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5566630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5566630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55660b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 3000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66480b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af097f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55585f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee485f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee484e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55585f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe041310f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040762e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04076da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04076da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55585f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04076da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648a58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe041312e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648a58> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe041312e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6648a58> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648a58> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af092e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648a58> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af096d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648a58> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6648a58> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648a58> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648a58> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af094e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040766d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6648a58> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af092e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6648a58> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6648a58> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af096d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6648a58> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648a58> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040766d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6648a58> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af096d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6648a58> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbefa89aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6648a58> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe041312e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6648a58> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c71ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbefa89aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c684e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6714a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6abe48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af626a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a90> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a90> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a90> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbefa89a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a90> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbefa89aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8ee10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a90> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a90> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a90> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a90> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a90> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe140507b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a90> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a90> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a90> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a90> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a90> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8ee10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a90> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a90> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a90> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a90> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67329e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6956d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd19b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee485f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d68> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d68> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d68> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d68> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d68> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d68> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d68> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c645898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04076a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d68> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a11d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d68> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d68> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d68> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67329e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d68> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67329e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d68> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a11d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe04131d68> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723f98> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723f98> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723f98> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723f98> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723f98> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723f98> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723f98> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723f98> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723f98> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723f98> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723f98> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723f98> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723f98> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723f98> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723f98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723748> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723748> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723748> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723748> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af850b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723748> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af855c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723748> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723748> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723748> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723748> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723748> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723748> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723748> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723748> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723748> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723748> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723748> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7043c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af857f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6956a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af857f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 10
Completed Iteration #14
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6951d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af768d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040762e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc080> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc080> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55580f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbefa89abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc080> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc080> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc080> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc080> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc080> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc080> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc080> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc080> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc080> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc080> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc080> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc080> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280736d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce10> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280733c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280abb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce10> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280abd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce10> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280aba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce10> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce10> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af096d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280734a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce10> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6950f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280abb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce10> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280aba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce10> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce10> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce10> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280739b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280aba58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce10> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeac5ee710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280734a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce10> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce10> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280373c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037ef0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037ef0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037ef0> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037ef0> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040641d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280373c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037ef0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeac5ee8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037ef0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037ef0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037ef0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28037ef0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037ef0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037ef0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeac5ee7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280373c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28037ef0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28037ef0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040643c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037ef0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28037ef0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d198> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d198> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d198> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeac57c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d198> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d198> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d198> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040646d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d198> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d198> 0.0 9
Completed Iteration #12
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d198> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d198> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d198> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d198> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d198> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d198> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeae927da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d198> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d198> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040646d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d198> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d198> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d198> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c71eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d198> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af857f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fa20> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fa20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7232b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fa20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af857f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fa20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fa20> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7232b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fa20> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fa20> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fa20> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7232b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fa20> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fa20> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fa20> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fa20> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fa20> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fa20> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7232b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fa20> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fa20> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280733c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fa20> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeae9688d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c98d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c98d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040646a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67329e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c98d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2e8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2e8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2e8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2e8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2e8> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2e8> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2e8> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fd30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2e8> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2e8> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e2e8> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668a400> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668a400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668a400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668a400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde668a400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668a400> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde668a400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668a400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668a400> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde668a400> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde668a400> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67329e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668a400> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde668a400> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6951d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668a400> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde668a400> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668a208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde668a400> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af857f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665a390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde668a400> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde668a400> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c588> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c588> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c588> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c588> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1c88> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c588> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c588> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c588> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c588> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c588> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c588> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c588> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af096d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c588> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c588> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fafd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66faef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fafd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fafd0> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66fafd0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fafd0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fafd0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66faf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66fafd0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66fafd0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fafd0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fafd0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66fafd0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66fafd0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66faeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fafd0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fafd0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678b390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66fafd0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5581cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66fafd0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5581ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66fafd0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5581a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66fafd0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66fafd0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55818d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55817b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5581eb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581eb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581eb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581eb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67795f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581eb8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5581eb8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5581eb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581eb8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5581eb8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5581eb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5581eb8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde5581eb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04108da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde5581eb8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581eb8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde5581eb8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde5581eb8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af768d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581eb8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde5581eb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ccc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ccc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c71eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ccc0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ccc0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ccc0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ccc0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ccc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ccc0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ccc0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ccc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ccc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ccc0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ccc0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ccc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ccc0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ccc0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67791d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bba8> 0.0 7
Completed Iteration #7
Best Reward: 0
coverage_call_count 3500
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bba8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afd19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b85f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bba8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5581ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bba8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bba8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e89b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e81d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66760b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e81d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6676668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e81d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66767b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e89b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67465f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e81d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66767b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55905f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55905c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590710> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67460f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5590710> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590710> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590710> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55905c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5590710> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6676358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590710> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590710> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5590710> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5590710> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590710> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde5590710> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde5590710> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbde5590710> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590710> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746208> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fbde5590710> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55905c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde5590710> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8ba8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8ba8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8ba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8ba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8ba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8ba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8ba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8ba8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8ba8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67790f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8ba8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8ba8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8ba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8ba8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746828> 0.0 2
Completed Iteration #3
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746828> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746828> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746828> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5590828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6676668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746828> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5590b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746828> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6746828> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6746828> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6676e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746828> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6746828> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6746828> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6746828> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746828> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67799e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6746828> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6746828> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5590400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67799e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6746828> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde6746828> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67799e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde6746828> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6676e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6746828> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557cda0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557cda0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557cda0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557cda0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040eac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557cda0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557cda0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557cda0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557cda0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde557cda0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557cf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde557cda0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c493c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde557cda0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde557cda0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde557cda0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557cf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde557cda0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ead68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde557cda0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557c630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde557cda0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557cda0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbacc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbabe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49828> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49828> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49828> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49828> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49828> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbacc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49828> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49828> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbacc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49828> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5590390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49828> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49828> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49828> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040faeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa58> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa58> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa58> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa58> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa58> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678bb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa58> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa58> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa58> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5590400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa58> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678bb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa58> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa58> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa58> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa58> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa58> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbeac57c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa58> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa58> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678bb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa58> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbeac57c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa58> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c493c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c496a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c496a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c496a0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c496a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c496a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c079b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c496a0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c496a0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4c496a0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c074a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c496a0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c160f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c496a0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c165f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c164e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c496a0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c496a0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c079b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c496a0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c076a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c493c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c496a0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c493c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4c496a0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde4c496a0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbde4c496a0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16f98> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16f98> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c71eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c71eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16f98> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c167f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16f98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16f98> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16f98> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16f98> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c246d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16f98> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16f98> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16f98> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16f98> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16f98> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16f98> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c71eba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16f98> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c71eba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16f98> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16f98> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c167b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07f98> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c074a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07f98> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07f98> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07f98> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07f98> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07f98> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07f98> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07f98> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07f98> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c074a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07f98> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5590b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c070b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07f98> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07f98> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040eac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07f98> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07f98> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c070b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07f98> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07f98> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07828> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07828> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07828> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07828> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07828> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07828> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07828> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07828> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07828> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c498d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07828> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07828> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07828> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07828> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07828> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07828> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e32e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07828> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f28> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47f51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f28> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f28> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f28> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f28> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f28> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f28> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f28> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f28> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47f51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f28> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4784518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f28> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4784668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e34e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f28> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f28> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4784518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f28> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e39e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f28> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f28> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4784710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4784198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4784898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4784e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4784898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67799e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4784e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4784898> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4784ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4784ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4784898> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4784e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4784898> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4784898> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4784198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4784898> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4784518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4784898> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4784b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4784ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4784898> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4784898> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4784898> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4784908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4784898> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e34e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47f52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4784898> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4784898> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4784198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4784898> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e32e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e32e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e32e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d79e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e32e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e32e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e32e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e32e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e32e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e32e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c492e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e32e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e32e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c496a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde47e32e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde47e32e8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde47e32e8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e32e8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde47e32e8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e32e8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e32e8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4784320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e32e8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c492e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e32e8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e39b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e39b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c079b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4784f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f60> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a37f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f60> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f60> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f60> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f60> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f60> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f60> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f60> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4757128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c079b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f60> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47575c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47574a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f60> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4757358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f60> 0.0 17
Completed Iteration #19
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47575f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f60> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4757908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f60> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4757b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c079b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f60> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47577b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f60> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4757c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e39b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f60> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47650b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47652b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757da0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c074a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757da0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47652b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4757da0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47574e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757da0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4757eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757da0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47654e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47579e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757da0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4765588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47652b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4757da0> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4765518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4757da0> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c074a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4757da0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4765470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4757da0> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47579e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4757da0> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4765a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4757da0> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4765b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4757da0> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4765d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4757da0> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4757da0> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4765f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47652b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde4757da0> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4765f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405ff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4757da0> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4757da0> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405ff60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4757da0> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde4757da0> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4757da0> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4765a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477eb00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47656a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477eb00> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4765b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477eb00> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477eb00> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4757da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde477eb00> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47579b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477eb00> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4757240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477eb00> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde477eb00> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4765748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477eb00> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47575f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477eb00> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47575c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde477eb00> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47651d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde477eb00> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4757748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477eb00> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47570b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47651d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde477eb00> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4757400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde477eb00> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4765668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde477eb00> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde477eb00> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde477eb00> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c079b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde477eb00> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde477eb00> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5581e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4784320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16c88> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16c88> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16c88> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040eac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16c88> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16c88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16c88> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16c88> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8c88> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16c88> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16c88> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16c88> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16c88> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16c88> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16c88> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16c88> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477e358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16c88> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16c88> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730048> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730048> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47309b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730048> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5590748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730048> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4730048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730048> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730048> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730048> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4730048> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4757588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730048> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47305f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4730048> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4730048> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4730048> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 4000
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4730048> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4730048> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730048> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4730048> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4730048> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4730048> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4c88> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4c88> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46d41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4c88> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46d42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4c88> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46d45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4c88> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4c88> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4c88> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4c88> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4c88> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4c88> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4c88> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4c88> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4c88> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4c88> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4c88> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4c88> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c46a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46c46a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47307f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c46a0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47309b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040eafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c46a0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c46a0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47305c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46c46a0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46c46a0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c46a0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46c46a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c46a0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040eafd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46c46a0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47307f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46c46a0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46c46a0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c46a0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47307f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46c46a0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde46c46a0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5590518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4757198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46e66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07208> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07208> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07208> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07208> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07208> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07208> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07208> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07208> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07208> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07208> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477e518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07208> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4757630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07208> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07208> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477e518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07208> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d320> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d320> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d320> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d320> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde468d320> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d320> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46a35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d320> 0.0 8
Completed Iteration #13
Best Reward: 0
coverage_call_count 4100
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde468d320> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46b80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d320> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46b83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d320> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46b86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde468d320> 0.0 12
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8e10> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46470b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8e10> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46472e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8e10> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4647198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46472e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8e10> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46474a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8e10> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4647908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46477f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8e10> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46476a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8e10> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4647cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4647be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8e10> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46b87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8e10> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8e10> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46472e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8e10> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46b84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8e10> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46b88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46472e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8e10> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4647be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8e10> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4647e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8e10> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8e10> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4757198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4647e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8e10> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4647e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8e10> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46a35c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468dbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468dbe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468dbe0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468dc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde468dbe0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c070b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c072b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468dbe0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde468dbe0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468dbe0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46a31d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468dbe0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468dbe0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde468dbe0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde468dbe0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040eafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde468dbe0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4784c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b82b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde468dbe0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47a32b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468dbe0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47a32b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde468dbe0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468dbe0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47a32b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde468dbe0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbde468dbe0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477e518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477e518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde477e518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477e518> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4647da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4647320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477e518> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde467c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4647f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477e518> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde477e518> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46b85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477e518> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde477e518> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde477e518> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477e518> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde467c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4647048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477e518> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde477e518> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4647048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde477e518> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde467c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4647048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde477e518> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde467ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca90> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde467cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4614198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca90> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde467c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4614198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca90> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46140f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca90> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca90> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4614518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca90> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde467cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4614cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca90> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46149e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4614860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca90> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4614c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4614860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca90> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4614550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467ccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca90> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46250f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca90> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46254e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46253c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca90> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4625278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4614860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca90> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4614f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467ccf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca90> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4614ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4614a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca90> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46258d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4614a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca90> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4625048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4614cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca90> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4625a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4614860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca90> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4625e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4625a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4625e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4625eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4635358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4625e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4625748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46254e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4625e80> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46252b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4625400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4625e80> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46142b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4625f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4625e80> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4614b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4625f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4625e80> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4614ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4614dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4625e80> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4614dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4625e80> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46252e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4625e80> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe041311d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04131fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4614ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4614dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4625e80> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4625048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4625e80> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe041314e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46252e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4625e80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4625048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4625e80> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4625400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4625e80> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4625be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46252e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4625e80> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4765860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4614dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde4625e80> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4765400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4625048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4625e80> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4765c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4635358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4625e80> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4625c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4625a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4625e80> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4765828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4625400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4625e80> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4765518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765748> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4625b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765748> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765748> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765748> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4625b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4765be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4765748> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557c7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4765748> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4765748> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557c7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4765748> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4765748> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4765748> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4625b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4765be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4765748> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4765748> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4625940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4625128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765748> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280fcc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4625128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4765748> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4765438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557c4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4765748> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765748> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746630> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbaf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67465f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67469e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6746630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746630> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5590d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55905f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746630> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6746630> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbaba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746630> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746630> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55905f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6746630> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55905f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6746630> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746630> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6746630> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55905f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde6746630> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5590710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746630> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6746630> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55905f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbde6746630> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6746630> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67795c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6746630> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6746630> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe041083c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6779d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779d30> 0.0 6
Completed Iteration #7
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6779d30> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779d30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779d30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6779d30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55900f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779d30> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55901d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6779d30> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6779d30> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde6779d30> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04108eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6779d30> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6779d30> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6779d30> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe041082b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde6779d30> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04055048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779d30> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6779f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde6779d30> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b940> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b940> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678bcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b940> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b940> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b940> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67469e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b940> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b940> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b940> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b940> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b940> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde557ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b940> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47650f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55902e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b940> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590898> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b940> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4625588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b940> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b940> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665ae48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde678b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665ae48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665ae48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4765198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde665ae48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5590da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665ae48> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4625b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde665ae48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde665ae48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde665ae48> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665a5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde665ae48> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde665ae48> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665ae48> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665ae48> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde665ae48> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde665ae48> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde665ae48> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde665ae48> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280aba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab240> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280aba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280373c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab240> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040646a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbeac5ee9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeac5ee7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040649e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040649e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab240> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040643c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab240> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab240> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab240> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040641d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040643c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab240> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6617b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab240> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab240> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67464a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab240> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4625cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1403cda0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab240> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab240> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af19cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084828> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040648d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084828> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084828> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 4400
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084828> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2aff3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28084828> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084828> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084828> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084828> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28084828> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28084828> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7236a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084828> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28084828> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04064780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28084828> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c736d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28084828> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28084828> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28084828> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28037860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28084828> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7eaef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe28084828> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7abc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe28084828> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28084198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04108400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280aba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde668a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6e2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668a0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4765ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668a0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28084a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c0b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557ca90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557ca90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7815c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557ca90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557ca90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47659e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde557ca90> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde557ca90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557ca90> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde557ca90> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55902e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557ca90> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55909b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde557ca90> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4765780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde557ca90> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7362b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557ca90> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde557ca90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af857b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557ca90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde557ca90> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55906d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde557ca90> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde557ca90> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c71eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557ca90> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde557ca90> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6951d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7362b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde557ca90> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af626a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6746208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde557ca90> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af629b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af629b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af624a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af629b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af629b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af629b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af624a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af629b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af855c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af629b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af629b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af629b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af629b0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6959e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af629b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6716a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280849e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af629b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af629b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbefa89a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6959e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af629b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af629b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe2af629b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04076a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af855c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2af629b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6959e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe2af629b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afaf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbefa89ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af629b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04076320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67320f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6aba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04076320> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbeae8b0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67324a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04076320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04076320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04076320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67329e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04076320> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbefa89add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67324a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04076320> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04076320> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe04076320> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c71ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67324a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe04076320> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04076320> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04076e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04076320> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2afafbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04076320> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04131cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe04076320> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbefa89aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04076e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04076320> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04076e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04076320> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe04076320> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c671fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab8d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbe04076320> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67326d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04076320> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04076390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04076320> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbefa89a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04076e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04076320> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af09048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe04076320> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde557c588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678bfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6779a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04064940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe04055c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c661048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678bfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4765630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6eb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f588> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f588> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f588> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af764e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f588> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6951d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665a5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f588> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668aeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f588> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe04076eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f588> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f588> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe04076eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f588> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f588> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ea470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c94a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f588> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f588> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668aeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f588> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6dfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f588> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c94a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f588> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f588> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140505f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050550> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050550> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050550> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe140509b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe14050550> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe14050550> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe14050550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140505f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe14050550> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe14050550> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe14050550> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050550> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050550> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050550> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050550> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe14050550> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050550> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee48748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe14050550> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe140505f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe14050550> 0.0 19
Completed Iteration #23
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe14050550> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670e358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe14050550> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28037828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b76d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde671e198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b76d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee480f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b76d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee480f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67b76d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b76d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b76d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbf0791c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b76d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67b76d8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee480f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde67b76d8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe140509e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee480f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde67b76d8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b76d8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67b76d8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67798d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b76d8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4765ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67b76d8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee480b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67b76d8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee1fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b76d8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4765780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee480b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde67b76d8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde671e2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde67b76d8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c7ab048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040c9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde67b76d8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6617b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbae48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6b5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbae48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbae48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbae48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbae48> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbae48> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665a5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbae48> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5590518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbae48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbae48> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ebb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbae48> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbae48> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbae48> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbae48> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde670eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66487b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbae48> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4765630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbae48> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4625588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde665ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbae48> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbae48> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5590e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbae48> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbae48> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4cbae48> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e93c8> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5566f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55665f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e93c8> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5566710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55663c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e93c8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5566358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55668d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e93c8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55666a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55663c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66e93c8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55660b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e93c8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66e93c8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55665f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66e93c8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5566c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e93c8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5566c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66e93c8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55665f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66e93c8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e93c8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e93c8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e93c8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5566c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66e93c8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55668d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde66e93c8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde66e93c8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4614b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55580b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a12e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4614748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55580b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55a12e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4614940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4614c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a12e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4614550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4614518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a12e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4614198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4614518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55a12e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280732e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a12e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a12e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5566198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a12e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4614c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55a12e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a12e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46140f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55580b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55a12e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46141d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe280732e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55a12e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c67f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a12e8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46147b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4614c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55a12e8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55580b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde55a12e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5566da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55a12e8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55663c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55580b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbde55a12e8> 0.0 18
Completed Iteration #20
Best Reward: 0
coverage_call_count 4700
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55582b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a12e8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5566518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55a12e8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5566588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55a12e8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde55a12e8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a16d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6951d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a16d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a16d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0411bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55a16d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0411b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a16d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a16d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55a16d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a16d8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a16d8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55a16d8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6959e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55a16d8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6746160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55a16d8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2809c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde55a16d8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c74f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a16d8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a16d8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbefa8a0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6648fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55a16d8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af95828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55a16d8> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6ab9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66487b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55a16d8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55589e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55a16d8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6617b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde55a16d8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55666a0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55666a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55666a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5566cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55666a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55666a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe140500b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55666a0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55666a0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55666a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55666a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55666a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55666a0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5566cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55666a0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55666a0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde670e390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55666a0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55666a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55666a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde678b668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde55666a0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde55666a0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55666a0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee480b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55666a0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5566668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde467c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730080> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde467cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730080> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde467c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730080> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4730080> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde467c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730080> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730080> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4730080> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4614710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4730080> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730080> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c723390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4730080> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4730080> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde467c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde4730080> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467ce48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4730080> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4647630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730908> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbde4730080> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040faef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4647390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4647160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4647fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46470b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4647588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4647da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4647748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040faef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca58> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040faa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca58> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde467cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca58> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca58> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca58> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2805dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467c4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca58> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46476a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca58> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af85828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467c4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca58> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca58> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde67b7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4647588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4647da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca58> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4647668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467c588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde467ca58> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730518> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5566668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730518> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4730518> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1405f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4730518> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde668a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730518> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4730518> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46475c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730518> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4614710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730518> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde467cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4730518> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66e9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730518> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4730518> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde4730518> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730518> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4730518> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6799fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4730518> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66484a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66488d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66484a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66488d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66488d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe14050588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66484a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4647470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47a38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df278> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47f56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df278> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df278> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4647470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df278> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47a38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df278> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4647470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df278> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df278> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4647470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df278> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df278> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df278> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df278> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde467c5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df278> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66760b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df278> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c167f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df278> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df278> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbe6c6df278> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47a37b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c776160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47a37b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7748> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7748> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4cba048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7748> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7748> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af62a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7748> 0.0 12
Completed Iteration #14
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0410dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7748> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7748> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7748> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7748> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee8ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7748> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5590898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7748> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe4c781a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7748> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4614710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4860> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4730518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4860> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe28073940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4860> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4860> 0.0 5
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47f58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4860> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4860> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c242e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47f58d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4860> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4860> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c243c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4860> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4860> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4860> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c245c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde668aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4860> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4860> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c240f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c40b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4860> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c40b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4860> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4860> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8eb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5581278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8eb8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55811d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5581940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55817b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8eb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8eb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8eb8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46146d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477e8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8eb8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8eb8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c246a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8eb8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477e8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8eb8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c241d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55817b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8eb8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55812b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55817b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8eb8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8eb8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477e8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8eb8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8eb8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8eb8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581470> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c079e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581470> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c491d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581470> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5581470> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c490f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c498d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581470> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4784208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5581470> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581470> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde5581470> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c077f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581470> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581470> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5581470> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5581b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde5581470> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde5581470> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5581e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde5581470> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde477e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5581470> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c494e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde5581470> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c247f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde67b72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c494a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4730908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6676438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c49cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4614eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde5558b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe1403c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe28073a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8be0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0ee7fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7d30> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66487b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4784f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7d30> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4784630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7d30> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7d30> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4784630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7d30> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7d30> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46b89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7d30> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7d30> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4784b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7d30> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4784710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7d30> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46b86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e33c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c695908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c495f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8ba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4784128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8ba8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde467cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c495f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8ba8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040eac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c495f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8ba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8ba8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c074e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8ba8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8ba8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8ba8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8ba8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8ba8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e36d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8ba8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8ba8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46d46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8ba8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47572e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4757710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47571d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4757320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4757518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46d42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47571d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46d46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe0410dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4a20> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe6c63d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4a20> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4a20> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4a20> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55a1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4a20> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4a20> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4a20> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4a20> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4a20> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c6959e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e38d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4a20> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46b81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4a20> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c16da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e38d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4a20> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47571d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4a20> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4a20> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47f5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4784400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8390> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4784fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8390> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46d45f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8390> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55810f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8390> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b89b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8390> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe280ab710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8390> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8390> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8390> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8390> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8390> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe14050208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde6732320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8390> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b89b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8390> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8390> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8390> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4784710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8390> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c495f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c248d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4757f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c248d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47575c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07550> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07550> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07550> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07550> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07550> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07550> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07550> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07550> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde665a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07550> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47a3898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c248d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07550> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07550> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47576d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07550> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07550> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07550> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c248d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07550> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5581358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c248d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07550> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07550> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46e62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468df28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07550> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46e64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46a38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46a35f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6438> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6438> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4635400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46a35f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6438> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4635518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4635198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4635400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46a35f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6438> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4635160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46a30b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6438> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46357f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6438> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6438> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4635a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46a30b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6438> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4635ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46a35f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6438> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4635c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6438> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6438> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4635c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6438> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4635c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6438> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6438> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4635710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46a35f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6438> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3b00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6438> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d630> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d630> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46a34a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d630> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d630> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d630> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46358d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d630> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde468d630> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46a30f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4635b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde468d630> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c704358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde468d630> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde468d630> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde468d630> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4757eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbde468d630> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde468d630> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6648da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4757fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde468d630> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde468d630> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde468d630> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4784898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde468d630> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47848d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4784198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47848d0> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47848d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47848d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47848d0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c246a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78dfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47848d0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47848d0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78dfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47848d0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde47848d0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47848d0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78dfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040eaac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47848d0> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47848d0> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47848d0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c07c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde47848d0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66faa90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde47848d0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46354a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4757080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46354a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78dff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46354a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46354a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46354a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47d7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4c499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46354a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46354a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46354a8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46354a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46354a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46354a8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde46354a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a01d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46354a8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde46354a8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46354a8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884b70> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbde46354a8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46354a8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884b70> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fbde46354a8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a01d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbde46354a8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46354a8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46354a8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b09e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0780> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78410f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b05f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0780> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0780> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0780> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0780> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b05f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0780> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b09e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0780> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0780> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0780> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0780> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0780> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c499b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0780> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884ac8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884ac8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78dfb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884ac8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a09b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884ac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884ac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884ac8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78dfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884ac8> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a09b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884ac8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46d45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884ac8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4635e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4635748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884ac8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4635748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884ac8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde5558b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78842b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884ac8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a09b0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884ac8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884ac8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884ac8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4614710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66761d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884ac8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4757fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78842b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884ac8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 13.380281690140844
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3160> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78415f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3160> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c24278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3160> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3160> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78415f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3160> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4757748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78415f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3160> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468d4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3160> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3160> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3160> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46c4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3160> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3160> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3160> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3160> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3160> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78415f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3160> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3160> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde47e3160> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc787ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc787aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a860> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78091d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78094e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78093c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a860> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78093c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a860> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78098d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78097b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc787af28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a860> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc787ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78093c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a860> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78093c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a860> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787af60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a860> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78092e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a860> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78093c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a860> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a860> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78093c8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a860> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78092b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a860> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a860> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a860> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a860> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a8d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78094a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78098d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a8d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78093c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a8d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78092e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a8d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc787ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a8d0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc787ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78098d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a8d0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a8d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66b8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a8d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78091d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a8d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe2af76278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78090b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a8d0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a8d0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a8d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46a3f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a8d0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a8d0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4614710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78098d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a8d0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78092e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a8d0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde55e84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78092e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a8d0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46d4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde4635470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a8d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4635978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a8d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78dfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e65c0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78dfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e65c0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e65c0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e65c0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4784b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e65c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78dfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46e65c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040fa1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46e65c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e65c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46e65c0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46e65c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46e65c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e65c0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46e65c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e65c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde46e65c0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46e65c0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46e65c0> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46e65c0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde55e8cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde46e65c0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781bc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b5f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781ba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b5f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b5f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b5f8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b5f8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781bf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b5f8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b5f8> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b5f8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781bc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b5f8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b5f8> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781bd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc781bc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b5f8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781ba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b5f8> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781bf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b5f8> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b5f8> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d43c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b5f8> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d45f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b5f8> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b5f8> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b5f8> 0.0 21
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b5f8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71f2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5d68> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5d68> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5d68> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71f20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5d68> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71f2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e56d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5d68> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5d68> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5d68> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71f26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5d68> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71f22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5d68> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71f25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5d68> 0.0 16
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71f2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5d68> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71f2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71f25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5d68> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5d68> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71f25c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5d68> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71f2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71f2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4668> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4668> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4668> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4668> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4668> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4668> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4668> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4668> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4668> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4668> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4668> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4668> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4784198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4668> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4668> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4668> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71f2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0128> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78dfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0128> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0128> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0128> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78842b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0128> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0128> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78842b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0128> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0128> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0128> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0128> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0128> 0.0 13
Completed Iteration #17
Best Reward: 0
coverage_call_count 5500
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0128> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0128> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0128> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4a58> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0128> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b57b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b55c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b55c0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71413c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b55c0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b55c0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b55c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71418d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b55c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b55c0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b55c0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b55c0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7154400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b55c0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71418d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b55c0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71418d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b55c0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b55c0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b55c0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b55c0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b55c0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71548d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7154550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71542b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7154b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71549e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71542b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7154c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71542b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7154978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71542b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7154d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7154278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71542b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7154fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71549e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71542b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc716f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71549e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc71542b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71544a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc716f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71542b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7154080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71542b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71542e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71542b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7154550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71542b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71418d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7154080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71542b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7154278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71542b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71416a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71549e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbdc71542b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71542b0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7154048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7154e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71542b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71542e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71542b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7154550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc71542b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7154080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc71542b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b55c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71542e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc71542b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a400> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78dfc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a400> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a400> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4757668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a400> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a7fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a400> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a7fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a400> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a400> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a400> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a400> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a400> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7154160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a7fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a400> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71f2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a400> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787aac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a400> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a400> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47847f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47847f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47847f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71e5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47847f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc716f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47847f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47847f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc716f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47847f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc716fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc716fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde47847f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc716fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47847f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc716fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47847f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc716ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde47847f0> 0.0 12
Completed Iteration #14
Best Reward: 0
coverage_call_count 5600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc716f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc716fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47847f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc711e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde468db00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde47847f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc711e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b54e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47847f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc716f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbde47847f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc711e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc716fa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbde47847f0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc711e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbde47847f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc711e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbde47847f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0860> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc716f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0860> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc716ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a7908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0860> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc711edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc716ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0860> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc711eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc711e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc711efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc711e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0860> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0860> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc711e978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71385f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71384e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc711efd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc711e4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0860> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc711e4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0860> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc711e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc711eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0860> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc711eb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0860> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71388d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0860> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7884160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0860> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0860> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71386a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0860> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc711e4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0860> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc711e978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0860> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9a90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71386a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9a90> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71385c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71387b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9a90> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde47847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9a90> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9a90> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc711e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9a90> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71d4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9a90> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9a90> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc711eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71386a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9a90> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc711e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9a90> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc711e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9a90> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71387b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9a90> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc716f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9a90> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71387b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9a90> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc711e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9a90> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc711e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71387b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9a90> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc716ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9a90> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc716f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde66fa0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9a90> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc711efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9a90> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71384e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe4c79d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71384e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde6732320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71384e0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71f2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc716fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71384e0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78b0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71f2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71384e0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71384e0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc716f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71384e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc71384e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71547b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71384e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71547b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71384e0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71384e0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71546a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71384e0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71384e0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71546a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71384e0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc71384e0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc71384e0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbdc71384e0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbdc71384e0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7154160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71384e0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc716fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc71384e0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7154710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71383c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc716feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc711ec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9d68> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9d68> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71383c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9d68> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc716ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9d68> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9d68> 0.0 12
Completed Iteration #12
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9d68> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9d68> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc711ec50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9d68> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc716ff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9d68> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9d68> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb3c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9d68> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc708dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc708de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc708deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d898> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70a04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70a0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d898> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70a0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70a05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d898> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70a0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d898> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d898> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70a0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d898> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70a0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70a05c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d898> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70a0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d898> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d898> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70a08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d898> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70a0898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d898> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708dd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d898> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708dd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d898> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4c246a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d898> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fbb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb208> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fbb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fbe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb208> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb208> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbde46e6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb208> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbe040ea198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb208> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb208> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70a0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb208> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fbb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb208> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb208> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70a00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb208> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fbb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb208> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70a00b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb208> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb208> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fbe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb208> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb208> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c93c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde468d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc716f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c93c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71384e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c93c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc711e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc716f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c93c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc711e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c93c8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c93c8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c93c8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc716f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c93c8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c93c8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b27b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c93c8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70592b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c93c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc716f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c93c8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7841b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c93c8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70595c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c93c8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c93c8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70596d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c93c8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71410f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b27b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c93c8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71b5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc787a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc716f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b27b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c93c8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b27b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c93c8> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c93c8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc711e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c93c8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 224
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2dd8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2dd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2dd8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7071240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2dd8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7071470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7071358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2dd8> 0.0 7
Completed Iteration #8
Best Reward: 0
coverage_call_count 5800
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7071898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7071780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2dd8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7071588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2dd8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7071cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7071780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2dd8> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2dd8> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7071b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2dd8> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70023c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70593c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2dd8> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70025c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2dd8> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70022b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70593c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2dd8> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70028d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7071a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70135f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70134e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7013470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70132b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002c50> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7013748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7013ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7013a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002c50> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70134e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002c50> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7071be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70021d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002c50> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7071c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70132b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002c50> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70710f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70028d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002c50> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002c50> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002c50> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70718d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70132b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002c50> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7013a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002c50> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7071240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70592b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7071e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7071e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc716f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7071e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059160> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059160> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059160> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc716f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059160> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70592e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059160> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7071e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059160> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc711eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059160> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059160> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70a0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc711eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059160> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde46b8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059160> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7809518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7071e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059160> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7071e10> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059160> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde4757668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7071e10> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059160> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059160> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71f2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc781bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059160> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059160> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059160> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141b00> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fbe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141b00> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7013128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7013240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141b00> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc78df780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141b00> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70a0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141b00> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141b00> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141b00> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141b00> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141b00> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fbe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141b00> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70a0da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141b00> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7013828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7013240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141b00> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7013cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141b00> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141b00> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7002390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141b00> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7141b00> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf7b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdc080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf7b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcfa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf7b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf7b8> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 5900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdc198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf7b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdc668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcfe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf7b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdc828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf7b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70139b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf7b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf7b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdc208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf7b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf7b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdcb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf7b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdc518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf7b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf7b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bef748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdcb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf7b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6befa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdcb70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf7b8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7013fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb978> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb978> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcfd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb978> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcfa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fbda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7013ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcfc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb978> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7013160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7013b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb978> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb978> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb978> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbde477e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71f2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb978> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc781bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcfa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb978> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fbda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb978> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7138c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcfa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb978> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc78a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7013fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb978> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7013828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb978> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc71f2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70fb978> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2518> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdc160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2518> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdcb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdcbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2518> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71a7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdcd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2518> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2518> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdcfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2518> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdc940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2518> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdcac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdcd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2518> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bef438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2518> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6befac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc716f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2518> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7071710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc716f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2518> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdcf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2518> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc716f6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2518> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70c9358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdcbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2518> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc71384e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2518> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdc400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2518> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2518> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 13.380281690140844
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bcf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdc908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdc8d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6befa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdc8d0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bef0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdc8d0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bab080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdc8d0> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc70b2080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6befbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdc8d0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6befd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7071f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdc8d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bab470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6befbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdc8d0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bab7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7071f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdc8d0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bef668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc7071f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdc8d0> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6babb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bab860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bab7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc7071f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdc8d0> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdc8d0> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdc908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdc8d0> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6beff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdc8d0> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6befbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bdc8d0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 13.380281690140844
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9a20> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9a20> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9a20> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 6000
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6b46400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9a20> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6b466a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6b46240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9a20> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6b469b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6b46898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9a20> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6b46b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9a20> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6b46d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9a20> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6b46dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9a20> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6b46b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6b46240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9a20> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6b5a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9a20> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc7059da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6b46898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9a20> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc6befe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6b46898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9a20> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fbdc708d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6b5a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fbdc6bb9a20> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 13.380281690140844
initial coverage: 13.3803
time passed (minutes): 60.324
iterations: 234
number of new inputs: 0
final coverage: 13.3803
total coverage increase: 0
