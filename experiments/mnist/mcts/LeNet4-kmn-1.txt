Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='kmn', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet4', model_input_scale=[0, 1], nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet4', 'mcts', 'kmn'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7efeb034df28>, tc2=<function tc2 at 0x7efeb035e048>, tc3=<function tc3 at 0x7efeb035e158>, tfc_threshold=169, time_period=3600, verbose=True)
initial coverage: 11.7254
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5410c908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5410c908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5410c908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe5410c908> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5410c908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe5410c908> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f19e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe5410c908> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540885f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5410c908> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540885f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe5410c908> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54088ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5410c908> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540882b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5410c908> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540885f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe5410c908> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe5410c908> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe5410c908> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5410c908> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5410c908> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe5410c908> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe5410c908> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe5410c908> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 11.725352112676056
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54146438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5410ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54146940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54146908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ba8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54088940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ba8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54146908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5410ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ba8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ba8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ba8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ba8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54088908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ba8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54055128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 11.725352112676056
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54146470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540554e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540b1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540554e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540b1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540554e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540b1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540554e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540554e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540554e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54146588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540554e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54146470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540554e0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540b1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540554e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540554e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540b1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540554e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540b1208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540554e0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540554e0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe540554e0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540882b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540554e0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54146470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540554e0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54088710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540554e0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540b1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540554e0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 11.725352112676056
Completed Iteration #0
Best Reward: 0
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe54088860> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe54088978> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.03521126760563398 2
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe540f13c8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.07042253521126796 3
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.07042253521126796 4
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.07042253521126796 5
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe540f1860> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe5410c7b8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.10563380281690193 6
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.10563380281690193 7
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540555f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.10563380281690193 8
Completed Iteration #8
Best Reward: 0.03521126760563398
Completed Iteration #9
Best Reward: 0.03521126760563398
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54055b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.10563380281690193 9
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe54055fd0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.1408450704225359 10
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54055f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54088978> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.1408450704225359 11
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540550b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.1408450704225359 12
Completed Iteration #14
Best Reward: 0.03521126760563398
Completed Iteration #15
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540742b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.1408450704225359 13
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540749e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.1408450704225359 14
Completed Iteration #19
Best Reward: 0.03521126760563398
Completed Iteration #20
Best Reward: 0.03521126760563398
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5410c7b8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.1408450704225359 15
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe54074400> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.10563380281690193 6
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.1760563380281699 16
Completed Iteration #22
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5410c7b8> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.1760563380281699 17
Completed Iteration #23
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540041d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54088978> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.1760563380281699 18
Completed Iteration #24
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54088240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.1760563380281699 19
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #0
root
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.10563380281690193 7
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.1760563380281699 20
Completed Iteration #0
Best Reward: 0.03521126760563398
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.10563380281690193 8
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.1760563380281699 21
Completed Iteration #2
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.10563380281690193 9
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.1760563380281699 22
Completed Iteration #3
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.10563380281690193 10
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.1760563380281699 23
Completed Iteration #4
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.10563380281690193 11
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.1760563380281699 24
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe54012048> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.1408450704225359 12
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.21126760563380387 25
Completed Iteration #6
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54146748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.1408450704225359 13
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.21126760563380387 26
Completed Iteration #7
Best Reward: 0.03521126760563398
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.21126760563380387 14
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.2816901408450718 27
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.21126760563380387 15
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.2816901408450718 28
Completed Iteration #11
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54055080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.21126760563380387 16
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.2816901408450718 29
Completed Iteration #12
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe540556a0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.24647887323943785 17
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.3169014084507058 30
Completed Iteration #13
Best Reward: 0.07042253521126796
Completed Iteration #14
Best Reward: 0.07042253521126796
Completed Iteration #15
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.24647887323943785 18
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.3169014084507058 31
Completed Iteration #16
Best Reward: 0.07042253521126796
Completed Iteration #17
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe54074048> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004ba8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.2816901408450718 19
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.3521126760563398 32
Completed Iteration #18
Best Reward: 0.07042253521126796
Completed Iteration #19
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.2816901408450718 20
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.3521126760563398 33
Completed Iteration #20
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.2816901408450718 21
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.3521126760563398 34
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.2816901408450718 22
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.3521126760563398 35
Completed Iteration #23
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540124e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.2816901408450718 23
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.3521126760563398 36
Completed Iteration #24
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe54012828> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.3169014084507058 24
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.38732394366197376 37
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #1
root->6
Best Reward: 0.07042253521126796
Completed Iteration #0
Best Reward: 0.07042253521126796
Completed Iteration #1
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.3169014084507058 25
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.38732394366197376 38
Completed Iteration #2
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe5402e2e8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.1408450704225359 5
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.3521126760563398 26
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.42253521126760774 39
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.1408450704225359 6
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.3521126760563398 27
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.42253521126760774 40
Completed Iteration #5
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.1408450704225359 7
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.3521126760563398 28
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.42253521126760774 41
Completed Iteration #6
Best Reward: 0.07042253521126796
Completed Iteration #7
Best Reward: 0.07042253521126796
Completed Iteration #8
Best Reward: 0.07042253521126796
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004ba8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.1408450704225359 8
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.3521126760563398 29
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.42253521126760774 42
Completed Iteration #11
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.1408450704225359 9
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.3521126760563398 30
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.42253521126760774 43
Completed Iteration #12
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe5402e5c0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004ba8> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.1760563380281699 10
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.38732394366197376 31
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.4577464788732417 44
Completed Iteration #13
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe5403c630> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c4e0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.21126760563380387 11
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.42253521126760774 32
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.4929577464788757 45
Completed Iteration #14
Best Reward: 0.07042253521126796
Completed Iteration #15
Best Reward: 0.07042253521126796
Completed Iteration #16
Best Reward: 0.07042253521126796
Completed Iteration #17
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe54055160> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1438> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012cf8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7efe54012e10> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.24647887323943785 12
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.4577464788732417 33
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.5281690140845097 46
Completed Iteration #18
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.3169014084507058 13
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.5281690140845097 34
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.5985915492957776 47
Completed Iteration #19
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54055ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.3169014084507058 14
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.5281690140845097 35
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.5985915492957776 48
Completed Iteration #20
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe540b1198> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.3521126760563398 15
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.5633802816901436 36
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.6338028169014116 49
Completed Iteration #21
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe540046a0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004588> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e5c0> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7efe54004ba8> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.38732394366197376 16
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.5985915492957776 37
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.6690140845070456 50
Completed Iteration #22
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.38732394366197376 17
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.5985915492957776 38
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.6690140845070456 51
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe5402e828> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c4e0> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.42253521126760774 18
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.6338028169014116 39
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.7042253521126796 52
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #2
root->6->19
Best Reward: 0.07042253521126796
Completed Iteration #0
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe5402e8d0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.4577464788732417 19
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.6690140845070456 40
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.7394366197183135 53
Completed Iteration #1
Best Reward: 0.07042253521126796
Completed Iteration #2
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe540128d0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.1760563380281699 5
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.5281690140845097 20
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.7394366197183135 41
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.8098591549295815 54
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Completed Iteration #5
Best Reward: 0.07042253521126796
Completed Iteration #6
Best Reward: 0.07042253521126796
Completed Iteration #7
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe5403c390> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.24647887323943785 6
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.5985915492957776 21
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.8098591549295815 42
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.8802816901408494 55
Completed Iteration #8
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe5403cfd0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.3169014084507058 7
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.6690140845070456 22
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.8802816901408494 43
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.9507042253521174 56
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Completed Iteration #11
Best Reward: 0.07042253521126796
Completed Iteration #12
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe5403cba8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.3521126760563398 8
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.7042253521126796 23
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.9154929577464834 44
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.9859154929577514 57
Completed Iteration #13
Best Reward: 0.07042253521126796
Completed Iteration #14
Best Reward: 0.07042253521126796
Completed Iteration #15
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ca6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.3521126760563398 9
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.7042253521126796 24
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.9154929577464834 45
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.9859154929577514 58
Completed Iteration #16
Best Reward: 0.07042253521126796
Completed Iteration #17
Best Reward: 0.07042253521126796
Completed Iteration #18
Best Reward: 0.07042253521126796
Completed Iteration #19
Best Reward: 0.07042253521126796
Completed Iteration #20
Best Reward: 0.07042253521126796
Completed Iteration #21
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347caac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347cac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540128d0> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.3521126760563398 10
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.7042253521126796 25
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.9154929577464834 46
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.9859154929577514 59
Completed Iteration #22
Best Reward: 0.07042253521126796
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #3
root->6->19->0
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.3521126760563398 11
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.7042253521126796 26
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.9154929577464834 47
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.9859154929577514 60
Completed Iteration #0
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.3521126760563398 12
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.7042253521126796 27
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.9154929577464834 48
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.9859154929577514 61
Completed Iteration #1
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.3521126760563398 13
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.7042253521126796 28
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.9154929577464834 49
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.9859154929577514 62
Completed Iteration #2
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe54004d30> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1278> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.10563380281690193 6
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.38732394366197376 14
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.7394366197183135 29
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.9507042253521174 50
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.0211267605633854 63
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.10563380281690193 7
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.38732394366197376 15
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.7394366197183135 30
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.9507042253521174 51
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.0211267605633854 64
Completed Iteration #5
Best Reward: 0.07042253521126796
Completed Iteration #6
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe347caa90> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1278> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.1408450704225359 8
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.42253521126760774 16
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.7746478873239475 31
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.9859154929577514 52
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.0563380281690193 65
Completed Iteration #7
Best Reward: 0.07042253521126796
Completed Iteration #8
Best Reward: 0.07042253521126796
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Completed Iteration #11
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.1408450704225359 9
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.42253521126760774 17
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.7746478873239475 32
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 0.9859154929577514 53
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.0563380281690193 66
Completed Iteration #12
Best Reward: 0.07042253521126796
Completed Iteration #13
Best Reward: 0.07042253521126796
Completed Iteration #14
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe347d14e0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.1760563380281699 10
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.4577464788732417 18
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.8098591549295815 33
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.0211267605633854 54
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.0915492957746533 67
Completed Iteration #15
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.1760563380281699 11
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.4577464788732417 19
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.8098591549295815 34
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.0211267605633854 55
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.0915492957746533 68
Completed Iteration #16
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe347d1f28> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c048> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.21126760563380387 12
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.4929577464788757 20
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.8450704225352155 35
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.0563380281690193 56
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.1267605633802873 69
Completed Iteration #17
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe347ee320> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe347caa20> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.24647887323943785 13
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.5281690140845097 21
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.8802816901408494 36
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.0915492957746533 57
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.1619718309859213 70
Completed Iteration #18
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ee668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1278> 0.07042253521126796 5
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.24647887323943785 14
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.5281690140845097 22
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.8802816901408494 37
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.0915492957746533 58
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.1619718309859213 71
Completed Iteration #19
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.24647887323943785 15
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.5281690140845097 23
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.8802816901408494 38
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.0915492957746533 59
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.1619718309859213 72
Completed Iteration #20
Best Reward: 0.07042253521126796
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
coverage_call_count 200
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe347ca860> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055ac8> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.2816901408450718 16
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.5633802816901436 24
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.9154929577464834 39
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.1267605633802873 60
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.1971830985915553 73
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #4
root->6->19->0->0
Best Reward: 0.07042253521126796
Completed Iteration #0
Best Reward: 0.07042253521126796
Completed Iteration #1
Best Reward: 0.07042253521126796
Completed Iteration #2
Best Reward: 0.07042253521126796
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.3521126760563398 17
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.6338028169014116 25
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 0.9859154929577514 40
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.1971830985915553 61
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.2676056338028232 74
Completed Iteration #5
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe347ee080> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.1408450704225359 4
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.38732394366197376 18
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.6690140845070456 26
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.0211267605633854 41
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.2323943661971892 62
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.3028169014084572 75
Completed Iteration #6
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ee908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.1408450704225359 5
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.38732394366197376 19
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.6690140845070456 27
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.0211267605633854 42
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.2323943661971892 63
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.3028169014084572 76
Completed Iteration #7
Best Reward: 0.07042253521126796
Completed Iteration #8
Best Reward: 0.07042253521126796
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Completed Iteration #11
Best Reward: 0.07042253521126796
Completed Iteration #12
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.1408450704225359 6
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.38732394366197376 20
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.6690140845070456 28
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.0211267605633854 43
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.2323943661971892 64
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.3028169014084572 77
Completed Iteration #13
Best Reward: 0.07042253521126796
Completed Iteration #14
Best Reward: 0.07042253521126796
Completed Iteration #15
Best Reward: 0.07042253521126796
Completed Iteration #16
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe3478f6a0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f400> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d14e0> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.1760563380281699 7
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.42253521126760774 21
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.7042253521126796 29
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.0563380281690193 44
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.2676056338028232 65
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.3380281690140912 78
Completed Iteration #17
Best Reward: 0.07042253521126796
Completed Iteration #18
Best Reward: 0.07042253521126796
Completed Iteration #19
Best Reward: 0.07042253521126796
Completed Iteration #20
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe3478fc18> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.21126760563380387 8
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.4577464788732417 22
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.7394366197183135 30
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.0915492957746533 45
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.3028169014084572 66
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.3732394366197251 79
Completed Iteration #21
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe3478ffd0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.24647887323943785 9
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.4929577464788757 23
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.7746478873239475 31
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.1267605633802873 46
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.3380281690140912 67
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.4084507042253591 80
Completed Iteration #22
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe34796470> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe347962b0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.1408450704225359 4
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.3169014084507058 10
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.5633802816901436 24
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.8450704225352155 32
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.1971830985915553 47
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.4084507042253591 68
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.478873239436627 81
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #5
root->6->19->0->0->1
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe347963c8> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796780> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.21126760563380387 5
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.38732394366197376 11
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.6338028169014116 25
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.9154929577464834 33
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.2676056338028232 48
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.478873239436627 69
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.549295774647895 82
Completed Iteration #0
Best Reward: 0.07042253521126796
Completed Iteration #1
Best Reward: 0.07042253521126796
Completed Iteration #2
Best Reward: 0.07042253521126796
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Completed Iteration #5
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe347d1dd8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796780> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.24647887323943785 6
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.42253521126760774 12
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.6690140845070456 26
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.9507042253521174 34
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.3028169014084572 49
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.514084507042261 70
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.584507042253529 83
Completed Iteration #6
Best Reward: 0.07042253521126796
Completed Iteration #7
Best Reward: 0.07042253521126796
Completed Iteration #8
Best Reward: 0.07042253521126796
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ee0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.24647887323943785 7
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.42253521126760774 13
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.6690140845070456 27
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.9507042253521174 35
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.3028169014084572 50
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.514084507042261 71
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.584507042253529 84
Completed Iteration #11
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe347ee860> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478fb38> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.2816901408450718 8
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.4577464788732417 14
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.7042253521126796 28
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 0.9859154929577514 36
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.3380281690140912 51
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.549295774647895 72
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.619718309859163 85
Completed Iteration #12
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe347964e0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796780> 0.1760563380281699 4
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.3521126760563398 9
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.5281690140845097 15
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.7746478873239475 29
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 1.0563380281690193 37
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.4084507042253591 52
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.619718309859163 73
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.690140845070431 86
Completed Iteration #13
Best Reward: 0.07042253521126796
Completed Iteration #14
Best Reward: 0.07042253521126796
Completed Iteration #15
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe34796518> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796780> 0.24647887323943785 5
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.42253521126760774 10
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.5985915492957776 16
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.8450704225352155 30
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 1.1267605633802873 38
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.478873239436627 53
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.690140845070431 74
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.760563380281699 87
Completed Iteration #16
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe347b60b8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe347962b0> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.4577464788732417 11
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.6338028169014116 17
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.8802816901408494 31
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 1.1619718309859213 39
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.514084507042261 54
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.725352112676065 75
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.7957746478873329 88
Completed Iteration #17
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe347b64e0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe347962b0> 0.1408450704225359 4
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.4929577464788757 12
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.6690140845070456 18
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.9154929577464834 32
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 1.1971830985915553 40
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.549295774647895 55
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.760563380281699 76
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.8309859154929669 89
Completed Iteration #18
Best Reward: 0.07042253521126796
Completed Iteration #19
Best Reward: 0.07042253521126796
Completed Iteration #20
Best Reward: 0.07042253521126796
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.4929577464788757 13
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.6690140845070456 19
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.9154929577464834 33
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 1.1971830985915553 41
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.549295774647895 56
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.760563380281699 77
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.8309859154929669 90
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #6
root->6->19->0->0->1->0
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34796748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347969b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347963c8> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7efe34796780> 0.24647887323943785 6
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.4929577464788757 14
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.6690140845070456 20
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.9154929577464834 34
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 1.1971830985915553 42
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.549295774647895 57
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.760563380281699 78
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.8309859154929669 91
Completed Iteration #0
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796780> 0.24647887323943785 7
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.4929577464788757 15
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.6690140845070456 21
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.9154929577464834 35
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 1.1971830985915553 43
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.549295774647895 58
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.760563380281699 79
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.8309859154929669 92
Completed Iteration #1
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe347966a0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796780> 0.2816901408450718 8
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.5281690140845097 16
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.7042253521126796 22
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 0.9507042253521174 36
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 1.2323943661971892 44
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.584507042253529 59
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.7957746478873329 80
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.8661971830986008 93
Completed Iteration #2
Best Reward: 0.07042253521126796
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Completed Iteration #5
Best Reward: 0.07042253521126796
Completed Iteration #6
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe347b6c50> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796780> 0.3521126760563398 9
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.5985915492957776 17
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.7746478873239475 23
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 1.0211267605633854 37
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 1.3028169014084572 45
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.654929577464797 60
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.8661971830986008 81
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.9366197183098688 94
Completed Iteration #7
Best Reward: 0.07042253521126796
Completed Iteration #8
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe347b69e8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796780> 0.38732394366197376 10
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.6338028169014116 18
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.8098591549295815 24
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 1.0563380281690193 38
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 1.3380281690140912 46
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.690140845070431 61
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.9014084507042348 82
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 1.9718309859155028 95
Completed Iteration #9
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe3478f828> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796780> 0.42253521126760774 11
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.6690140845070456 19
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.8450704225352155 25
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 1.0915492957746533 39
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 1.3732394366197251 47
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.725352112676065 62
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.9366197183098688 83
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 2.0070422535211367 96
Completed Iteration #10
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe347cacf8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe347eef28> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f828> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7efe34796780> 0.4577464788732417 12
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.7042253521126796 20
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.8802816901408494 26
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 1.1267605633802873 40
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 1.4084507042253591 48
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.760563380281699 63
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.9718309859155028 84
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 2.0422535211267707 97
Completed Iteration #11
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796518> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7efe34796780> 0.4577464788732417 13
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.7042253521126796 21
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.8802816901408494 27
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 1.1267605633802873 41
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 1.4084507042253591 49
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.760563380281699 64
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.9718309859155028 85
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 2.0422535211267707 98
Completed Iteration #12
Best Reward: 0.07042253521126796
Completed Iteration #13
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34742470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34796780> 0.4577464788732417 14
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.7042253521126796 22
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.8802816901408494 28
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 1.1267605633802873 42
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 1.4084507042253591 50
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.760563380281699 65
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 1.9718309859155028 86
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 2.0422535211267707 99
Completed Iteration #14
Best Reward: 0.07042253521126796
Completed Iteration #15
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe347b6940> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478fe48> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f828> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7efe34796780> 0.4929577464788757 15
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.7394366197183135 23
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.9154929577464834 29
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 1.1619718309859213 43
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 1.443661971830993 51
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.7957746478873329 66
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 2.0070422535211367 87
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 2.0774647887324047 100
Completed Iteration #16
Best Reward: 0.07042253521126796
Completed Iteration #17
Best Reward: 0.07042253521126796
Completed Iteration #18
Best Reward: 0.07042253521126796
Completed Iteration #19
Best Reward: 0.07042253521126796
Completed Iteration #20
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe3474e080> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742cf8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6c50> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7efe34796780> 0.5281690140845097 16
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.7746478873239475 24
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.9507042253521174 30
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 1.1971830985915553 44
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 1.478873239436627 52
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.8309859154929669 67
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 2.0422535211267707 88
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 2.1126760563380387 101
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Completed Iteration #23
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe5403ca20> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796780> 0.5985915492957776 17
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.8450704225352155 25
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 1.0211267605633854 31
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 1.2676056338028232 45
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 1.549295774647895 53
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.9014084507042348 68
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 2.1126760563380387 89
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 2.1830985915493066 102
Completed Iteration #24
Best Reward: 0.07042253521126796
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #7
root->6->19->0->0->1->0->5
Best Reward: 0.07042253521126796
Completed Iteration #0
Best Reward: 0.07042253521126796
Completed Iteration #1
Best Reward: 0.07042253521126796
Completed Iteration #2
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe347964a8> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6d30> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe347964e0> 0.1408450704225359 3
backprop <src.mcts.MCTS_Node object at 0x7efe34796780> 0.6690140845070456 18
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.9154929577464834 26
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 1.0915492957746533 32
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 1.3380281690140912 46
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 1.619718309859163 54
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.9718309859155028 69
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 2.1830985915493066 90
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 2.2535211267605746 103
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34742160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347420b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347964e0> 0.1408450704225359 4
backprop <src.mcts.MCTS_Node object at 0x7efe34796780> 0.6690140845070456 19
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.9154929577464834 27
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 1.0915492957746533 33
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 1.3380281690140912 47
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 1.619718309859163 55
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.9718309859155028 70
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 2.1830985915493066 91
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 2.2535211267605746 104
Completed Iteration #5
Best Reward: 0.07042253521126796
Completed Iteration #6
Best Reward: 0.07042253521126796
Completed Iteration #7
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347425c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347964e0> 0.1408450704225359 5
backprop <src.mcts.MCTS_Node object at 0x7efe34796780> 0.6690140845070456 20
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.9154929577464834 28
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 1.0915492957746533 34
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 1.3380281690140912 48
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 1.619718309859163 56
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.9718309859155028 71
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 2.1830985915493066 92
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 2.2535211267605746 105
Completed Iteration #8
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34742be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347425c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347964e0> 0.1408450704225359 6
backprop <src.mcts.MCTS_Node object at 0x7efe34796780> 0.6690140845070456 21
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.9154929577464834 29
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 1.0915492957746533 35
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 1.3380281690140912 49
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 1.619718309859163 57
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 1.9718309859155028 72
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 2.1830985915493066 93
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 2.2535211267605746 106
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Completed Iteration #11
Best Reward: 0.07042253521126796
Completed Iteration #12
Best Reward: 0.07042253521126796
Completed Iteration #13
Best Reward: 0.07042253521126796
Completed Iteration #14
Best Reward: 0.07042253521126796
Completed Iteration #15
Best Reward: 0.07042253521126796
Completed Iteration #16
Best Reward: 0.07042253521126796
Completed Iteration #17
Best Reward: 0.07042253521126796
Completed Iteration #18
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe34761518> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6d30> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7efe347964e0> 0.1760563380281699 7
backprop <src.mcts.MCTS_Node object at 0x7efe34796780> 0.7042253521126796 22
backprop <src.mcts.MCTS_Node object at 0x7efe5402e630> 0.9507042253521174 30
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 1.1267605633802873 36
backprop <src.mcts.MCTS_Node object at 0x7efe540f15c0> 1.3732394366197251 50
backprop <src.mcts.MCTS_Node object at 0x7efe54012b70> 1.654929577464797 58
backprop <src.mcts.MCTS_Node object at 0x7efe540a4ef0> 2.0070422535211367 73
backprop <src.mcts.MCTS_Node object at 0x7efe540f1fd0> 2.2183098591549406 94
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 2.2887323943662086 107
Completed Iteration #19
Best Reward: 0.07042253521126796
Completed Iteration #20
Best Reward: 0.07042253521126796
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #8
root->6->19->0->0->1->0->5->1
Best Reward: 0.07042253521126796
iteration: 3
found coverage increase 0.07042253521126796
Current Total Coverage 11.795774647887324
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ca4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.0 6
Completed Iteration #9
Best Reward: 0
coverage_call_count 300
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.07042253521126618 7
Completed Iteration #10
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34742588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.07042253521126618 8
Completed Iteration #11
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34796e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.07042253521126618 4
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.07042253521126618 9
Completed Iteration #12
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347610b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.07042253521126618 10
Completed Iteration #13
Best Reward: 0.07042253521126618
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe34761438> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c208> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.10563380281690016 11
Completed Iteration #14
Best Reward: 0.07042253521126618
Completed Iteration #15
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34761d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.07042253521126618 5
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.10563380281690016 12
Completed Iteration #16
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347428d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.10563380281690016 13
Completed Iteration #17
Best Reward: 0.07042253521126618
Completed Iteration #18
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.10563380281690016 14
Completed Iteration #19
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.10563380281690016 15
Completed Iteration #20
Best Reward: 0.07042253521126618
Completed Iteration #21
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3476c208> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.10563380281690016 16
Completed Iteration #22
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.07042253521126618 6
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.10563380281690016 17
Completed Iteration #23
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c208> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.10563380281690016 18
Completed Iteration #24
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.10563380281690016 19
Completed Iteration #25
Best Reward: 0.07042253521126618
Completed MCTS Level/Depth: #0
root
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.07042253521126618 7
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.10563380281690016 20
Completed Iteration #0
Best Reward: 0.07042253521126618
Completed Iteration #1
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34718160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.07042253521126618 8
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.10563380281690016 21
Completed Iteration #2
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34718390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.07042253521126618 9
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.10563380281690016 22
Completed Iteration #3
Best Reward: 0.07042253521126618
Completed Iteration #4
Best Reward: 0.07042253521126618
Completed Iteration #5
Best Reward: 0.07042253521126618
Completed Iteration #6
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.07042253521126618 10
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.10563380281690016 23
Completed Iteration #7
Best Reward: 0.07042253521126618
Completed Iteration #8
Best Reward: 0.07042253521126618
Completed Iteration #9
Best Reward: 0.07042253521126618
Completed Iteration #10
Best Reward: 0.07042253521126618
Completed Iteration #11
Best Reward: 0.07042253521126618
Completed Iteration #12
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347244e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.07042253521126618 11
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.10563380281690016 24
Completed Iteration #13
Best Reward: 0.07042253521126618
Completed Iteration #14
Best Reward: 0.07042253521126618
Completed Iteration #15
Best Reward: 0.07042253521126618
Completed Iteration #16
Best Reward: 0.07042253521126618
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe34718fd0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.10563380281690016 12
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.14084507042253414 25
Completed Iteration #17
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.10563380281690016 13
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.14084507042253414 26
Completed Iteration #18
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.10563380281690016 14
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.14084507042253414 27
Completed Iteration #19
Best Reward: 0.07042253521126618
Completed Iteration #20
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.10563380281690016 15
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.14084507042253414 28
Completed Iteration #21
Best Reward: 0.07042253521126618
Completed Iteration #22
Best Reward: 0.07042253521126618
Completed Iteration #23
Best Reward: 0.07042253521126618
Completed Iteration #24
Best Reward: 0.07042253521126618
Completed Iteration #25
Best Reward: 0.07042253521126618
Completed MCTS Level/Depth: #1
root->5
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7efe34742a58> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474e4e0> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.14084507042253236 4
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.17605633802816634 16
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.21126760563380031 29
Completed Iteration #0
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.14084507042253236 5
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.17605633802816634 17
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.21126760563380031 30
Completed Iteration #1
Best Reward: 0.07042253521126618
Completed Iteration #2
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7efe34761400> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476cef0> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.21126760563379854 6
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.24647887323943252 18
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.2816901408450665 31
Completed Iteration #3
Best Reward: 0.07042253521126618
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe34761cc0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476cd30> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.24647887323943252 7
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.2816901408450665 19
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.3169014084507005 32
Completed Iteration #4
Best Reward: 0.07042253521126618
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe347185f8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe347245c0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.2816901408450665 8
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.3169014084507005 20
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.35211267605633445 33
Completed Iteration #5
Best Reward: 0.07042253521126618
Completed Iteration #6
Best Reward: 0.07042253521126618
Completed Iteration #7
Best Reward: 0.07042253521126618
Completed Iteration #8
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7efe3476cc88> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.3521126760563327 9
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.38732394366196665 21
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.42253521126760063 34
Completed Iteration #9
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474e4e0> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.3521126760563327 10
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.38732394366196665 22
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.42253521126760063 35
Completed Iteration #10
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476cd30> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.3521126760563327 11
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.38732394366196665 23
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.42253521126760063 36
Completed Iteration #11
Best Reward: 0.07042253521126618
Completed Iteration #12
Best Reward: 0.07042253521126618
Completed Iteration #13
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347334a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.3521126760563327 12
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.38732394366196665 24
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.42253521126760063 37
Completed Iteration #14
Best Reward: 0.07042253521126618
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe3476cf60> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe34733780> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.38732394366196665 13
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.42253521126760063 25
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.4577464788732346 38
Completed Iteration #15
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.38732394366196665 14
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.42253521126760063 26
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.4577464788732346 39
Completed Iteration #16
Best Reward: 0.07042253521126618
Completed Iteration #17
Best Reward: 0.07042253521126618
Completed Iteration #18
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476cef0> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.38732394366196665 15
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.42253521126760063 27
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.4577464788732346 40
Completed Iteration #19
Best Reward: 0.07042253521126618
Completed Iteration #20
Best Reward: 0.07042253521126618
Completed Iteration #21
Best Reward: 0.07042253521126618
Completed Iteration #22
Best Reward: 0.07042253521126618
Completed Iteration #23
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347337b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.38732394366196665 16
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.42253521126760063 28
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.4577464788732346 41
Completed Iteration #24
Best Reward: 0.07042253521126618
Completed Iteration #25
Best Reward: 0.07042253521126618
Completed MCTS Level/Depth: #2
root->5->16
Best Reward: 0.07042253521126618
Completed Iteration #0
Best Reward: 0.07042253521126618
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe346cbb38> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.10563380281690016 3
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.42253521126760063 17
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.4577464788732346 29
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.4929577464788686 42
Completed Iteration #1
Best Reward: 0.07042253521126618
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe346cbfd0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.14084507042253414 4
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.4577464788732346 18
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.4929577464788686 30
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.5281690140845026 43
Completed Iteration #2
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346d4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476cc88> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.14084507042253414 5
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.4577464788732346 19
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.4929577464788686 31
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.5281690140845026 44
Completed Iteration #3
Best Reward: 0.07042253521126618
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe347426a0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.1760563380281681 6
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.4929577464788686 20
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.5281690140845026 32
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.5633802816901365 45
Completed Iteration #4
Best Reward: 0.07042253521126618
Completed Iteration #5
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.2464788732394343 7
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.5633802816901348 21
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.5985915492957687 33
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.6338028169014027 46
Completed Iteration #6
Best Reward: 0.07042253521126618
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe3476c400> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.28169014084506827 8
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.5985915492957687 22
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.6338028169014027 34
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.6690140845070367 47
Completed Iteration #7
Best Reward: 0.07042253521126618
Completed Iteration #8
Best Reward: 0.07042253521126618
Completed Iteration #9
Best Reward: 0.07042253521126618
Completed Iteration #10
Best Reward: 0.07042253521126618
Completed Iteration #11
Best Reward: 0.07042253521126618
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe34733be0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe34733b70> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c400> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.31690140845070225 9
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.6338028169014027 23
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.6690140845070367 35
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.7042253521126707 48
Completed Iteration #12
Best Reward: 0.07042253521126618
Completed Iteration #13
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7efe34724b38> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.38732394366196843 10
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.7042253521126689 24
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.7394366197183029 36
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.7746478873239369 49
Completed Iteration #14
Best Reward: 0.07042253521126618
Completed Iteration #15
Best Reward: 0.07042253521126618
Completed Iteration #16
Best Reward: 0.07042253521126618
Completed Iteration #17
Best Reward: 0.07042253521126618
Completed Iteration #18
Best Reward: 0.07042253521126618
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe346d4128> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.4225352112676024 11
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.7394366197183029 25
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.7746478873239369 37
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.8098591549295708 50
Completed Iteration #19
Best Reward: 0.07042253521126618
Completed Iteration #20
Best Reward: 0.07042253521126618
Completed Iteration #21
Best Reward: 0.07042253521126618
Completed Iteration #22
Best Reward: 0.07042253521126618
Completed Iteration #23
Best Reward: 0.07042253521126618
Completed Iteration #24
Best Reward: 0.07042253521126618
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe346d4828> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.4577464788732364 12
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.7746478873239369 26
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.8098591549295708 38
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.8450704225352048 51
Completed Iteration #25
Best Reward: 0.07042253521126618
Completed MCTS Level/Depth: #3
root->5->16->4
Best Reward: 0.07042253521126618
Completed Iteration #0
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.4577464788732364 13
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.7746478873239369 27
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.8098591549295708 39
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.8450704225352048 52
Completed Iteration #1
Best Reward: 0.07042253521126618
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe346f17b8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f16d8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.10563380281690016 4
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.49295774647887036 14
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.8098591549295708 28
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.8450704225352048 40
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.8802816901408388 53
Completed Iteration #2
Best Reward: 0.07042253521126618
Completed Iteration #3
Best Reward: 0.07042253521126618
Completed Iteration #4
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.10563380281690016 5
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.49295774647887036 15
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.8098591549295708 29
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.8450704225352048 41
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.8802816901408388 54
Completed Iteration #5
Best Reward: 0.07042253521126618
Completed Iteration #6
Best Reward: 0.07042253521126618
Completed Iteration #7
Best Reward: 0.07042253521126618
Completed Iteration #8
Best Reward: 0.07042253521126618
coverage_call_count 400
Completed Iteration #9
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.10563380281690016 6
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.49295774647887036 16
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.8098591549295708 30
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.8450704225352048 42
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.8802816901408388 55
Completed Iteration #10
Best Reward: 0.07042253521126618
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe3467fb38> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467fa58> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.14084507042253414 7
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.5281690140845043 17
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.8450704225352048 31
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.8802816901408388 43
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.9154929577464728 56
Completed Iteration #11
Best Reward: 0.07042253521126618
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe347619e8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467fa58> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.1760563380281681 8
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.5633802816901383 18
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.8802816901408388 32
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.9154929577464728 44
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.9507042253521067 57
Completed Iteration #12
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347242b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.1760563380281681 9
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.5633802816901383 19
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.8802816901408388 33
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.9154929577464728 45
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 0.9507042253521067 58
Completed Iteration #13
Best Reward: 0.07042253521126618
Completed Iteration #14
Best Reward: 0.07042253521126618
Completed Iteration #15
Best Reward: 0.07042253521126618
Completed Iteration #16
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7efe34733ba8> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.2464788732394343 10
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.6338028169014045 20
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.950704225352105 34
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.985915492957739 46
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 1.021126760563373 59
Completed Iteration #17
Best Reward: 0.07042253521126618
Completed Iteration #18
Best Reward: 0.07042253521126618
Completed Iteration #19
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.2464788732394343 11
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.6338028169014045 21
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.950704225352105 35
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.985915492957739 47
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 1.021126760563373 60
Completed Iteration #20
Best Reward: 0.07042253521126618
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe34718588> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4588> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.28169014084506827 12
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.6690140845070385 22
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.985915492957739 36
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 1.021126760563373 48
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 1.056338028169007 61
Completed Iteration #21
Best Reward: 0.07042253521126618
Completed Iteration #22
Best Reward: 0.07042253521126618
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe346f1780> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 0.10563380281690016 3
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.31690140845070225 13
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.7042253521126725 23
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 1.021126760563373 37
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 1.056338028169007 49
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 1.0915492957746409 62
Completed Iteration #23
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f16d8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.31690140845070225 14
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.7042253521126725 24
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 1.021126760563373 38
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 1.056338028169007 50
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 1.0915492957746409 63
Completed Iteration #24
Best Reward: 0.07042253521126618
Completed Iteration #25
Best Reward: 0.07042253521126618
Completed MCTS Level/Depth: #4
root->5->16->4->11
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 0.10563380281690016 4
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.31690140845070225 15
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.7042253521126725 25
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 1.021126760563373 39
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 1.056338028169007 51
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 1.0915492957746409 64
Completed Iteration #0
Best Reward: 0.07042253521126618
Completed Iteration #1
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 0.10563380281690016 5
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.31690140845070225 16
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.7042253521126725 26
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 1.021126760563373 40
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 1.056338028169007 52
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 1.0915492957746409 65
Completed Iteration #2
Best Reward: 0.07042253521126618
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe346cb5f8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 0.14084507042253414 6
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.3521126760563362 17
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.7394366197183064 27
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 1.056338028169007 41
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 1.0915492957746409 53
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 1.1267605633802749 66
Completed Iteration #3
Best Reward: 0.07042253521126618
Completed Iteration #4
Best Reward: 0.07042253521126618
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe3469c4e0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 0.1760563380281681 7
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.3873239436619702 18
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.7746478873239404 28
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 1.0915492957746409 42
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 1.1267605633802749 54
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 1.1619718309859088 67
Completed Iteration #5
Best Reward: 0.07042253521126618
Completed Iteration #6
Best Reward: 0.07042253521126618
Completed Iteration #7
Best Reward: 0.07042253521126618
Completed Iteration #8
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7efe346a61d0> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469cf98> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7efe346cb5f8> 0.10563380281690016 3
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 0.2464788732394343 8
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.4577464788732364 19
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.8450704225352066 29
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 1.161971830985907 43
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 1.197183098591541 55
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 1.232394366197175 68
Completed Iteration #9
Best Reward: 0.07042253521126618
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe347426d8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 0.28169014084506827 9
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.49295774647887036 20
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.8802816901408406 30
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 1.197183098591541 44
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 1.232394366197175 56
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 1.267605633802809 69
Completed Iteration #10
Best Reward: 0.07042253521126618
Completed Iteration #11
Best Reward: 0.07042253521126618
Completed Iteration #12
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 0.28169014084506827 10
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.49295774647887036 21
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.8802816901408406 31
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 1.197183098591541 45
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 1.232394366197175 57
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 1.267605633802809 70
Completed Iteration #13
Best Reward: 0.07042253521126618
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 0.35211267605633445 11
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.5633802816901365 22
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.9507042253521067 32
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 1.2676056338028072 46
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 1.3028169014084412 58
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 1.3380281690140752 71
Completed Iteration #14
Best Reward: 0.07042253521126618
Completed Iteration #15
Best Reward: 0.07042253521126618
Completed Iteration #16
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469cf98> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7efe346cb5f8> 0.10563380281690016 4
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 0.35211267605633445 12
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.5633802816901365 23
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.9507042253521067 33
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 1.2676056338028072 47
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 1.3028169014084412 59
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 1.3380281690140752 72
Completed Iteration #17
Best Reward: 0.07042253521126618
Completed Iteration #18
Best Reward: 0.07042253521126618
Completed Iteration #19
Best Reward: 0.07042253521126618
Completed Iteration #20
Best Reward: 0.07042253521126618
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe346f1c50> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 0.38732394366196843 13
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.5985915492957705 24
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.9859154929577407 34
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 1.3028169014084412 48
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 1.3380281690140752 60
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 1.3732394366197092 73
Completed Iteration #21
Best Reward: 0.07042253521126618
Completed Iteration #22
Best Reward: 0.07042253521126618
Completed Iteration #23
Best Reward: 0.07042253521126618
Completed Iteration #24
Best Reward: 0.07042253521126618
Completed Iteration #25
Best Reward: 0.07042253521126618
Completed MCTS Level/Depth: #5
root->5->16->4->11->4
Best Reward: 0.07042253521126618
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 0.38732394366196843 14
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.5985915492957705 25
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 0.9859154929577407 35
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 1.3028169014084412 49
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 1.3380281690140752 61
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 1.3732394366197092 74
Completed Iteration #0
Best Reward: 0.07042253521126618
Completed Iteration #1
Best Reward: 0.07042253521126618
Reward: 0.10563380281690016
backprop <src.mcts.MCTS_Node object at 0x7efe346a6470> 0.10563380281690016 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724da0> 0.10563380281690016 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 0.17605633802816634 4
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 0.4929577464788686 15
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.7042253521126707 26
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 1.0915492957746409 36
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 1.4084507042253414 50
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 1.4436619718309753 62
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 1.4788732394366093 75
Completed Iteration #2
Best Reward: 0.10563380281690016
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7efe346cbf28> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724da0> 0.17605633802816634 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 0.24647887323943252 5
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 0.5633802816901348 16
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.7746478873239369 27
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 1.161971830985907 37
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 1.4788732394366075 51
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 1.5140845070422415 63
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 1.5492957746478755 76
Completed Iteration #3
Best Reward: 0.10563380281690016
Completed Iteration #4
Best Reward: 0.10563380281690016
Completed Iteration #5
Best Reward: 0.10563380281690016
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 0.24647887323943252 6
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 0.5633802816901348 17
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.7746478873239369 28
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 1.161971830985907 38
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 1.4788732394366075 52
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 1.5140845070422415 64
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 1.5492957746478755 77
Completed Iteration #6
Best Reward: 0.10563380281690016
Completed Iteration #7
Best Reward: 0.10563380281690016
Completed Iteration #8
Best Reward: 0.10563380281690016
Completed Iteration #9
Best Reward: 0.10563380281690016
Completed Iteration #10
Best Reward: 0.10563380281690016
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe346a6b38> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe346418d0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 0.2816901408450665 7
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 0.5985915492957687 18
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.8098591549295708 29
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 1.197183098591541 39
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 1.5140845070422415 53
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 1.5492957746478755 65
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 1.5845070422535095 78
Completed Iteration #11
Best Reward: 0.10563380281690016
Completed Iteration #12
Best Reward: 0.10563380281690016
Completed Iteration #13
Best Reward: 0.10563380281690016
Completed Iteration #14
Best Reward: 0.10563380281690016
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7efe346d45f8> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724da0> 0.24647887323943252 4
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 0.3521126760563327 8
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 0.6690140845070349 19
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.880281690140837 30
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 1.2676056338028072 40
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 1.5845070422535077 54
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 1.6197183098591417 66
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 1.6549295774647756 79
Completed Iteration #15
Best Reward: 0.10563380281690016
Completed Iteration #16
Best Reward: 0.10563380281690016
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7efe3469c898> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742048> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 0.42253521126759885 9
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 0.7394366197183011 20
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 0.9507042253521032 31
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 1.3380281690140734 41
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 1.6549295774647739 55
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 1.6901408450704078 67
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 1.7253521126760418 80
Completed Iteration #17
Best Reward: 0.10563380281690016
Completed Iteration #18
Best Reward: 0.10563380281690016
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7efe346f17f0> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724da0> 0.3169014084506987 5
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 0.49295774647886503 10
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 0.8098591549295673 21
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 1.0211267605633694 32
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 1.4084507042253396 42
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 1.72535211267604 56
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 1.760563380281674 68
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 1.795774647887308 81
Completed Iteration #19
Best Reward: 0.10563380281690016
Completed Iteration #20
Best Reward: 0.10563380281690016
Completed Iteration #21
Best Reward: 0.10563380281690016
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7efe346a66d8> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742048> 0.14084507042253236 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 0.5633802816901312 11
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 0.8802816901408335 22
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 1.0915492957746356 33
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 1.4788732394366058 43
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 1.7957746478873062 57
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 1.8309859154929402 69
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 1.8661971830985742 82
Completed Iteration #22
Best Reward: 0.10563380281690016
Completed Iteration #23
Best Reward: 0.10563380281690016
Completed Iteration #24
Best Reward: 0.10563380281690016
Completed Iteration #25
Best Reward: 0.10563380281690016
Completed MCTS Level/Depth: #6
root->5->16->4->11->4->1
Best Reward: 0.10563380281690016
Completed Iteration #0
Best Reward: 0.10563380281690016
Completed Iteration #1
Best Reward: 0.10563380281690016
Reward: 0.10563380281690016
backprop <src.mcts.MCTS_Node object at 0x7efe34641f98> 0.10563380281690016 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641128> 0.10563380281690016 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6470> 0.21126760563380031 3
backprop <src.mcts.MCTS_Node object at 0x7efe34724da0> 0.42253521126759885 6
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 0.6690140845070314 12
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 0.9859154929577336 23
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 1.1971830985915357 34
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 1.584507042253506 44
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 1.9014084507042064 58
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 1.9366197183098404 70
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 1.9718309859154743 83
Completed Iteration #2
Best Reward: 0.10563380281690016
Completed Iteration #3
Best Reward: 0.10563380281690016
Completed Iteration #4
Best Reward: 0.10563380281690016
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7efe346520f0> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724da0> 0.49295774647886503 7
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 0.7394366197182975 13
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 1.0563380281689998 24
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 1.267605633802802 35
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 1.654929577464772 45
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 1.9718309859154726 59
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 2.0070422535211065 71
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 2.0422535211267405 84
Completed Iteration #5
Best Reward: 0.10563380281690016
Completed Iteration #6
Best Reward: 0.10563380281690016
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe34652748> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724da0> 0.528169014084499 8
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 0.7746478873239315 14
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 1.0915492957746338 25
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 1.3028169014084359 36
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 1.690140845070406 46
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 2.0070422535211065 60
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 2.0422535211267405 72
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 2.0774647887323745 85
Completed Iteration #7
Best Reward: 0.10563380281690016
Completed Iteration #8
Best Reward: 0.10563380281690016
Completed Iteration #9
Best Reward: 0.10563380281690016
Completed Iteration #10
Best Reward: 0.10563380281690016
Completed Iteration #11
Best Reward: 0.10563380281690016
Completed Iteration #12
Best Reward: 0.10563380281690016
Completed Iteration #13
Best Reward: 0.10563380281690016
Completed Iteration #14
Best Reward: 0.10563380281690016
Completed Iteration #15
Best Reward: 0.10563380281690016
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe34658320> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724da0> 0.563380281690133 9
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 0.8098591549295655 15
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 1.1267605633802678 26
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 1.3380281690140698 37
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 1.72535211267604 47
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 2.0422535211267405 61
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 2.0774647887323745 73
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 2.1126760563380085 86
Completed Iteration #16
Best Reward: 0.10563380281690016
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe34658860> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724da0> 0.598591549295767 10
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 0.8450704225351995 16
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 1.1619718309859017 27
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 1.3732394366197038 38
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 1.760563380281674 48
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 2.0774647887323745 62
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 2.1126760563380085 74
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 2.1478873239436425 87
Completed Iteration #17
Best Reward: 0.10563380281690016
Completed Iteration #18
Best Reward: 0.10563380281690016
Completed Iteration #19
Best Reward: 0.10563380281690016
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe80> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1f60> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f17f0> 0.10563380281690016 3
backprop <src.mcts.MCTS_Node object at 0x7efe34724da0> 0.633802816901401 11
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 0.8802816901408335 17
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 1.1971830985915357 28
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 1.4084507042253378 39
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 1.795774647887308 49
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 2.1126760563380085 63
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 2.1478873239436425 75
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 2.1830985915492764 88
Completed Iteration #20
Best Reward: 0.10563380281690016
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d45f8> 0.07042253521126618 3
backprop <src.mcts.MCTS_Node object at 0x7efe34724da0> 0.633802816901401 12
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 0.8802816901408335 18
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 1.1971830985915357 29
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 1.4084507042253378 40
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 1.795774647887308 50
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 2.1126760563380085 64
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 2.1478873239436425 76
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 2.1830985915492764 89
Completed Iteration #21
Best Reward: 0.10563380281690016
Completed Iteration #22
Best Reward: 0.10563380281690016
Completed Iteration #23
Best Reward: 0.10563380281690016
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7efe34641160> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1e10> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7efe346520f0> 0.14084507042253236 3
backprop <src.mcts.MCTS_Node object at 0x7efe34724da0> 0.7042253521126671 13
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 0.9507042253520996 19
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 1.267605633802802 30
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 1.478873239436604 41
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 1.8661971830985742 51
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 2.1830985915492747 65
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 2.2183098591549086 77
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 2.2535211267605426 90
Completed Iteration #24
Best Reward: 0.10563380281690016
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe346521d0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724da0> 0.7394366197183011 14
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 0.9859154929577336 20
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 1.3028169014084359 31
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 1.514084507042238 42
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 1.9014084507042082 52
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 2.2183098591549086 66
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 2.2535211267605426 78
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 2.2887323943661766 91
Completed Iteration #25
Best Reward: 0.10563380281690016
Completed MCTS Level/Depth: #7
root->5->16->4->11->4->1->7
Best Reward: 0.10563380281690016
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34652780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6470> 0.21126760563380031 4
backprop <src.mcts.MCTS_Node object at 0x7efe34724da0> 0.7394366197183011 15
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 0.9859154929577336 21
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 1.3028169014084359 32
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 1.514084507042238 43
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 1.9014084507042082 53
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 2.2183098591549086 67
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 2.2535211267605426 79
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 2.2887323943661766 92
Completed Iteration #0
Best Reward: 0.10563380281690016
Completed Iteration #1
Best Reward: 0.10563380281690016
Reward: 0.10563380281690016
backprop <src.mcts.MCTS_Node object at 0x7efe34658710> 0.10563380281690016 2
backprop <src.mcts.MCTS_Node object at 0x7efe346584e0> 0.10563380281690016 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6470> 0.3169014084507005 5
backprop <src.mcts.MCTS_Node object at 0x7efe34724da0> 0.8450704225352013 16
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 1.0915492957746338 22
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 1.408450704225336 33
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 1.6197183098591381 44
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 2.0070422535211083 54
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 2.323943661971809 68
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 2.3591549295774428 80
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 2.3943661971830767 93
Completed Iteration #2
Best Reward: 0.10563380281690016
Completed Iteration #3
Best Reward: 0.10563380281690016
Completed Iteration #4
Best Reward: 0.10563380281690016
Reward: 0.10563380281690016
backprop <src.mcts.MCTS_Node object at 0x7efe34658b38> 0.10563380281690016 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658d68> 0.10563380281690016 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658710> 0.21126760563380031 3
backprop <src.mcts.MCTS_Node object at 0x7efe346584e0> 0.21126760563380031 3
backprop <src.mcts.MCTS_Node object at 0x7efe346a6470> 0.42253521126760063 6
backprop <src.mcts.MCTS_Node object at 0x7efe34724da0> 0.9507042253521014 17
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 1.197183098591534 23
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 1.5140845070422362 34
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 1.7253521126760383 45
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 2.1126760563380085 55
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 2.429577464788709 69
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 2.464788732394343 81
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 2.499999999999977 94
Completed Iteration #5
Best Reward: 0.10563380281690016
Completed Iteration #6
Best Reward: 0.10563380281690016
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe34677438> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677208> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6470> 0.4577464788732346 7
backprop <src.mcts.MCTS_Node object at 0x7efe34724da0> 0.9859154929577354 18
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 1.232394366197168 24
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 1.5492957746478702 35
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 1.7605633802816723 46
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 2.1478873239436425 56
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 2.464788732394343 70
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 2.499999999999977 82
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 2.535211267605611 95
Completed Iteration #7
Best Reward: 0.10563380281690016
Reward: 0.07042253521126618
backprop <src.mcts.MCTS_Node object at 0x7efe5410c748> 0.07042253521126618 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641128> 0.17605633802816634 3
backprop <src.mcts.MCTS_Node object at 0x7efe346a6470> 0.5281690140845008 8
backprop <src.mcts.MCTS_Node object at 0x7efe34724da0> 1.0563380281690016 19
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 1.302816901408434 25
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 1.6197183098591363 36
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 1.8309859154929384 47
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 2.2183098591549086 57
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 2.535211267605609 71
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 2.570422535211243 83
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 2.605633802816877 96
Completed Iteration #8
Best Reward: 0.10563380281690016
Completed Iteration #9
Best Reward: 0.10563380281690016
Completed Iteration #10
Best Reward: 0.10563380281690016
Completed Iteration #11
Best Reward: 0.10563380281690016
Completed Iteration #12
Best Reward: 0.10563380281690016
Completed Iteration #13
Best Reward: 0.10563380281690016
Completed Iteration #14
Best Reward: 0.10563380281690016
coverage_call_count 500
Completed Iteration #15
Best Reward: 0.10563380281690016
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34658c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346584e0> 0.21126760563380031 4
backprop <src.mcts.MCTS_Node object at 0x7efe346a6470> 0.5281690140845008 9
backprop <src.mcts.MCTS_Node object at 0x7efe34724da0> 1.0563380281690016 20
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 1.302816901408434 26
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 1.6197183098591363 37
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 1.8309859154929384 48
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 2.2183098591549086 58
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 2.535211267605609 72
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 2.570422535211243 84
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 2.605633802816877 97
Completed Iteration #16
Best Reward: 0.10563380281690016
Completed Iteration #17
Best Reward: 0.10563380281690016
Completed Iteration #18
Best Reward: 0.10563380281690016
Completed Iteration #19
Best Reward: 0.10563380281690016
Completed Iteration #20
Best Reward: 0.10563380281690016
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe34677588> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677198> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6470> 0.5633802816901348 10
backprop <src.mcts.MCTS_Node object at 0x7efe34724da0> 1.0915492957746356 21
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 1.338028169014068 27
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 1.6549295774647703 38
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 1.8661971830985724 49
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 2.2535211267605426 59
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 2.570422535211243 73
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 2.605633802816877 85
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 2.640845070422511 98
Completed Iteration #21
Best Reward: 0.10563380281690016
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346527f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346a6470> 0.5633802816901348 11
backprop <src.mcts.MCTS_Node object at 0x7efe34724da0> 1.0915492957746356 22
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 1.338028169014068 28
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 1.6549295774647703 39
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 1.8661971830985724 50
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 2.2535211267605426 60
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 2.570422535211243 74
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 2.605633802816877 86
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 2.640845070422511 99
Completed Iteration #22
Best Reward: 0.10563380281690016
Completed Iteration #23
Best Reward: 0.10563380281690016
Completed Iteration #24
Best Reward: 0.10563380281690016
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe34677f98> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677278> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677588> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7efe34677198> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7efe346a6470> 0.5985915492957687 12
backprop <src.mcts.MCTS_Node object at 0x7efe34724da0> 1.1267605633802695 23
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe10> 1.373239436619702 29
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ef0> 1.6901408450704043 40
backprop <src.mcts.MCTS_Node object at 0x7efe34718d30> 1.9014084507042064 51
backprop <src.mcts.MCTS_Node object at 0x7efe3476ce48> 2.2887323943661766 61
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 2.605633802816877 75
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 2.640845070422511 87
backprop <src.mcts.MCTS_Node object at 0x7efe3476c1d0> 2.676056338028145 100
Completed Iteration #25
Best Reward: 0.10563380281690016
Completed MCTS Level/Depth: #8
root->5->16->4->11->4->1->7->3
Best Reward: 0.10563380281690016
iteration: 4
found coverage increase 0.10563380281690016
Current Total Coverage 11.901408450704224
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7550> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7550> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7550> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7550> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7550> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7550> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7550> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7550> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7550> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd74e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7550> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7550> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7550> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd74e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7550> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34652470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7550> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34652710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7550> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34658ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 5
found coverage increase 0
Current Total Coverage 11.901408450704224
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34677a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54104128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54104390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541042e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe7c5d0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54104400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efecabbdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe541e5b70> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.03521126760563398 7
Completed Iteration #5
Best Reward: 0.03521126760563398
Completed Iteration #6
Best Reward: 0.03521126760563398
Completed Iteration #7
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54104278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.03521126760563398 8
Completed Iteration #8
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbdb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.03521126760563398 9
Completed Iteration #9
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541042e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.03521126760563398 10
Completed Iteration #10
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbdb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.03521126760563398 11
Completed Iteration #11
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbdb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.03521126760563398 12
Completed Iteration #12
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.03521126760563398 13
Completed Iteration #13
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efecabbddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.03521126760563398 14
Completed Iteration #14
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.03521126760563398 15
Completed Iteration #15
Best Reward: 0.03521126760563398
Completed Iteration #16
Best Reward: 0.03521126760563398
Completed Iteration #17
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346585f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54104400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.03521126760563398 16
Completed Iteration #18
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346587f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346589e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.03521126760563398 17
Completed Iteration #19
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34658748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.03521126760563398 18
Completed Iteration #20
Best Reward: 0.03521126760563398
Completed Iteration #21
Best Reward: 0.03521126760563398
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe34658320> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe346589e8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.07042253521126796 19
Completed Iteration #22
Best Reward: 0.03521126760563398
Completed Iteration #23
Best Reward: 0.03521126760563398
Completed Iteration #24
Best Reward: 0.03521126760563398
Completed Iteration #25
Best Reward: 0.03521126760563398
Completed MCTS Level/Depth: #0
root
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346413c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.07042253521126796 20
Completed Iteration #0
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34641c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.03521126760563398 5
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.07042253521126796 21
Completed Iteration #1
Best Reward: 0.03521126760563398
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe7e8a0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.03521126760563398 6
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.07042253521126796 22
Completed Iteration #2
Best Reward: 0.03521126760563398
Completed Iteration #3
Best Reward: 0.03521126760563398
Completed Iteration #4
Best Reward: 0.03521126760563398
Completed Iteration #5
Best Reward: 0.03521126760563398
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.10563380281690193 7
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.1408450704225359 23
Completed Iteration #6
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe5417cd30> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.1408450704225359 8
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.1760563380281699 24
Completed Iteration #7
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346413c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.1408450704225359 9
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.1760563380281699 25
Completed Iteration #8
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34641630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.1408450704225359 10
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.1760563380281699 26
Completed Iteration #9
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34641278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.1408450704225359 11
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.1760563380281699 27
Completed Iteration #10
Best Reward: 0.07042253521126796
Completed Iteration #11
Best Reward: 0.07042253521126796
Completed Iteration #12
Best Reward: 0.07042253521126796
Completed Iteration #13
Best Reward: 0.07042253521126796
Completed Iteration #14
Best Reward: 0.07042253521126796
Completed Iteration #15
Best Reward: 0.07042253521126796
Completed Iteration #16
Best Reward: 0.07042253521126796
Completed Iteration #17
Best Reward: 0.07042253521126796
Completed Iteration #18
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34652518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.1408450704225359 12
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.1760563380281699 28
Completed Iteration #19
Best Reward: 0.07042253521126796
Completed Iteration #20
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.1408450704225359 13
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.1760563380281699 29
Completed Iteration #21
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.1408450704225359 14
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.1760563380281699 30
Completed Iteration #22
Best Reward: 0.07042253521126796
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #1
root->1
Best Reward: 0.07042253521126796
Completed Iteration #0
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe346a6710> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6ac8> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.1408450704225359 3
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.21126760563380387 15
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.24647887323943785 31
Completed Iteration #1
Best Reward: 0.07042253521126796
Completed Iteration #2
Best Reward: 0.07042253521126796
Completed Iteration #3
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.1408450704225359 4
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.21126760563380387 16
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.24647887323943785 32
Completed Iteration #4
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34652240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.1408450704225359 5
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.21126760563380387 17
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.24647887323943785 33
Completed Iteration #5
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34652d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.1408450704225359 6
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.21126760563380387 18
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.24647887323943785 34
Completed Iteration #6
Best Reward: 0.07042253521126796
Completed Iteration #7
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe3469c0b8> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6ac8> 0.1408450704225359 3
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.21126760563380387 7
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.2816901408450718 19
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.3169014084507058 35
Completed Iteration #8
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.21126760563380387 8
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.2816901408450718 20
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.3169014084507058 36
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Completed Iteration #11
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe48> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6ac8> 0.21126760563380387 4
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.2816901408450718 9
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.3521126760563398 21
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.38732394366197376 37
Completed Iteration #12
Best Reward: 0.07042253521126796
Completed Iteration #13
Best Reward: 0.07042253521126796
Completed Iteration #14
Best Reward: 0.07042253521126796
coverage_call_count 600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.2816901408450718 10
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.3521126760563398 22
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.38732394366197376 38
Completed Iteration #15
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe3467f208> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.3521126760563398 11
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.42253521126760774 23
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.4577464788732417 39
Completed Iteration #16
Best Reward: 0.07042253521126796
Completed Iteration #17
Best Reward: 0.07042253521126796
Completed Iteration #18
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe48> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7efe346a6ac8> 0.21126760563380387 5
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.3521126760563398 12
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.42253521126760774 24
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.4577464788732417 40
Completed Iteration #19
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe34641438> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.1408450704225359 3
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.42253521126760774 13
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.4929577464788757 25
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.5281690140845097 41
Completed Iteration #20
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34652c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.42253521126760774 14
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.4929577464788757 26
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.5281690140845097 42
Completed Iteration #21
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe34652b38> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6ac8> 0.2816901408450718 6
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.4929577464788757 15
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.5633802816901436 27
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.5985915492957776 43
Completed Iteration #22
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe346a6208> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.21126760563380387 4
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.5633802816901436 16
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.6338028169014116 28
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.6690140845070456 44
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #2
root->1->16
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f208> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.21126760563380387 5
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.5633802816901436 17
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.6338028169014116 29
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.6690140845070456 45
Completed Iteration #0
Best Reward: 0.07042253521126796
Completed Iteration #1
Best Reward: 0.07042253521126796
Completed Iteration #2
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe3467feb8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.24647887323943785 6
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.5985915492957776 18
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.6690140845070456 30
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.7042253521126796 46
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Completed Iteration #5
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe3469ce10> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.2816901408450718 7
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.6338028169014116 19
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.7042253521126796 31
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.7394366197183135 47
Completed Iteration #6
Best Reward: 0.07042253521126796
Completed Iteration #7
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe346f1668> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.3169014084507058 8
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.6690140845070456 20
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.7394366197183135 32
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.7746478873239475 48
Completed Iteration #8
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe346f1710> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.3521126760563398 9
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.7042253521126796 21
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.7746478873239475 33
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.8098591549295815 49
Completed Iteration #9
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe346f18d0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.38732394366197376 10
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.7394366197183135 22
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.8098591549295815 34
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.8450704225352155 50
Completed Iteration #10
Best Reward: 0.07042253521126796
Completed Iteration #11
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe346cb7f0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe346cb438> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467feb8> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.42253521126760774 11
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.7746478873239475 23
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.8450704225352155 35
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.8802816901408494 51
Completed Iteration #12
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.4929577464788757 12
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.8450704225352155 24
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.9154929577464834 36
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.9507042253521174 52
Completed Iteration #13
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1668> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.4929577464788757 13
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.8450704225352155 25
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.9154929577464834 37
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.9507042253521174 53
Completed Iteration #14
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe346cbb38> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.5281690140845097 14
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.8802816901408494 26
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.9507042253521174 38
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.9859154929577514 54
Completed Iteration #15
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe7c5d0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641438> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.5281690140845097 15
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.8802816901408494 27
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.9507042253521174 39
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.9859154929577514 55
Completed Iteration #16
Best Reward: 0.07042253521126796
Completed Iteration #17
Best Reward: 0.07042253521126796
Completed Iteration #18
Best Reward: 0.07042253521126796
Completed Iteration #19
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1668> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.5281690140845097 16
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.8802816901408494 28
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.9507042253521174 40
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.9859154929577514 56
Completed Iteration #20
Best Reward: 0.07042253521126796
Completed Iteration #21
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6208> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.5281690140845097 17
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.8802816901408494 29
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.9507042253521174 41
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.9859154929577514 57
Completed Iteration #22
Best Reward: 0.07042253521126796
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe346a67f0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.5985915492957776 18
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.9507042253521174 30
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.0211267605633854 42
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.0563380281690193 58
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #3
root->1->16->8
Best Reward: 0.07042253521126796
Completed Iteration #0
Best Reward: 0.07042253521126796
Completed Iteration #1
Best Reward: 0.07042253521126796
Completed Iteration #2
Best Reward: 0.07042253521126796
Completed Iteration #3
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe34658208> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.1408450704225359 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.6690140845070456 19
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.0211267605633854 31
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.0915492957746533 43
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.1267605633802873 59
Completed Iteration #4
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.1408450704225359 4
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.6690140845070456 20
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.0211267605633854 32
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.0915492957746533 44
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.1267605633802873 60
Completed Iteration #5
Best Reward: 0.07042253521126796
Completed Iteration #6
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.1408450704225359 5
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.6690140845070456 21
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.0211267605633854 33
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.0915492957746533 45
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.1267605633802873 61
Completed Iteration #7
Best Reward: 0.07042253521126796
Completed Iteration #8
Best Reward: 0.07042253521126796
Completed Iteration #9
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346d4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.1408450704225359 6
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.6690140845070456 22
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.0211267605633854 34
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.0915492957746533 46
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.1267605633802873 62
Completed Iteration #10
Best Reward: 0.07042253521126796
Completed Iteration #11
Best Reward: 0.07042253521126796
Completed Iteration #12
Best Reward: 0.07042253521126796
Completed Iteration #13
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe346d4080> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.1760563380281699 7
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.7042253521126796 23
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.0563380281690193 35
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.1267605633802873 47
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.1619718309859213 63
Completed Iteration #14
Best Reward: 0.07042253521126796
Completed Iteration #15
Best Reward: 0.07042253521126796
Completed Iteration #16
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.1760563380281699 8
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.7042253521126796 24
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.0563380281690193 36
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.1267605633802873 48
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.1619718309859213 64
Completed Iteration #17
Best Reward: 0.07042253521126796
Completed Iteration #18
Best Reward: 0.07042253521126796
Completed Iteration #19
Best Reward: 0.07042253521126796
Completed Iteration #20
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34733550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.1760563380281699 9
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.7042253521126796 25
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.0563380281690193 37
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.1267605633802873 49
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.1619718309859213 65
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #4
root->1->16->8->3
Best Reward: 0.07042253521126796
Completed Iteration #0
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.1760563380281699 10
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.7042253521126796 26
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.0563380281690193 38
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.1267605633802873 50
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.1619718309859213 66
Completed Iteration #1
Best Reward: 0.07042253521126796
Completed Iteration #2
Best Reward: 0.07042253521126796
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Completed Iteration #5
Best Reward: 0.07042253521126796
Completed Iteration #6
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe34641c18> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.1760563380281699 5
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.24647887323943785 11
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.7746478873239475 27
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.1267605633802873 39
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.1971830985915553 51
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.2323943661971892 67
Completed Iteration #7
Best Reward: 0.07042253521126796
Completed Iteration #8
Best Reward: 0.07042253521126796
Completed Iteration #9
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.1760563380281699 6
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.24647887323943785 12
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.7746478873239475 28
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.1267605633802873 40
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.1971830985915553 52
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.2323943661971892 68
Completed Iteration #10
Best Reward: 0.07042253521126796
Completed Iteration #11
Best Reward: 0.07042253521126796
Completed Iteration #12
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346d4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.1760563380281699 7
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.24647887323943785 13
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.7746478873239475 29
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.1267605633802873 41
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.1971830985915553 53
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.2323943661971892 69
Completed Iteration #13
Best Reward: 0.07042253521126796
Completed Iteration #14
Best Reward: 0.07042253521126796
Completed Iteration #15
Best Reward: 0.07042253521126796
Completed Iteration #16
Best Reward: 0.07042253521126796
Completed Iteration #17
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.24647887323943785 8
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.3169014084507058 14
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.8450704225352155 30
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.1971830985915553 42
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.2676056338028232 54
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.3028169014084572 70
Completed Iteration #18
Best Reward: 0.07042253521126796
Completed Iteration #19
Best Reward: 0.07042253521126796
Completed Iteration #20
Best Reward: 0.07042253521126796
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe34724a20> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.2816901408450718 9
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.3521126760563398 15
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.8802816901408494 31
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.2323943661971892 43
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.3028169014084572 55
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.3380281690140912 71
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #5
root->1->16->8->3->0
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34718208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.2816901408450718 10
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.3521126760563398 16
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.8802816901408494 32
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.2323943661971892 44
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.3028169014084572 56
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.3380281690140912 72
Completed Iteration #0
Best Reward: 0.07042253521126796
Completed Iteration #1
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe34718860> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe347180f0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.3169014084507058 11
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.38732394366197376 17
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.9154929577464834 33
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.2676056338028232 45
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.3380281690140912 57
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.3732394366197251 73
Completed Iteration #2
Best Reward: 0.07042253521126796
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Completed Iteration #5
Best Reward: 0.07042253521126796
Completed Iteration #6
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.3169014084507058 12
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.38732394366197376 18
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.9154929577464834 34
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.2676056338028232 46
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.3380281690140912 58
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.3732394366197251 74
Completed Iteration #7
Best Reward: 0.07042253521126796
Completed Iteration #8
Best Reward: 0.07042253521126796
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Completed Iteration #11
Best Reward: 0.07042253521126796
Reward: 0.07042253521126796
backprop <src.mcts.MCTS_Node object at 0x7efe34761630> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c668> 0.07042253521126796 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.1760563380281699 6
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.38732394366197376 13
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.4577464788732417 19
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 0.9859154929577514 35
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.3380281690140912 47
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.4084507042253591 59
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.443661971830993 75
Completed Iteration #12
Best Reward: 0.07042253521126796
Completed Iteration #13
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe3474ec88> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c668> 0.10563380281690193 3
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.21126760563380387 7
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.42253521126760774 14
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.4929577464788757 20
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 1.0211267605633854 36
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.3732394366197251 48
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.443661971830993 60
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.478873239436627 76
Completed Iteration #14
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34641080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761630> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7efe3476c668> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.21126760563380387 8
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.42253521126760774 15
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.4929577464788757 21
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 1.0211267605633854 37
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.3732394366197251 49
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.443661971830993 61
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.478873239436627 77
Completed Iteration #15
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346d4c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347180f0> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.21126760563380387 9
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.42253521126760774 16
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.4929577464788757 22
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 1.0211267605633854 38
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.3732394366197251 50
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.443661971830993 62
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.478873239436627 78
Completed Iteration #16
Best Reward: 0.07042253521126796
Completed Iteration #17
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.21126760563380387 10
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.42253521126760774 17
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.4929577464788757 23
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 1.0211267605633854 39
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.3732394366197251 51
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.443661971830993 63
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.478873239436627 79
Completed Iteration #18
Best Reward: 0.07042253521126796
Completed Iteration #19
Best Reward: 0.07042253521126796
Completed Iteration #20
Best Reward: 0.07042253521126796
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Completed Iteration #23
Best Reward: 0.07042253521126796
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c668> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.21126760563380387 11
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.42253521126760774 18
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.4929577464788757 24
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 1.0211267605633854 40
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.3732394366197251 52
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.443661971830993 64
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.478873239436627 80
Completed Iteration #24
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.21126760563380387 12
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.42253521126760774 19
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.4929577464788757 25
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 1.0211267605633854 41
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.3732394366197251 53
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.443661971830993 65
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.478873239436627 81
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #6
root->1->16->8->3->0->0
Best Reward: 0.07042253521126796
Completed Iteration #0
Best Reward: 0.07042253521126796
Completed Iteration #1
Best Reward: 0.07042253521126796
Completed Iteration #2
Best Reward: 0.07042253521126796
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Completed Iteration #5
Best Reward: 0.07042253521126796
Completed Iteration #6
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe3474e9e8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c668> 0.1408450704225359 6
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.24647887323943785 13
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.4577464788732417 20
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.5281690140845097 26
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 1.0563380281690193 42
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.4084507042253591 54
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.478873239436627 66
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.514084507042261 82
Completed Iteration #7
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe3474ee48> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474ea90> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761630> 0.10563380281690193 4
backprop <src.mcts.MCTS_Node object at 0x7efe3476c668> 0.1760563380281699 7
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.2816901408450718 14
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.4929577464788757 21
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.5633802816901436 27
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 1.0915492957746533 43
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.443661971830993 55
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.514084507042261 67
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.549295774647895 83
Completed Iteration #8
Best Reward: 0.07042253521126796
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347611d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474e9e8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7efe3476c668> 0.1760563380281699 8
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.2816901408450718 15
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.4929577464788757 22
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.5633802816901436 28
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 1.0915492957746533 44
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.443661971830993 56
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.514084507042261 68
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.549295774647895 84
Completed Iteration #11
Best Reward: 0.07042253521126796
Completed Iteration #12
Best Reward: 0.07042253521126796
Completed Iteration #13
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe34742a58> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c668> 0.21126760563380387 9
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.3169014084507058 16
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.5281690140845097 23
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.5985915492957776 29
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 1.1267605633802873 45
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.478873239436627 57
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.549295774647895 69
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.584507042253529 85
Completed Iteration #14
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c668> 0.21126760563380387 10
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.3169014084507058 17
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.5281690140845097 24
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.5985915492957776 30
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 1.1267605633802873 46
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.478873239436627 58
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.549295774647895 70
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.584507042253529 86
Completed Iteration #15
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe3476c860> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe346cb358> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ba8> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7efe3476c668> 0.24647887323943785 11
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.3521126760563398 18
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.5633802816901436 25
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.6338028169014116 31
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 1.1619718309859213 47
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.514084507042261 59
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.584507042253529 71
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.619718309859163 87
Completed Iteration #16
Best Reward: 0.07042253521126796
Completed Iteration #17
Best Reward: 0.07042253521126796
Completed Iteration #18
Best Reward: 0.07042253521126796
Completed Iteration #19
Best Reward: 0.07042253521126796
Completed Iteration #20
Best Reward: 0.07042253521126796
Completed Iteration #21
Best Reward: 0.07042253521126796
Completed Iteration #22
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe3474e550> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474e7f0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474ec88> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7efe3476c668> 0.2816901408450718 12
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.38732394366197376 19
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.5985915492957776 26
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.6690140845070456 32
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 1.1971830985915553 48
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.549295774647895 60
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.619718309859163 72
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.654929577464797 88
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #7
root->1->16->8->3->0->0->0
Best Reward: 0.07042253521126796
Completed Iteration #0
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347427b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474ea90> 0.03521126760563398 3
backprop <src.mcts.MCTS_Node object at 0x7efe34761630> 0.10563380281690193 5
backprop <src.mcts.MCTS_Node object at 0x7efe3476c668> 0.2816901408450718 13
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.38732394366197376 20
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.5985915492957776 27
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.6690140845070456 33
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 1.1971830985915553 49
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.549295774647895 61
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.619718309859163 73
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.654929577464797 89
Completed Iteration #1
Best Reward: 0.07042253521126796
Completed Iteration #2
Best Reward: 0.07042253521126796
Completed Iteration #3
Best Reward: 0.07042253521126796
Completed Iteration #4
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347423c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34761630> 0.10563380281690193 6
backprop <src.mcts.MCTS_Node object at 0x7efe3476c668> 0.2816901408450718 14
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.38732394366197376 21
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.5985915492957776 28
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.6690140845070456 34
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 1.1971830985915553 50
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.549295774647895 62
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.619718309859163 74
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.654929577464797 90
Completed Iteration #5
Best Reward: 0.07042253521126796
Completed Iteration #6
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346d4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761630> 0.10563380281690193 7
backprop <src.mcts.MCTS_Node object at 0x7efe3476c668> 0.2816901408450718 15
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.38732394366197376 22
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.5985915492957776 29
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.6690140845070456 35
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 1.1971830985915553 51
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.549295774647895 63
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.619718309859163 75
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.654929577464797 91
Completed Iteration #7
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe347967b8> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796a20> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761630> 0.1408450704225359 8
backprop <src.mcts.MCTS_Node object at 0x7efe3476c668> 0.3169014084507058 16
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.42253521126760774 23
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.6338028169014116 30
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.7042253521126796 36
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 1.2323943661971892 52
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.584507042253529 64
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.654929577464797 76
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.690140845070431 92
Completed Iteration #8
Best Reward: 0.07042253521126796
Completed Iteration #9
Best Reward: 0.07042253521126796
Completed Iteration #10
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34796358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34761630> 0.1408450704225359 9
backprop <src.mcts.MCTS_Node object at 0x7efe3476c668> 0.3169014084507058 17
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.42253521126760774 24
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.6338028169014116 31
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.7042253521126796 37
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 1.2323943661971892 53
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.584507042253529 65
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.654929577464797 77
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.690140845070431 93
Completed Iteration #11
Best Reward: 0.07042253521126796
Completed Iteration #12
Best Reward: 0.07042253521126796
Completed Iteration #13
Best Reward: 0.07042253521126796
Completed Iteration #14
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347427b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3474ea90> 0.03521126760563398 4
backprop <src.mcts.MCTS_Node object at 0x7efe34761630> 0.1408450704225359 10
backprop <src.mcts.MCTS_Node object at 0x7efe3476c668> 0.3169014084507058 18
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.42253521126760774 25
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.6338028169014116 32
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.7042253521126796 38
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 1.2323943661971892 54
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.584507042253529 66
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.654929577464797 78
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.690140845070431 94
Completed Iteration #15
Best Reward: 0.07042253521126796
Completed Iteration #16
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe347428d0> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742c50> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761630> 0.1760563380281699 11
backprop <src.mcts.MCTS_Node object at 0x7efe3476c668> 0.3521126760563398 19
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.4577464788732417 26
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.6690140845070456 33
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.7394366197183135 39
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 1.2676056338028232 55
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.619718309859163 67
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.690140845070431 79
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.725352112676065 95
Completed Iteration #17
Best Reward: 0.07042253521126796
Completed Iteration #18
Best Reward: 0.07042253521126796
Completed Iteration #19
Best Reward: 0.07042253521126796
Completed Iteration #20
Best Reward: 0.07042253521126796
Completed Iteration #21
Best Reward: 0.07042253521126796
Reward: 0.03521126760563398
backprop <src.mcts.MCTS_Node object at 0x7efe346d4f98> 0.03521126760563398 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796a20> 0.07042253521126796 3
backprop <src.mcts.MCTS_Node object at 0x7efe34761630> 0.21126760563380387 12
backprop <src.mcts.MCTS_Node object at 0x7efe3476c668> 0.38732394366197376 20
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.4929577464788757 27
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.7042253521126796 34
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.7746478873239475 40
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 1.3028169014084572 56
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.654929577464797 68
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.725352112676065 80
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.760563380281699 96
Completed Iteration #22
Best Reward: 0.07042253521126796
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34796240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796a20> 0.07042253521126796 4
backprop <src.mcts.MCTS_Node object at 0x7efe34761630> 0.21126760563380387 13
backprop <src.mcts.MCTS_Node object at 0x7efe3476c668> 0.38732394366197376 21
backprop <src.mcts.MCTS_Node object at 0x7efe346d4898> 0.4929577464788757 28
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.7042253521126796 35
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.7746478873239475 41
backprop <src.mcts.MCTS_Node object at 0x7efe3467f780> 1.3028169014084572 57
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 1.654929577464797 69
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 1.725352112676065 81
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 1.760563380281699 97
Completed Iteration #23
Best Reward: 0.07042253521126796
Completed Iteration #24
Best Reward: 0.07042253521126796
Completed Iteration #25
Best Reward: 0.07042253521126796
Completed MCTS Level/Depth: #8
root->1->16->8->3->0->0->0->10
Best Reward: 0.07042253521126796
iteration: 6
found coverage increase 0.07042253521126796
Current Total Coverage 11.971830985915492
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6668> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6668> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6668> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347b6668> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347b6668> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6668> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347b6668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347b6668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe347b6668> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347b6668> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347eeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6668> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efecabc3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6668> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6668> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347b6668> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34742dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347b6668> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34742940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efe347b6668> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34742f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347b6668> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347962e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347b6668> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 11.971830985915492
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34796b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347966d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34742be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796550> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796550> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796550> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ee6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796550> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796550> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34796550> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347eedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34796550> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5410c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796550> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ee320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34796550> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796550> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ee6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796550> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347966d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34796550> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34796550> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347966d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34796550> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347966d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe34796550> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ee668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34796550> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 11.971830985915492
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1b70> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347cae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347cac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ca208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1b70> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ca128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1b70> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ca780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ca2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1b70> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ca978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1b70> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ca208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1b70> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347333c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1b70> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347eef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347d1b70> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1b70> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ca1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347cae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1b70> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34742438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ca208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347d1b70> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ca710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1b70> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ca9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347333c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34742a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1b70> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347cae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1b70> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ca2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1b70> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347d1b70> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ca668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347cae10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347d1b70> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ca630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347d1b70> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe347d1b70> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe347d1b70> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 11.971830985915492
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347eeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1518> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5410c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347eedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1518> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34796b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1518> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34742940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1518> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1518> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1518> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347caf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347eedd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1518> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347d1518> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1518> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe347d1518> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1518> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474eda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347d1518> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347eedd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347d1518> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346d4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee0f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efe347d1518> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347eedd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe347d1518> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34742cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347cad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1518> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 11.971830985915492
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1668> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1668> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1668> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1668> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1668> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1668> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ee860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1668> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1668> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347d1668> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe347d1668> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1668> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1668> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1668> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1668> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474ea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347d1668> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540125c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1668> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540120f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1668> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1668> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540125f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1668> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540127b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540120f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1668> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1668> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 11.971830985915492
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540122e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540122e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540128d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540122e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540122e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540122e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540122e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540122e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540744a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540122e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540742b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540122e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540128d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540122e8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540122e8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540122e8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540122e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540122e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540122e8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540122e8> 0.0 17
Completed Iteration #23
Best Reward: 0
coverage_call_count 900
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe540122e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 11.971830985915492
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540044a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe54004208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540124e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540043c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004208> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540044a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe54004208> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004208> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004208> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54088be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004208> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe54004208> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540883c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004208> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe54004208> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe54004208> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540044a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe54004208> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540742b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540883c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe54004208> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540883c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe54004208> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540883c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe54004208> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54088be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe54004208> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe54004208> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 11.971830985915492
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540125f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 3
Completed Iteration #1
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 4
Completed Iteration #2
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 5
Completed Iteration #3
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 6
Completed Iteration #4
Best Reward: 0.035211267605635754
Completed Iteration #5
Best Reward: 0.035211267605635754
Completed Iteration #6
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540045f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 7
Completed Iteration #7
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 8
Completed Iteration #8
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34761908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 9
Completed Iteration #9
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540125f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 10
Completed Iteration #10
Best Reward: 0.035211267605635754
Completed Iteration #11
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 11
Completed Iteration #12
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ca5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 12
Completed Iteration #13
Best Reward: 0.035211267605635754
Completed Iteration #14
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efecabc3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 13
Completed Iteration #15
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.035211267605635754 4
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 14
Completed Iteration #16
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 15
Completed Iteration #17
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34742be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 16
Completed Iteration #18
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540125f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 17
Completed Iteration #19
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 18
Completed Iteration #20
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347eedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 19
Completed Iteration #21
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ee3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 20
Completed Iteration #22
Best Reward: 0.035211267605635754
Completed Iteration #23
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.035211267605635754 5
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 21
Completed Iteration #24
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34796b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 22
Completed Iteration #25
Best Reward: 0.035211267605635754
Completed MCTS Level/Depth: #0
root
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.035211267605635754 6
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 23
Completed Iteration #0
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.035211267605635754 7
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 24
Completed Iteration #1
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.035211267605635754 8
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 25
Completed Iteration #2
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540880f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.035211267605635754 9
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 26
Completed Iteration #3
Best Reward: 0.035211267605635754
Completed Iteration #4
Best Reward: 0.035211267605635754
Completed Iteration #5
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54055470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.035211267605635754 10
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 27
Completed Iteration #6
Best Reward: 0.035211267605635754
Completed Iteration #7
Best Reward: 0.035211267605635754
Completed Iteration #8
Best Reward: 0.035211267605635754
Completed Iteration #9
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.035211267605635754 11
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 28
Completed Iteration #10
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54055518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.035211267605635754 12
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 29
Completed Iteration #11
Best Reward: 0.035211267605635754
Completed Iteration #12
Best Reward: 0.035211267605635754
Completed Iteration #13
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54146470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.035211267605635754 13
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 30
Completed Iteration #14
Best Reward: 0.035211267605635754
Completed Iteration #15
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54146470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.035211267605635754 14
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 31
Completed Iteration #16
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.035211267605635754 15
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 32
Completed Iteration #17
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.035211267605635754 16
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 33
Completed Iteration #18
Best Reward: 0.035211267605635754
Completed Iteration #19
Best Reward: 0.035211267605635754
Completed Iteration #20
Best Reward: 0.035211267605635754
Completed Iteration #21
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5410c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.035211267605635754 17
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 34
Completed Iteration #22
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.035211267605635754 18
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 35
Completed Iteration #23
Best Reward: 0.035211267605635754
Completed Iteration #24
Best Reward: 0.035211267605635754
Completed Iteration #25
Best Reward: 0.035211267605635754
Completed MCTS Level/Depth: #1
root->2
Best Reward: 0.035211267605635754
Completed Iteration #0
Best Reward: 0.035211267605635754
Completed Iteration #1
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54055da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54088c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.035211267605635754 4
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.035211267605635754 19
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 36
Completed Iteration #2
Best Reward: 0.035211267605635754
Completed Iteration #3
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54055be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.035211267605635754 5
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.035211267605635754 20
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.035211267605635754 37
Completed Iteration #4
Best Reward: 0.035211267605635754
Completed Iteration #5
Best Reward: 0.035211267605635754
Completed Iteration #6
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.07042253521127151 6
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.07042253521127151 21
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.07042253521127151 38
Completed Iteration #7
Best Reward: 0.035211267605635754
Completed Iteration #8
Best Reward: 0.035211267605635754
Completed Iteration #9
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.07042253521127151 7
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.07042253521127151 22
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.07042253521127151 39
Completed Iteration #10
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.07042253521127151 8
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.07042253521127151 23
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.07042253521127151 40
Completed Iteration #11
Best Reward: 0.035211267605635754
Completed Iteration #12
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54088c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.07042253521127151 9
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.07042253521127151 24
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.07042253521127151 41
Completed Iteration #13
Best Reward: 0.035211267605635754
Completed Iteration #14
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.07042253521127151 10
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.07042253521127151 25
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.07042253521127151 42
Completed Iteration #15
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.07042253521127151 11
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.07042253521127151 26
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.07042253521127151 43
Completed Iteration #16
Best Reward: 0.035211267605635754
Completed Iteration #17
Best Reward: 0.035211267605635754
Completed Iteration #18
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.07042253521127151 12
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.07042253521127151 27
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.07042253521127151 44
Completed Iteration #19
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.07042253521127151 13
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.07042253521127151 28
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.07042253521127151 45
Completed Iteration #20
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe7e872940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.07042253521127151 14
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.07042253521127151 29
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.07042253521127151 46
Completed Iteration #21
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efe541a6fd0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742ba8> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.10563380281690726 15
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.10563380281690726 30
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.10563380281690726 47
Completed Iteration #22
Best Reward: 0.035211267605635754
Completed Iteration #23
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efe7c52e978> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055748> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.14084507042254302 16
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.14084507042254302 31
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.14084507042254302 48
Completed Iteration #24
Best Reward: 0.035211267605635754
coverage_call_count 1000
Completed Iteration #25
Best Reward: 0.035211267605635754
Completed MCTS Level/Depth: #2
root->2->18
Best Reward: 0.035211267605635754
Completed Iteration #0
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efe5403c908> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.07042253521127151 4
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.17605633802817877 17
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.17605633802817877 32
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.17605633802817877 49
Completed Iteration #1
Best Reward: 0.035211267605635754
Completed Iteration #2
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.07042253521127151 5
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.17605633802817877 18
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.17605633802817877 33
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.17605633802817877 50
Completed Iteration #3
Best Reward: 0.035211267605635754
Completed Iteration #4
Best Reward: 0.035211267605635754
Completed Iteration #5
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efe540b1be0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe540b1978> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.07042253521127151 4
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.10563380281690726 6
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.21126760563381453 19
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.21126760563381453 34
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.21126760563381453 51
Completed Iteration #6
Best Reward: 0.035211267605635754
Completed Iteration #7
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efe541a6cf8> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.14084507042254302 7
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.24647887323945028 20
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.24647887323945028 35
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.24647887323945028 52
Completed Iteration #8
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efe540a48d0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.17605633802817877 8
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.28169014084508603 21
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.28169014084508603 36
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.28169014084508603 53
Completed Iteration #9
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efe541468d0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.21126760563381453 9
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.3169014084507218 22
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.3169014084507218 37
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.3169014084507218 54
Completed Iteration #10
Best Reward: 0.035211267605635754
Completed Iteration #11
Best Reward: 0.035211267605635754
Completed Iteration #12
Best Reward: 0.035211267605635754
Completed Iteration #13
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efe7c52e9b0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.24647887323945028 10
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.35211267605635754 23
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.35211267605635754 38
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.35211267605635754 55
Completed Iteration #14
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346773c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a48d0> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.24647887323945028 11
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.35211267605635754 24
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.35211267605635754 39
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.35211267605635754 56
Completed Iteration #15
Best Reward: 0.035211267605635754
Completed Iteration #16
Best Reward: 0.035211267605635754
Completed Iteration #17
Best Reward: 0.035211267605635754
Completed Iteration #18
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346776a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c908> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.24647887323945028 12
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.35211267605635754 25
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.35211267605635754 40
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.35211267605635754 57
Completed Iteration #19
Best Reward: 0.035211267605635754
Completed Iteration #20
Best Reward: 0.035211267605635754
Completed Iteration #21
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7be0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.28169014084508603 13
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.3873239436619933 26
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.3873239436619933 41
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.3873239436619933 58
Completed Iteration #22
Best Reward: 0.035211267605635754
Completed Iteration #23
Best Reward: 0.035211267605635754
Completed Iteration #24
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.28169014084508603 14
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.3873239436619933 27
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.3873239436619933 42
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.3873239436619933 59
Completed Iteration #25
Best Reward: 0.035211267605635754
Completed MCTS Level/Depth: #3
root->2->18->0
Best Reward: 0.035211267605635754
Completed Iteration #0
Best Reward: 0.035211267605635754
Completed Iteration #1
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.10563380281690726 5
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.3169014084507218 15
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.42253521126762905 28
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.42253521126762905 43
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.42253521126762905 60
Completed Iteration #2
Best Reward: 0.035211267605635754
Completed Iteration #3
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5198> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.07042253521127151 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.14084507042254302 6
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.35211267605635754 16
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.4577464788732648 29
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.4577464788732648 44
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.4577464788732648 61
Completed Iteration #4
Best Reward: 0.035211267605635754
Completed Iteration #5
Best Reward: 0.035211267605635754
Completed Iteration #6
Best Reward: 0.035211267605635754
Completed Iteration #7
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.14084507042254302 7
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.35211267605635754 17
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.4577464788732648 30
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.4577464788732648 45
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.4577464788732648 62
Completed Iteration #8
Best Reward: 0.035211267605635754
Completed Iteration #9
Best Reward: 0.035211267605635754
Completed Iteration #10
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efe7c52e748> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe540b1978> 0.07042253521127151 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.17605633802817877 8
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.3873239436619933 18
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.49295774647890056 31
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.49295774647890056 46
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.49295774647890056 63
Completed Iteration #11
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efe3478f278> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a60f0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.21126760563381453 9
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.42253521126762905 19
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.5281690140845363 32
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.5281690140845363 47
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.5281690140845363 64
Completed Iteration #12
Best Reward: 0.035211267605635754
Completed Iteration #13
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efe34677c50> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a60f0> 0.07042253521127151 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.24647887323945028 10
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.4577464788732648 20
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.5633802816901721 33
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.5633802816901721 48
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.5633802816901721 65
Completed Iteration #14
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7eb8> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe540b1978> 0.10563380281690726 4
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.28169014084508603 11
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.49295774647890056 21
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.5985915492958078 34
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.5985915492958078 49
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.5985915492958078 66
Completed Iteration #15
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a60f0> 0.07042253521127151 4
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.28169014084508603 12
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.49295774647890056 22
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.5985915492958078 35
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.5985915492958078 50
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.5985915492958078 67
Completed Iteration #16
Best Reward: 0.035211267605635754
Completed Iteration #17
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34677898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.28169014084508603 13
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.49295774647890056 23
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.5985915492958078 36
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.5985915492958078 51
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.5985915492958078 68
Completed Iteration #18
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540b1978> 0.10563380281690726 5
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.28169014084508603 14
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.49295774647890056 24
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.5985915492958078 37
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.5985915492958078 52
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.5985915492958078 69
Completed Iteration #19
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5240> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.07042253521127151 3
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.10563380281690726 4
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.3169014084507218 15
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.5281690140845363 25
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.6338028169014436 38
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.6338028169014436 53
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.6338028169014436 70
Completed Iteration #20
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5ac8> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.14084507042254302 5
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.35211267605635754 16
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.5633802816901721 26
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.6690140845070793 39
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.6690140845070793 54
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.6690140845070793 71
Completed Iteration #21
Best Reward: 0.035211267605635754
Completed Iteration #22
Best Reward: 0.035211267605635754
Completed Iteration #23
Best Reward: 0.035211267605635754
Completed Iteration #24
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5b38> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a60f0> 0.10563380281690726 5
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.3873239436619933 17
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.5985915492958078 27
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.7042253521127151 40
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.7042253521127151 55
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.7042253521127151 72
Completed Iteration #25
Best Reward: 0.035211267605635754
Completed MCTS Level/Depth: #4
root->2->18->0->0
Best Reward: 0.035211267605635754
Completed Iteration #0
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.14084507042254302 6
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.3873239436619933 18
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.5985915492958078 28
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.7042253521127151 41
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.7042253521127151 56
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.7042253521127151 73
Completed Iteration #1
Best Reward: 0.035211267605635754
Completed Iteration #2
Best Reward: 0.035211267605635754
Completed Iteration #3
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efe541a6898> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.17605633802817877 7
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.42253521126762905 19
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.6338028169014436 29
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.7394366197183508 42
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.7394366197183508 57
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.7394366197183508 74
Completed Iteration #4
Best Reward: 0.035211267605635754
Completed Iteration #5
Best Reward: 0.035211267605635754
Completed Iteration #6
Best Reward: 0.035211267605635754
Completed Iteration #7
Best Reward: 0.035211267605635754
Completed Iteration #8
Best Reward: 0.035211267605635754
Completed Iteration #9
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdfafe52e8> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.21126760563381453 8
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.4577464788732648 20
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.6690140845070793 30
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.7746478873239866 43
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.7746478873239866 58
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.7746478873239866 75
Completed Iteration #10
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a6898> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.21126760563381453 9
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.4577464788732648 21
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.6690140845070793 31
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.7746478873239866 44
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.7746478873239866 59
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.7746478873239866 76
Completed Iteration #11
Best Reward: 0.035211267605635754
Completed Iteration #12
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff978> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.24647887323945028 10
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.49295774647890056 22
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.7042253521127151 32
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.8098591549296223 45
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.8098591549296223 60
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.8098591549296223 77
Completed Iteration #13
Best Reward: 0.035211267605635754
Completed Iteration #14
Best Reward: 0.035211267605635754
Completed Iteration #15
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdf80ffa20> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ffcc0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff438> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.28169014084508603 11
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.5281690140845363 23
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.7394366197183508 33
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.8450704225352581 46
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.8450704225352581 61
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.8450704225352581 78
Completed Iteration #16
Best Reward: 0.035211267605635754
Completed Iteration #17
Best Reward: 0.035211267605635754
Completed Iteration #18
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5a20> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677588> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.10563380281690726 4
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.3169014084507218 12
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.5633802816901721 24
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.7746478873239866 34
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.8802816901408939 47
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.8802816901408939 62
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.8802816901408939 79
Completed Iteration #19
Best Reward: 0.035211267605635754
Completed Iteration #20
Best Reward: 0.035211267605635754
Completed Iteration #21
Best Reward: 0.035211267605635754
Completed Iteration #22
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdf81188d0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.35211267605635754 13
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.5985915492958078 25
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.8098591549296223 35
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.9154929577465296 48
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.9154929577465296 63
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.9154929577465296 80
Completed Iteration #23
Best Reward: 0.035211267605635754
Completed Iteration #24
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff438> 0.035211267605635754 4
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.35211267605635754 14
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.5985915492958078 26
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.8098591549296223 36
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.9154929577465296 49
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.9154929577465296 64
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.9154929577465296 81
Completed Iteration #25
Best Reward: 0.035211267605635754
Completed MCTS Level/Depth: #5
root->2->18->0->0->0
Best Reward: 0.035211267605635754
Completed Iteration #0
Best Reward: 0.035211267605635754
Completed Iteration #1
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdf8121588> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677588> 0.07042253521127151 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.14084507042254302 5
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.3873239436619933 15
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.6338028169014436 27
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.8450704225352581 37
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.9507042253521654 50
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.9507042253521654 65
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.9507042253521654 82
Completed Iteration #2
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.14084507042254302 6
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.3873239436619933 16
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.6338028169014436 28
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.8450704225352581 38
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.9507042253521654 51
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.9507042253521654 66
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.9507042253521654 83
Completed Iteration #3
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.14084507042254302 7
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.3873239436619933 17
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.6338028169014436 29
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.8450704225352581 39
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.9507042253521654 52
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.9507042253521654 67
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.9507042253521654 84
Completed Iteration #4
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.14084507042254302 8
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.3873239436619933 18
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.6338028169014436 30
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.8450704225352581 40
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.9507042253521654 53
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.9507042253521654 68
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.9507042253521654 85
Completed Iteration #5
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdf80fff98> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a65c0> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.17605633802817877 9
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.42253521126762905 19
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.6690140845070793 31
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.8802816901408939 41
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.9859154929578011 54
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.9859154929578011 69
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.9859154929578011 86
Completed Iteration #6
Best Reward: 0.035211267605635754
Completed Iteration #7
Best Reward: 0.035211267605635754
Completed Iteration #8
Best Reward: 0.035211267605635754
Completed Iteration #9
Best Reward: 0.035211267605635754
Completed Iteration #10
Best Reward: 0.035211267605635754
Completed Iteration #11
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf81184e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.17605633802817877 10
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.42253521126762905 20
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.6690140845070793 32
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.8802816901408939 42
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.9859154929578011 55
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 0.9859154929578011 70
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.9859154929578011 87
Completed Iteration #12
Best Reward: 0.035211267605635754
Completed Iteration #13
Best Reward: 0.035211267605635754
Completed Iteration #14
Best Reward: 0.035211267605635754
Completed Iteration #15
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdf81187f0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677588> 0.10563380281690726 4
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.21126760563381453 11
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.4577464788732648 21
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.7042253521127151 33
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.9154929577465296 43
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.0211267605634369 56
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.0211267605634369 71
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.0211267605634369 88
Completed Iteration #16
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.21126760563381453 12
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.4577464788732648 22
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.7042253521127151 34
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.9154929577465296 44
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.0211267605634369 57
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.0211267605634369 72
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.0211267605634369 89
Completed Iteration #17
Best Reward: 0.035211267605635754
Completed Iteration #18
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdf8121e80> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.07042253521127151 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.24647887323945028 13
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.49295774647890056 23
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.7394366197183508 35
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.9507042253521654 45
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.0563380281690726 58
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.0563380281690726 73
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.0563380281690726 90
Completed Iteration #19
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.24647887323945028 14
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.49295774647890056 24
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.7394366197183508 36
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.9507042253521654 46
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.0563380281690726 59
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.0563380281690726 74
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.0563380281690726 91
Completed Iteration #20
Best Reward: 0.035211267605635754
Completed Iteration #21
Best Reward: 0.035211267605635754
Completed Iteration #22
Best Reward: 0.035211267605635754
Completed Iteration #23
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdf8121e48> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.10563380281690726 4
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.28169014084508603 15
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.5281690140845363 25
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.7746478873239866 37
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.9859154929578011 47
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.0915492957747084 60
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.0915492957747084 75
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.0915492957747084 92
Completed Iteration #24
Best Reward: 0.035211267605635754
Completed Iteration #25
Best Reward: 0.035211267605635754
Completed MCTS Level/Depth: #6
root->2->18->0->0->0->2
Best Reward: 0.035211267605635754
coverage_call_count 1100
Completed Iteration #0
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd0b8> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.14084507042254302 5
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.3169014084507218 16
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.5633802816901721 26
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.8098591549296223 38
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 1.0211267605634369 48
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.1267605633803441 61
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.1267605633803441 76
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.1267605633803441 93
Completed Iteration #1
Best Reward: 0.035211267605635754
Completed Iteration #2
Best Reward: 0.035211267605635754
Completed Iteration #3
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff588> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.17605633802817877 6
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.35211267605635754 17
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.5985915492958078 27
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.8450704225352581 39
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 1.0563380281690726 49
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.16197183098598 62
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.16197183098598 77
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.16197183098598 94
Completed Iteration #4
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdf81189b0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.21126760563381453 7
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.3873239436619933 18
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.6338028169014436 28
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.8802816901408939 40
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 1.0915492957747084 50
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.1971830985916156 63
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.1971830985916156 78
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.1971830985916156 95
Completed Iteration #5
Best Reward: 0.035211267605635754
Completed Iteration #6
Best Reward: 0.035211267605635754
Completed Iteration #7
Best Reward: 0.035211267605635754
Completed Iteration #8
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efe54055588> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.24647887323945028 8
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.42253521126762905 19
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.6690140845070793 29
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.9154929577465296 41
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 1.1267605633803441 51
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.2323943661972514 64
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.2323943661972514 79
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.2323943661972514 96
Completed Iteration #9
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdf81219b0> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677320> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055588> 0.07042253521127151 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.28169014084508603 9
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.4577464788732648 20
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.7042253521127151 30
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.9507042253521654 42
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 1.16197183098598 52
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.2676056338028872 65
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.2676056338028872 80
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.2676056338028872 97
Completed Iteration #10
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.28169014084508603 10
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.4577464788732648 21
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.7042253521127151 31
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.9507042253521654 43
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 1.16197183098598 53
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.2676056338028872 66
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.2676056338028872 81
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.2676056338028872 98
Completed Iteration #11
Best Reward: 0.035211267605635754
Completed Iteration #12
Best Reward: 0.035211267605635754
Completed Iteration #13
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055588> 0.07042253521127151 4
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.28169014084508603 11
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.4577464788732648 22
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.7042253521127151 32
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.9507042253521654 44
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 1.16197183098598 54
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.2676056338028872 67
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.2676056338028872 82
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.2676056338028872 99
Completed Iteration #14
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.28169014084508603 12
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.4577464788732648 23
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.7042253521127151 33
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.9507042253521654 45
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 1.16197183098598 55
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.2676056338028872 68
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.2676056338028872 83
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.2676056338028872 100
Completed Iteration #15
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.28169014084508603 13
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.4577464788732648 24
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.7042253521127151 34
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.9507042253521654 46
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 1.16197183098598 56
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.2676056338028872 69
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.2676056338028872 84
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.2676056338028872 101
Completed Iteration #16
Best Reward: 0.035211267605635754
Completed Iteration #17
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.28169014084508603 14
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.4577464788732648 25
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.7042253521127151 35
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.9507042253521654 47
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 1.16197183098598 57
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.2676056338028872 70
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.2676056338028872 85
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.2676056338028872 102
Completed Iteration #18
Best Reward: 0.035211267605635754
Completed Iteration #19
Best Reward: 0.035211267605635754
Completed Iteration #20
Best Reward: 0.035211267605635754
Completed Iteration #21
Best Reward: 0.035211267605635754
Completed Iteration #22
Best Reward: 0.035211267605635754
Completed Iteration #23
Best Reward: 0.035211267605635754
Completed Iteration #24
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ffef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5240> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.28169014084508603 15
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.4577464788732648 26
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.7042253521127151 36
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.9507042253521654 48
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 1.16197183098598 58
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.2676056338028872 71
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.2676056338028872 86
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.2676056338028872 103
Completed Iteration #25
Best Reward: 0.035211267605635754
Completed MCTS Level/Depth: #7
root->2->18->0->0->0->2->3
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff588> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.28169014084508603 16
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.4577464788732648 27
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.7042253521127151 37
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.9507042253521654 49
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 1.16197183098598 59
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.2676056338028872 72
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.2676056338028872 87
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.2676056338028872 104
Completed Iteration #0
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1c88> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1e80> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff588> 0.07042253521127151 4
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.3169014084507218 17
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.49295774647890056 28
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.7394366197183508 38
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.9859154929578011 50
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 1.1971830985916156 60
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.302816901408523 73
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.302816901408523 88
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.302816901408523 105
Completed Iteration #1
Best Reward: 0.035211267605635754
Completed Iteration #2
Best Reward: 0.035211267605635754
Completed Iteration #3
Best Reward: 0.035211267605635754
Completed Iteration #4
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff588> 0.07042253521127151 5
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.3169014084507218 18
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.49295774647890056 29
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.7394366197183508 39
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.9859154929578011 51
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 1.1971830985916156 61
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.302816901408523 74
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.302816901408523 89
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.302816901408523 106
Completed Iteration #5
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1e80> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff588> 0.07042253521127151 6
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.3169014084507218 19
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.49295774647890056 30
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.7394366197183508 40
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 0.9859154929578011 52
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 1.1971830985916156 62
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.302816901408523 75
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.302816901408523 90
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.302816901408523 107
Completed Iteration #6
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8208> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1e80> 0.07042253521127151 4
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff588> 0.10563380281690726 7
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.35211267605635754 20
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.5281690140845363 31
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.7746478873239866 41
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 1.0211267605634369 53
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 1.2323943661972514 63
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.3380281690141587 76
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.3380281690141587 91
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.3380281690141587 108
Completed Iteration #7
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdf80cdb00> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1e80> 0.10563380281690726 5
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff588> 0.14084507042254302 8
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.3873239436619933 21
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.5633802816901721 32
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.8098591549296223 42
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 1.0563380281690726 54
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 1.2676056338028872 64
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.3732394366197944 77
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.3732394366197944 92
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.3732394366197944 109
Completed Iteration #8
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff588> 0.14084507042254302 9
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.3873239436619933 22
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.5633802816901721 33
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.8098591549296223 43
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 1.0563380281690726 55
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 1.2676056338028872 65
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.3732394366197944 78
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.3732394366197944 93
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.3732394366197944 110
Completed Iteration #9
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1e80> 0.10563380281690726 6
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff588> 0.14084507042254302 10
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.3873239436619933 23
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.5633802816901721 34
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.8098591549296223 44
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 1.0563380281690726 56
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 1.2676056338028872 66
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.3732394366197944 79
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.3732394366197944 94
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.3732394366197944 111
Completed Iteration #10
Best Reward: 0.035211267605635754
Completed Iteration #11
Best Reward: 0.035211267605635754
Completed Iteration #12
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdf80cda90> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5f98> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff588> 0.17605633802817877 11
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.42253521126762905 24
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.5985915492958078 35
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.8450704225352581 45
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 1.0915492957747084 57
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 1.302816901408523 67
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.4084507042254302 80
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.4084507042254302 95
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.4084507042254302 112
Completed Iteration #13
Best Reward: 0.035211267605635754
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5f98> 0.035211267605635754 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff588> 0.17605633802817877 12
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.42253521126762905 25
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.5985915492958078 36
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.8450704225352581 46
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 1.0915492957747084 58
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 1.302816901408523 68
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.4084507042254302 81
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.4084507042254302 96
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.4084507042254302 113
Completed Iteration #14
Best Reward: 0.035211267605635754
Completed Iteration #15
Best Reward: 0.035211267605635754
Completed Iteration #16
Best Reward: 0.035211267605635754
Completed Iteration #17
Best Reward: 0.035211267605635754
Reward: 0.035211267605635754
backprop <src.mcts.MCTS_Node object at 0x7efdf80cdf28> 0.035211267605635754 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1e80> 0.14084507042254302 7
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff588> 0.21126760563381453 13
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.4577464788732648 26
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.6338028169014436 37
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.8802816901408939 47
backprop <src.mcts.MCTS_Node object at 0x7efe540a4588> 1.1267605633803441 59
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 1.3380281690141587 69
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 1.443661971831066 82
backprop <src.mcts.MCTS_Node object at 0x7efe5402e208> 1.443661971831066 97
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 1.443661971831066 114
Completed Iteration #18
Best Reward: 0.035211267605635754
Completed Iteration #19
Best Reward: 0.035211267605635754
Completed Iteration #20
Best Reward: 0.035211267605635754
Completed Iteration #21
Best Reward: 0.035211267605635754
Completed Iteration #22
Best Reward: 0.035211267605635754
Completed Iteration #23
Best Reward: 0.035211267605635754
Completed Iteration #24
Best Reward: 0.035211267605635754
Completed Iteration #25
Best Reward: 0.035211267605635754
Completed MCTS Level/Depth: #8
root->2->18->0->0->0->2->3->1
Best Reward: 0.035211267605635754
iteration: 14
found coverage increase 0.035211267605635754
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8780> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8780> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8780> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8780> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8780> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80890f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8780> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80895c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8780> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8780> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8780> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8780> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8780> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f87f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8780> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8780> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8780> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80fffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b710> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf809b710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c17b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf809b710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c17b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf809b710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b710> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b710> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b710> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf809b710> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80896a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b710> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf809b710> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b710> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdf809b710> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdf809b710> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf809b710> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf809b710> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c17b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdf809b710> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a67f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf809b710> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf809b710> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048588> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 1200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80486a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048588> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048588> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80fffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80487f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8048588> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80487f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf8048588> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048588> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8048588> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048588> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8048588> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8048588> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf8048588> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf8048588> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdf8048588> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048588> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80487f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdf8048588> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdf8048588> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809ba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048588> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80892b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e89e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f80b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f80b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c16d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8780> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c16d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d748> 0.0 2
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d748> 0.0 3
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d748> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d748> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d748> 0.0 6
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf806d748> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80895f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d748> 0.0 8
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf806d748> 0.0 9
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80489e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf806d748> 0.0 10
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf806d748> 0.0 11
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf806d748> 0.0 12
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf806d748> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d748> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46442e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46442e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46442e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46449b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46442e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46442e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd46442e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd46445c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd46442e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46442e8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd46442e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46512e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46442e8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdd46442e8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46516d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46442e8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46442e8> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd46442e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd46517f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46516d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd46442e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdd46442e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46516d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdd46442e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdd46442e8> 0.0 19
Completed Iteration #24
Best Reward: 0
coverage_call_count 1300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdd46442e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a390> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a390> 0.0 3
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cdd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a390> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a390> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a390> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cdd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf807a390> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a390> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a390> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a390> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a390> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a390> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cdd30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdf807a390> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cdd30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdf807a390> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd46447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a390> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a390> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a390> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf807a390> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46447f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80895f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8d68> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46624a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8d68> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8d68> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46624a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8d68> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8d68> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd46620f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8d68> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80899e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8d68> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8d68> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8d68> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8d68> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8d68> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46627b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8d68> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8d68> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8d68> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46447f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8d68> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048b38> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048b38> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048b38> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048b38> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7daa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048b38> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048b38> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dac18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8048b38> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd46629b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8048b38> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8048b38> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048b38> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8048b38> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dac18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf8048b38> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf8048b38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7daa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8048b38> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048b38> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8048b38> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8048b38> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf8048b38> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7844a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7844a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7844a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7844a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7844a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7844a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7844a8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7964e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7844a8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7844a8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7844a8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7845f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7844a8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7844a8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc7844a8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdcc7844a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc7844a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdcc7844a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7844a8> 0.0 18
Completed Iteration #22
Best Reward: 0
coverage_call_count 1400
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784d30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdcc7844a8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc7844a8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80899e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da898> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da898> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dab00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd46626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da898> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da898> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7daef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da898> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dab38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da898> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da898> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46628d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da898> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da898> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da898> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da898> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7daac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da898> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da898> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da898> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784f98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da898> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a1d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a1d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46447b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a1d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a1d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf807a1d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a1d0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46447b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a1d0> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdf807a1d0> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a1d0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf807a1d0> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7daba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c550> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c550> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c550> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c550> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c550> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c550> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c550> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c550> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c550> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c550> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74cf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c550> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c550> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7daba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c550> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c550> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c550> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c550> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c550> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c550> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a470> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a470> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a470> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a470> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a470> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a470> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a470> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a470> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a470> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a550> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a470> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a470> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a470> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a470> 0.0 18
Completed Iteration #20
Best Reward: 0
coverage_call_count 1500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a470> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a470> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd4a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd4a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd4a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd4a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd4a8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd4a8> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd4a8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd4a8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd4a8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd4a8> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd4a8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd4a8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd4a8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd4a8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd4a8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd4a8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c5f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c5f8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c5f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c5f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c5f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c5f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c5f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c5f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c5f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c5f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c5f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7277f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76ad30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c5f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c5f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c5f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7274a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76ad30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c5f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c5f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c5f8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7279b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc727cc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc727cc0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727cc0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727cc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727cc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7344e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc727cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7276d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc727cc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc727cc0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727cc0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc727cc0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdcc727cc0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc727cc0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7346d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc734320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc727cc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc727cc0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7d68> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7348d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7d68> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7344e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7d68> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7d68> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7d68> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c79b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7d68> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7d68> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c79b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7d68> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7d68> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7d68> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7d68> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7d68> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd46442e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c72b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7d68> 0.0 19
Completed Iteration #21
Best Reward: 0
coverage_call_count 1600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7358> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7d68> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46442e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c72b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7d68> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7d68> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e80> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e80> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e80> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e80> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf809b4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e80> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf81210f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e80> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e80> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e80> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e80> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd46445f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e80> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b4a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e80> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e80> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf81217b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e80> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e80> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e80> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf81187b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1cc0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf81184e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf81181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1cc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1cc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c19b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1cc0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1cc0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1cc0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1cc0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1cc0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c19b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1cc0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1cc0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c15f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1cc0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1cc0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1cc0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1cc0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1cc0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c15f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1cc0> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf81181d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1cc0> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe7e8bc8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121a20> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80fff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121a20> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ffdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121a20> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121a20> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121a20> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ffb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80fff28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8121a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121a20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121a20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8121a20> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121a20> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8121a20> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8121a20> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ffda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8121a20> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8121a20> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5419ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf8121a20> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8121a20> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121a20> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ffdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8121a20> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80fff28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf8121a20> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf81187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf8121a20> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf81189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540b1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf8121a20> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf81187b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8118f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf81186d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ffc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118f98> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540b1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118f98> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf8118f98> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118f98> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8118f98> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf81211d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b6d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdf8118f98> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf81186d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8118f98> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8118f98> 0.0 14
Completed Iteration #18
Best Reward: 0
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf81216d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118f98> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540b1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8118f98> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540b1e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf8118f98> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf8118f98> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c71d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd74a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806df28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4644908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644908> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644908> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4644908> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806df28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdd4644908> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c71d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4644908> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644908> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806df28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdd4644908> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe7c52ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c71d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdd4644908> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806df28> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdd4644908> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a69e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4644908> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644908> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4644908> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 37
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff908> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe7c52ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff908> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff908> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54055390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe7c52e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff908> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54055fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff908> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54055438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff908> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54055128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff908> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540557f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff908> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff908> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540557f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff908> 0.0 11
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff908> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809be80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff908> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff908> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f278> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54055eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f278> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f278> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54088978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f278> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3478f278> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54146710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f278> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe3478f278> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f278> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54055128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3478f278> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3478f278> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3478f278> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54055da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f278> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3478f278> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe3478f278> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe3478f278> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe3478f278> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54055b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe7c52e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe7c52ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe7c52ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402eb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe7c52ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe7c52ea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe7c52ea58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 40
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf809b908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b908> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf81184a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b908> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b908> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf809b908> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b908> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54088390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b908> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540120b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf809b908> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b908> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54088390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf809b908> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdf809b908> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf809b908> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a6c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf809b198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf809b908> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf809b908> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ffcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541468d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541468d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541468d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541468d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541468d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540045f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541468d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe541468d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541468d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540748d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe541468d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541468d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe541468d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541468d0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe541468d0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe541468d0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe541468d0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe541468d0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5410c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ffcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe541468d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe541468d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe541468d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347eee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe541468d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347eea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe541468d0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ee550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee080> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347ee080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347ee080> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ee6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee080> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54146898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee080> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540742b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee080> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347ee080> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5410c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347ee080> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347ee080> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347ee080> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347ee080> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347ee080> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee080> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347ee080> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347ee080> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540047f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540888d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540047f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540047f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540047f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540047f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540047f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540047f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540047f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540047f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540047f0> 0.0 11
Completed Iteration #11
Best Reward: 0
coverage_call_count 1900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540047f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540047f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540047f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540047f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540047f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe540047f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54055cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540047f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540047f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540047f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5410c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe7c52e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347cac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ca9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347caba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d12e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347cae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34796240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796e48> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796e48> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ca5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796e48> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34742940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347962b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796e48> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34742d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796e48> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34742a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796e48> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34796e48> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34796e48> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34742978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34796e48> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796e48> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347962b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34796e48> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34796e48> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34761fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34796e48> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34796e48> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34796e48> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34796e48> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34742208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742208> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742208> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347cae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742208> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347cafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742208> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe7c52e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347cad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742208> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347cafd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34742208> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742208> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ca080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34742208> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347cad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34742208> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347cad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34742208> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe5403c080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34742208> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34742208> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34742208> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742208> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347caa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34742208> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742208> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474ecf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34742208> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 47
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf809b128> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34761b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b128> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b128> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347616d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b128> 0.0 9
Completed Iteration #10
Best Reward: 0
coverage_call_count 2000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b128> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf809b128> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b128> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf809b128> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34742438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf809b128> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf809b128> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347617f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf809b128> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf809b128> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf809b128> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34718748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34718e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34718160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0f0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34718b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34733c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0f0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34733c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0f0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0f0> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0f0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34718d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0f0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabc3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0f0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0f0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34733c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0f0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34733c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0f0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34733c18> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0f0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346d41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d47b8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346d47b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d47b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346d47b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34742358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe346d47b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d47b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346d44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d47b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d47b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe346d47b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efecabc3240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346d47b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe346d47b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346d47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34733518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d47b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347242b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d47b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346d47b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe346d47b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d47b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34718be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d47b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe346d47b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346d47b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34718978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe346d47b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34761748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347616a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347616a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347335c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347616a0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347616a0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347616a0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347335c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347616a0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347616d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347616a0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ee400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347616a0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403c470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347616a0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347616a0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347616a0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347616a0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809bda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347616a0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347616a0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347616a0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347617f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347616a0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe347616a0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347616a0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347616a0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346d40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809bda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347616a0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34733c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34718940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347cab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 2100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ca128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347cab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe7c52ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346cbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346cbf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347cafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cb470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346cbf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c4a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe7c52ed68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe7e8a0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe80> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3469c1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe80> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541e5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe80> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe80> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe7c52e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe80> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe80> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541e5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe80> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54798be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe80> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346d4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe80> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe80> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe80> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467fa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe80> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3469c4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe80> 0.0 18
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe80> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe80> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467fa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe80> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469cc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe80> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe80> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34641780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469cc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe3467fe80> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34641d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346416a0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541e5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346416a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346416a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346416a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34641a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346416a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346416a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe346416a0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346416a0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346416a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346416a0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cb390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346cb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346416a0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346cb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346416a0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346416a0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ca978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe346416a0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469cf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe346416a0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541e5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346416a0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346416a0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cbfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346410b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34641dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641dd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34641dd8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34641dd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346d4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641dd8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34742b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641dd8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346414a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34641dd8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34641dd8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641dd8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34641dd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34641dd8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347616d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34641dd8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a61d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34641dd8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe34641dd8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34718b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a61d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe34641dd8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34652550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34652f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34652710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718940> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34652b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34652438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34718940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe7c5d0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34652710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34718940> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346526d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718940> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718940> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34718940> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346527f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718940> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718940> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347caba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718940> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718940> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34652710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34718940> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347611d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34718940> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346527b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346526d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34718940> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347caba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34718940> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34652240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe34718940> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34652438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34718940> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346526d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34718940> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54104278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54104438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54104400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efecabbdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54104400> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54104438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe54104400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34658588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54104400> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34658518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe54104400> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34658b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346585c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54104400> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34658208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54104438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe54104400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34658320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417cba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe54104400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417cba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe54104400> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417cba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efe54104400> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346774a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541042e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54104400> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34677ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54104438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe54104400> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34677c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346585c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe54104400> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34677c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346778d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54104400> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34677b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54104400> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34677320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541042e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe54104400> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347caba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346585c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe54104400> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34658828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541042e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe54104400> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54104400> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346522e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346527f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe7c5d0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346527f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346775c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346522e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346527f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541040b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34652438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346527f0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efecabbdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346527f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346527f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346527f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346527f0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346527f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34652710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346527f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34718c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346527f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346522e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe346527f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe346527f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34652048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbde48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346527f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34677eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe346527f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541040b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34652438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346527f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541040b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34652438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe346527f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346527f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347616d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346522e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe346527f0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346527f0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1630> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1630> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1630> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1630> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1630> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1630> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1630> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7276a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347d1630> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1630> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1630> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346a6c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1630> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7270b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346529e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1630> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346529e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1630> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1630> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34658390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1630> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1630> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe347d1630> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 12.007042253521128
coverage_call_count 2300
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727ac8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727ac8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727ac8> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc727ac8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727ac8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc727ac8> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc727ac8> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cdd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc727ac8> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7276d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727ac8> 0.0 13
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc727ac8> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80897f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8089c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089c18> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089c18> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8089c18> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089c18> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089c18> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089c18> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80892b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089c18> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089c18> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8089c18> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cdac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf8089c18> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8089c18> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf8089c18> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80892b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8089c18> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80892b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf8089c18> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f40b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8089c18> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76aef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76aef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc76aef0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76aef0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76aef0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7272b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76aef0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7278d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76aef0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a60f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc76aef0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc76aef0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76aef0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7278d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc76aef0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347969b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7279b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76aef0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7278d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc76aef0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc76aef0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a60f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc76aef0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdcc76aef0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76aef0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541040b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a60f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdcc76aef0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658a58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346529e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34652710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346521d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34652c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34677358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34761748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658a58> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34658a58> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34658a58> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34658a58> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80899e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658a58> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34658a58> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34652710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34658a58> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe34658a58> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34652c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34658a58> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34677898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80899e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34658a58> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34652710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34658a58> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80899e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34658a58> 0.0 19
Completed Iteration #22
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34658a58> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1eb8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efe34658a58> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807ac18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807ac18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7845f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807ac18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807ac18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807ac18> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807ac18> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807ac18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807ac18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807ac18> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7845f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807ac18> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7845f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf807ac18> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807ac18> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80484e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf807ac18> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7843c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807ac18> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf807ac18> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7843c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf807ac18> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807ac18> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7845f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdf807ac18> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807ac18> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf807ac18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f81d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f81d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347615f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f81d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f81d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34742b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f81d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34652c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f81d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f81d0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80f81d0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f81d0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80f81d0> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346419e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80f81d0> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80f81d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f81d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf80f81d0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80f81d0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80f81d0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734470> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbde48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc734470> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbde48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc734470> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734470> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc734470> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc734470> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734470> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbde48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdcc734470> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbde48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdcc734470> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734470> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc734470> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc734470> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734470> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc734470> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc734470> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f3c8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467f3c8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe3467f3c8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f3c8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f3c8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f3c8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467f3c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f3c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7daf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f3c8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467f3c8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7daeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f3c8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7daa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe3467f3c8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd46627f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467f3c8> 0.0 14
Completed Iteration #19
Best Reward: 0
coverage_call_count 2500
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76aef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467f3c8> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f3c8> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467f3c8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd46629b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f3c8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd46517f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cc0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cc0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cc0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cc0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74cc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cc0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cc0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cc0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cc0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cc0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd46622b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cc0> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cc0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346410b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cc0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cc0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cc0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cc0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346d4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8908> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7849b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8908> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8908> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75cd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8908> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8908> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8908> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8908> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807add8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8908> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8908> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807add8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8908> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8908> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8908> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8908> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8908> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8908> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad68> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad68> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad68> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad68> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad68> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad68> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad68> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad68> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad68> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad68> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad68> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad68> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad68> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad68> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d135f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad68> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad68> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d138d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad68> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d130f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad68> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d132b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d132b0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d132b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d131d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d132b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d132b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d132b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d132b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d132b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d132b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d132b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d132b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d132b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
coverage_call_count 2600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5d132b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d132b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d132b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5d132b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d132b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe10> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe10> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe10> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe10> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe10> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe10> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe10> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc62e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe10> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe10> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe10> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe10> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe10> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe10> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe10> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe10> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2dbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe10> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe10> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2dbe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe10> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7963c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d131d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7963c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7963c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7963c8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7963c8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7963c8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7963c8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7963c8> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7963c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7963c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc7963c8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc7963c8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7963c8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7963c8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdcc7963c8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc7963c8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7963c8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc7963c8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fd30> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fd30> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fd30> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fd30> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7843c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fd30> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fd30> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fd30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7843c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fd30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fd30> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fd30> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fd30> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fd30> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f82b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf8089ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fd30> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089ba8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fd30> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fd30> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fd30> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fd30> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fd30> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fd30> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089ba8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fd30> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5ef0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5ef0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5ef0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5ef0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7daf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5ef0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5ef0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c847b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5ef0> 0.0 9
Completed Iteration #12
Best Reward: 0
coverage_call_count 2700
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5ef0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5ef0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c845c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5ef0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5ef0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5ef0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5ef0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5ef0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5ef0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5ef0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5ef0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5ef0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac18> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ae80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac18> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac18> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ae80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac18> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac18> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac18> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac18> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac18> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac18> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ae80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac18> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac18> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac18> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac18> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac18> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac18> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac18> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac18> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6908> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6908> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6908> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6908> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6908> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6908> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d130f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6908> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6908> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6908> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6908> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6908> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6908> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d137b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5a20> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6908> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2de48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6908> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5a20> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6908> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac50> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac50> 0.0 3
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac50> 0.0 4
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac50> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c582e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c581d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac50> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac50> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac50> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac50> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac50> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c581d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac50> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac50> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac50> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac50> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac50> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac50> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac50> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac50> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58898> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58898> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58898> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c721d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58898> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58898> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c721d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58898> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58898> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58898> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58898> 0.0 10
Completed Iteration #10
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c721d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58898> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c723c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58898> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58898> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c030f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58898> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c721d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58898> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58898> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58898> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c721d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58898> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da58> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da58> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da58> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da58> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da58> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da58> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da58> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c727f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da58> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c729e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da58> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da58> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4dd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da58> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da58> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da58> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c581d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da58> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7daf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58be0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58be0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58be0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58be0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58be0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58be0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58be0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58be0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58be0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58be0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75cc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58be0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58be0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58be0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58be0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75cc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58be0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58be0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58be0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d470> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d470> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d470> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d470> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d470> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f40f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d470> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d470> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34652a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d470> 0.0 9
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346524e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d470> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d470> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d470> 0.0 12
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d470> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f40f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d470> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34652cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541044a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c978> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34658080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe5417c978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34658710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe5417c978> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34677668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe5417c978> 0.0 6
Completed Iteration #6
Best Reward: 0
coverage_call_count 2900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34652358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34658588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c978> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34677198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c978> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34677ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346777b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c978> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c978> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe5417c978> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34677cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe5417c978> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54104908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe5417c978> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346777b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe5417c978> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54104160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c978> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe5417c978> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34658a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe5417c978> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe5417c978> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34652a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4550> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34652588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4550> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efecabbde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4550> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34677ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4550> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4550> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4550> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4550> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4550> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cde48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4550> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4550> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4550> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4550> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34652b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4550> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cde48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540a4550> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540a4550> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4550> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4550> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c725f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c726d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c726d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540129b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c726d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe7c52e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe7c52e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c726d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c726d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c726d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c726d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c726d8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe7c52e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c726d8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c725f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c726d8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c726d8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c726d8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c725f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c726d8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34658d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe7c52e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c726d8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c726d8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c726d8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe7c52ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c726d8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469cac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c726d8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80895c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7daf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34641438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f978> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34641fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f978> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54189fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467f978> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541e5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f978> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f978> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f978> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541e5cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467f978> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467f978> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe3467f978> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f978> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467f978> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f978> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347339b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347339e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f978> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe3467f978> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467f978> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34718cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7daf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467f978> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe3467f978> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3467f978> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34718358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346d4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346d41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718390> 0.0 4
Completed Iteration #2
Best Reward: 0
coverage_call_count 3000
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346d4630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346d4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34718630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34718390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347336a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718390> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718390> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541e5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34718390> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718390> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d16a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34718390> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346d4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34718390> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718390> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34641080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34718390> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34641128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34718390> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe34718390> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34718208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34718390> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346419b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347336a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34718390> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34718390> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34718390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346cb358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346cb358> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346cb358> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe7c52ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346cb358> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346cb358> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe7c52e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346cb358> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346cb358> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe7c52e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346cb358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe7c52e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe346cb358> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34658320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469ccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe346cb358> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469ccf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe346cb358> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346cb358> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469c5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346cb358> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346cb358> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346cb358> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346cb358> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54104080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe346cb358> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efecabbdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346cb358> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe7c52e908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe346cb358> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346cb358> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72cf8> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72cf8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72cf8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72cf8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72cf8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72cf8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346cb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72cf8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72cf8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346cb6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72cf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72cf8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34761048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72cf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34761978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72cf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346cb6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72cf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72cf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34761358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72cf8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ca780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72cf8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ca128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346414e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72cf8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346414e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72cf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347967b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474e080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34796e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ca828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474e080> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347423c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474e080> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34742438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474e080> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347424e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ca828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3474e080> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347610f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3474e080> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474e080> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347967b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3474e080> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ee630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347963c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3474e080> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347eef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347eeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474e080> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347eedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ca828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe3474e080> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474e080> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3474e080> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c587b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347eeac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3474e080> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474e080> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347eed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3474e080> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347616d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742710> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 3100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347cac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742710> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80892e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ca128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742710> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80899b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742710> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742710> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742710> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347caac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742710> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ca128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34742710> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54104080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34742710> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34742710> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809bda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34742710> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe34742710> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346cba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742710> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34761e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ca128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34742710> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe7c52e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80899b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34742710> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34742710> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34742710> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34658320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34742710> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742710> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80899b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34742710> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34652f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f43c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34742710> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347240b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c940> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540045f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c940> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347240b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f11d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c940> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c940> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34796320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c940> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c940> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347240b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c940> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c940> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540746d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c940> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540742b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c940> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c940> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540742b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c940> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c940> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c940> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540883c8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54088be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540883c8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540883c8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540884a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540883c8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540888d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540883c8> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540883c8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe7c52ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540883c8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540883c8> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540883c8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540884a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540883c8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402edd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540883c8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54088be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540883c8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540883c8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54055b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540883c8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54055c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540883c8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf81212b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54146898> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf81217b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54146898> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54146898> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54146898> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54146898> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54146898> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe54146898> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe54146898> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54146898> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54055d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe54146898> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54146518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf81212e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54146898> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf81212e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe54146898> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347966a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe54146898> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54055cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54146898> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a6a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe54146898> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b69e8> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b69e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540556d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b69e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ee6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b69e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b69e8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a6fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347b69e8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540742b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b69e8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540886d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b69e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540556d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347b69e8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34796780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a6fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347b69e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540556d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347b69e8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347b69e8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540556d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe347b69e8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540886d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347b69e8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540554e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b69e8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34742710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347b69e8> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347b69e8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a6fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe347b69e8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540554e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347b69e8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b69e8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34761ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540554e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347b69e8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347b69e8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6860> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54104358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe7c52ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6860> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6860> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6860> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6860> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347b6860> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6860> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347b6860> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6860> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347b6860> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347b6860> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ffd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6860> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b68d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347b6860> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347b6860> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347b6860> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efecabbdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347b6860> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54055c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347b6860> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf81188d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347617f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5ba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540b1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540b1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5ba8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5ba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ffda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5ba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5ba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd46443c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347617f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5ba8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5ba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34641780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347617f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5ba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347617f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54055630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5ba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347617f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5ba8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5ba8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe52e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5ba8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c88> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c88> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c88> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c88> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c88> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c88> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c88> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c88> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540b1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c88> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46443c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c88> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c88> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf81181d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46443c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c88> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c88> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46443c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c88> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c88> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c88> 0.0 17
Completed Iteration #22
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c88> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34677a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c88> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe7c52ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118208> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c88> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c726d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347caa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540b1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c13c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c13c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c726d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 18
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 19
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 20
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 21
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 22
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540556d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff6a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 23
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 24
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540554e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 25
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 26
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540886d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe52e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5080> 0.0 27
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a6fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478fda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403ccf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403ccf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540129b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1dd8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34761c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478fda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478fda0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7965f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7965f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7965f8> 0.0 4
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7965f8> 0.0 5
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7965f8> 0.0 6
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7965f8> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7965f8> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7965f8> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7965f8> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7965f8> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc7965f8> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7965f8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdcc7965f8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e80f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7965f8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7965f8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a898> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a898> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a898> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a898> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a898> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7966d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a898> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a898> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a898> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7daa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a898> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a898> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a898> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf807a898> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a898> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a898> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a898> 0.0 16
Completed Iteration #20
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a898> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf807a898> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf807a898> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf807a898> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80486a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f518> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f518> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f518> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f518> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34641780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f518> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f518> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f518> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f518> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ca4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f518> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f518> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a6c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f518> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f518> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f518> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f518> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f518> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3478fda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f518> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ffa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349e8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349e8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e84e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e84e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349e8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349e8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349e8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349e8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349e8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349e8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349e8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662c88> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662c88> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662c88> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74ca20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4662c88> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74ca20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdd4662c88> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4662c88> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662c88> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662c88> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7279b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662c88> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662c88> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4662c88> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdd4662c88> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdd4662c88> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdd4662c88> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4662c88> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdd4662c88> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c842b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c842b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7345c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c842b0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c842b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c842b0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c842b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7276a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f42b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c842b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f42b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c842b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c842b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34641780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c842b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c842b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c842b0> 0.0 13
Completed Iteration #17
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c842b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c842b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c842b0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c586d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c842b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb5c842b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f7f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f7f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f7f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7968d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f7f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f7f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f7f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f7f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c843c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f7f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f7f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f7f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f7f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f7f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c843c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f7f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f7f0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7968d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f7f0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f7f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f7f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2def0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2def0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2def0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2def0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2def0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2def0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2def0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2def0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2def0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2def0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2def0> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2def0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2def0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2def0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2def0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2def0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6390> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6390> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6390> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6390> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6390> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6390> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6390> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6390> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7847b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6390> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6390> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6390> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc69b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6390> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6390> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6390> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6390> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6390> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6390> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6390> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6e48> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6e48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d135f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6e48> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2dd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6e48> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6e48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d135f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6e48> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6e48> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6e48> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6e48> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6e48> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6e48> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6e48> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34641780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6e48> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6e48> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6e48> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6e48> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6e48> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6e48> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd46510b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f43c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7842e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c847f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f43c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c847f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c843c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c847f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c034e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f43c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c847f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c036d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f43c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c030b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c843c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c847f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c037f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7842e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc734b70> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f442e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03c50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03c50> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03c50> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f446a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c037b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c037b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03c50> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03c50> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03c50> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf56d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03c50> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03c50> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03c50> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7345c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03c50> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03c50> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03c50> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c037b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03c50> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03c50> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f556d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03c50> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f442e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03c50> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55c50> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f440f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55c50> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55c50> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55c50> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55c50> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c030b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55c50> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55c50> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55c50> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55c50> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f443c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55c50> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55c50> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55c50> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55c50> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4651048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d135f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651048> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346414e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4651048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651048> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4651048> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651048> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdd4651048> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4651048> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdd4651048> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346414e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdd4651048> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2def0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdd4651048> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651048> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7349e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc734a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdd4651048> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346414e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdd4651048> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651048> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdd4651048> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2def0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdd4651048> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f553c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734a58> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7efdd4651048> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55f60> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55f60> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55f60> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55f60> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f124a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f123c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f125f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55f60> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55f60> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55f60> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55f60> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55f60> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55f60> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55f60> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f123c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55f60> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f125f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55f60> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55f60> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f125f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55f60> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55f60> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7276a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f312b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7276a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1cf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7276a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12780> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12780> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12780> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12780> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12780> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12780> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12780> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12780> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12780> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12780> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12780> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12780> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f319b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12780> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f315f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12780> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12780> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12be0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12be0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12be0> 0.0 7
Completed Iteration #8
Best Reward: 0
coverage_call_count 3800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12be0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12be0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12be0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12be0> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12be0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12be0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12be0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12be0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12be0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eefa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12be0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12be0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eefe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12be0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eefd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12be0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12be0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e812e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81208> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e815f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e814e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81208> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81208> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eefc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81208> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eefda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eefbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81208> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e813c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81208> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81208> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81208> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e814e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81208> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81208> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81208> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e813c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81208> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81208> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81208> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e814e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81208> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e813c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81208> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eefbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81208> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81208> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81208> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e814e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81208> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81208> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81208> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ada0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ada0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e818d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ada0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ada0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ada0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ada0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ada0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e813c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ada0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ada0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e815f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ada0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ada0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf5c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ada0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ada0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e817f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ada0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eefa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ada0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ada0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ada0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf5c0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ada0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ada0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e810b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9aa20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9aa20> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c037f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9aa20> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9aa20> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9aa20> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9aa20> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9aa20> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ac50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9aa20> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9aa20> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9aa20> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346414e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9aa20> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eefac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9aa20> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9aa20> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d135f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9aa20> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eefbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9aa20> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9aa20> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eefac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9aa20> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c4a8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f122e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c4a8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c4a8> 0.0 4
Completed Iteration #4
Best Reward: 0
coverage_call_count 3900
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c4a8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c4a8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c4a8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaff60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c4a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c4a8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f128d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c4a8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c4a8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f128d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c4a8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f122e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c4a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c4a8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f128d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c4a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c4a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12390> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c4a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f122e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c4a8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c4a8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c4a8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ccf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ccf8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ccf8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ccf8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ccf8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ccf8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ccf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ccf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e740b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ccf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ccf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ccf8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ccf8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ce80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ccf8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ccf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e034a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ce80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ccf8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ccf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ceb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ccf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e746a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e742e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e740b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03d30> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03d30> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03d30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03d30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03d30> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03d30> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e033c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03d30> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e740b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03d30> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03d30> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03d30> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03d30> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03d30> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03d30> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03d30> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cbe0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cbe0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cbe0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cbe0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cbe0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34742710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ce80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cbe0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cbe0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f315f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cbe0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cbe0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cbe0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cbe0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cbe0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ce80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cbe0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cbe0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cbe0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cbe0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cbe0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cbe0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cbe0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e032b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eefbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e032b0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e032b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e032b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eefbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e032b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e032b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e032b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e032b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e032b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e810b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e032b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e032b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e032b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e032b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eefbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e032b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e032b0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e032b0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e032b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdf98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdf98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdf98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdf98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdf98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdf98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdf98> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdf98> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49dda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdf98> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdf98> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49dde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdf98> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e185c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdf98> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdf98> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddf98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdf98> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdf98> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdf98> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdf98> 0.0 18
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdf98> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdf98> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49cde10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdf98> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdf98> 0.0 22
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddf98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdf98> 0.0 23
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c037f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdf98> 0.0 24
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddf98> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdf98> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e184e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafc88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e187b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafc88> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafc88> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafc88> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f319b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafc88> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafc88> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f122e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafc88> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafc88> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e187b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafc88> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafc88> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9abe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafc88> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e036a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9abe0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafc88> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e184e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafc88> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9abe0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafc88> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafc88> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e187b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafc88> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafc88> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdeb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdeb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdeb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdeb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49eebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49eeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdeb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49eeac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdeb8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdeb8> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdeb8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdeb8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdeb8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49eea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdeb8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdeb8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdeb8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49eee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdeb8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdeb8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdeb8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdeb8> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdeb8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d390> 0.0 2
Completed Iteration #0
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d390> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb499d390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb499d390> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d390> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb499d390> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49acd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d390> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49aceb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb499d390> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499ddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb499d390> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb499d390> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb499d390> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb499d390> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49bbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d390> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb499d390> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb499d390> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49acba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d390> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e812e8> 0.0 2
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49510f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499dd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e812e8> 0.0 3
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4951400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49512e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e812e8> 0.0 4
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49514a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4951518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e812e8> 0.0 5
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e812e8> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e812e8> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bbcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499dd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e812e8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e812e8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499dd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e812e8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e812e8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49512e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e812e8> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4951518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e812e8> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4951518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e812e8> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e812e8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49aca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d5f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb499d5f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49eeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d5f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb499d5f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49eec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d5f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49eebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d5f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49eeef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb499d5f8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d5f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb499d5f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d5f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49eebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb499d5f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e184e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d5f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f122e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49eebe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb499d5f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb499d5f8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb499d5f8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49acb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb499d5f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49acf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49eeac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb499d5f8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499d6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49eeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49eedd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49eedd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49eedd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4951208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49eedd8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4951208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49eedd8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49511d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49eedd8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4951b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49eedd8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4951ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49eedd8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4907128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49eedd8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4951208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb49eedd8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4907390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb49eedd8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4907320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49eedd8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4907710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4951f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49eedd8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4907a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb49eedd8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4951f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49eedd8> 0.0 16
Completed Iteration #22
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4907e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49eedd8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4907b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb49eedd8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb491a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49075c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb491a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49075c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb491a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49075c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4907f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49075c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb491a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4907940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49075c0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb491abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49075c0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb491a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49075c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb491aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb49075c0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49075c0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4927240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49075c0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb491ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49075c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb49075c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4907630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb49075c0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4907fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49075c0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4907550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4907630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb491a400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb49075c0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb491af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4951f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49075c0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49270b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49075c0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4927630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb49075c0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49276d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb49075c0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4927a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4927438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4927a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4927710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49274e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4927a90> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb491a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4927780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4927a90> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb491aef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4927438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4927a90> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb491a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4927a90> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347429e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4927a90> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4927cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4927a90> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49273c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4927da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4927a90> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4927630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4927da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4927a90> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4927eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf809b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4927cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4927a90> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4927a90> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eefd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4927a90> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49270f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4927a90> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4927a90> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49270f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4927a90> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4927780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4927a90> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef9b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef9b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef9b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4927208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef9b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef9b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef9b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf809bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef9b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef9b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef9b0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e818d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef9b0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4927128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4927f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef9b0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eefa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4927d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef9b0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef9b0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef9b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef9b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef9b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4927d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef9b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef9b0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c037f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e819e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef9b0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c030f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03e10> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03e10> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c039e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03e10> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03e10> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03e10> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03e10> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03e10> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03e10> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c030f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03e10> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03e10> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7844e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03e10> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03e10> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03e10> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03e10> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03e10> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03e10> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03e10> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7841d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03e10> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c030f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03e10> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03e10> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e817f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e817f0> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e817f0> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e817f0> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3467f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e817f0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e817f0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e817f0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c846a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e817f0> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e817f0> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf53c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e817f0> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e817f0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e817f0> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3467f588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e817f0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7840b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e817f0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d131d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e817f0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f441d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9acc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e819e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9acc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84cc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f15f8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eefa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f15f8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eefa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540f15f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f15f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f15f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4927128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49270b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f15f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f15f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540f15f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540f15f8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540f15f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eefa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540f15f8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f15f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540f15f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef9e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe540f15f8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f15f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef9e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efe540f15f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f15f8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc74cb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540f15f8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540f15f8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8550> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8550> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a69b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8550> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7966a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8550> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8550> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c034a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8550> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4927898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8550> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8550> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8550> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8550> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8550> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8550> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8550> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8550> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8550> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8550> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe3476c8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8550> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a780> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a780> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8118f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a780> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a780> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a780> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf807a780> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf81189b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a780> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a780> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a780> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a780> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a780> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540b1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a780> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe7c52e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a780> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf807a780> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf807a780> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7969e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdf807a780> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f4828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf807a780> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a780> 0.0 20
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8118cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf807a780> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdf807a780> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 142
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7968d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a240> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf81187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a240> 0.0 3
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4927128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a240> 0.0 4
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4927128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a240> 0.0 5
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49279b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4927128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf807a240> 0.0 6
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a240> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a240> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a240> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eefa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a240> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a240> 0.0 11
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80cd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a240> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf807a240> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a240> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5403c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807a240> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8048e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf807a240> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e819e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 13
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540b15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf81188d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc784710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe7c52ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4662908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540f12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 24
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc727a58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 25
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c849e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7080> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540f1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7080> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806dba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7080> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7080> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7080> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ffeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7080> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7080> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 4500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c72b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7080> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806d080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7080> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7080> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7080> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7080> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7080> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7080> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a6780> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd72e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a6780> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a6780> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe541a6780> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541467b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a6780> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe541a6780> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347b6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a6780> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe541a6780> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7dae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a6780> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a6780> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540554a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a6780> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541a6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347b6d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe541a6780> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54055828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe541a6780> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe541a6780> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe541a6780> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe541a6780> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54074668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe541a6780> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54088550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff5f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efe541a6780> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe541a6780> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402e518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe541a6780> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541a6780> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806db38> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf806db38> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c73c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806db38> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806db38> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c73c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf806db38> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e810f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806db38> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc784240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c03a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf806db38> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806db38> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf806db38> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c9a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806db38> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c73c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf806db38> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4927588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c73c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdf806db38> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf806db38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806db38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf806db38> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdf806db38> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e81f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c73c8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdf806db38> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc75c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c73c8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7efdf806db38> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54055da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf806db38> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7278d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54074c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7845c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7e48> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe7c52e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49270b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7e48> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3476cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7e48> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf81187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7e48> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346a6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7e48> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7845c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7e48> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469cb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7e48> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54012da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7e48> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7da4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49270b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7e48> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3469cb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7e48> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7e48> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7e48> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7e48> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7e48> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347969e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7e48> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34796128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7845c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7e48> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34761fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347963c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34761400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ee7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347610f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347eeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34796f98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796f98> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34742438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34796f98> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347427b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34796f98> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796f98> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ca7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3474eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796f98> 0.0 10
Completed Iteration #12
Best Reward: 0
coverage_call_count 4600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347cac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796f98> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346cb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34796f98> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347cac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34796f98> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80ff9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe34796f98> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347429b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346cb518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34796f98> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34761d30> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efe34796f98> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347cab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347cac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34796f98> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8121278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34796f98> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3474e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346cb518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34796f98> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34742978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ca5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ca828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ca828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5403c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346a6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ca828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ee6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ca828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ca828> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ca5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347ca828> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347ca828> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347ca828> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc796160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ca828> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8121400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34742be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ca828> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347ca828> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d13320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5402efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ca828> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347ca828> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ca828> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347ca828> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80c19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe347ca828> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807abe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347ca828> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347ca828> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f44588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe347ca828> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd46446d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7630> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34718860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7630> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34718748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7630> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34641128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7630> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7630> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347187f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7630> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347187f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7630> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34641cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7630> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34641320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe3476c0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7630> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd46448d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7630> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7630> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34733160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540559b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7630> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346d4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541e5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4080> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346d4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346d4080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efecabbdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4080> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4080> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4080> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541040b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346d4080> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541e5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346d4080> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346d4080> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34658320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34733dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4080> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4080> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34733dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346d4080> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346583c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe346d4080> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe346d4080> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541e5b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe346d4080> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34652518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346d4080> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34677ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4080> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34652438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34733dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe346d4080> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe7c5d0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34677978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34652ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541f97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347d1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 9
Completed Iteration #8
Best Reward: 0
coverage_call_count 4700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540a4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417cdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34677fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c722e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34677c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efecabbdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efecabbdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34658828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe541f97b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe347d1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34652438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541040b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 21
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 22
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe540a4320> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efecabc3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80890f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80890f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346f1b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80890f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347335c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80890f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34641320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80890f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe5417c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80890f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c76a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80890f0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347244e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80890f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cf52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80890f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf807a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80890f0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdf80890f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ca5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf8089400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80890f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347424e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80890f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc7f40f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80890f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ca978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80890f0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf806d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdf80890f0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdf80890f0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5402e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34718630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49270b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34641470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34796470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eef828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641470> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34641470> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34641470> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807aba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34641470> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54004400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641470> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c724a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34641470> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34641470> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf807aba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe34641470> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641470> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe54004320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34641470> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34641470> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347ee6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34641470> 0.0 19
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34641470> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34641470> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34641470> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34641470> 0.0 23
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe34641470> 0.0 24
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c725c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb491af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58470> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4907358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58470> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4907c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58470> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58470> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346d4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34677ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58470> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80e8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4907358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb491a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58470> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58470> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb491a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58470> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb491a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4de48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58470> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540042b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58470> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb491ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4907c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58470> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49079b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58e80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58470> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4907518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4907c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58470> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4907fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491af98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58470> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4907828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4907c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58470> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb491ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4907e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58470> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49071d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58e80> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58470> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4951c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58470> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4951198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4951240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49515f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4951f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4951dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49515f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4951a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4951dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49515f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
coverage_call_count 4800
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb491aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4951dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb49515f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4907c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49515f8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4907dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49516a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49515f8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4907cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49516a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49515f8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347ee630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49515f8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb491af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4907160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49515f8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49515c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491ab38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49515f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3469c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4951dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb49515f8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc74cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4951dd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdb49515f8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafe5b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4951f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49515f8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c72630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4951240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49515f8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4907e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4951ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49515f8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4951ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49515f8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdfafd7e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49515f8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4951cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4951240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb49515f8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4951160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4907160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49515f8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49079e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4907748> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb491a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49519e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4907748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4907748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80481d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4907748> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80481d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4907748> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34658080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4907748> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4951a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4907748> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80f86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49079e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4907748> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4907748> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49519e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4907748> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347cacf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491a550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb4907748> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34724710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4907748> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4907748> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4907080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4907748> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34641f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4907748> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4dbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4907748> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4907748> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe347d10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346418d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347335c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8089320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347335c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347335c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4907940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efecabc3160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4644908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc76a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d1f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe347335c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf80892b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efe346f1fd0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf358> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34641d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf358> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf358> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf358> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf358> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf358> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf358> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf358> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf358> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1c8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf358> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1cbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf358> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf358> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf358> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf358> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1cb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf358> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf358> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe540550f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd978> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346d4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346d4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd978> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd978> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd978> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd978> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe541e5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd978> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1ce48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd978> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34641a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dde10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd978> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd978> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd978> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4951320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd978> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd978> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe54012240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd978> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd978> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49070f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d240> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49074a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4907518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d240> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d240> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d240> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d240> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4907518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d240> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d240> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d240> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d240> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d240> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d240> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d240> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f124e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4907518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d240> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d240> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d240> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d240> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4651470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e742b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4d240> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796160> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e180b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f120f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc796160> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e185f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc796160> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f129e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdcc796160> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e745f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796160> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f120f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc796160> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f120f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdcc796160> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e742e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796160> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f553c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efe34658080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdcc796160> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e742e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc796160> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe34658080> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7efdcc796160> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796160> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdcc796160> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796160> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc796160> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f311d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31ac8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31ac8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f311d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31ac8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f311d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31ac8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49270b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31ac8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31ac8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31ac8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34658080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31ac8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31ac8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31ac8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31ac8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31ac8> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31ac8> 0.0 20
Completed Iteration #23
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc734a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31ac8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31ac8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5d2deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e749b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e187f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f124e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c582e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e742b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe5417c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346522b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e742b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34641278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e742b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e819e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c84518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491ae80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c581d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491ae80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f120f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491ae80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491ae80> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491ae80> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe346d4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb491ae80> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb491ae80> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4907080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7340b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491ae80> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491ae80> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34641a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb491ae80> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc727160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb491ae80> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f1ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f120f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb491ae80> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f129e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb491ae80> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb491ae80> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdf80f8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491ae80> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb491ae80> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb491ae80> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f120f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb491ae80> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdcc7340b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb491ae80> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eafe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb491ae80> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb491ae80> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb491ae80> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec89e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a400> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a400> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a400> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec87b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a400> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a400> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a400> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec87b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a400> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a400> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a400> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a400> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec87b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a400> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a400> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a400> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a400> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a400> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec80b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a400> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec80b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a400> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a400> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9af28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9af28> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9af28> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdf8048e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9af28> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9af28> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9af28> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9af28> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9af28> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9af28> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9af28> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4644fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9af28> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc6c7630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdd4651908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9af28> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49cd6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9af28> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9af28> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34641278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9af28> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ad30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9af28> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c581d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9af28> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18be0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18be0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdcc734cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18be0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18be0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4dc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18be0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4dc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18be0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18be0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18be0> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4907080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18be0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f556a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18be0> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18be0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e819e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18be0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f556a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18be0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f314e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18be0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18be0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18be0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18be0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efe346d4c50> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18be0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18be0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03588> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03588> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49eeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49eef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03588> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03588> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03588> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49eef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03588> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03588> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03588> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49eedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03588> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49eef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03588> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03588> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49eef28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03588> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499d828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03588> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03588> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03588> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499dc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03588> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03588> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03588> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03588> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499db38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03588> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ace80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03588> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49acef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb499db38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4e03588> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49acb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac630> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e5c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac630> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac630> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac630> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac630> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49acf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac630> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbd22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac630> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac630> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac630> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac630> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbd26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac630> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb499d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac630> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4eaf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac630> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49acc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac630> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac630> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ace10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac630> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc60b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc60b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49acbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc60b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc60b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49eeba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc60b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4907080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc60b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc60b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49074a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc60b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc60b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f55f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc60b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc60b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc60b8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49bbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc60b8> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc60b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc60b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc60b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc61d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc60b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc61d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc60b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc60b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49eeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6080> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6080> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb840b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6080> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb84390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6080> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6080> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb84710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6080> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6080> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb84a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6080> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49eeeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6080> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb84780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb84b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6080> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb84080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6080> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb92208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6080> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb92160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb84390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6080> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb84048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e9a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6080> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb84e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb84240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6080> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb92780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92588> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb92ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92588> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb92e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92588> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb9e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92588> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb84748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb9e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92588> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb929e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb9e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb92588> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb9e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb92588> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb9e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb9e390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafb92588> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb9e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb9e390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdafb92588> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb9e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafb92588> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb9eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92588> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb9ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb92588> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb9eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb92588> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafb92588> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb92588> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb84e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb92588> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb9e160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafb92588> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb9eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb9e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92588> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdafb92588> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbd20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdafb92588> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb9eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafb92588> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb92b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb9e5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb92588> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd320> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb9e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd320> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb925c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd320> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd320> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbbdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbbdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd320> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd320> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd320> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb9eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd320> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb9e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb925c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd320> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb9eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd320> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb9e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd320> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb9e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd320> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb9e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd320> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbdb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd320> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb84e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd320> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb84160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbdf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd320> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd320> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb84b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb84048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb84d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb92cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb9e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb92940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb92ef0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbbde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92ef0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb92400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb847b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92ef0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92ef0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb923c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb92ef0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49cde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92ef0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb84d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb92ef0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49074a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e182e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb92ef0> 0.0 13
Completed Iteration #15
Best Reward: 0
coverage_call_count 5300
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb92da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e182e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafb92ef0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbdef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb92ef0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb847b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb92ef0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb9e320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb92ef0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb92ef0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4ec85f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2c50> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2c50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2c50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49eedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc60b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2c50> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2c50> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2c50> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2c50> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb4cb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb4ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2c50> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb4cd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2c50> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb7f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc60b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2c50> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb7f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2c50> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb7f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2c50> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb7f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2c50> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb7fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb7f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb7fdd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4907080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb7fdd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e74550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb7f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb7fdd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb7fdd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb7fdd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb7fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb4ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb7fdd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb7fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbda20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb7fdd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb7ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb7fdd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb0a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb7f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb7fdd8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb0a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb7fdd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb7f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb4ca90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb7fdd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb0a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbbda20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafb7fdd8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb0a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafb7fdd8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb0a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb4ca90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafb7fdd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb0ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb0a358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb7fdd8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb0a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb7f780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafb7fdd8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdafb7fdd8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb0af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb0ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb0ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a6d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb0a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb0aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a6d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a6d8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49eeeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a6d8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49eedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a6d8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb0ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a6d8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb4ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a6d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb4ca58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a6d8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb7f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb0ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a6d8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb0a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb0aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a6d8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb7f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49ee940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a6d8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdd4662630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb7fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a6d8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49dd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb4ca58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a6d8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe34724358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a6d8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f12d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb0aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a6d8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c4dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb0a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c5f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb7f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb499d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb7f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c5f8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c5f8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb9ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb0a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c5f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb9e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb7fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c5f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb0aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb0a940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c5f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c5f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c5f8> 0.0 10
Completed Iteration #11
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb92550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c5f8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb92cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c5f8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4e18358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c5f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb7fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c5f8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbbdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c5f8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb84eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c5f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb7fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c5f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb84b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb7f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c5f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb9e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c5f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c5f8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb2ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2abe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb2af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2abe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb92da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2abe0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb2ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad84a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb2abe0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafad8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2abe0> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafad89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb2abe0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafad8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad84a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafb2abe0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafad8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2abe0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb2ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2abe0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafad85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb2abe0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafae8128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2abe0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4e182e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad8438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb2abe0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb0ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad84a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdafb2abe0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb925f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad8278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2abe0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad8a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb2abe0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad8278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb2abe0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafad8518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad84a8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdafb2abe0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafad8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafb2abe0> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafae82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2ae48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafb2abe0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb92908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae86a0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafad82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae86a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafae8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae8828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafae86a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafae8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae86a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafae8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae86a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa811d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae86a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa81470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae86a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafae8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae86a0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafae8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae84e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafae86a0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa813c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae8828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafae86a0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa81198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae8ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafae86a0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa816d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae8f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafae86a0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa81ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa819b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae86a0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa81860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae8ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafae86a0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa81c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae8ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdafae86a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafae8390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae8ac8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdafae86a0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafad8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae8f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafae86a0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafad8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa819b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafae86a0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5c58fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa819b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafae86a0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ddc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae86a0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafad81d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb925f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb92518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb925f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafad8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb925f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb2abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb925f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafae82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae8400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb925f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafad8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb925f8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb925f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb5cc6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb925f8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb92fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad8978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb925f8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafad82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad8438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb925f8> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb2afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb925f8> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb925f8> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb84b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49074a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafad8978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafb925f8> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae8940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb925f8> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb925f8> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafb925f8> 0.0 17
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb2ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdafb925f8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb4f31518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb925f8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb0aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae8940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafb925f8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb7f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafb925f8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb7fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdafb925f8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb4ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb925f8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb2aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad8978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdafb925f8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa810b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa81160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafaac358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaac240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafaac1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad8a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa81828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafaac710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 7
Completed Iteration #8
Best Reward: 0
coverage_call_count 5500
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafaacb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaaca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafaac9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaac128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafaacc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafaacd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaac240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafab60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafab6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafab6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb7f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaac240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa81518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafaac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad8a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdb4f316d8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafab6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafab67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaaca58> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafab6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafab6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaaca58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafaaccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafab6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaaca58> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafab6a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49bbda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaaca58> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafab6a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafab6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaaca58> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa50240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafab67f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafaaca58> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa50470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa50358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaaca58> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafab6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa50748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaaca58> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafab6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafab67f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafaaca58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa500b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa50358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafaaca58> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa50a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafab6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafaaca58> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa50eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa50da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaaca58> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa50fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafab6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafaaca58> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa50ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafab65f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaaca58> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa50c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa50748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafaaca58> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa50208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa50358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafaaca58> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa62208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafab67f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdafaaca58> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa62710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa625f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa500b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa50358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdafaaca58> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa624a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafab65f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafaaca58> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa62a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa627b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa62ac8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa50b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa62d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa62ac8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa62b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa50908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa62ac8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa620f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa627b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa62ac8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa75128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa62d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa62ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa62cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa75908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa62ac8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa62518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa62eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa62ac8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa62c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa627b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafa62ac8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa62ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa62550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa62ac8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa62240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa75518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa62ac8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa50978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa62d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafa62ac8> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa62d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa627b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdafa62ac8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa50390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa506d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa62ac8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa50e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa75908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa62ac8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafab6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa75908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafa62ac8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafab6cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa627b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdafa62ac8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafab6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa75518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa62ac8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafab6e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa62e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa62630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafab6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafab6908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa62630> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa81240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa62630> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafaacb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaacd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa62630> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafab6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa62630> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafaac748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafab6908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa62630> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafaaca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaac080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa62630> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efe3478f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa62630> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa62630> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb4ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa62e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa62630> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa62630> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafaac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdb49bb630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa62630> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafab62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa62630> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb2ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaacd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa62630> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb2ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaacd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafa62630> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaac080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa62630> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb929e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaacb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafad80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaacb38> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafad8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa75080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaacb38> 0.0 4
Completed Iteration #5
Best Reward: 0
coverage_call_count 5600
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa75780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaacb38> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa75080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafaacb38> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa50dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaacb38> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa50cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb7ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaacb38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaacb38> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb92be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa75080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafaacb38> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafab63c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaacb38> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb7f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad8ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafaacb38> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafaac2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad8ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafaacb38> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa75a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafaacb38> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa75ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb2aba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafaacb38> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafae8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa75080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdafaacb38> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaacb38> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb92518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafaacb38> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e6a0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa812b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e6a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa3d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e6a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa3d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa3d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e6a0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa2eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa3d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e6a0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa2ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e6a0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa3d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa3d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e6a0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa3d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e6a0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa3deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e6a0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa2eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa75e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e6a0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa3d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa3df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e6a0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa3d8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e6a0> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa3d6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e6a0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa3d8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e6a0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa3d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdbe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa3d400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa3dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdbe0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa3d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa3d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdbe0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa3d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa3d080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdbe0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa3dda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdbe0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa3d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdbe0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa3d2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdbe0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa2ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdbe0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdbe0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb929e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdbe0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafad8ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb7f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdbe0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafad8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdbe0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb92da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa3dda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdbe0> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa3d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdbe0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa75780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd7f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdbe0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa3d2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdbe0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdb49ac4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa75160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa3d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa2ebe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdbe0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafad8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa75e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb84b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa3dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa75a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb84b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa81e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb84b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa819e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb84b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb84b38> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb84b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafae8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa75a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb84b38> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafaacba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaac860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb84b38> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafab6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafab6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb84b38> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa62b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafb84b38> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa50cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae8d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb84b38> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafab6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb4c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb84b38> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafab6358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb84b38> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafab6358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb84b38> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaac860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb84b38> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaac860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafb84b38> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafb7f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafab6358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafb84b38> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa3df28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa75e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafb84b38> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafaaca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa50860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81240> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafaac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa81240> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaacda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81240> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf38a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafa81240> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf38a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa50860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa81240> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf38a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa75f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81240> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf38a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa81240> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf38ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafa81240> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf396208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf38a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81240> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf38aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf38a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa81240> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf38ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdafa81240> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf396438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf38a860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafa81240> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf38a860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdafa81240> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3967f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdafa81240> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf396ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf396828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf396c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf38a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf396e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf396c18> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf396d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf38a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf396c18> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf396a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf38a940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf396c18> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf396860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf396c18> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf38a940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf396c18> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf396860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf396c18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf396390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf38a940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdaf396c18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3960b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf396c18> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf396c18> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aaeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf396c18> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b80b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3960b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf396c18> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa62588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf396c18> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf396c18> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf38a940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdaf396c18> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa50860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf396c18> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa3d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81748> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81748> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafab6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafab6898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81748> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafaacf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafab6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81748> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafaac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa81748> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa75d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaacba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81748> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafad84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa75b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81748> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa81240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81748> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafaac588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafab6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa81748> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf38a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaacb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81748> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf38a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaacba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa81748> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa81748> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafa81748> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf38acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaacb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa81748> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf396dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaacba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafa81748> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf396278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafab6898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa81748> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3964a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa75b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa81748> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf38a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa2ec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdafa81748> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafa81c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdafa81748> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa6a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf38af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b86a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa6a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b8160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa6a0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa6a0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa6a0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b8a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b86a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa6a0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b86a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa6a0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbbd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa6a0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafaacda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aadd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa6a0> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf38a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b8160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa6a0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf396a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b8ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa6a0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aadd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa6a0> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b84e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa6a0> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b8ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafae8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa6a0> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafbd2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b8160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa6a0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 12.007042253521128
coverage_call_count 5800
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e4e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf35eac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e4e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e4e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e4e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e4e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf35ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e4e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf379240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf35eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e4e0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf379630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf379518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e4e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e4e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf379588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf35ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e4e0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf379908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf379518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e4e0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf379a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf35ef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e4e0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf379be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf379ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e4e0> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf309048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e4e0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf379c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf379518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e4e0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf379668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b8978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e4e0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3092e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf379ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e4e0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf309748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf379ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e4e0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf309b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf309780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf309b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3799b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf309dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf309b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf309c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf379da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf309b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf309f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf309f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf309b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf31d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf31d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf309b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa75da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf309b70> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cd240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf309b70> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf379da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf309b70> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafae8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf35ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf309b70> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b8978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf379da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf309b70> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf35e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf31d1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf309b70> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf31d1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf309b70> 0.0 13
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf309b70> 0.0 14
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa81e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa0f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa0f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa0f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b87b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa0f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafab6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa0f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafaac278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa0f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf38a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdf60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa0f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafaac588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf38a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa0f0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafa2e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa0f0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf38a780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa0f0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf379ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3cdf60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa0f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafab67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf38ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa0f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3961d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad8940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa0f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3790f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf38a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa0f0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf379128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf38ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa0f0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf309ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafad8940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa0f0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3096a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3092e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa0f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf379b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf38ac50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa0f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf309cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf396a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf379ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf309c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf309438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf379ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf309fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf309438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf379ba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf31d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf31d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf379ba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaacba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf379ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf396a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf379ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf379ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf35ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf396048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf379ba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf31d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf31d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf379ba8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf31d5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf396a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf379ba8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aadd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf3b8be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf379ba8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf379630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaacba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf379ba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf31db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf35eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf379ba8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf31dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf379400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf379ba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf31d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf31d6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf379ba8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf31dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf31d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf379ba8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d40b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdafaacba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf379ba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf31de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf35eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf379ba8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf31d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf35eeb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf379ba8> 0.0 20
Completed Iteration #23
Best Reward: 0
coverage_call_count 5900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf31d160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf379ba8> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf396048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf379ba8> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 12.007042253521128
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4710> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf31deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4710> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4710> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4710> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e77b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4710> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4710> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4710> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4710> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4710> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4710> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4710> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2f60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4710> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf3aa198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4710> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf38a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4710> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf31d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4710> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4710> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4710> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 12.007042253521128
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2f66a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2f6588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7da0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2f67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7da0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7da0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7da0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d49b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7da0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7da0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d46a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7da0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2f64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7da0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2f6588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7da0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7da0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7da0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7da0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf31d8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7da0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf31dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2f64a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7da0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf31de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7da0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf31dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7da0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7da0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf309fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7da0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdafb2a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2d4208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7da0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7efdaf309588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7668> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7efdaf2e7da0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 12.007042253521128
initial coverage: 11.7254
time passed (minutes): 60.3135
iterations: 202
number of new inputs: 256
final coverage: 12.007
total coverage increase: 0.28169
