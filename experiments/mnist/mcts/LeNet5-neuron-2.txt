Parameters: Namespace(action_division_p1=(1, 3, 3, 1), actions_p2=[('contrast', 1.2), ('contrast', 1.4), ('contrast', 1.6), ('contrast', 1.8), ('contrast', 2.0), ('contrast', 2.2), ('contrast', 2.4000000000000004), ('contrast', 2.6), ('contrast', 2.8), ('contrast', 3.0), ('brightness', 10), ('brightness', 20), ('brightness', 30), ('brightness', 40), ('brightness', 50), ('brightness', 60), ('brightness', 70), ('brightness', 80), ('brightness', 90), ('brightness', 100), ('blur', 1), ('blur', 2), ('blur', 3), ('blur', 4), ('blur', 5), ('blur', 6), ('blur', 7), ('blur', 8), ('blur', 9), ('blur', 10)], batch_size=64, calc_implicit_reward=None, calc_implicit_reward_neuron=None, coverage='neuron', dataset='MNIST', image_verbose=False, implicit_reward=False, input_chooser='random', input_lower_limit=0, input_shape=(1, 28, 28, 1), input_upper_limit=255, model='LeNet5', nb_iterations=None, nb_new_inputs=1000, params_set=['mnist', 'LeNet5', 'mcts', 'neuron'], random_seed=None, runner='mcts', save_batch=False, tc1=<function tc1 at 0x7fe081c6ff28>, tc2=<function tc2 at 0x7fe081c7e048>, tc3=<function tc3 at 0x7fe081c7e158>, tfc_threshold=3300000, time_period=3600, verbose=True)
initial coverage: 67.1756
self.actions_p1
[{'lower_limits': array([0, 0, 0, 0]), 'upper_limits': array([1, 9, 9, 1])},
 {'lower_limits': array([0, 0, 9, 0]), 'upper_limits': array([ 1,  9, 18,  1])},
 {'lower_limits': array([ 0,  0, 18,  0]),
  'upper_limits': array([ 1,  9, 28,  1])},
 {'lower_limits': array([0, 9, 0, 0]), 'upper_limits': array([ 1, 18,  9,  1])},
 {'lower_limits': array([0, 9, 9, 0]), 'upper_limits': array([ 1, 18, 18,  1])},
 {'lower_limits': array([ 0,  9, 18,  0]),
  'upper_limits': array([ 1, 18, 28,  1])},
 {'lower_limits': array([ 0, 18,  0,  0]),
  'upper_limits': array([ 1, 28,  9,  1])},
 {'lower_limits': array([ 0, 18,  9,  0]),
  'upper_limits': array([ 1, 28, 18,  1])},
 {'lower_limits': array([ 0, 18, 18,  0]),
  'upper_limits': array([ 1, 28, 28,  1])}]
self.actions_p2
[('contrast', 1.2),
 ('contrast', 1.4),
 ('contrast', 1.6),
 ('contrast', 1.8),
 ('contrast', 2.0),
 ('contrast', 2.2),
 ('contrast', 2.4000000000000004),
 ('contrast', 2.6),
 ('contrast', 2.8),
 ('contrast', 3.0),
 ('brightness', 10),
 ('brightness', 20),
 ('brightness', 30),
 ('brightness', 40),
 ('brightness', 50),
 ('brightness', 60),
 ('brightness', 70),
 ('brightness', 80),
 ('brightness', 90),
 ('brightness', 100),
 ('blur', 1),
 ('blur', 2),
 ('blur', 3),
 ('blur', 4),
 ('blur', 5),
 ('blur', 6),
 ('blur', 7),
 ('blur', 8),
 ('blur', 9),
 ('blur', 10)]
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186dff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01876afd0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01876afd0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01876afd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01876afd0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186eecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01876afd0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01876afd0> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe01876afd0> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01876afd0> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01876afd0> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01876afd0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe01876afd0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe01876afd0> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186990b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01876afd0> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe01876afd0> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01876afd0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 0
found coverage increase 0
Current Total Coverage 67.17557251908397
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186994e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186990f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186995c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186990f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186990f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186990f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186996a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186990f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186997f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186990f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186990f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018776278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187722e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186990f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018776358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe0186990f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186990f0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186df978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186995c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186990f0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186995c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186990f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186eeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186990f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186990f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186996a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186990f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186990f0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186990f0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186996a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186990f0> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186990f0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 1
found coverage increase 0
Current Total Coverage 67.17557251908397
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad908> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186add68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad908> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186addd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186adef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad908> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187722e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad908> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018776710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad908> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad908> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018776710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad908> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018776710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad908> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018776710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad908> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186996a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186adba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad908> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad908> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad908> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad908> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad908> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018776710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad908> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186adba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad908> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186adc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186995c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad908> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad908> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186eea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186adef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad908> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad908> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad908> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 2
found coverage increase 0
Current Total Coverage 67.17557251908397
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186adb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186eeb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada20> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186856a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186eeb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada20> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada20> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada20> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186eedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada20> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada20> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada20> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada20> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada20> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186eedd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada20> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada20> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186856d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada20> 0.0 21
Completed Iteration #22
Best Reward: 0
coverage_call_count 100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada20> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186eedd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada20> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada20> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 3
found coverage increase 0
Current Total Coverage 67.17557251908397
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186711d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e048> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e048> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01864e048> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186719b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e048> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186711d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01864e048> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e048> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e048> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187720b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e048> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01864e048> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186711d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe01864e048> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e048> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c45f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01864e048> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe01864e048> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe01864e048> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe01864e048> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01864e048> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186854a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01864e048> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e048> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 4
found coverage increase 0
Current Total Coverage 67.17557251908397
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c44a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186854e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.3816793893129784 7
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186854e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.3816793893129784 8
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.3816793893129784 9
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 0.3816793893129784 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.3816793893129784 10
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.3816793893129784 11
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.3816793893129784 12
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186854e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.3816793893129784 13
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.3816793893129784 14
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.3816793893129784 15
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 0.3816793893129784 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.3816793893129784 16
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.3816793893129784 17
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1400> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4e80> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 0.7633587786259568 7
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.7633587786259568 18
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 0.7633587786259568 8
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.7633587786259568 19
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 0.7633587786259568 9
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.7633587786259568 20
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 0.7633587786259568 10
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.7633587786259568 21
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 0.7633587786259568 11
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.7633587786259568 22
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 0.7633587786259568 12
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.7633587786259568 23
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186710b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4e80> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 0.7633587786259568 13
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.7633587786259568 24
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4e80> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 0.7633587786259568 14
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.7633587786259568 25
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187720f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186856d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1400> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4e80> 0.3816793893129784 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 0.7633587786259568 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 0.7633587786259568 15
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.7633587786259568 26
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 0.7633587786259568 16
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.7633587786259568 27
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186eedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864ec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 0.7633587786259568 7
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 0.7633587786259568 17
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.7633587786259568 28
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #1
root->5
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fe0186719b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 1.1450381679389352 8
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 1.1450381679389352 18
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 1.1450381679389352 29
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e860> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 1.5267175572519136 9
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 1.5267175572519136 19
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 1.5267175572519136 30
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc77ee80> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 1.908396946564892 10
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 1.908396946564892 20
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 1.908396946564892 31
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 2.2900763358778704 11
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 2.2900763358778704 21
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 2.2900763358778704 32
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 2.671755725190849 12
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 2.671755725190849 22
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 2.671755725190849 33
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1e10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864ec18> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 3.053435114503827 13
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 3.053435114503827 23
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 3.053435114503827 34
Completed Iteration #21
Best Reward: 0.3816793893129784
coverage_call_count 200
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfcc0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1a20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1e10> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fe01864ec18> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 3.4351145038168056 14
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 3.4351145038168056 24
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 3.4351145038168056 35
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee320> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77ec18> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e860> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 3.816793893129784 15
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 3.816793893129784 25
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 3.816793893129784 36
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #2
root->5->19
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77ee80> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 3.816793893129784 16
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 3.816793893129784 26
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 3.816793893129784 37
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc799c88> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186719b0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 2.671755725190849 9
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 4.198473282442762 17
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 4.198473282442762 27
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 4.198473282442762 38
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e860> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 2.671755725190849 10
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 4.198473282442762 18
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 4.198473282442762 28
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 4.198473282442762 39
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc77ed30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e550> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186719b0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 3.053435114503827 11
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 4.580152671755741 19
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 4.580152671755741 29
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 4.580152671755741 40
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1908> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 3.4351145038168056 12
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 4.961832061068719 20
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 4.961832061068719 30
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 4.961832061068719 41
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1668> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 3.816793893129784 13
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 5.343511450381698 21
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 5.343511450381698 31
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 5.343511450381698 42
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc77eda0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 4.198473282442762 14
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 5.725190839694676 22
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 5.725190839694676 32
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 5.725190839694676 43
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77eda0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 4.198473282442762 15
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 5.725190839694676 23
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 5.725190839694676 33
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 5.725190839694676 44
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 4.580152671755741 16
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 6.106870229007654 24
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 6.106870229007654 34
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 6.106870229007654 45
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc743ba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 4.961832061068719 17
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 6.488549618320633 25
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 6.488549618320633 35
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 6.488549618320633 46
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77eda0> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 4.961832061068719 18
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 6.488549618320633 26
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 6.488549618320633 36
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 6.488549618320633 47
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fe01864ecc0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 5.343511450381698 19
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 6.870229007633611 27
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 6.870229007633611 37
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 6.870229007633611 48
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186711d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc743ba8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 5.343511450381698 20
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 6.870229007633611 28
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 6.870229007633611 38
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 6.870229007633611 49
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77ed68> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77ee80> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 5.725190839694676 21
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 7.25190839694659 29
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 7.25190839694659 39
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 7.25190839694659 50
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #3
root->5->19->6
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fe018671c50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 6.106870229007654 22
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 7.633587786259568 30
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 7.633587786259568 40
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 7.633587786259568 51
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1da0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 6.488549618320633 23
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 8.015267175572546 31
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 8.015267175572546 41
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 8.015267175572546 52
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 6.488549618320633 24
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 8.015267175572546 32
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 8.015267175572546 42
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 8.015267175572546 53
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432b0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 2.2900763358778704 9
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 6.488549618320633 25
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 8.015267175572546 33
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 8.015267175572546 43
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 8.015267175572546 54
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ee10> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799e80> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 2.671755725190849 10
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 6.870229007633611 26
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 8.396946564885525 34
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 8.396946564885525 44
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 8.396946564885525 55
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799e80> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 2.671755725190849 11
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 6.870229007633611 27
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 8.396946564885525 35
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 8.396946564885525 45
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 8.396946564885525 56
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1b70> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7430f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 3.053435114503827 12
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 7.25190839694659 28
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 8.778625954198503 36
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 8.778625954198503 46
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 8.778625954198503 57
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ef28> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 2.2900763358778704 9
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 3.4351145038168056 13
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 7.633587786259568 29
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 9.160305343511482 37
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 9.160305343511482 47
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 9.160305343511482 58
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ef98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ee10> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc799e80> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 3.816793893129784 14
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 8.015267175572546 30
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 9.54198473282446 38
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 9.54198473282446 48
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 9.54198473282446 59
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799e80> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 3.816793893129784 15
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 8.015267175572546 31
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 9.54198473282446 39
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 9.54198473282446 49
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 9.54198473282446 60
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 3.816793893129784 16
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 8.015267175572546 32
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 9.54198473282446 40
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 9.54198473282446 50
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 9.54198473282446 61
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #4
root->5->19->6->1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ecc0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671c50> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 2.671755725190849 10
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 4.198473282442762 17
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 8.396946564885525 33
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 9.923664122137438 41
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 9.923664122137438 51
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 9.923664122137438 62
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671c50> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 2.671755725190849 11
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 4.198473282442762 18
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 8.396946564885525 34
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 9.923664122137438 42
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 9.923664122137438 52
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 9.923664122137438 63
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc76ccf8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c898> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1908> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 3.053435114503827 12
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 4.580152671755741 19
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 8.778625954198503 35
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 10.305343511450417 43
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 10.305343511450417 53
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 10.305343511450417 64
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671c50> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 3.053435114503827 13
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 4.580152671755741 20
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 8.778625954198503 36
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 10.305343511450417 44
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 10.305343511450417 54
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 10.305343511450417 65
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ecc0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fe018671c50> 0.7633587786259568 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 3.053435114503827 14
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 4.580152671755741 21
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 8.778625954198503 37
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 10.305343511450417 45
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 10.305343511450417 55
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 10.305343511450417 66
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc776ba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 3.4351145038168056 15
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 4.961832061068719 22
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 9.160305343511482 38
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 10.687022900763395 46
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 10.687022900763395 56
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 10.687022900763395 67
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc776f98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 3.816793893129784 16
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 5.343511450381698 23
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 9.54198473282446 39
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 11.068702290076374 47
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 11.068702290076374 57
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 11.068702290076374 68
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc701048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc776d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc776ba8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 3.816793893129784 17
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 5.343511450381698 24
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 9.54198473282446 40
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 11.068702290076374 48
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 11.068702290076374 58
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 11.068702290076374 69
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 3.816793893129784 18
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 5.343511450381698 25
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 9.54198473282446 41
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 11.068702290076374 49
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 11.068702290076374 59
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 11.068702290076374 70
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 4.198473282442762 19
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 5.725190839694676 26
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 9.923664122137438 42
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 11.450381679389352 50
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 11.450381679389352 60
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 11.450381679389352 71
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc776ba8> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 4.198473282442762 20
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 5.725190839694676 27
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 9.923664122137438 43
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 11.450381679389352 51
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 11.450381679389352 61
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 11.450381679389352 72
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 4.198473282442762 21
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 5.725190839694676 28
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 9.923664122137438 44
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 11.450381679389352 52
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 11.450381679389352 62
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 11.450381679389352 73
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc776828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1390> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 4.198473282442762 22
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 5.725190839694676 29
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 9.923664122137438 45
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 11.450381679389352 53
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 11.450381679389352 63
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 11.450381679389352 74
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #5
root->5->19->6->1->3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc701630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 1.908396946564892 9
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 4.198473282442762 23
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 5.725190839694676 30
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 9.923664122137438 46
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 11.450381679389352 54
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 11.450381679389352 64
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 11.450381679389352 75
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c048> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 4.580152671755741 24
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 6.106870229007654 31
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 10.305343511450417 47
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 11.83206106870233 55
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 11.83206106870233 65
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 11.83206106870233 76
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc7012b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7430b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1908> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 2.671755725190849 11
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 4.961832061068719 25
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 6.488549618320633 32
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 10.687022900763395 48
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 12.213740458015309 56
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 12.213740458015309 66
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 12.213740458015309 77
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc719550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c898> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1908> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 3.053435114503827 12
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 5.343511450381698 26
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 6.870229007633611 33
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 11.068702290076374 49
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 12.595419847328287 57
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 12.595419847328287 67
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 12.595419847328287 78
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
coverage_call_count 300
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc735438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 3.4351145038168056 13
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 5.725190839694676 27
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 7.25190839694659 34
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 11.450381679389352 50
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 12.977099236641266 58
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 12.977099236641266 68
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 12.977099236641266 79
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #6
root->5->19->6->1->3->10
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f28> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1668> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 3.816793893129784 14
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 6.106870229007654 28
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 7.633587786259568 35
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 11.83206106870233 51
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 13.358778625954244 59
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 13.358778625954244 69
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 13.358778625954244 80
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7016d8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7012b0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7430b8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1908> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 3.053435114503827 9
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 4.198473282442762 15
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 6.488549618320633 29
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 8.015267175572546 36
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 12.213740458015309 52
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 13.740458015267222 60
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 13.740458015267222 70
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 13.740458015267222 81
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc722978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7199b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1668> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 3.4351145038168056 10
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 4.580152671755741 16
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 6.870229007633611 30
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 8.396946564885525 37
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 12.595419847328287 53
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 14.1221374045802 61
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 14.1221374045802 71
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 14.1221374045802 82
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc7222b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 3.816793893129784 11
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 4.961832061068719 17
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 7.25190839694659 31
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 8.778625954198503 38
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 12.977099236641266 54
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 14.50381679389318 62
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 14.50381679389318 72
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 14.50381679389318 83
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c048> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 3.816793893129784 12
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 4.961832061068719 18
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 7.25190839694659 32
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 8.778625954198503 39
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 12.977099236641266 55
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 14.50381679389318 63
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 14.50381679389318 73
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 14.50381679389318 84
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc735a90> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7222b0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 4.198473282442762 13
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 5.343511450381698 19
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 7.633587786259568 33
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 9.160305343511482 40
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 13.358778625954244 56
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 14.885496183206158 64
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 14.885496183206158 74
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 14.885496183206158 85
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc735f60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735630> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7222b0> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 4.580152671755741 14
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 5.725190839694676 20
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 8.015267175572546 34
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 9.54198473282446 41
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 13.740458015267222 57
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 15.267175572519136 65
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 15.267175572519136 75
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 15.267175572519136 86
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 4.961832061068719 15
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 6.106870229007654 21
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 8.396946564885525 35
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 9.923664122137438 42
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 14.1221374045802 58
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 15.648854961832114 66
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 15.648854961832114 76
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 15.648854961832114 87
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eb00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e710> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735a90> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc735630> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7222b0> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 5.343511450381698 16
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 6.488549618320633 22
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 8.778625954198503 36
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 10.305343511450417 43
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 14.50381679389318 59
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 16.030534351145093 67
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 16.030534351145093 77
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 16.030534351145093 88
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc722630> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 5.725190839694676 17
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 6.870229007633611 23
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 9.160305343511482 37
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 10.687022900763395 44
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 14.885496183206158 60
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 16.41221374045807 68
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 16.41221374045807 78
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 16.41221374045807 89
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7357b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 5.725190839694676 18
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 6.870229007633611 24
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 9.160305343511482 38
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 10.687022900763395 45
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 14.885496183206158 61
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 16.41221374045807 69
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 16.41221374045807 79
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 16.41221374045807 90
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #7
root->5->19->6->1->3->10->1
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7356a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76ccf8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c898> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1908> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 5.725190839694676 19
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 6.870229007633611 25
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 9.160305343511482 39
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 10.687022900763395 46
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 14.885496183206158 62
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 16.41221374045807 70
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 16.41221374045807 80
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 16.41221374045807 91
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cdd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719d68> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1908> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 6.106870229007654 20
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 7.25190839694659 26
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 9.54198473282446 40
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 11.068702290076374 47
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 15.267175572519136 63
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 16.79389312977105 71
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 16.79389312977105 81
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 16.79389312977105 92
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc701400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7011d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719550> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c898> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1908> 2.2900763358778704 9
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 6.106870229007654 21
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 7.25190839694659 27
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 9.54198473282446 41
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 11.068702290076374 48
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 15.267175572519136 64
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 16.79389312977105 72
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 16.79389312977105 82
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 16.79389312977105 93
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c898> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1908> 2.671755725190849 10
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 6.488549618320633 22
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 7.633587786259568 28
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 9.923664122137438 42
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 11.450381679389352 49
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 15.648854961832114 65
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 17.175572519084028 73
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 17.175572519084028 83
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 17.175572519084028 94
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ceb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1908> 2.671755725190849 11
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 6.488549618320633 23
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 7.633587786259568 29
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 9.923664122137438 43
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 11.450381679389352 50
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 15.648854961832114 66
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 17.175572519084028 74
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 17.175572519084028 84
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 17.175572519084028 95
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7430b8> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1908> 2.671755725190849 12
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 6.488549618320633 24
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 7.633587786259568 30
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 9.923664122137438 44
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 11.450381679389352 51
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 15.648854961832114 67
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 17.175572519084028 75
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 17.175572519084028 85
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 17.175572519084028 96
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc735978> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c898> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1908> 3.053435114503827 13
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 6.870229007633611 25
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 8.015267175572546 31
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 10.305343511450417 45
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 11.83206106870233 52
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 16.030534351145093 68
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 17.557251908397006 76
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 17.557251908397006 86
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 17.557251908397006 97
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c898> 1.5267175572519136 8
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1908> 3.053435114503827 14
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 6.870229007633611 26
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 8.015267175572546 32
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 10.305343511450417 46
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 11.83206106870233 53
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 16.030534351145093 69
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 17.557251908397006 77
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 17.557251908397006 87
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 17.557251908397006 98
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7430b8> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1908> 3.053435114503827 15
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 6.870229007633611 27
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 8.015267175572546 33
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 10.305343511450417 47
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 11.83206106870233 54
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 16.030534351145093 70
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 17.557251908397006 78
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 17.557251908397006 88
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 17.557251908397006 99
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc6cef98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719470> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719550> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c898> 1.908396946564892 9
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1908> 3.4351145038168056 16
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 7.25190839694659 28
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 8.396946564885525 34
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 10.687022900763395 48
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 12.213740458015309 55
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 16.41221374045807 71
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 17.938931297709985 79
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 17.938931297709985 89
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 17.938931297709985 100
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6cec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6eda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7012b0> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7430b8> 0.7633587786259568 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1908> 3.4351145038168056 17
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 7.25190839694659 29
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 8.396946564885525 35
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 10.687022900763395 49
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 12.213740458015309 56
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 16.41221374045807 72
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 17.938931297709985 80
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 17.938931297709985 90
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 17.938931297709985 101
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7012b0> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7430b8> 0.7633587786259568 7
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1908> 3.4351145038168056 18
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 7.25190839694659 30
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 8.396946564885525 36
backprop <src.mcts.MCTS_Node object at 0x7fdffc7998d0> 10.687022900763395 50
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e0f0> 12.213740458015309 57
backprop <src.mcts.MCTS_Node object at 0x7fe01864e630> 16.41221374045807 73
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1e80> 17.938931297709985 81
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 17.938931297709985 91
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 17.938931297709985 102
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #8
root->5->19->6->1->3->10->1->2
Best Reward: 0.3816793893129784
iteration: 5
found coverage increase 0.3816793893129784
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6358> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6358> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc719198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6358> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7229b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6358> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6358> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6358> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6358> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6358> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6358> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7762b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6358> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6358> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6358> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6358> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6358> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6358> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6240> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6358> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 6
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f69e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6992e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6f60> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6f60> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6f60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f69e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6f60> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6991d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f69e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6f60> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6996d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6f60> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6992e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc699400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6f60> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6f60> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
coverage_call_count 400
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6997f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6f60> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6addd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6f60> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6cecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6f60> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 7
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6994e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7229e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ada20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7229e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7229e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7229e8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6404e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7229e8> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6400f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7229e8> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7229e8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7229e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6405c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7229e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7229e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7229e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6adba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7229e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7229e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7354a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7229e8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6405c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7229e8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7229e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6adbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7229e8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7229e8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 8
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722eb8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722eb8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722eb8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186852b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722eb8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc722eb8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722eb8> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722eb8> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6cecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722eb8> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722eb8> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc722eb8> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6cee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc722eb8> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ceda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc722eb8> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722eb8> 0.0 14
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ada58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc722eb8> 0.0 15
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ceda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc722eb8> 0.0 16
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc722eb8> 0.0 17
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc722eb8> 0.0 18
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc722eb8> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7014e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc722eb8> 0.0 20
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc722eb8> 0.0 21
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc722eb8> 0.0 22
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7761d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc722eb8> 0.0 23
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 9
found coverage increase 0
Current Total Coverage 67.55725190839695
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640e80> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640e80> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640e80> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640e80> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc640e80> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc640e80> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc640e80> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640e80> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc640e80> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc776e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640e80> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc640e80> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc640e80> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640e80> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc640e80> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbda20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640e80> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc640e80> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc640e80> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640e80> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f0b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc640e80> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 10
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbdd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd6a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd6a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd6a0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6adeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd6a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6cec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd6a0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6406a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbdd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd6a0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd6a0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd6a0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd6a0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd6a0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd6a0> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd6a0> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd6a0> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd6a0> 0.0 15
Completed Iteration #16
Best Reward: 0
coverage_call_count 500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd17f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbdda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd6a0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd6a0> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd6a0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbdd68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd6a0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd6a0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f1d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd6a0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbdda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd6a0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 11
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5b00> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5b00> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5b00> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff80f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5b00> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04df24e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5b00> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04ffd3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04ffd3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5b00> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04de564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5b00> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe09dd81fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5b00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01877f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5b00> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff80f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5b00> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01877f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5b00> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5b00> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04ffd3940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd11d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5b00> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5b00> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd11d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5b00> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5b00> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04ffd3048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5b00> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 12
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a7b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc743c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a7b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7437f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a7b8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a7b8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a7b8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a7b8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7435c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a7b8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a7b8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a7b8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a7b8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a7b8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a7b8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a7b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7996a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a7b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a7b8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc743d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a7b8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc743c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a7b8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 13
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f98> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f98> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f98> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f98> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f98> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f98> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f98> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7438d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f98> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f98> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f98> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f98> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f98> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77eba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f98> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f98> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f98> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f98> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186df9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f98> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f98> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 14
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018671a20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671a20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186719b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018671a20> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671a20> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018671a20> 0.0 11
Completed Iteration #13
Best Reward: 0
coverage_call_count 600
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe018671a20> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018671a20> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018671a20> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671a20> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186715c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671a20> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe018671a20> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671ba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe018671a20> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 15
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4d68> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4d68> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4d68> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186712b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4d68> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186df9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4d68> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c47b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4d68> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4d68> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77eeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4d68> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4d68> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c47b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4d68> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4d68> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4d68> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4d68> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4d68> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4d68> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77eeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4d68> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c47b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4d68> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4d68> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4d68> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 16
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7436d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc743438> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc743be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc743438> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7434e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc743438> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc743438> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc743438> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7436d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc743438> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc743438> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01876af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01876a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc743438> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc743be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc743438> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04de4aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7434e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc743438> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01876a048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc743438> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc743be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc743438> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187609e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc743be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc743438> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018760c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc743438> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc743438> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7434e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc743438> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc743438> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe59b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc743438> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7436d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc743438> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018776710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc743438> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01876add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc743438> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 17
found coverage increase 0
Current Total Coverage 67.55725190839695
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187606a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018776320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187600b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018776320> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018760390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018776320> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018760400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018776320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018776320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187601d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018776320> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018776320> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018776320> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018776320> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe018776320> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018760358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018776320> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe018776320> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018776320> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018776320> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe018776320> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186eee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018760860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe018776320> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 18
found coverage increase 0
Current Total Coverage 67.55725190839695
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186eeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee320> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee320> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee320> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee320> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee320> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186adbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee320> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee320> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186adef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee320> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee320> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186eef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186eecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee320> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee320> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee320> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee320> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee320> 0.0 15
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 19
found coverage increase 0
Current Total Coverage 67.55725190839695
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e128> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186adcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e128> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018760dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01864e128> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018760908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e128> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01864e128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018760668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187601d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e128> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e128> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01876add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01864e128> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01864e128> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01864e128> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e128> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186adcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01864e128> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe01864e128> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe01864e128> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 20
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc743080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7435c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432b0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7435c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432b0> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018760cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc743080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186710b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7435c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 21
found coverage increase 0
Current Total Coverage 67.55725190839695
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f278> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f278> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbdc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f278> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7438d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f278> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01879c710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f278> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01879c710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01874f278> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbdf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01874f278> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01874f278> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f278> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01874f278> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874fd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01874f278> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874fda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe01874f278> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f278> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f278> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f278> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874fd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe01874f278> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 22
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6409e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6409e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6409e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6409e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01879cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6409e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6409e8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6409e8> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6409e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6409e8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6409e8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc6409e8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6409e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6409e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6409e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6402e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6409e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc6409e8> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 23
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874fb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874fb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6407f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874fb38> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874fb38> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04de4aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01874fb38> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01874fb38> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018776588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874fb38> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe01874fb38> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01874fb38> 0.0 10
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186eef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874fb38> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe01874fb38> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018776588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01874fb38> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01874fb38> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187606a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc743be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874fb38> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018760550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01874fb38> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01876add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187603c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874fb38> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 24
found coverage increase 0
Current Total Coverage 67.55725190839695
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187601d0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6406a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187601d0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187601d0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0187601d0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0187601d0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187601d0> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186993c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0187601d0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7010f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187601d0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0187601d0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187601d0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7016d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187601d0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7014a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0187601d0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc701eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0187601d0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0187601d0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0187601d0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6406a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0187601d0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc701d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187601d0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 25
found coverage increase 0
Current Total Coverage 67.55725190839695
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef438> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef438> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef438> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef438> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef438> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc701048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef438> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef438> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef438> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef438> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef438> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7350f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef438> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc701b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7356a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef438> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef438> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef438> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef438> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef438> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef438> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef978> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef438> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef438> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef438> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7356a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef438> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef438> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 26
found coverage increase 0
Current Total Coverage 67.55725190839695
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701940> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01876add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701940> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701940> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
coverage_call_count 900
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc701940> 0.0 5
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc701390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc701940> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701940> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187603c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701940> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186adb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701940> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6407f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701940> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc701940> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc701940> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6407f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc701940> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc701940> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc701940> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc701940> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe54a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701940> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc701940> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc701940> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc701940> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 27
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760550> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018760550> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ede48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760550> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760550> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760550> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760550> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018760550> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018760550> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018760550> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760550> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760550> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760550> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760550> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe018760550> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018760550> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018760550> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edb00> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe018760550> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018760550> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe018760550> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe018760550> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 28
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7224a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7224a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7224a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7224a8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7224a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7225c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7224a8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6cee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7225c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7224a8> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6cec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7224a8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7224a8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc719668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7224a8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7224a8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7225c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7224a8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7224a8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc719588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7225c0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7224a8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc719cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7224a8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc719978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7224a8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7224a8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 29
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7195c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc719be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc719080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0b8> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6cec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0b8> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0b8> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6cec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0b8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0b8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0b8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0b8> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc719ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0b8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0b8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0b8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0b8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0b8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0b8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0b8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 30
found coverage increase 0
Current Total Coverage 67.55725190839695
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719ac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186adb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719ac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719ac8> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 1000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01876add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719ac8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc719ac8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc719ac8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7225c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719ac8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864eb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc719ac8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719ac8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7225c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc719ac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc701f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719ac8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187605f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc719ac8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc719ac8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc719ac8> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc719ac8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc719ac8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018776588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187605f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc719ac8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc719ac8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187605f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc719ac8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 31
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187603c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc701d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc722860> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc722860> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc722860> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc722860> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc722860> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6adcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722860> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc776c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc701f60> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc722860> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6adcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc722860> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701f60> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc722860> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc722860> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6adc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701f60> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fdffc722860> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc722860> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701f60> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7fdffc722860> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 32
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186854a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186854e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186854a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186854a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc776a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186854a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186854e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186854a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186854a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186854a8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186857f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186854a8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186854a8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186854a8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186854a8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186854a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186854a8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186854a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc776a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186854a8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186854a8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186854a8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 33
found coverage increase 0
Current Total Coverage 67.55725190839695
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f62b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e8d0> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e8d0> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f62b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e8d0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e8d0> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e8d0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e8d0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e8d0> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6adcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e8d0> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6adcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e8d0> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e8d0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e8d0> 0.0 12
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e8d0> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874fbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e8d0> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e8d0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc701e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e8d0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 34
found coverage increase 0
Current Total Coverage 67.55725190839695
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 3
Completed Iteration #2
Best Reward: 0
coverage_call_count 1100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6407f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7196d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76ce10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76ca90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018760e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7017b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874fd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 35
found coverage increase 0
Current Total Coverage 67.55725190839695
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699e48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699e48> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6995c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699e48> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6997b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699e48> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc699e48> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc699e48> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699e48> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699e48> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc699e48> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc699e48> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc699e48> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699e48> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6997b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc699e48> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc699e48> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc699e48> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc699e48> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc699e48> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699d68> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc699e48> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 36
found coverage increase 0
Current Total Coverage 67.55725190839695
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff41359e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 0.3816793893129784 8
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff41359b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 0.3816793893129784 9
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 0.3816793893129784 10
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 0.3816793893129784 11
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 0.3816793893129784 12
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff41359b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 0.3816793893129784 13
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 0.3816793893129784 14
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff41358d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 0.3816793893129784 15
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff41357b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 0.3816793893129784 16
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff86a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 0.3816793893129784 5
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 0.3816793893129784 17
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff41359b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 0.3816793893129784 18
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff41353c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 0.3816793893129784 6
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 0.3816793893129784 19
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 0.3816793893129784 7
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 0.3816793893129784 20
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 0.3816793893129784 8
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 0.3816793893129784 21
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fe0187766a0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 0.7633587786259568 9
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 0.7633587786259568 22
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 0.7633587786259568 10
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 0.7633587786259568 23
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 1.1450381679389352 11
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 1.1450381679389352 24
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187766a0> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 1.1450381679389352 12
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 1.1450381679389352 25
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed438> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414aa58> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e390> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 1.5267175572519136 13
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 1.5267175572519136 26
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc76ca90> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 1.908396946564892 14
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 1.908396946564892 27
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187766a0> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 1.908396946564892 15
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 1.908396946564892 28
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e390> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 1.908396946564892 16
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 1.908396946564892 29
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fe0186adcc0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a6d8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e390> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 2.2900763358778704 17
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 2.2900763358778704 30
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186adcc0> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdff414a6d8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e390> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 2.671755725190849 18
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 2.671755725190849 31
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e390> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 2.671755725190849 19
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 2.671755725190849 32
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #1
root->4
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 2.671755725190849 20
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 2.671755725190849 33
Completed Iteration #0
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 2.671755725190849 21
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 2.671755725190849 34
Completed Iteration #1
Best Reward: 0.3816793893129784
coverage_call_count 1200
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 3.053435114503827 22
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 3.053435114503827 35
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 1.1450381679389352 7
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 3.053435114503827 23
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 3.053435114503827 36
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5ef0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 1.5267175572519136 8
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 3.4351145038168056 24
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 3.4351145038168056 37
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5f60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 1.908396946564892 9
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 3.816793893129784 25
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 3.816793893129784 38
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4b70> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ee48> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 4.198473282442762 26
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 4.198473282442762 39
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5898> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 2.671755725190849 11
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 4.580152671755741 27
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 4.580152671755741 40
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4278> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5828> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 3.053435114503827 12
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 4.961832061068719 28
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 4.961832061068719 41
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe860> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 3.4351145038168056 13
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 5.343511450381698 29
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 5.343511450381698 42
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff40fea58> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ee48> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 3.816793893129784 14
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 5.725190839694676 30
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 5.725190839694676 43
Completed Iteration #23
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff410a4e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40feba8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fea58> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ee48> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 4.198473282442762 15
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 6.106870229007654 31
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 6.106870229007654 44
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc699518> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5f60> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 4.580152671755741 16
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 6.488549618320633 32
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 6.488549618320633 45
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #2
root->4->17
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5898> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 4.580152671755741 17
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 6.488549618320633 33
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 6.488549618320633 46
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5898> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 1.5267175572519136 8
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 4.580152671755741 18
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 6.488549618320633 34
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 6.488549618320633 47
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff40f40b8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 1.908396946564892 9
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 4.961832061068719 19
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 6.870229007633611 35
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 6.870229007633611 48
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe518> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 5.343511450381698 20
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 7.25190839694659 36
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 7.25190839694659 49
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76ca90> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 2.2900763358778704 11
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 5.343511450381698 21
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 7.25190839694659 37
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 7.25190839694659 50
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab860> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 2.671755725190849 12
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 5.725190839694676 22
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 7.633587786259568 38
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 7.633587786259568 51
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #3
root->4->17->1
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 2.671755725190849 13
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 5.725190839694676 23
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 7.633587786259568 39
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 7.633587786259568 52
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 3.053435114503827 14
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 6.106870229007654 24
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 8.015267175572546 40
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 8.015267175572546 53
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 3.053435114503827 15
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 6.106870229007654 25
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 8.015267175572546 41
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 8.015267175572546 54
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b67f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 0.7633587786259568 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 3.053435114503827 16
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 6.106870229007654 26
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 8.015267175572546 42
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 8.015267175572546 55
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 0.7633587786259568 7
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 3.053435114503827 17
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 6.106870229007654 27
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 8.015267175572546 43
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 8.015267175572546 56
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff410a278> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 1.1450381679389352 8
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 3.4351145038168056 18
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 6.488549618320633 28
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 8.396946564885525 44
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 8.396946564885525 57
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40abc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410a278> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc699940> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 1.1450381679389352 9
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 3.4351145038168056 19
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 6.488549618320633 29
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 8.396946564885525 45
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 8.396946564885525 58
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe2b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab208> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 1.5267175572519136 10
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 3.816793893129784 20
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 6.870229007633611 30
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 8.778625954198503 46
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 8.778625954198503 59
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 1.5267175572519136 11
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 3.816793893129784 21
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 6.870229007633611 31
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 8.778625954198503 47
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 8.778625954198503 60
Completed Iteration #21
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4cf8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 1.908396946564892 12
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 4.198473282442762 22
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 7.25190839694659 32
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 9.160305343511482 48
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 9.160305343511482 61
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8eb8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 2.2900763358778704 13
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 4.580152671755741 23
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 7.633587786259568 33
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 9.54198473282446 49
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 9.54198473282446 62
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #4
root->4->17->1->1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff410acf8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 2.671755725190849 14
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 4.961832061068719 24
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 8.015267175572546 34
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 9.923664122137438 50
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 9.923664122137438 63
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 1.908396946564892 8
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 2.671755725190849 15
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 4.961832061068719 25
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 8.015267175572546 35
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 9.923664122137438 51
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 9.923664122137438 64
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410acf8> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 1.908396946564892 9
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 2.671755725190849 16
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 4.961832061068719 26
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 8.015267175572546 36
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 9.923664122137438 52
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 9.923664122137438 65
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdf98> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 3.053435114503827 17
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 5.343511450381698 27
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 8.396946564885525 37
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 10.305343511450417 53
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 10.305343511450417 66
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff40569e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056208> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410acf8> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 2.671755725190849 11
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 3.4351145038168056 18
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 5.725190839694676 28
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 8.778625954198503 38
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 10.687022900763395 54
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 10.687022900763395 67
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fe01864e4e0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 3.053435114503827 12
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 3.816793893129784 19
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 6.106870229007654 29
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 9.160305343511482 39
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 11.068702290076374 55
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 11.068702290076374 68
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40abbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab208> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 3.053435114503827 13
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 3.816793893129784 20
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 6.106870229007654 30
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 9.160305343511482 40
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 11.068702290076374 56
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 11.068702290076374 69
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff40abcf8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4cf8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 1.908396946564892 7
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 3.4351145038168056 14
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 4.198473282442762 21
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 6.488549618320633 31
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 9.54198473282446 41
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 11.450381679389352 57
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 11.450381679389352 70
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 3.4351145038168056 15
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 4.198473282442762 22
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 6.488549618320633 32
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 9.54198473282446 42
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 11.450381679389352 58
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 11.450381679389352 71
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 3.4351145038168056 16
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 4.198473282442762 23
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 6.488549618320633 33
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 9.54198473282446 43
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 11.450381679389352 59
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 11.450381679389352 72
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056208> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdff410acf8> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 3.4351145038168056 17
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 4.198473282442762 24
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 6.488549618320633 34
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 9.54198473282446 44
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 11.450381679389352 60
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 11.450381679389352 73
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #5
root->4->17->1->1->0
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff40569b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab208> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 2.2900763358778704 8
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 3.816793893129784 18
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 4.580152671755741 25
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 6.870229007633611 35
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 9.923664122137438 45
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 11.83206106870233 61
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 11.83206106870233 74
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab208> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 2.2900763358778704 9
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 3.816793893129784 19
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 4.580152671755741 26
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 6.870229007633611 36
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 9.923664122137438 46
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 11.83206106870233 62
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 11.83206106870233 75
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
coverage_call_count 1300
Completed Iteration #5
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40692b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40690f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdf98> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd390> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 2.2900763358778704 10
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 3.816793893129784 20
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 4.580152671755741 27
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 6.870229007633611 37
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 9.923664122137438 47
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 11.83206106870233 63
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 11.83206106870233 76
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff4069b00> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4069390> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdf98> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd390> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 2.671755725190849 11
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 4.198473282442762 21
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 4.961832061068719 28
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 7.25190839694659 38
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 10.305343511450417 48
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 12.213740458015309 64
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 12.213740458015309 77
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 2.671755725190849 12
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 4.198473282442762 22
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 4.961832061068719 29
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 7.25190839694659 39
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 10.305343511450417 49
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 12.213740458015309 65
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 12.213740458015309 78
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5e48> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410a780> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 3.053435114503827 13
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 4.580152671755741 23
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 5.343511450381698 30
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 7.633587786259568 40
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 10.687022900763395 50
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 12.595419847328287 66
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 12.595419847328287 79
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Completed Iteration #14
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4056c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4cf8> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 3.053435114503827 14
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 4.580152671755741 24
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 5.343511450381698 31
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 7.633587786259568 41
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 10.687022900763395 51
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 12.595419847328287 67
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 12.595419847328287 80
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6d30> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd390> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 3.4351145038168056 15
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 4.961832061068719 25
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 5.725190839694676 32
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 8.015267175572546 42
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 11.068702290076374 52
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 12.977099236641266 68
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 12.977099236641266 81
Completed Iteration #16
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.3816793893129784 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4cf8> 0.7633587786259568 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 3.4351145038168056 16
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 4.961832061068719 26
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 5.725190839694676 33
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 8.015267175572546 43
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 11.068702290076374 53
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 12.977099236641266 69
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 12.977099236641266 82
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4069240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410a780> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 3.4351145038168056 17
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 4.961832061068719 27
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 5.725190839694676 34
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 8.015267175572546 44
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 11.068702290076374 54
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 12.977099236641266 70
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 12.977099236641266 83
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff4069dd8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4069cf8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4069b00> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4069390> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdf98> 1.1450381679389352 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd390> 1.5267175572519136 6
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 3.816793893129784 18
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 5.343511450381698 28
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 6.106870229007654 35
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 8.396946564885525 45
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 11.450381679389352 55
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 13.358778625954244 71
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 13.358778625954244 84
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4080278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd390> 1.5267175572519136 7
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 3.816793893129784 19
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 5.343511450381698 29
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 6.106870229007654 36
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 8.396946564885525 46
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 11.450381679389352 56
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 13.358778625954244 72
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 13.358778625954244 85
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #6
root->4->17->1->1->0->10
Best Reward: 0.3816793893129784
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40912b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40910f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdf98> 1.1450381679389352 6
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd390> 1.5267175572519136 8
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 3.816793893129784 20
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 5.343511450381698 30
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 6.106870229007654 37
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 8.396946564885525 47
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 11.450381679389352 57
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 13.358778625954244 73
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 13.358778625954244 86
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd390> 1.5267175572519136 9
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 3.816793893129784 21
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 5.343511450381698 31
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 6.106870229007654 38
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 8.396946564885525 48
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 11.450381679389352 58
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 13.358778625954244 74
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 13.358778625954244 87
Completed Iteration #7
Best Reward: 0.3816793893129784
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff4056a90> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd390> 1.908396946564892 10
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 4.198473282442762 22
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 5.725190839694676 32
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 6.488549618320633 39
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 8.778625954198503 49
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 11.83206106870233 59
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 13.740458015267222 75
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 13.740458015267222 88
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4069be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd390> 1.908396946564892 11
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 4.198473282442762 23
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 5.725190839694676 33
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 6.488549618320633 40
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 8.778625954198503 50
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 11.83206106870233 60
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 13.740458015267222 76
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 13.740458015267222 89
Completed Iteration #12
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff4080550> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd2e8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056a90> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd390> 2.2900763358778704 12
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 4.580152671755741 24
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 6.106870229007654 34
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 6.870229007633611 41
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 9.160305343511482 51
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 12.213740458015309 61
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 14.1221374045802 77
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 14.1221374045802 90
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40805c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4069390> 0.7633587786259568 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdf98> 1.1450381679389352 7
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd390> 2.2900763358778704 13
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 4.580152671755741 25
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 6.106870229007654 35
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 6.870229007633611 42
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 9.160305343511482 52
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 12.213740458015309 62
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 14.1221374045802 78
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 14.1221374045802 91
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff4069588> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40805f8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056a90> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd390> 2.671755725190849 14
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 4.961832061068719 26
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 6.488549618320633 36
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 7.25190839694659 43
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 9.54198473282446 53
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 12.595419847328287 63
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 14.50381679389318 79
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 14.50381679389318 92
Completed Iteration #18
Best Reward: 0.3816793893129784
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #7
root->4->17->1->1->0->10->1
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff4091940> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025080> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4069588> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40805f8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4056a90> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd390> 3.053435114503827 15
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 5.343511450381698 27
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 6.870229007633611 37
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 7.633587786259568 44
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 9.923664122137438 54
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 12.977099236641266 64
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 14.885496183206158 80
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 14.885496183206158 93
Completed Iteration #0
Best Reward: 0.3816793893129784
Completed Iteration #1
Best Reward: 0.3816793893129784
Completed Iteration #2
Best Reward: 0.3816793893129784
Completed Iteration #3
Best Reward: 0.3816793893129784
Completed Iteration #4
Best Reward: 0.3816793893129784
Completed Iteration #5
Best Reward: 0.3816793893129784
Completed Iteration #6
Best Reward: 0.3816793893129784
Completed Iteration #7
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff40252b0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091278> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056a90> 1.908396946564892 6
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd390> 3.4351145038168056 16
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 5.725190839694676 28
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 7.25190839694659 38
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 8.015267175572546 45
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 10.305343511450417 55
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 13.358778625954244 65
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 15.267175572519136 81
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 15.267175572519136 94
Completed Iteration #8
Best Reward: 0.3816793893129784
Completed Iteration #9
Best Reward: 0.3816793893129784
Completed Iteration #10
Best Reward: 0.3816793893129784
Completed Iteration #11
Best Reward: 0.3816793893129784
Completed Iteration #12
Best Reward: 0.3816793893129784
Completed Iteration #13
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff4025e80> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025908> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056a90> 2.2900763358778704 7
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd390> 3.816793893129784 17
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 6.106870229007654 29
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 7.633587786259568 39
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 8.396946564885525 46
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 10.687022900763395 56
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 13.740458015267222 66
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 15.648854961832114 82
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 15.648854961832114 95
Completed Iteration #14
Best Reward: 0.3816793893129784
Completed Iteration #15
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff4025f28> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd2e8> 0.7633587786259568 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4056a90> 2.671755725190849 8
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd390> 4.198473282442762 18
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 6.488549618320633 30
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 8.015267175572546 40
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 8.778625954198503 47
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 11.068702290076374 57
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 14.1221374045802 67
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 16.030534351145093 83
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 16.030534351145093 96
Completed Iteration #16
Best Reward: 0.3816793893129784
Completed Iteration #17
Best Reward: 0.3816793893129784
Completed Iteration #18
Best Reward: 0.3816793893129784
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40802e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091278> 0.3816793893129784 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4056a90> 2.671755725190849 9
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd390> 4.198473282442762 19
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 6.488549618320633 31
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 8.015267175572546 41
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 8.778625954198503 48
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 11.068702290076374 58
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 14.1221374045802 68
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 16.030534351145093 84
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 16.030534351145093 97
Completed Iteration #19
Best Reward: 0.3816793893129784
Completed Iteration #20
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff40566d8> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40807f0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4069588> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40805f8> 1.1450381679389352 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4056a90> 3.053435114503827 10
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd390> 4.580152671755741 20
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 6.870229007633611 32
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 8.396946564885525 42
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 9.160305343511482 49
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 11.450381679389352 59
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 14.50381679389318 69
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 16.41221374045807 85
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 16.41221374045807 98
Completed Iteration #21
Best Reward: 0.3816793893129784
Completed Iteration #22
Best Reward: 0.3816793893129784
Completed Iteration #23
Best Reward: 0.3816793893129784
Completed Iteration #24
Best Reward: 0.3816793893129784
Reward: 0.3816793893129784
backprop <src.mcts.MCTS_Node object at 0x7fdff40808d0> 0.3816793893129784 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40805f8> 1.5267175572519136 5
backprop <src.mcts.MCTS_Node object at 0x7fdff4056a90> 3.4351145038168056 11
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd390> 4.961832061068719 21
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf60> 7.25190839694659 33
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 8.778625954198503 43
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5668> 9.54198473282446 50
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eeb8> 11.83206106870233 60
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a58> 14.885496183206158 70
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 16.79389312977105 86
backprop <src.mcts.MCTS_Node object at 0x7fdff4135f60> 16.79389312977105 99
Completed Iteration #25
Best Reward: 0.3816793893129784
Completed MCTS Level/Depth: #8
root->4->17->1->1->0->10->1->1
Best Reward: 0.3816793893129784
iteration: 37
found coverage increase 0.3816793893129784
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4035ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40350b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4035cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4035278> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4035b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035278> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035278> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4035f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035278> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4080da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035278> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4056978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035278> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4025128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4035278> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4025e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4035278> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b60b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4035278> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4035278> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4069358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035278> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4069470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4035278> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40914e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdff4035278> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4025278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4035278> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40699e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4035278> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4035e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4035278> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4035c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4035278> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 38
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4035160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4080358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d048> 0.0 5
Completed Iteration #3
Best Reward: 0
coverage_call_count 1400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d048> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d048> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404da90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d048> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d048> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404d048> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff404d048> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4069710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404df98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404d048> 0.0 12
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404d048> 0.0 13
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d048> 0.0 14
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404da90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404d048> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404d048> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404d048> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff404d048> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d54e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff404d048> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404d048> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404d048> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 39
found coverage increase 0
Current Total Coverage 67.93893129770993
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4035828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4091a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404dc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d55f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4091908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404dc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec06bac8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 0.3816793893129642 5
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 0.3816793893129642 16
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 0.3816793893129642 17
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0792e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 0.3816793893129642 18
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec06beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 0.3816793893129642 19
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 0.3816793893129642 20
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 0.3816793893129642 6
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 0.3816793893129642 21
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff4069710> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 0.7633587786259284 7
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 0.7633587786259284 22
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5908> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 1.1450381679388926 8
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 1.1450381679388926 23
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5550> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 1.5267175572518568 9
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 1.5267175572518568 24
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5908> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 1.5267175572518568 10
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 1.5267175572518568 25
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4035e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5908> 0.3816793893129642 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 1.5267175572518568 11
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 1.5267175572518568 26
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 1.908396946564821 12
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 1.908396946564821 27
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff404d3c8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035748> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06bac8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 2.290076335877785 13
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 2.290076335877785 28
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4069710> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 2.290076335877785 14
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 2.290076335877785 29
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b358> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 2.6717557251907493 15
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 2.6717557251907493 30
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d58d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 2.6717557251907493 16
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 2.6717557251907493 31
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff4056940> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b940> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06bac8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 3.0534351145037135 17
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 3.0534351145037135 32
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfb38> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035b70> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4069710> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 3.4351145038166777 18
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 3.4351145038166777 33
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff404d400> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfa90> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 3.816793893129642 19
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 3.816793893129642 34
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #1
root->4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff404dba8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404ddd8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b358> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 4.198473282442606 20
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 4.198473282442606 35
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 4.58015267175557 21
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 4.58015267175557 36
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0790b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfa90> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 1.908396946564821 7
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 4.58015267175557 22
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 4.58015267175557 37
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec079a90> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5be0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 4.9618320610685345 23
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 4.9618320610685345 38
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b630> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d0f0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079a90> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5be0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 5.343511450381499 24
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 5.343511450381499 39
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 5.725190839694463 25
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 5.725190839694463 40
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec0938d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093358> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 6.106870229007427 26
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 6.106870229007427 41
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec093d30> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 6.488549618320391 27
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 6.488549618320391 42
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 3.816793893129642 13
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 6.488549618320391 28
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 6.488549618320391 43
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4056710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093d30> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 3.816793893129642 14
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 6.488549618320391 29
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 6.488549618320391 44
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff404dda0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 4.198473282442606 15
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 6.870229007633355 30
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 6.870229007633355 45
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfa90> 0.3816793893129642 4
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 4.198473282442606 16
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 6.870229007633355 31
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 6.870229007633355 46
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff4091128> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 4.58015267175557 17
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 7.25190839694632 32
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 7.25190839694632 47
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d0f0> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec079a90> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5be0> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 4.58015267175557 18
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 7.25190839694632 33
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 7.25190839694632 48
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec093860> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5be0> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 4.9618320610685345 19
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 7.633587786259284 34
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 7.633587786259284 49
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec093fd0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093390> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093d30> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 5.343511450381499 20
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 8.015267175572248 35
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 8.015267175572248 50
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #2
root->4->12
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a04a8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 5.725190839694463 21
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 8.396946564885212 36
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 8.396946564885212 51
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec0793c8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 4.198473282442606 13
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 6.106870229007427 22
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 8.778625954198176 37
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 8.778625954198176 52
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec093470> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093e10> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 4.58015267175557 14
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 6.488549618320391 23
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 9.16030534351114 38
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 9.16030534351114 53
Completed Iteration #2
Best Reward: 0.3816793893129642
coverage_call_count 1500
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0f60> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 4.9618320610685345 15
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 6.870229007633355 24
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 9.541984732824105 39
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 9.541984732824105 54
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec034860> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034400> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0f60> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 5.343511450381499 16
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 7.25190839694632 25
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 9.923664122137069 40
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 9.923664122137069 55
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec034cf8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034c18> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a04a8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 5.725190839694463 17
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 7.633587786259284 26
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 10.305343511450033 41
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 10.305343511450033 56
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0347f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404ddd8> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b358> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 5.725190839694463 18
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 7.633587786259284 27
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 10.305343511450033 42
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 10.305343511450033 57
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff4035a20> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 6.106870229007427 19
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 8.015267175572248 28
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 10.687022900762997 43
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 10.687022900762997 58
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff404d7f0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404ddd8> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b358> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 6.488549618320391 20
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 8.396946564885212 29
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 11.068702290075962 44
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 11.068702290075962 59
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec093dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404ddd8> 0.7633587786259284 5
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b358> 1.1450381679388926 6
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 6.488549618320391 21
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 8.396946564885212 30
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 11.068702290075962 45
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 11.068702290075962 60
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec034668> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404ddd8> 1.1450381679388926 6
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b358> 1.5267175572518568 7
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 6.870229007633355 22
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 8.778625954198176 31
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 11.450381679388926 46
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 11.450381679388926 61
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #3
root->4->12->4
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec041c18> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034ba8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 7.25190839694632 23
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 9.16030534351114 32
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 11.83206106870189 47
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 11.83206106870189 62
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e668> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e128> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091128> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 7.633587786259284 24
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 9.541984732824105 33
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 12.213740458014854 48
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 12.213740458014854 63
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec0419b0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e128> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4091128> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 8.015267175572248 25
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 9.923664122137069 34
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 12.595419847327818 49
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 12.595419847327818 64
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff4035400> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093e10> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 8.396946564885212 26
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 10.305343511450033 35
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 12.977099236640782 50
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 12.977099236640782 65
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff4080c88> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093e10> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 4.198473282442606 12
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 8.778625954198176 27
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 10.687022900762997 36
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 13.358778625953747 51
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 13.358778625953747 66
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e208> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e7b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404dda0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 4.58015267175557 13
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 9.16030534351114 28
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 11.068702290075962 37
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 13.74045801526671 52
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 13.74045801526671 67
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bff98> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 4.9618320610685345 14
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 9.541984732824105 29
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 11.450381679388926 38
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 14.122137404579675 53
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 14.122137404579675 68
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff404dc18> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093e10> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 5.343511450381499 15
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 9.923664122137069 30
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 11.83206106870189 39
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 14.50381679389264 54
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 14.50381679389264 69
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #4
root->4->12->4->0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5278> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d208> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 5.725190839694463 16
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 10.305343511450033 31
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 12.213740458014854 40
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 14.885496183205603 55
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 14.885496183205603 70
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf4a8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e7b8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404dda0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 6.106870229007427 17
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 10.687022900762997 32
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 12.595419847327818 41
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 15.267175572518568 56
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 15.267175572518568 71
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec093c50> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e7b8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdff404dda0> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 4.198473282442606 12
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 6.488549618320391 18
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 11.068702290075962 33
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 12.977099236640782 42
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 15.648854961831532 57
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 15.648854961831532 72
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec034198> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d208> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 4.58015267175557 13
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 6.870229007633355 19
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 11.450381679388926 34
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 13.358778625953747 43
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 16.030534351144496 58
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 16.030534351144496 73
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a00b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034b00> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091128> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 4.9618320610685345 14
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 7.25190839694632 20
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 11.83206106870189 35
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 13.74045801526671 44
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 16.41221374045746 59
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 16.41221374045746 74
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec041550> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 5.343511450381499 15
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 7.633587786259284 21
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 12.213740458014854 36
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 14.122137404579675 45
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 16.793893129770424 60
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 16.793893129770424 75
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bff98> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 5.343511450381499 16
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 7.633587786259284 22
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 12.213740458014854 37
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 14.122137404579675 46
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 16.793893129770424 61
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 16.793893129770424 76
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec079320> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 5.725190839694463 17
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 8.015267175572248 23
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 12.595419847327818 38
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 14.50381679389264 47
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 17.17557251908339 62
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 17.17557251908339 77
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4035ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079320> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 5.725190839694463 18
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 8.015267175572248 24
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 12.595419847327818 39
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 14.50381679389264 48
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 17.17557251908339 63
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 17.17557251908339 78
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff404d128> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 6.106870229007427 19
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 8.396946564885212 25
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 12.977099236640782 40
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 14.885496183205603 49
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 17.557251908396353 64
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 17.557251908396353 79
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5b38> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404de80> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec041550> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 6.488549618320391 20
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 8.778625954198176 26
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 13.358778625953747 41
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 15.267175572518568 50
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 17.938931297709317 65
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 17.938931297709317 80
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #5
root->4->12->4->0->0
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec034710> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0e48> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5278> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404d208> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 6.870229007633355 21
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 9.16030534351114 27
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 13.74045801526671 42
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 15.648854961831532 51
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 18.32061068702228 66
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 18.32061068702228 81
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec05eba8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034c50> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034710> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0e48> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5278> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdff404d208> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 7.25190839694632 22
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 9.541984732824105 28
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 14.122137404579675 43
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 16.030534351144496 52
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 18.702290076335245 67
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 18.702290076335245 82
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d208> 1.5267175572518568 6
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 7.25190839694632 23
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 9.541984732824105 29
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 14.122137404579675 44
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 16.030534351144496 53
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 18.702290076335245 68
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 18.702290076335245 83
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec093b70> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079f60> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0938d0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec093358> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 7.633587786259284 24
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 9.923664122137069 30
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 14.50381679389264 45
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 16.41221374045746 54
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 19.08396946564821 69
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 19.08396946564821 84
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff4035e10> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d208> 1.908396946564821 7
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 8.015267175572248 25
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 10.305343511450033 31
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 14.885496183205603 46
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 16.793893129770424 55
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 19.465648854961174 70
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 19.465648854961174 85
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff4025d68> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025978> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 8.396946564885212 26
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 10.687022900762997 32
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 15.267175572518568 47
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 17.17557251908339 56
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 19.847328244274138 71
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 19.847328244274138 86
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff4025470> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093358> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 8.778625954198176 27
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 11.068702290075962 33
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 15.648854961831532 48
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 17.557251908396353 57
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 20.229007633587102 72
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 20.229007633587102 87
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b9b0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 4.198473282442606 13
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 9.16030534351114 28
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 11.450381679388926 34
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 16.030534351144496 49
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 17.938931297709317 58
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 20.610687022900066 73
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 20.610687022900066 88
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093b70> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec079f60> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0938d0> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec093358> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 4.198473282442606 14
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 9.16030534351114 29
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 11.450381679388926 35
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 16.030534351144496 50
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 17.938931297709317 59
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 20.610687022900066 74
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 20.610687022900066 89
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec034358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025978> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 4.198473282442606 15
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 9.16030534351114 30
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 11.450381679388926 36
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 16.030534351144496 51
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 17.938931297709317 60
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 20.610687022900066 75
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 20.610687022900066 90
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff4035160> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025978> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 4.58015267175557 16
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 9.541984732824105 31
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 11.83206106870189 37
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 16.41221374045746 52
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 18.32061068702228 61
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 20.99236641221303 76
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 20.99236641221303 91
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec0932e8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025f98> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b9b0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 4.9618320610685345 17
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 9.923664122137069 32
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 12.213740458014854 38
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 16.793893129770424 53
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 18.702290076335245 62
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 21.374045801525995 77
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 21.374045801525995 92
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4091c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d208> 1.908396946564821 8
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 4.9618320610685345 18
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 9.923664122137069 33
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 12.213740458014854 39
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 16.793893129770424 54
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 18.702290076335245 63
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 21.374045801525995 78
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 21.374045801525995 93
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #6
root->4->12->4->0->0->1
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
coverage_call_count 1600
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff4091c88> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 5.343511450381499 19
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 10.305343511450033 34
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 12.595419847327818 40
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 17.17557251908339 55
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 19.08396946564821 64
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 21.75572519083896 79
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 21.75572519083896 94
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4080630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 5.343511450381499 20
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 10.305343511450033 35
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 12.595419847327818 41
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 17.17557251908339 56
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 19.08396946564821 65
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 21.75572519083896 80
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 21.75572519083896 95
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4080ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40807f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0932e8> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4025f98> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b9b0> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 1.1450381679388926 6
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 5.343511450381499 21
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 10.305343511450033 36
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 12.595419847327818 42
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 17.17557251908339 57
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 19.08396946564821 66
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 21.75572519083896 81
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 21.75572519083896 96
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec05eb38> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05ec50> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091c88> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 1.5267175572518568 7
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 5.725190839694463 22
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 10.687022900762997 37
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 12.977099236640782 43
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 17.557251908396353 58
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 19.465648854961174 67
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 22.137404580151923 82
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 22.137404580151923 97
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec079438> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034a20> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091c88> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 1.908396946564821 8
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 6.106870229007427 23
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 11.068702290075962 38
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 13.358778625953747 44
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 17.938931297709317 59
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 19.847328244274138 68
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 22.519083969464887 83
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 22.519083969464887 98
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff40916a0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 2.290076335877785 9
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 6.488549618320391 24
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 11.450381679388926 39
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 13.74045801526671 45
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 18.32061068702228 60
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 20.229007633587102 69
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 22.90076335877785 84
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 22.90076335877785 99
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff40696d8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d630> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091c88> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 2.6717557251907493 10
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 6.870229007633355 25
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 11.83206106870189 40
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 14.122137404579675 46
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 18.702290076335245 61
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 20.610687022900066 70
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 23.282442748090816 85
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 23.282442748090816 100
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec0340b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40257b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0932e8> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4025f98> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b9b0> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 3.0534351145037135 11
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 7.25190839694632 26
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 12.213740458014854 41
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 14.50381679389264 47
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 19.08396946564821 62
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 20.99236641221303 71
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 23.66412213740378 86
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 23.66412213740378 101
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff4056438> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4080668> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b9b0> 1.5267175572518568 6
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 3.4351145038166777 12
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 7.633587786259284 27
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 12.595419847327818 42
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 14.885496183205603 48
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 19.465648854961174 63
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 21.374045801525995 72
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 24.045801526716744 87
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 24.045801526716744 102
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4056828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b9b0> 1.5267175572518568 7
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 3.4351145038166777 13
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 7.633587786259284 28
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 12.595419847327818 43
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 14.885496183205603 49
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 19.465648854961174 64
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 21.374045801525995 73
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 24.045801526716744 88
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 24.045801526716744 103
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd5f8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d630> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4091c88> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 3.816793893129642 14
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 8.015267175572248 29
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 12.977099236640782 44
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 15.267175572518568 50
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 19.847328244274138 65
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 21.75572519083896 74
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 24.427480916029708 89
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 24.427480916029708 104
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 3.816793893129642 15
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 8.015267175572248 30
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 12.977099236640782 45
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 15.267175572518568 51
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 19.847328244274138 66
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 21.75572519083896 75
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 24.427480916029708 90
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 24.427480916029708 105
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #7
root->4->12->4->0->0->1->3
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0342e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05ec50> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4091c88> 1.908396946564821 7
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 3.816793893129642 16
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 8.015267175572248 31
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 12.977099236640782 46
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 15.267175572518568 52
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 19.847328244274138 67
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 21.75572519083896 76
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 24.427480916029708 91
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 24.427480916029708 106
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e978> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40913c8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091c88> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 4.198473282442606 17
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 8.396946564885212 32
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 13.358778625953747 47
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 15.648854961831532 53
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 20.229007633587102 68
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 22.137404580151923 77
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 24.809160305342672 92
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 24.809160305342672 107
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff4080748> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40913c8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4091c88> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 4.58015267175557 18
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 8.778625954198176 33
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 13.74045801526671 48
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 16.030534351144496 54
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 20.610687022900066 69
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 22.519083969464887 78
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 25.190839694655637 93
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 25.190839694655637 108
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec079400> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034a20> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4091c88> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 4.9618320610685345 19
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 9.16030534351114 34
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 14.122137404579675 49
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 16.41221374045746 55
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 20.99236641221303 70
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 22.90076335877785 79
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 25.5725190839686 94
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 25.5725190839686 109
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40690b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4069780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd5f8> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404d630> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4091c88> 3.0534351145037135 11
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 4.9618320610685345 20
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 9.16030534351114 35
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 14.122137404579675 50
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 16.41221374045746 56
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 20.99236641221303 71
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 22.90076335877785 80
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 25.5725190839686 95
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 25.5725190839686 110
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec093f28> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40913c8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4091c88> 3.4351145038166777 12
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 5.343511450381499 21
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 9.541984732824105 36
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 14.50381679389264 51
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 16.793893129770424 57
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 21.374045801525995 72
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 23.282442748090816 81
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 25.954198473281565 96
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 25.954198473281565 111
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40696d8> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404d630> 0.7633587786259284 5
backprop <src.mcts.MCTS_Node object at 0x7fdff4091c88> 3.4351145038166777 13
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 5.343511450381499 22
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 9.541984732824105 37
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 14.50381679389264 52
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 16.793893129770424 58
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 21.374045801525995 73
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 23.282442748090816 82
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 25.954198473281565 97
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 25.954198473281565 112
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd2b0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034a20> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4091c88> 3.816793893129642 14
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 5.725190839694463 23
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 9.923664122137069 38
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 14.885496183205603 53
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 17.17557251908339 59
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 21.75572519083896 74
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 23.66412213740378 83
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 26.33587786259453 98
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 26.33587786259453 113
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec079668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093f28> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40913c8> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7fdff4091c88> 3.816793893129642 15
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 5.725190839694463 24
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 9.923664122137069 39
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 14.885496183205603 54
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 17.17557251908339 60
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 21.75572519083896 75
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 23.66412213740378 84
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 26.33587786259453 99
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 26.33587786259453 114
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079400> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec034a20> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7fdff4091c88> 3.816793893129642 16
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 5.725190839694463 25
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 9.923664122137069 40
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 14.885496183205603 55
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 17.17557251908339 61
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 21.75572519083896 76
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 23.66412213740378 85
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 26.33587786259453 100
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 26.33587786259453 115
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff4080b00> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdfd0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079400> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec034a20> 1.5267175572518568 6
backprop <src.mcts.MCTS_Node object at 0x7fdff4091c88> 4.198473282442606 17
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 6.106870229007427 26
backprop <src.mcts.MCTS_Node object at 0x7fdfec079da0> 10.305343511450033 41
backprop <src.mcts.MCTS_Node object at 0x7fdfec079cc0> 15.267175572518568 56
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 17.557251908396353 62
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b588> 22.137404580151923 77
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 24.045801526716744 86
backprop <src.mcts.MCTS_Node object at 0x7fdff40359e8> 26.717557251907493 101
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 26.717557251907493 116
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #8
root->4->12->4->0->0->1->3->2
Best Reward: 0.3816793893129642
iteration: 40
found coverage increase 0.3816793893129642
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b64e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4056128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b64e0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4080cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b64e0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4035c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40250f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b64e0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018760198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40250f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40b64e0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b64e0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4025438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40b64e0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40250f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40b64e0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018760ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b64e0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b64e0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40b64e0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40feba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40b64e0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018760828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b64e0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40febe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b64e0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40b64e0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40b64e0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 41
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40252b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091f28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4056d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4091f28> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091f28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4080f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4080780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091f28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018760080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4069da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091f28> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4091f28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091f28> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018760908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091f28> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4069b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4069da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4091f28> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091f28> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40abe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4091f28> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40abb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091f28> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40abef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4091f28> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091f28> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4091f28> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4091f28> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4091f28> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdc50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdff4091f28> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4091f28> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4091f28> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 42
found coverage increase 0
Current Total Coverage 68.32061068702289
coverage_call_count 1700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4b38> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40abac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4b38> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410af98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410a630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4b38> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4b38> 0.0 6
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410a5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4b38> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4b38> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410a5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4b38> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40e52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4b38> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4b38> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4b38> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4035630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4b38> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4056048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4b38> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4080cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4b38> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187600f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4b38> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 43
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018760080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760198> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018760048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018760198> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4069b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760198> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe018760198> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760198> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40feb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760198> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40feb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018760198> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760198> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187766a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760198> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760198> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018760198> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b64a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760198> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018760198> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760198> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fedd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018760198> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40feb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe018760198> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018760198> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018760198> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe018760198> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 44
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40abcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f40b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f40b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e51d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f40b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e51d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f40b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f40b8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f40b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f40b8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f40b8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4091208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40f40b8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187605c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f40b8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f40b8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4069be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f40b8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e51d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40f40b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40f40b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187605c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f40b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f40b8> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5198> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40f40b8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f40b8> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40f40b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 45
found coverage increase 0
Current Total Coverage 68.32061068702289
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135860> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186855f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135860> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135860> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc74eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135860> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4135860> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135860> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4135860> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135860> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4135860> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135860> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135860> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4135860> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
coverage_call_count 1800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdff4135860> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 46
found coverage increase 0
Current Total Coverage 68.32061068702289
Completed Iteration #0
Best Reward: 0
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.3816793893129926 2
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc776400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.3816793893129926 3
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.3816793893129926 4
Completed Iteration #3
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186854a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.3816793893129926 5
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f66d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.3816793893129926 6
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.3816793893129926 7
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.3816793893129926 8
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.3816793893129926 9
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186859b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.3816793893129926 10
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e400> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ef60> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 0.7633587786259852 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.7633587786259852 11
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 0.7633587786259852 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.7633587786259852 12
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 0.7633587786259852 7
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.7633587786259852 13
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 0.7633587786259852 8
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.7633587786259852 14
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f66d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.7633587786259852 15
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186859b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.7633587786259852 16
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186859b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.7633587786259852 17
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 0.7633587786259852 9
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.7633587786259852 18
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186854a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 0.7633587786259852 10
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.7633587786259852 19
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4056128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 0.7633587786259852 11
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.7633587786259852 20
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ef60> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 0.7633587786259852 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 0.7633587786259852 12
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.7633587786259852 21
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 0.7633587786259852 13
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.7633587786259852 22
Completed Iteration #9
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 0.7633587786259852 14
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.7633587786259852 23
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 0.7633587786259852 15
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.7633587786259852 24
Completed Iteration #12
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 0.7633587786259852 16
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.7633587786259852 25
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 0.7633587786259852 17
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.7633587786259852 26
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018760f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 0.7633587786259852 18
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.7633587786259852 27
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ef60> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 0.7633587786259852 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 0.7633587786259852 19
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.7633587786259852 28
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4069518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 0.7633587786259852 20
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.7633587786259852 29
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 0.7633587786259852 7
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 0.7633587786259852 21
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.7633587786259852 30
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40aba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 0.7633587786259852 22
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 0.7633587786259852 31
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #1
root->1
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdff4091400> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 1.1450381679389778 8
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 1.1450381679389778 23
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 1.1450381679389778 32
Completed Iteration #0
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091400> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 1.1450381679389778 9
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 1.1450381679389778 24
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 1.1450381679389778 33
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 1.1450381679389778 10
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 1.1450381679389778 25
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 1.1450381679389778 34
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 1.1450381679389778 11
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 1.1450381679389778 26
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 1.1450381679389778 35
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ada20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 1.1450381679389778 12
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 1.1450381679389778 27
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 1.1450381679389778 36
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe710> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685e10> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 1.5267175572519704 13
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 1.5267175572519704 28
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 1.5267175572519704 37
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 0.3816793893129926 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 1.5267175572519704 14
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 1.5267175572519704 29
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 1.5267175572519704 38
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 1.5267175572519704 15
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 1.5267175572519704 30
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 1.5267175572519704 39
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ef60> 0.3816793893129926 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 1.5267175572519704 16
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 1.5267175572519704 31
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 1.5267175572519704 40
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685e10> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 1.5267175572519704 17
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 1.5267175572519704 32
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 1.5267175572519704 41
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdffc7224a8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 0.7633587786259852 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 1.908396946564963 18
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 1.908396946564963 33
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 1.908396946564963 42
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #2
root->1->19
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410a8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091400> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 0.7633587786259852 7
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 1.908396946564963 19
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 1.908396946564963 34
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 1.908396946564963 43
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 0.7633587786259852 8
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 1.908396946564963 20
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 1.908396946564963 35
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 1.908396946564963 44
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7224a8> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 0.7633587786259852 9
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 1.908396946564963 21
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 1.908396946564963 36
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 1.908396946564963 45
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187605c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 0.7633587786259852 10
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 1.908396946564963 22
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 1.908396946564963 37
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 1.908396946564963 46
Completed Iteration #7
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 0.7633587786259852 11
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 1.908396946564963 23
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 1.908396946564963 38
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 1.908396946564963 47
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdffc719da0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719780> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7224a8> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 1.1450381679389778 12
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 2.2900763358779557 24
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 2.2900763358779557 39
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 2.2900763358779557 48
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc701e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 1.1450381679389778 13
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 2.2900763358779557 25
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 2.2900763358779557 40
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 2.2900763358779557 49
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 1.5267175572519704 14
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 2.6717557251909483 26
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 2.6717557251909483 41
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 2.6717557251909483 50
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #3
root->1->19->4
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 1.908396946564963 15
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 3.053435114503941 27
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 3.053435114503941 42
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 3.053435114503941 51
Completed Iteration #1
Best Reward: 0.3816793893129926
coverage_call_count 1900
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 1.908396946564963 16
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 3.053435114503941 28
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 3.053435114503941 43
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 3.053435114503941 52
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed278> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 2.2900763358779557 17
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 3.4351145038169335 29
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 3.4351145038169335 44
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 3.4351145038169335 53
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4470> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0b8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed278> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 2.6717557251909483 18
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 3.816793893129926 30
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 3.816793893129926 45
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 3.816793893129926 54
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 1.5267175572519704 7
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 2.6717557251909483 19
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 3.816793893129926 31
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 3.816793893129926 46
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 3.816793893129926 55
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe1d0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6198> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 1.908396946564963 8
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 3.053435114503941 20
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 4.198473282442919 32
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 4.198473282442919 47
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 4.198473282442919 56
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdffc76ca90> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 2.2900763358779557 9
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 3.4351145038169335 21
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 4.580152671755911 33
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 4.580152671755911 48
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 4.580152671755911 57
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdffc735ef0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735630> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4470> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0b8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed278> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 2.6717557251909483 10
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 3.816793893129926 22
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 4.961832061068904 34
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 4.961832061068904 49
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 4.961832061068904 58
Completed Iteration #18
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdffc701c18> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6198> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 3.053435114503941 11
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 4.198473282442919 23
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 5.343511450381897 35
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 5.343511450381897 50
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 5.343511450381897 59
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efbe0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed7b8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe1d0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6198> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 3.4351145038169335 12
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 4.580152671755911 24
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 5.725190839694889 36
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 5.725190839694889 51
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 5.725190839694889 60
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7196a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701c18> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6198> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 3.4351145038169335 13
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 4.580152671755911 25
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 5.725190839694889 37
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 5.725190839694889 52
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 5.725190839694889 61
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #4
root->1->19->4->0
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 1.5267175572519704 7
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 3.4351145038169335 14
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 4.580152671755911 26
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 5.725190839694889 38
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 5.725190839694889 53
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 5.725190839694889 62
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 1.5267175572519704 8
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 3.4351145038169335 15
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 4.580152671755911 27
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 5.725190839694889 39
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 5.725190839694889 54
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 5.725190839694889 63
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 1.5267175572519704 9
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 3.4351145038169335 16
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 4.580152671755911 28
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 5.725190839694889 40
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 5.725190839694889 55
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 5.725190839694889 64
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 1.5267175572519704 10
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 3.4351145038169335 17
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 4.580152671755911 29
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 5.725190839694889 41
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 5.725190839694889 56
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 5.725190839694889 65
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdffc6409e8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f710> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 1.908396946564963 11
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 3.816793893129926 18
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 4.961832061068904 30
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 6.106870229007882 42
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 6.106870229007882 57
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 6.106870229007882 66
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad0b8> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed278> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 1.908396946564963 12
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 3.816793893129926 19
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 4.961832061068904 31
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 6.106870229007882 43
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 6.106870229007882 58
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 6.106870229007882 67
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdffc735a90> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640be0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 2.2900763358779557 13
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 4.198473282442919 20
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 5.343511450381897 32
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 6.488549618320874 44
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 6.488549618320874 59
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 6.488549618320874 68
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 2.2900763358779557 14
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 4.198473282442919 21
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 5.343511450381897 33
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 6.488549618320874 45
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 6.488549618320874 60
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 6.488549618320874 69
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 2.2900763358779557 15
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 4.198473282442919 22
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 5.343511450381897 34
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 6.488549618320874 46
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 6.488549618320874 61
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 6.488549618320874 70
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 2.2900763358779557 16
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 4.198473282442919 23
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 5.343511450381897 35
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 6.488549618320874 47
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 6.488549618320874 62
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 6.488549618320874 71
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #5
root->1->19->4->0->8
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 2.2900763358779557 17
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 4.198473282442919 24
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 5.343511450381897 36
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 6.488549618320874 48
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 6.488549618320874 63
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 6.488549618320874 72
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f710> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 1.1450381679389778 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 2.2900763358779557 18
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 4.198473282442919 25
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 5.343511450381897 37
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 6.488549618320874 49
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 6.488549618320874 64
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 6.488549618320874 73
Completed Iteration #3
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdffc701518> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640be0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 1.5267175572519704 7
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 2.6717557251909483 19
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 4.580152671755911 26
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 5.725190839694889 38
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 6.870229007633867 50
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 6.870229007633867 65
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 6.870229007633867 74
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fe01864e7f0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f390> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 1.908396946564963 8
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 3.053435114503941 20
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 4.961832061068904 27
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 6.106870229007882 39
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 7.25190839694686 51
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 7.25190839694686 66
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 7.25190839694686 75
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fe0186994a8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699f28> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701518> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc640be0> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 2.2900763358779557 9
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 3.4351145038169335 21
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 5.343511450381897 28
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 6.488549618320874 40
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 7.633587786259852 52
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 7.633587786259852 67
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 7.633587786259852 76
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 2.2900763358779557 10
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 3.4351145038169335 22
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 5.343511450381897 29
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 6.488549618320874 41
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 7.633587786259852 53
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 7.633587786259852 68
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 7.633587786259852 77
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 2.2900763358779557 11
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 3.4351145038169335 23
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 5.343511450381897 30
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 6.488549618320874 42
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 7.633587786259852 54
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 7.633587786259852 69
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 7.633587786259852 78
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fe01864e828> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f710> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 2.6717557251909483 12
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 3.816793893129926 24
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 5.725190839694889 31
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 6.870229007633867 43
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 8.015267175572845 55
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 8.015267175572845 70
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 8.015267175572845 79
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f390> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 2.6717557251909483 13
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 3.816793893129926 25
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 5.725190839694889 32
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 6.870229007633867 44
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 8.015267175572845 56
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 8.015267175572845 71
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 8.015267175572845 80
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee240> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6406d8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735a90> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc640be0> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 3.053435114503941 14
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 4.198473282442919 26
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 6.106870229007882 33
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 7.25190839694686 45
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 8.396946564885837 57
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 8.396946564885837 72
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 8.396946564885837 81
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e7f0> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fe01874f390> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 3.053435114503941 15
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 4.198473282442919 27
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 6.106870229007882 34
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 7.25190839694686 46
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 8.396946564885837 58
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 8.396946564885837 73
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 8.396946564885837 82
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #6
root->1->19->4->0->8->2
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640be0> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 3.053435114503941 16
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 4.198473282442919 28
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 6.106870229007882 35
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 7.25190839694686 47
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 8.396946564885837 59
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 8.396946564885837 74
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 8.396946564885837 83
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fe01876a240> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640be0> 1.908396946564963 7
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 3.4351145038169335 17
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 4.580152671755911 29
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 6.488549618320874 36
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 7.633587786259852 48
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 8.77862595419883 60
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 8.77862595419883 75
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 8.77862595419883 84
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6406d8> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc735a90> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc640be0> 1.908396946564963 8
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 3.4351145038169335 18
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 4.580152671755911 30
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 6.488549618320874 37
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 7.633587786259852 49
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 8.77862595419883 61
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 8.77862595419883 76
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 8.77862595419883 85
Completed Iteration #12
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4cc0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640be0> 2.2900763358779557 9
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 3.816793893129926 19
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 4.961832061068904 31
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 6.870229007633867 38
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 8.015267175572845 50
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 9.160305343511823 62
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 9.160305343511823 77
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 9.160305343511823 86
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fe018699a20> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbda58> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4cc0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc640be0> 2.6717557251909483 10
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 4.198473282442919 20
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 5.343511450381897 32
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 7.25190839694686 39
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 8.396946564885837 51
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 9.541984732824815 63
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 9.541984732824815 78
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 9.541984732824815 87
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699f28> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc701518> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc640be0> 2.6717557251909483 11
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 4.198473282442919 21
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 5.343511450381897 33
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 7.25190839694686 40
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 8.396946564885837 52
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 9.541984732824815 64
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 9.541984732824815 79
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 9.541984732824815 88
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640be0> 2.6717557251909483 12
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 4.198473282442919 22
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 5.343511450381897 34
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 7.25190839694686 41
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 8.396946564885837 53
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 9.541984732824815 65
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 9.541984732824815 80
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 9.541984732824815 89
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfa58> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad748> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4cc0> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc640be0> 3.053435114503941 13
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 4.580152671755911 23
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 5.725190839694889 35
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 7.633587786259852 42
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 8.77862595419883 54
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 9.923664122137808 66
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 9.923664122137808 81
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 9.923664122137808 90
Completed Iteration #24
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4550> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbda58> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4cc0> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc640be0> 3.4351145038169335 14
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 4.961832061068904 24
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 6.106870229007882 36
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 8.015267175572845 43
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 9.160305343511823 55
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 10.3053435114508 67
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 10.3053435114508 82
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 10.3053435114508 91
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #7
root->1->19->4->0->8->2->5
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7433c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfa58> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad748> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4cc0> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc640be0> 3.4351145038169335 15
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 4.961832061068904 25
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 6.106870229007882 37
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 8.015267175572845 44
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 9.160305343511823 56
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 10.3053435114508 68
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 10.3053435114508 83
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 10.3053435114508 92
Completed Iteration #1
Best Reward: 0.3816793893129926
coverage_call_count 2000
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fe01864e898> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbda58> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4cc0> 1.908396946564963 7
backprop <src.mcts.MCTS_Node object at 0x7fdffc640be0> 3.816793893129926 16
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 5.343511450381897 26
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 6.488549618320874 38
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 8.396946564885837 45
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 9.541984732824815 57
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 10.687022900763793 69
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 10.687022900763793 84
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 10.687022900763793 93
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc701f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbda58> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4cc0> 1.908396946564963 8
backprop <src.mcts.MCTS_Node object at 0x7fdffc640be0> 3.816793893129926 17
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 5.343511450381897 27
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 6.488549618320874 39
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 8.396946564885837 46
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 9.541984732824815 58
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 10.687022900763793 70
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 10.687022900763793 85
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 10.687022900763793 94
Completed Iteration #7
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699a20> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbda58> 1.1450381679389778 6
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4cc0> 1.908396946564963 9
backprop <src.mcts.MCTS_Node object at 0x7fdffc640be0> 3.816793893129926 18
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 5.343511450381897 28
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 6.488549618320874 40
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 8.396946564885837 47
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 9.541984732824815 59
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 10.687022900763793 71
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 10.687022900763793 86
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 10.687022900763793 95
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4cc0> 1.908396946564963 10
backprop <src.mcts.MCTS_Node object at 0x7fdffc640be0> 3.816793893129926 19
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 5.343511450381897 29
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 6.488549618320874 41
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 8.396946564885837 48
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 9.541984732824815 60
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 10.687022900763793 72
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 10.687022900763793 87
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 10.687022900763793 96
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee320> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad748> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4cc0> 2.2900763358779557 11
backprop <src.mcts.MCTS_Node object at 0x7fdffc640be0> 4.198473282442919 20
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 5.725190839694889 30
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 6.870229007633867 42
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 8.77862595419883 49
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 9.923664122137808 61
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 11.068702290076786 73
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 11.068702290076786 88
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 11.068702290076786 97
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fe018671320> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad748> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4cc0> 2.6717557251909483 12
backprop <src.mcts.MCTS_Node object at 0x7fdffc640be0> 4.580152671755911 21
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 6.106870229007882 31
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 7.25190839694686 43
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 9.160305343511823 50
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 10.3053435114508 62
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 11.450381679389778 74
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 11.450381679389778 89
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 11.450381679389778 98
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fe018671fd0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671c88> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee320> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad748> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4cc0> 3.053435114503941 13
backprop <src.mcts.MCTS_Node object at 0x7fdffc640be0> 4.961832061068904 22
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 6.488549618320874 32
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 7.633587786259852 44
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 9.541984732824815 51
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 10.687022900763793 63
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 11.832061068702771 75
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 11.832061068702771 90
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 11.832061068702771 99
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e2b0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad748> 1.908396946564963 7
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4cc0> 3.4351145038169335 14
backprop <src.mcts.MCTS_Node object at 0x7fdffc640be0> 5.343511450381897 23
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 6.870229007633867 33
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 8.015267175572845 45
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 9.923664122137808 52
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 11.068702290076786 64
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 12.213740458015764 76
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 12.213740458015764 91
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 12.213740458015764 100
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e908> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1d30> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699a20> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbda58> 1.5267175572519704 7
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4cc0> 3.816793893129926 15
backprop <src.mcts.MCTS_Node object at 0x7fdffc640be0> 5.725190839694889 24
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cfd0> 7.25190839694686 34
backprop <src.mcts.MCTS_Node object at 0x7fdffc735198> 8.396946564885837 46
backprop <src.mcts.MCTS_Node object at 0x7fdffc701978> 10.3053435114508 53
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 11.450381679389778 65
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 12.595419847328756 77
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f67b8> 12.595419847328756 92
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64a8> 12.595419847328756 101
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #8
root->1->19->4->0->8->2->5->4
Best Reward: 0.3816793893129926
iteration: 47
found coverage increase 0.3816793893129926
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186dff28> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186adc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186dff28> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186dff28> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186dff28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186dff28> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186999b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186dff28> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186dff28> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186dff28> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186dff28> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186dff28> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186dff28> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186eeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186dff28> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186dff28> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186eeac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186dff28> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186dff28> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7996a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe0186dff28> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186dff28> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186eedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186dff28> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186dff28> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 48
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04de564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a160> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04ffd3048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04df24e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a160> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01877f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04ffd3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a160> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a160> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a160> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff85f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04ffd3be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a160> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a160> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a160> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a160> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04ffd3be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a160> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a160> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a160> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01876a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a160> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04ffd3be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a160> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a160> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04df24e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a160> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a160> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a160> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a160> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 49
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a14e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04ffd3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe52b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04df24eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5e10> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04ffd38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5e10> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 50
found coverage increase 0
Current Total Coverage 68.70229007633588
coverage_call_count 2100
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8668> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186999b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8668> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186eef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186df9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8668> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8668> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8668> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8668> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186df9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8668> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04de564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8668> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8668> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186df9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8668> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8668> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8668> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8668> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8668> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8668> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8668> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 51
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a17b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc743a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a17b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a17b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a17b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a17b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a17b8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a17b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a17b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a17b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a17b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a17b8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a17b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a17b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a17b8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a17b8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a17b8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a17b8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 52
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198f98> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1980f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198f98> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a72b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198f98> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a75f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198f98> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198f98> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a70b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198f98> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a70b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198f98> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1985c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198f98> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198f98> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198f98> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198f98> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd11d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198f98> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a75f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198f98> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198f98> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1432e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198f98> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198f98> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198f98> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198f98> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 53
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1435f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143908> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1531d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143908> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143908> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143908> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a78d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143908> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143908> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143908> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143908> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143908> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143908> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143908> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143908> 0.0 16
Completed Iteration #22
Best Reward: 0
coverage_call_count 2200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198c18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143908> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143908> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 54
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1436a0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1436a0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1436a0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1436a0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1436a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1436a0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6407b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1436a0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1436a0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1985f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc743668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1436a0> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7995f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1987f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1436a0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186999b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1436a0> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186713c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1436a0> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc743668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1436a0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186eedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1436a0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1436a0> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a70f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1436a0> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1436a0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 55
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186eeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8b38> 0.0 2
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8b38> 0.0 3
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8b38> 0.0 4
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1532b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8b38> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8b38> 0.0 6
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff83c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8b38> 0.0 7
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e154a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8b38> 0.0 8
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e156a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186eeb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8b38> 0.0 9
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8b38> 0.0 10
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e159e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1532b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8b38> 0.0 11
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8b38> 0.0 12
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1532b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8b38> 0.0 13
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186eeb00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8b38> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 56
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04df34208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143400> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143400> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1982b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143400> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e156d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f08d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143400> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143400> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143400> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143400> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143400> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143400> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143400> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143400> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f08d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143400> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143400> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1982b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143400> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04df24e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143400> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143400> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 57
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e150f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e150f0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e150f0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e150f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e157f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e150f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e150f0> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e150f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e150f0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6407b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e150f0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1532b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e150f0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e150f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e150f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186713c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15400> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e150f0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15400> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e150f0> 0.0 15
Completed Iteration #19
Best Reward: 0
coverage_call_count 2300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a70b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186713c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15400> 0.0 8
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e150f0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e150f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e150f0> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e259b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e150f0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 58
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1435c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1985c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e255c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e159e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25cc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1536d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25cc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e159e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25cc0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1985c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25cc0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e406a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25cc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25cc0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25cc0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1985c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25cc0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25cc0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25cc0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25cc0> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1536d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25cc0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25cc0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e159e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25cc0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1536d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25cc0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 59
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ced30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cea90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cea90> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cea90> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cea90> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cea90> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cea90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cea90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cea90> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cea90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cea90> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cea90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ced68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cea90> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e253c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cea90> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cea90> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df860> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cea90> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df860> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cea90> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cea90> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cea90> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cea90> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cea90> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cea20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cea90> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cea90> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 60
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e404a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40da0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40da0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40da0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40da0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40da0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05862b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e404a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40da0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40da0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40da0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40da0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40da0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40da0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40da0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40da0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40da0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40da0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40da0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e409e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40da0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f95c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40da0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 61
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f95f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe80> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ceeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe80> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cedd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ced68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe80> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f95f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe80> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe80> 0.0 13
Completed Iteration #16
Best Reward: 0
coverage_call_count 2400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186999b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ced68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe80> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe80> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe80> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a79b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f95f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe80> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ced68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe80> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ceeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe80> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 62
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153978> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153978> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153978> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e157f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153978> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05867f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153978> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153978> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153978> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153978> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153978> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153978> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e253c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153978> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05869b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153978> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153978> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153978> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153978> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 63
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cef28> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cef28> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cef28> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cef28> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cef28> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b92b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cef28> 0.0 7
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cef28> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cef28> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cef28> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cef28> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05602b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cef28> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054ecf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cef28> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cef28> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cef28> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cef28> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05601d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05606a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cef28> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cef28> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 64
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560c88> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05607f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05710b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560c88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560c88> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05710b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560c88> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054ecf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560c88> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560c88> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560c88> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560c88> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560c88> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05866d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560c88> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560c88> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05600f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560c88> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560c88> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560c88> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e157f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05600f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560c88> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05863c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560c88> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560c88> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560c88> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 65
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05867f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186eeb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cf8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cf8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cf8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cf8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05605f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cf8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cf8> 0.0 12
Completed Iteration #14
Best Reward: 0
coverage_call_count 2500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cf8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05867f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cf8> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cf8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05867f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cf8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 66
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05603c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ced68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9860> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05711d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9860> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9860> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ced68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9860> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9860> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9860> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e258d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1434a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9860> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1434a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9860> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9860> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9860> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05715c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9860> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9860> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfdd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9860> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05282b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ced68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9860> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfdd8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9860> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 67
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05283c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05286d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05285f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05285f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05285f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05285f8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05285f8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05285f8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05713c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05285f8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05389b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05382e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05285f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05285f8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05285f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05285f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05713c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05285f8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05285f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05382e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05285f8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05285f8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05382e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05285f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05285f8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 68
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186999b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571860> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571860> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571860> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571860> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05289b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571860> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571860> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571860> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7999b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571860> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571860> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e253c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571860> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05719e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571860> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571860> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571860> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571860> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571860> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 69
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cecc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cecc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05607b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cecc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cecc0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cecc0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cecc0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cecc0> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ced68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cecc0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cecc0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cecc0> 0.0 11
Completed Iteration #12
Best Reward: 0
coverage_call_count 2600
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cecc0> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cecc0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cecc0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cecc0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04efba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9470> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cecc0> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cecc0> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04efa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cecc0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 70
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571320> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04efd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571320> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571320> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571320> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04efd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571320> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571320> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571320> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04887b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571320> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571320> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571320> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571320> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04efd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571320> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571320> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571320> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571320> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571320> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9a58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571320> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 71
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b860> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b860> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b860> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b860> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b860> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04883c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b860> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b860> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b860> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b860> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b860> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b860> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04887b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b860> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b860> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b860> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b860> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04883c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b860> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 72
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153cc0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153cc0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a76d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153cc0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a76d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153cc0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153cc0> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153cc0> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04ffd38d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153cc0> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7437b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153cc0> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153cc0> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153cc0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153cc0> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a76d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153cc0> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 73
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e14a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01876a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e14a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e14a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01876add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e14a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e14a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e14a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e14a8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e14a8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e14a8> 0.0 10
Completed Iteration #12
Best Reward: 0
coverage_call_count 2700
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186adc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e14a8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ade10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e14a8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e14a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a15c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e14a8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e14a8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e14a8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e14a8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c49e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e14a8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e14a8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 74
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186adb70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186adb70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186adcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186adb70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186adb70> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186adcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186adb70> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186adb70> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186adb70> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186adb70> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874fa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186adb70> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186adb70> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186adcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186adb70> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874fa58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186adb70> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186adb70> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874fa58> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe0186adb70> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186adb70> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874fda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186adb70> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874fa58> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe0186adb70> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186adb70> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186adb70> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 75
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6405f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7eff98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7eff98> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7eff98> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7359e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7eff98> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7eff98> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7eff98> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbdef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7eff98> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7eff98> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7eff98> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7eff98> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7eff98> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7357f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7eff98> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7eff98> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7eff98> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7eff98> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbdef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7eff98> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7eff98> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7eff98> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7eff98> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7eff98> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 76
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01876add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187722e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04df24eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187722e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01876af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7430f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01874f748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de4aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a77f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01876af60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 77
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1da0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1da0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1da0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1da0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1531d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1da0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1da0> 0.0 7
Completed Iteration #9
Best Reward: 0
coverage_call_count 2800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1da0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1da0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1da0> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc719e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1da0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc719ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1da0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc719da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1da0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7193c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1da0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a74e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1da0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc719ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1da0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1da0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1da0> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1da0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ada20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1da0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 78
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc719128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6adfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad748> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad748> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff41355f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7352e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad748> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad748> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7352e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad748> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad748> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7355c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad748> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff41352b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad748> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad748> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad748> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7352e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad748> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7764a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad748> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6adfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad748> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad748> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad748> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ade80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad748> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad748> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6adfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad748> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad748> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad748> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 79
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc719a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187722e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff41357f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719da0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7433c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc719470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e16a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01876af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e16a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 21
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 80
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f2b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f2b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f2b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186850f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f2b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f2b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f2b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01874f2b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01874f2b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a76d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f2b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01874f2b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f2b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f2b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe01874f2b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc719e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe01874f2b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ada20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01874f2b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe01874f2b0> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018776550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe01874f2b0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719e48> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fe01874f2b0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe01874f2b0> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad2e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe01874f2b0> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 81
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4668> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4668> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4668> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0415f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4668> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec041978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4668> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0413c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec041dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4668> 0.0 7
Completed Iteration #6
Best Reward: 0
coverage_call_count 2900
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0412e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec041c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4668> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec041710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4668> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40abb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4668> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec041b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4668> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec041c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4668> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec041dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4668> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40abe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec041b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4668> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec041dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4668> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec041e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec041b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4668> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec041dd8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4668> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec041c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4668> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40abef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4668> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4668> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 82
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec041b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4a20> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05ed68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec041828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4a20> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4a20> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4a20> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4a20> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4a20> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0411d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4a20> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec041588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4a20> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec041978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4a20> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40abac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec041c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4a20> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4a20> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab0f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4a20> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab0f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4a20> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05ec88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4a20> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 83
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fec18> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fec18> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fec18> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec041b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40fec18> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fec18> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40fec18> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fec18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fec18> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a75c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fec18> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018776550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40fec18> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40fec18> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874f940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f64e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40fec18> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec041390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a75c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40fec18> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a75c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40fec18> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40fec18> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc699748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40fec18> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fec18> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 84
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01876af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1531d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a03c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec034f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc776438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec034b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0346a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 12
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec034e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec093a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec093b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a03c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4135668> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 85
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec093828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0342b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec093940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0342b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec093f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0342b0> 0.0 4
Completed Iteration #3
Best Reward: 0
coverage_call_count 3000
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4069828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4069b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0342b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec093cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0342b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec093a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0937b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0342b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4069ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0932e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0342b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4069c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0342b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0340b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0342b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0340b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0342b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05ee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0937b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0342b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0341d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0342b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0937b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec0342b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4069a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0937b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfec0342b0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4069c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0342b0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0342b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4069b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0342b0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 86
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187609e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7224e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018760080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187602e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018760f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7224e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc722d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4069710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722d30> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4069b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4069d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722d30> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4069ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7224e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc722d30> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722d30> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc722d30> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4069d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc722d30> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc722d30> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4069a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187605c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722d30> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0930f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187602e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc722d30> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc722d30> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722d30> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec093b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc722d30> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc722d30> 0.0 19
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187602e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc722d30> 0.0 20
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec093e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc722d30> 0.0 21
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc722d30> 0.0 22
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec034fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187602e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc722d30> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec034ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc722d30> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 87
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018760630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4069320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec034780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7221d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0ba8> 0.0 3
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec034358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0ba8> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc719b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4069320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0ba8> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0ba8> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0ba8> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0ba8> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187607f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0ba8> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04ffd3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0ba8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7221d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0ba8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7221d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0ba8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187607f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0ba8> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0ba8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0ba8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4069748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0ba8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187607f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0ba8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 88
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec093390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec041390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a70f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b61d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b68d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ced30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4fd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4fd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0349b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6cee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4fd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4025400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a70f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4fd0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4025a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4fd0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4fd0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4fd0> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4025e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4fd0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4025da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4fd0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4080cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a70f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4fd0> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4080b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b61d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4fd0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec093a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b60f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4fd0> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b61d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4fd0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4fd0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a70f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4fd0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6cee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4fd0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 89
found coverage increase 0
Current Total Coverage 68.70229007633588
coverage_call_count 3100
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4080e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4080f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025978> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4080400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4080ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025978> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40802b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4080128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025978> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4080748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4080a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025978> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4080518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025978> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4025dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40251d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025978> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4035240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4080a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4025978> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40356d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40354a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025978> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4035400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4080ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4025978> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec034400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025978> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4035e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4080f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4025978> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc701588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4080f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4025978> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc701e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4080518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4025978> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40cde80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4025978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc701668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4080128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4025978> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7013c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4080a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4025978> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40abf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025978> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40251d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4025978> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40257f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4080f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdff4025978> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 90
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7015f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025cf8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025cf8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025cf8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4025cf8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025cf8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025cf8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025a90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4025cf8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025cf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4080438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025cf8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4025cf8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4025cf8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025a90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdff4025cf8> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025cf8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4025f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4025cf8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4025cf8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4025cf8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40800b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025cf8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec093c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4025cf8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 91
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0930b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe7b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc701ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fec18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe7b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe7b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe7b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe7b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe7b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40febe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe7b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc719b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe7b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe7b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe7b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe7b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe7b8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fec18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe7b8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fec18> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe7b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe7b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4056ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe7b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe7b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719a20> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe7b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 92
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4056a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40565c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0790f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40565c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4080630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40565c0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40565c0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40565c0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40565c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4056048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40565c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec079a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40565c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4056cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40565c0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40565c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4025f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410a5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40565c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec079908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40565c0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec079dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40565c0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec079d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40565c0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec079ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40565c0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40565c0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec079320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40561d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40565c0> 0.0 18
Completed Iteration #21
Best Reward: 0
coverage_call_count 3200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40565c0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404d1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40565c0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056518> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdff40565c0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404d278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056518> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fdff40565c0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 93
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40e50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404dcf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4056e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404dcf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404d128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404dcf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec079048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff404dcf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404dcf8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404dcf8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec06ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06bb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404dcf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404dcf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404dcf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404dcf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec079940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404dcf8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec079b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff404dcf8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4056160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404dcf8> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404dcf8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404db70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404dcf8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404dcf8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec079320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdff404dcf8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec079208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404dcf8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40e56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404dcf8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40565c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdff404dcf8> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc719978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404dcf8> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 94
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404ddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079710> 0.0 2
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079710> 0.0 3
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4056390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079710> 0.0 4
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079710> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4069588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec079710> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018776358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0346a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079710> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40801d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079710> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fec18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079710> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec079128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404ddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec079710> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018760908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec079710> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec093fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079710> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0346a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec079710> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05ef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079710> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec079710> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40801d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec079710> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 95
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd3c8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6cee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd3c8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd3c8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd3c8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd3c8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd3c8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd3c8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd3c8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06bac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd3c8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4056128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd3c8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06bac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd3c8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd3c8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd3c8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b66d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd3c8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec06beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd3c8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4025400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd3c8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd3c8> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd3c8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 96
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4056048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5e48> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5e48> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5e48> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5e48> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5e48> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5e48> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5e48> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5e48> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5e48> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5e48> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5e48> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40915f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5e48> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
coverage_call_count 3300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4091c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5e48> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4091780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5ef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5e48> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5e48> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5e48> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04885c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5e48> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40919e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5e48> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 97
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091048> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091048> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091048> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4091a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091048> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4091b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091048> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091048> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091048> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4091048> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4025f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091048> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4091048> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4091048> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091048> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0347b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc701ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4091048> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4091048> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40916d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4091048> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4091048> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 98
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec041128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd7f0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd7f0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd7f0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd7f0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd7f0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4080438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd7f0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd7f0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4056320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd7f0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd7f0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd7f0> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec079128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd7f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04effd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd7f0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04eff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd7f0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd7f0> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04eff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410aa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd7f0> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410ad30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd7f0> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410ad30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd7f0> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd7f0> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 99
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40690b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf860> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04efb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf860> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04efdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf860> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf860> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04efb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf860> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf860> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf860> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04efb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf860> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf860> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf860> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf860> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf860> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05604a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf860> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054ea20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf860> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf860> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf860> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410ac88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf860> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 100
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054edd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c99b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f96d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9320> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9320> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05608d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9320> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9320> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9320> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c99b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9320> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9320> 0.0 14
Completed Iteration #16
Best Reward: 0
coverage_call_count 3400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9320> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9320> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9320> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05609e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9320> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c99b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9320> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c99b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9320> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 101
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05604a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560630> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560630> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560630> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054ebe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560630> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560630> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cefd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05604a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560630> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c96a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560630> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560630> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560630> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560630> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04eff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560630> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560630> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018760908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560630> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018776358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488da0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560630> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560630> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 102
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093ba8> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093ba8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04efb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093ba8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec093ba8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4091588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec093ba8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4091860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093ba8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093ba8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40914a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093ba8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05605f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093ba8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec034860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40912e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093ba8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40256a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec093ba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04efdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec093ba8> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec093ba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfec093ba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40256a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec093ba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40912e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec093ba8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01877f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40912e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec093ba8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 103
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054efd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25390> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25390> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25390> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25390> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e250b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25390> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e259b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25390> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1435c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25390> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25390> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25390> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1438d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25390> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25390> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25390> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f94a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25390> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1435c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25390> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25390> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25390> 0.0 17
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25390> 0.0 18
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25390> 0.0 19
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25390> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25390> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25390> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25f98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25390> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 104
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9710> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9710> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186eeac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9710> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9710> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9710> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9710> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e250b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e258d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9710> 0.0 8
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9710> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9710> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e258d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9710> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec034860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9710> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
coverage_call_count 3500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9710> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01877f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9710> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9710> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9710> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9710> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b8d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9710> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e258d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9710> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b8d0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9710> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9710> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9710> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4035d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25080> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9710> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 105
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee5c0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee5c0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee5c0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40912e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee5c0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f94a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee5c0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee5c0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee5c0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec093cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee5c0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40912e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee5c0> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee5c0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4056a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee5c0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee5c0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04ffd3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40912e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee5c0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee5c0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f94a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee5c0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404dac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee5c0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee5c0> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee5c0> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410aa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee5c0> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cef28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee5c0> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee5c0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 106
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04eff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560b70> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560b70> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560b70> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560b70> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560b70> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560b70> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560b70> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054eb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560b70> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e250f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560b70> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560b70> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560b70> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560b70> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054eb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560b70> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f02e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560b70> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560b70> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560b70> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054eb38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560b70> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560b70> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 107
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05288d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05284a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9e48> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9e48> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9e48> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05285f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9e48> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9e48> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05284a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9e48> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9e48> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05284a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9e48> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7432e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9e48> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9e48> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9e48> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9e48> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9e48> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9e48> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05283c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9e48> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9e48> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9e48> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9e48> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 108
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05864e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860f0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860f0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860f0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860f0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04efa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860f0> 0.0 9
Completed Iteration #9
Best Reward: 0
coverage_call_count 3600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860f0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404db00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860f0> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f07b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860f0> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4056a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860f0> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860f0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860f0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860f0> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860f0> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05864e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860f0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860f0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc701ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05864e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860f0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860f0> 0.0 21
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b90f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860f0> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 109
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4025a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05604a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860b8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1435f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860b8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1435f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860b8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05604a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860b8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860b8> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05604a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860b8> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860b8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860b8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860b8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860b8> 0.0 13
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860b8> 0.0 14
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860b8> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 110
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699390> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699390> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699390> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05385c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699390> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05380f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699390> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699390> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018699390> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018699390> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699390> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018699390> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05380f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018699390> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e150f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018699390> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699390> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05385c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018699390> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe018699390> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186994a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018699390> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe018699390> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 111
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05385f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15978> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15978> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15978> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e401d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15978> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15978> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15978> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15978> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05384a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15978> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1981d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15978> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05384a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15978> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15978> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15978> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15978> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e159b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15978> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05384a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15978> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05384a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15978> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15978> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15978> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15978> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 112
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40a58> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40a58> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1980b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40a58> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40a58> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40a58> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4025a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186994a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40a58> 0.0 7
Completed Iteration #10
Best Reward: 0
coverage_call_count 3700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40a58> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40a58> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40a58> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186eef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40a58> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40a58> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40a58> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40a58> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40a58> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40a58> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40912e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186eef28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40a58> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186994a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40a58> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 113
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05605c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488c50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488c50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488c50> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488c50> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488c50> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488c50> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488c50> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488c50> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488c50> 0.0 11
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e406d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488c50> 0.0 12
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cef28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488c50> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488c50> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488c50> 0.0 15
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488c50> 0.0 16
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05719e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05712e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488c50> 0.0 17
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05710f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488c50> 0.0 18
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05712e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488c50> 0.0 19
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488c50> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04de564e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488c50> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488c50> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfe80> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488c50> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 114
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4056a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1435f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e156a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e156a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186714a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04accc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04acf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186716d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ace80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056ac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186716d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e156a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff84a8> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 115
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b47b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4320> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40561d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b47f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4320> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4320> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4320> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4320> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186714a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4320> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4320> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b47f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4320> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4320> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4320> 0.0 14
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4320> 0.0 15
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4320> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4320> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04acd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4320> 0.0 18
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe09dd81fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4320> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05860b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4320> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 116
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e780> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04acf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e780> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40912e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e780> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e780> 0.0 5
Completed Iteration #6
Best Reward: 0
coverage_call_count 3800
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4025400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e780> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e780> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05715f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e780> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e780> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e780> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05715f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e780> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e780> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05712e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77ed30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e780> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e780> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e780> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e780> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e780> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 117
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186991d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8ba8> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05710b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8ba8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05710b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8ba8> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8ba8> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186991d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8ba8> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8ba8> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8ba8> 0.0 9
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8ba8> 0.0 10
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8ba8> 0.0 11
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8ba8> 0.0 12
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04acb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8ba8> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 118
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f940> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98676518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986760f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f940> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98676780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986760b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f940> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f940> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f940> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98676a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f940> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98676358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986769e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f940> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98676dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f940> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98676400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986769e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f940> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986769e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f940> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f940> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98676fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986760b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f940> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98676828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986769e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f940> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986017f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986764e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f940> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f940> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986769e8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f940> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f940> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986769e8> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f940> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f940> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 119
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986769b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986769b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986769b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf986769b0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986769b0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98676f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986769b0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf986769b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf986769b0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986019b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986769b0> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986019b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf986769b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf986769b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986769b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b44e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf986769b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40912e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986769b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986769b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986019b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf986769b0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf986769b0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 120
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df2e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df2e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05604a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df2e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98676208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df2e8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
coverage_call_count 3900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ace80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df2e8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04acac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df2e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df2e8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df2e8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04acac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df2e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04acac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df2e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9862abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df2e8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df2e8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df2e8> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986364a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04acac8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df2e8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986366a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df2e8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 121
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986361d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a4a8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a4a8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a4a8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a4a8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a4a8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a4a8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a4a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a4a8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a4a8> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a4a8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a4a8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a4a8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862aba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a4a8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a4a8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a4a8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 122
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cbe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb518> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb518> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb518> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb518> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981dda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb518> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ddcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb518> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ddd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981dde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb518> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cbf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb518> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cbf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb518> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb518> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb518> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb518> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04acd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cba20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb518> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb518> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ddc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb518> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cba20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb518> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 123
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986364a8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986364a8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986364a8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986364a8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf986364a8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986364a8> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf986364a8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf986364a8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf986364a8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986364a8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf986364a8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9862ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf986364a8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986364a8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf986364a8> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e278> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf986364a8> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cbc88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf986364a8> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf986364a8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cbc88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf986364a8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc701ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf986364a8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf986364a8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 124
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25e80> 0.0 3
Completed Iteration #3
Best Reward: 0
coverage_call_count 4000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25e80> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98601c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25e80> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25e80> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25e80> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25e80> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25e80> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25e80> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25e80> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25e80> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25e80> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98676940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25e80> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25e80> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25e80> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25e80> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25e80> 0.0 18
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25e80> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25e80> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25e80> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 125
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a22b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981eca20> 0.0 2
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981eca20> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981eca20> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981eca20> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a24a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981eca20> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981eca20> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981eca20> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ece80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a24e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981eca20> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a24e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981eca20> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981eca20> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a24e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981eca20> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981a24a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981eca20> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a24a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf981eca20> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981eca20> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a24e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf981eca20> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 126
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98146710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1d68> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981464e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1d68> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981464e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1d68> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1d68> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1d68> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1d68> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1d68> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981464e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1d68> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1d68> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1d68> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1d68> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b19e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1d68> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1d68> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981464e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1d68> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1d68> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1d68> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98676940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1d68> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981eccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a27f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1d68> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1d68> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 127
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecb38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecb38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecb38> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc701ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04ffd3860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecb38> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98601cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecb38> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecb38> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecb38> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ddd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecb38> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecb38> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecb38> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04ffd3860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecb38> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98601cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecb38> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cbc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecb38> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04ffd3860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecb38> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecb38> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecb38> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecb38> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecb38> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecb38> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4a58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecb38> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecb38> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 128
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98146a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862af98> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862af98> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 4100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862af98> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862af98> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862af98> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862af98> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9862af98> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98146668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862af98> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98146470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cbf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9862af98> 0.0 10
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98146f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9862af98> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98146be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862af98> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9862af98> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981462e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9862af98> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636e48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9862af98> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf9862af98> 0.0 16
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862af98> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cbf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9862af98> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9862af98> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9862af98> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9862af98> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636e48> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf9862af98> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9862af98> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 129
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a048> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a048> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a048> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a048> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a048> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9810aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a048> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9810acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a048> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9810af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a048> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a048> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a048> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a048> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a048> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9862aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a048> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810ae10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a048> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a048> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a048> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a048> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a048> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 130
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ece80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec080> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec080> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec080> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec080> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec080> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec080> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec080> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec080> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05dfb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec080> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cbd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec080> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ece80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec080> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec080> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec080> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ddb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cbc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec080> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec080> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ddf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77eda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec080> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981dde10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cbc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec080> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 131
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f4e0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9862abe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f4e0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f4e0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f4e0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986015f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f4e0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98601278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f4e0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986010f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986015f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f4e0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9862ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f4e0> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f4e0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862aa20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f4e0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f4e0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ddcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f4e0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ddc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f4e0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981dda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f4e0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f4e0> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98676748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f4e0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f898> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f4e0> 0.0 18
Completed Iteration #23
Best Reward: 0
coverage_call_count 4200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981dde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ddc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f4e0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862aa20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f4e0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 132
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98676b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f6d8> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187b4b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f6d8> 0.0 3
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98676320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f6d8> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f6d8> 0.0 5
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986766d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f6d8> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f6d8> 0.0 7
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f6d8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b41d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f6d8> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f6d8> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f6d8> 0.0 11
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018671ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f6d8> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f6d8> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf98676160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f6d8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f6d8> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f6d8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 133
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1986d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571b00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571b00> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571b00> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571b00> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571b00> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98601358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571b00> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98676278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571b00> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571b00> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1982e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571b00> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98601358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571b00> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b45c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571b00> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b44e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571b00> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571b00> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b43c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571978> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571b00> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571b00> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186719e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571b00> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98676198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1982e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571b00> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98676e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571b00> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 134
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676160> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986017f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98601780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676160> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98601828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676160> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98601780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf98676160> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98601828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf98676160> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676160> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf98676160> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98601dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676160> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf98676160> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9862ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676160> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676160> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986018d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98601dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf98676160> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05384e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf98676160> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf98676160> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676160> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05385f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf98676160> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf98676160> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 135
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1988d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b42e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1988d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1988d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1988d0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b42e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1988d0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986762b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1988d0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01864e4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1988d0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e402b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05387b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1988d0> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1988d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e154e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1988d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05382e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1988d0> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05387b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1988d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd9e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1988d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd9e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1988d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1988d0> 0.0 16
Completed Iteration #19
Best Reward: 0
coverage_call_count 4300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1988d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7434e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05387b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1988d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b42e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1988d0> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b42e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1988d0> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 136
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a13c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1e80> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7433c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1e80> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1e80> 0.0 4
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05280f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1e80> 0.0 5
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01877f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7433c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1e80> 0.0 6
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1e80> 0.0 7
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a13c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1e80> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a15f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1e80> 0.0 9
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1e80> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ceda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f04a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1e80> 0.0 11
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a15f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1e80> 0.0 12
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187b49e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1e80> 0.0 13
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 137
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7437b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e154e0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e154e0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e154e0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e402b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e400b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e154e0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc77e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e154e0> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e154e0> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e159b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e154e0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e159b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e154e0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186999e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e154e0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98601780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e154e0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e400b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e154e0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e154e0> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e154e0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e154e0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e159b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e154e0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e159b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e154e0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986760b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e154e0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7437b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e154e0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc799940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e154e0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e400b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e154e0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1988d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e154e0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 138
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05867b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1438d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cbac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e150f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986766d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1434e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e150f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05867b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05867b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff89b0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 139
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e252b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e252b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e252b0> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e252b0> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e252b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e252b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054ecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e252b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e252b0> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054ecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e252b0> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e252b0> 0.0 11
Completed Iteration #16
Best Reward: 0
coverage_call_count 4400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e252b0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e252b0> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e252b0> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e252b0> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054ecc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e252b0> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05609b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e252b0> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 140
found coverage increase 0
Current Total Coverage 68.70229007633588
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cee80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cee80> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cecc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cee80> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cee80> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cee80> 0.0 6
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cecc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cee80> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05608d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cee80> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cee80> 0.0 9
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cee80> 0.0 10
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cee80> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cee80> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cee80> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cee80> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05608d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cee80> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05608d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cee80> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c97f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cee80> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 141
found coverage increase 0
Current Total Coverage 68.70229007633588
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143908> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 0.3816793893129642 5
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 0.3816793893129642 6
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586908> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 0.7633587786259284 7
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528128> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe50f0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586908> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 1.1450381679388926 8
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01864e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 1.1450381679388926 9
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 1.1450381679388926 10
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98676be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7437b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586908> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 1.1450381679388926 11
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 1.1450381679388926 12
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 1.1450381679388926 13
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05389e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 1.1450381679388926 14
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186999e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 1.1450381679388926 6
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 1.1450381679388926 15
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 1.1450381679388926 16
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 1.1450381679388926 7
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 1.1450381679388926 17
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 1.5267175572518568 8
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 1.5267175572518568 18
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdf98601908> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25048> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 1.908396946564821 9
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 1.908396946564821 19
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdf986b41d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 2.290076335877785 10
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 2.290076335877785 20
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e257b8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15ac8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143908> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 2.6717557251907493 11
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 2.6717557251907493 21
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 2.6717557251907493 12
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 2.6717557251907493 22
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f4e0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 3.0534351145037135 13
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 3.0534351145037135 23
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e402b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 3.0534351145037135 14
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 3.0534351145037135 24
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf470> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f8d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f4e0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 3.4351145038166777 15
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 3.4351145038166777 25
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b41d0> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 3.4351145038166777 16
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 3.4351145038166777 26
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cf28> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cef0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40b38> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 3.816793893129642 17
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 3.816793893129642 27
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5898> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25048> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 4.198473282442606 18
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 4.198473282442606 28
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cf28> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cef0> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40b38> 0.3816793893129642 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 4.198473282442606 19
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 4.198473282442606 29
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586908> 0.7633587786259284 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 4.198473282442606 20
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 4.198473282442606 30
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff410a128> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 4.58015267175557 21
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 4.58015267175557 31
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 4.58015267175557 22
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 4.58015267175557 32
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #1
root->6
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec079668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5898> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25048> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 4.58015267175557 23
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 4.58015267175557 33
Completed Iteration #7
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5898> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 1.5267175572518568 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 4.9618320610685345 24
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 4.9618320610685345 34
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4ac8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 1.908396946564821 7
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 5.343511450381499 25
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 5.343511450381499 35
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586898> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25048> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 2.290076335877785 8
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 5.725190839694463 26
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 5.725190839694463 36
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
coverage_call_count 4500
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5780> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5748> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4ac8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 2.6717557251907493 9
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 6.106870229007427 27
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 6.106870229007427 37
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 6.488549618320391 28
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 6.488549618320391 38
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff410a278> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5748> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4ac8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 6.870229007633355 29
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 6.870229007633355 39
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #2
root->6->9
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5860> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 7.25190839694632 30
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 7.25190839694632 40
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec06bd68> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091f60> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5860> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 4.198473282442606 13
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 7.633587786259284 31
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 7.633587786259284 41
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff404dcc0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5748> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4ac8> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 4.58015267175557 14
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 8.015267175572248 32
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 8.015267175572248 42
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdffc6997f0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 4.9618320610685345 15
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 8.396946564885212 33
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 8.396946564885212 43
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff4025748> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 5.343511450381499 16
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 8.778625954198176 34
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 8.778625954198176 44
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdf98> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 4.198473282442606 12
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 5.725190839694463 17
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 9.16030534351114 35
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 9.16030534351114 45
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdffc701198> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035710> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdf98> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 4.58015267175557 13
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 6.106870229007427 18
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 9.541984732824105 36
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 9.541984732824105 46
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528160> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056978> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6997f0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 4.9618320610685345 14
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 6.488549618320391 19
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 9.923664122137069 37
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 9.923664122137069 47
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #3
root->6->9->0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5128> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056978> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6997f0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 5.343511450381499 15
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 6.870229007633355 20
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 10.305343511450033 38
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 10.305343511450033 48
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf4e0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056978> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6997f0> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 5.725190839694463 16
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 7.25190839694632 21
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 10.687022900762997 39
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 10.687022900762997 49
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd2b0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079048> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 6.106870229007427 17
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 7.633587786259284 22
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 11.068702290075962 40
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 11.068702290075962 50
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff40351d0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079048> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 6.488549618320391 18
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 8.015267175572248 23
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 11.450381679388926 41
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 11.450381679388926 51
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a550> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 6.870229007633355 19
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 8.396946564885212 24
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 11.83206106870189 42
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 11.83206106870189 52
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #4
root->6->9->0->5
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fe018760a20> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 7.25190839694632 20
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 8.778625954198176 25
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 12.213740458014854 43
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 12.213740458014854 53
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fe0187609e8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 4.198473282442606 12
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 7.633587786259284 21
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 9.16030534351114 26
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 12.595419847327818 44
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 12.595419847327818 54
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40693c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056978> 1.1450381679388926 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc6997f0> 1.5267175572518568 6
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 3.0534351145037135 10
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 4.198473282442606 13
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 7.633587786259284 22
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 9.16030534351114 27
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 12.595419847327818 45
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 12.595419847327818 55
Completed Iteration #10
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6f28> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1d30> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760a20> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 3.4351145038166777 11
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 4.58015267175557 14
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 8.015267175572248 23
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 9.541984732824105 28
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 12.977099236640782 46
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 12.977099236640782 56
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f668> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 4.9618320610685345 15
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 8.396946564885212 24
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 9.923664122137069 29
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 13.358778625953747 47
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 13.358778625953747 57
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5978> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1d30> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fe018760a20> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 4.198473282442606 13
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 5.343511450381499 16
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 8.778625954198176 25
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 10.305343511450033 30
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 13.74045801526671 48
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 13.74045801526671 58
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff410a588> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 4.58015267175557 14
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 5.725190839694463 17
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 9.16030534351114 26
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 10.687022900762997 31
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 14.122137404579675 49
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 14.122137404579675 59
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fe0187600f0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 4.9618320610685345 15
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 6.106870229007427 18
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 9.541984732824105 27
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 11.068702290075962 32
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 14.50381679389264 50
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 14.50381679389264 60
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6160> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4069b00> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f668> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 5.343511450381499 16
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 6.488549618320391 19
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 9.923664122137069 28
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 11.450381679388926 33
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 14.885496183205603 51
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 14.885496183205603 61
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #5
root->6->9->0->5->0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6668> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6710> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5978> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1d30> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fe018760a20> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 5.725190839694463 17
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 6.870229007633355 20
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 10.305343511450033 29
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 11.83206106870189 34
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 15.267175572518568 52
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 15.267175572518568 62
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab860> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1d30> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fe018760a20> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 6.106870229007427 18
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 7.25190839694632 21
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 10.687022900762997 30
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 12.213740458014854 35
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 15.648854961831532 53
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 15.648854961831532 63
Completed Iteration #12
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6400> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec041da0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5978> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1d30> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fe018760a20> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 6.488549618320391 19
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 7.633587786259284 22
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 11.068702290075962 31
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 12.595419847327818 36
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 16.030534351144496 54
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 16.030534351144496 64
Completed Iteration #13
Best Reward: 0.3816793893129642
coverage_call_count 4600
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0550> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6710> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5978> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1d30> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fe018760a20> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 6.870229007633355 20
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 8.015267175572248 23
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 11.450381679388926 32
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 12.977099236640782 37
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 16.41221374045746 55
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 16.41221374045746 65
Completed Iteration #18
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a518> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e898> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fe018760a20> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 7.25190839694632 21
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 8.396946564885212 24
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 11.83206106870189 33
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 13.358778625953747 38
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 16.793893129770424 56
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 16.793893129770424 66
Completed Iteration #19
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6978> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1d30> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7fe018760a20> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 7.633587786259284 22
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 8.778625954198176 25
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 12.213740458014854 34
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 13.74045801526671 39
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 17.17557251908339 57
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 17.17557251908339 67
Completed Iteration #20
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec0937f0> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1d30> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7fe018760a20> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 8.015267175572248 23
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 9.16030534351114 26
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 12.595419847327818 35
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 14.122137404579675 40
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 17.557251908396353 58
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 17.557251908396353 68
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec034fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e898> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fe018760a20> 3.816793893129642 12
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 8.015267175572248 24
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 9.16030534351114 27
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 12.595419847327818 36
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 14.122137404579675 41
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 17.557251908396353 59
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 17.557251908396353 69
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #6
root->6->9->0->5->0->21
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1c50> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe470> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0937f0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1d30> 3.4351145038166777 10
backprop <src.mcts.MCTS_Node object at 0x7fe018760a20> 4.198473282442606 13
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 8.396946564885212 25
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 9.541984732824105 28
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 12.977099236640782 37
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 14.50381679389264 42
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 17.938931297709317 60
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 17.938931297709317 70
Completed Iteration #1
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec041f60> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1d30> 3.816793893129642 11
backprop <src.mcts.MCTS_Node object at 0x7fe018760a20> 4.58015267175557 14
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 8.778625954198176 26
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 9.923664122137069 29
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 13.358778625953747 38
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 14.885496183205603 43
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 18.32061068702228 61
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 18.32061068702228 71
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff4069940> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1d30> 4.198473282442606 12
backprop <src.mcts.MCTS_Node object at 0x7fe018760a20> 4.9618320610685345 15
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 9.16030534351114 27
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 10.305343511450033 30
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 13.74045801526671 39
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 15.267175572518568 44
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 18.702290076335245 62
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 18.702290076335245 72
Completed Iteration #5
Best Reward: 0.3816793893129642
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe470> 0.3816793893129642 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0937f0> 0.7633587786259284 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1d30> 4.198473282442606 13
backprop <src.mcts.MCTS_Node object at 0x7fe018760a20> 4.9618320610685345 16
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 9.16030534351114 28
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 10.305343511450033 31
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 13.74045801526671 40
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 15.267175572518568 45
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 18.702290076335245 63
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 18.702290076335245 73
Completed Iteration #6
Best Reward: 0.3816793893129642
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7048> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0198> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab860> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1d30> 4.58015267175557 14
backprop <src.mcts.MCTS_Node object at 0x7fe018760a20> 5.343511450381499 17
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 9.541984732824105 29
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 10.687022900762997 32
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 14.122137404579675 41
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 15.648854961831532 46
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 19.08396946564821 64
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 19.08396946564821 74
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec093c50> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1d30> 4.9618320610685345 15
backprop <src.mcts.MCTS_Node object at 0x7fe018760a20> 5.725190839694463 18
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 9.923664122137069 30
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 11.068702290075962 33
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 14.50381679389264 42
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 16.030534351144496 47
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 19.465648854961174 65
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 19.465648854961174 75
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfec05ee80> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1d30> 5.343511450381499 16
backprop <src.mcts.MCTS_Node object at 0x7fe018760a20> 6.106870229007427 19
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 10.305343511450033 31
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 11.450381679388926 34
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 14.885496183205603 43
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 16.41221374045746 48
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 19.847328244274138 66
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 19.847328244274138 76
Completed Iteration #24
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7f98> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0128> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05ee80> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1d30> 5.725190839694463 17
backprop <src.mcts.MCTS_Node object at 0x7fe018760a20> 6.488549618320391 20
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 10.687022900762997 32
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 11.83206106870189 35
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 15.267175572518568 44
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 16.793893129770424 49
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 20.229007633587102 67
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 20.229007633587102 77
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #7
root->6->9->0->5->0->21->0
Best Reward: 0.3816793893129642
Completed Iteration #0
Best Reward: 0.3816793893129642
Completed Iteration #1
Best Reward: 0.3816793893129642
Completed Iteration #2
Best Reward: 0.3816793893129642
Completed Iteration #3
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdff4135128> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135748> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6400> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec041da0> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5978> 1.908396946564821 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1d30> 6.106870229007427 18
backprop <src.mcts.MCTS_Node object at 0x7fe018760a20> 6.870229007633355 21
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 11.068702290075962 33
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 12.213740458014854 36
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 15.648854961831532 45
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 17.17557251908339 50
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 20.610687022900066 68
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 20.610687022900066 78
Completed Iteration #4
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fe018685b00> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc776898> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0550> 0.7633587786259284 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6710> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5978> 2.290076335877785 7
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1d30> 6.488549618320391 19
backprop <src.mcts.MCTS_Node object at 0x7fe018760a20> 7.25190839694632 22
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 11.450381679388926 34
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 12.595419847327818 37
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 16.030534351144496 46
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 17.557251908396353 51
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 20.99236641221303 69
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 20.99236641221303 79
Completed Iteration #5
Best Reward: 0.3816793893129642
Completed Iteration #6
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e390> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec041da0> 1.1450381679388926 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5978> 2.6717557251907493 8
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1d30> 6.870229007633355 20
backprop <src.mcts.MCTS_Node object at 0x7fe018760a20> 7.633587786259284 23
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 11.83206106870189 35
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 12.977099236640782 38
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 16.41221374045746 47
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 17.938931297709317 52
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 21.374045801525995 70
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 21.374045801525995 80
Completed Iteration #7
Best Reward: 0.3816793893129642
Completed Iteration #8
Best Reward: 0.3816793893129642
Completed Iteration #9
Best Reward: 0.3816793893129642
Completed Iteration #10
Best Reward: 0.3816793893129642
Completed Iteration #11
Best Reward: 0.3816793893129642
Reward: 0.3816793893129642
backprop <src.mcts.MCTS_Node object at 0x7fdffc719eb8> 0.3816793893129642 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec041da0> 1.5267175572518568 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5978> 3.0534351145037135 9
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1d30> 7.25190839694632 21
backprop <src.mcts.MCTS_Node object at 0x7fe018760a20> 8.015267175572248 24
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdeb8> 12.213740458014854 36
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 13.358778625953747 39
backprop <src.mcts.MCTS_Node object at 0x7fdfec079630> 16.793893129770424 48
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1cf8> 18.32061068702228 53
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 21.75572519083896 71
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 21.75572519083896 81
Completed Iteration #12
Best Reward: 0.3816793893129642
Completed Iteration #13
Best Reward: 0.3816793893129642
Completed Iteration #14
Best Reward: 0.3816793893129642
Completed Iteration #15
Best Reward: 0.3816793893129642
Completed Iteration #16
Best Reward: 0.3816793893129642
Completed Iteration #17
Best Reward: 0.3816793893129642
Completed Iteration #18
Best Reward: 0.3816793893129642
Completed Iteration #19
Best Reward: 0.3816793893129642
Completed Iteration #20
Best Reward: 0.3816793893129642
Completed Iteration #21
Best Reward: 0.3816793893129642
Completed Iteration #22
Best Reward: 0.3816793893129642
Completed Iteration #23
Best Reward: 0.3816793893129642
Completed Iteration #24
Best Reward: 0.3816793893129642
Completed Iteration #25
Best Reward: 0.3816793893129642
Completed MCTS Level/Depth: #8
root->6->9->0->5->0->21->0->21
Best Reward: 0.3816793893129642
iteration: 142
found coverage increase 0.3816793893129642
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0a90> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0a90> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0930b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0a90> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0a90> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0a90> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0a90> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0a90> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0a90> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6eda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0a90> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01879cac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0a90> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0930b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0a90> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0a90> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0a90> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0930b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0a90> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7352e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0a90> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0a90> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0a90> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 143
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbdc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c46d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
coverage_call_count 4700
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0410f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbda90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4025470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbda90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 144
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa90> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ef60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa90> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa90> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ef60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa90> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa90> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa90> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7192e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa90> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc719320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa90> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735eb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa90> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735eb8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa90> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edd68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa90> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc735a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa90> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff41355f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735eb8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa90> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa90> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40abac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa90> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa90> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc719320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa90> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa90> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04efa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efa90> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 145
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bf28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bf28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bf28> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bf28> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bf28> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bf28> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bf28> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bf28> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bf28> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bf28> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049be10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bf28> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bf28> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7357f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bf28> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049be10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bf28> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bf28> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1531d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bf28> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1536d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bf28> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bf28> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bc18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bf28> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 146
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153828> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153828> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153828> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04acba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153828> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153828> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a02b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153828> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a02b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153828> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04acba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153828> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153828> 0.0 14
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153828> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04acba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153828> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04acba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153828> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153828> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153828> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf98636668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153828> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a02b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153828> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153828> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 147
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a06d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0358> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a06d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0358> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0358> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0358> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0358> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0358> 0.0 7
Completed Iteration #11
Best Reward: 0
coverage_call_count 4800
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0358> 0.0 8
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0358> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0358> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0358> 0.0 11
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0358> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0358> 0.0 13
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0358> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0358> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 148
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7352e8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7352e8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7352e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec400> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7352e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7352e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7352e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7352e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7352e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7352e8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04efdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7352e8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04efa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04efdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7352e8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ee10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7352e8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec400> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc7352e8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7352e8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7352e8> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7352e8> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7352e8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b48d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4135da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7352e8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 149
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc776668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7767f0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1536a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7767f0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7767f0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc776668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7767f0> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7767f0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7767f0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a29e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a21d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7767f0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a21d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7767f0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1536a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7767f0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1536a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7767f0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a27b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a21d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc7767f0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7767f0> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7767f0> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7767f0> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7767f0> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817afd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc7767f0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 150
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a5c0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9810aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a5c0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a5c0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a28d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a5c0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a5c0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9810afd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a5c0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a5c0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98146978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a5c0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981463c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a5c0> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981465f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a5c0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810ae48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a5c0> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a5c0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9810ab70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a5c0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a7f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a5c0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a5c0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a5c0> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a5c0> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a7f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a5c0> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a518> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a5c0> 0.0 20
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 151
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1128> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1128> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4135c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1128> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc776780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1128> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1128> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1128> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
coverage_call_count 4900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1128> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1128> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b18d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1128> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc719e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1128> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04acfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1128> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc719390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b18d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1128> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1128> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7b38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1128> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1128> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b18d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1128> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7b38> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1128> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 152
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98146b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1da0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98146ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1da0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ece48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1da0> 0.0 4
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1da0> 0.0 5
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6edc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1da0> 0.0 6
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1da0> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ecd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1da0> 0.0 8
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98146668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817ada0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1da0> 0.0 9
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1da0> 0.0 10
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811ba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1da0> 0.0 11
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1da0> 0.0 12
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1da0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98146b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817ada0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1da0> 0.0 14
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1da0> 0.0 15
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 153
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8530b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853320> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8530b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853320> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853320> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8532e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853320> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8539e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853320> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8534e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853320> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8532e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853320> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853320> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8622b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8537f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853320> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853320> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8534e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853320> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853320> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853320> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853320> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8535c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8530b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853320> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8530b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853320> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 154
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8780b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8784e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878470> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878470> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8627f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878470> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878470> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8780f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878470> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98146b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878470> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8627f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878470> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8627f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878470> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878470> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878470> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8784e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878470> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878470> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878470> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8627f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878470> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878470> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8627f0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878470> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878470> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878470> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878470> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8627f0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878470> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7354e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878470> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 155
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8536d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853dd8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98146a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853dd8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853dd8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ec4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8536d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853dd8> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc776780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853dd8> 0.0 8
Completed Iteration #7
Best Reward: 0
coverage_call_count 5000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8536d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853dd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc719780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853dd8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc776780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853dd8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98146ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853dd8> 0.0 12
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853dd8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853dd8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8536d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853dd8> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853dd8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853dd8> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853dd8> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc776780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853dd8> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 156
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817aac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bb70> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981469b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bb70> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bb70> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bb70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981466d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bb70> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981469b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bb70> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bb70> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bb70> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8625f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981469b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bb70> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817aac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bb70> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8786a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bb70> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bb70> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bb70> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bb70> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981469b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bb70> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82db38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bb70> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981466d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bb70> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bb70> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817aac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bb70> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 157
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d6d8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d6d8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83dcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d6d8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d6d8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d6d8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d6d8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d6d8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d6d8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d6d8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8782b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d588> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d6d8> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d6d8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83de10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d6d8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d6d8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83dbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d6d8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d6d8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d6d8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83de80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d6d8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 158
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cbb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb940> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb940> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83da20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb940> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8786a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb940> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb940> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb940> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb940> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb940> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04efa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb940> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc719780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb940> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98146940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82de80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb940> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83da20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb940> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb940> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb940> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8786a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb940> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8786a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb940> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82df60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb940> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb940> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb940> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 159
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146710> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146710> 0.0 4
Completed Iteration #4
Best Reward: 0
coverage_call_count 5100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146710> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146710> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf98146710> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7ef278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8626d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf98146710> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8626d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf98146710> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8789e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146710> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e56a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8626d8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf98146710> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf98146710> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf98146710> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf98146710> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf98146710> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8530b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146710> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf98146710> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bcf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf98146710> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146710> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e50b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf98146710> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 160
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b518> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38bba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b518> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b518> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b518> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b518> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b518> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b518> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39aba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b518> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b518> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b518> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b518> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b518> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b518> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b518> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83dc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b518> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 161
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e59e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e59e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e59e8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b06a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e59e8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e59e8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e59e8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e59e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e59e8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e59e8> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e59e8> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e59e8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b06a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e59e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e59e8> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b06a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e59e8> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e59e8> 0.0 16
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e59e8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 162
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc18> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38bfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc18> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc18> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc18> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc18> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38bac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc18> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc18> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc18> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e50b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc18> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05eda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc18> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc18> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc18> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc18> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc18> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc18> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc18> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc18> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 163
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
coverage_call_count 5200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cba58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b908> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b908> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b908> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b908> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b908> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b908> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b908> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b908> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b908> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b908> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b908> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cba58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b908> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b908> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b908> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b908> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b908> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878cf8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b908> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 164
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3756a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343a58> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3010f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343a58> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3010b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343a58> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375828> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343a58> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3010b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343a58> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3010f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343a58> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343a58> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343a58> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3010b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343a58> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343a58> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3017b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343a58> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3013c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3010f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343a58> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375828> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343a58> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3019e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343a58> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375828> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343a58> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3752e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343a58> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 165
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3141d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5860> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5860> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3015c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3143c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5860> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5860> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5860> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5860> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5860> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3143c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5860> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3757f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5860> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3141d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5860> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc719780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3143c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5860> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5860> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04efa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5860> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5860> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5860> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3141d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5860> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 166
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3437b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c18> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83da58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c18> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c18> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8625f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c18> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c18> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c18> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c18> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c18> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c18> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817ad30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c18> 0.0 14
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c18> 0.0 15
Completed Iteration #23
Best Reward: 0
coverage_call_count 5300
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c18> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 167
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3142b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3142b0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3147b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3437f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3142b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3142b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3437f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3142b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3142b0> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3142b0> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3142b0> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38bcc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3142b0> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3142b0> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cda58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3142b0> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3140f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3142b0> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3142b0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3437f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3142b0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3142b0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38bcc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3142b0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3142b0> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 168
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2decf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de518> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ded68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2dee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de518> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2deeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de518> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ded30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de518> 0.0 5
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de518> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de518> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2def60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de518> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de518> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de518> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de518> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de518> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de518> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdf98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de518> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de518> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de518> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de518> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2dee80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de518> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 169
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd5f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd5f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2deba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd5f8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd5f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd5f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2deba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd5f8> 0.0 7
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd5f8> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd5f8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd5f8> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39ada0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2deba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd5f8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd5f8> 0.0 12
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd5f8> 0.0 13
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd5f8> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd5f8> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2deba8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd5f8> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 170
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ede80> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ede80> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ede80> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ede80> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ede80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed4a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ede80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ede80> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ede80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ede80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ede48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ede80> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ede80> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edb00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ede80> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edbe0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ede80> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edbe0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ede80> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29be10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed4a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ede80> 0.0 16
Completed Iteration #22
Best Reward: 0
coverage_call_count 5400
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ede80> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ede80> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 171
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a92e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a98d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b400> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b400> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b400> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b400> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b400> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b400> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b400> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b400> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b400> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b400> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2bafd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b400> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b400> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a98d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b400> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b400> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b400> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a98d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b400> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 172
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2bac18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2bac50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2bac50> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2bab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2bac50> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2bac50> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2bac50> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2bac50> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2bac50> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2650b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2bac50> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2bac50> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2bac50> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2bac50> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2bab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2bac50> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2bac50> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f2e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2bac50> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2bac50> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2bac50> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f2e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2bac50> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2bac50> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 173
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2badd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24ff28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2badd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9c50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9c50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9c50> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 174
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ede80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c50> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2baac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c50> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e56d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c50> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c50> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8625f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c50> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c50> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c50> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c50> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cddd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c50> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2deac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c50> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2deac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c50> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b265630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c50> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b265668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c50> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b265860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c50> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2655c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c50> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2657b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c50> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b265eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c50> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b265748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c50> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b265da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cddd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c50> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c50> 0.0 21
Completed Iteration #22
Best Reward: 0
coverage_call_count 5500
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2baac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c50> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2655c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c50> 0.0 23
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c50> 0.0 24
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 175
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fac8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b265a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2657f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fac8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fac8> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fac8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b265128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fac8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fac8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fac8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fac8> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fac8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fac8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2138d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fac8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fac8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2279e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2271d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fac8> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fac8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fac8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fac8> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fac8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 176
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f1d0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f1d0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f358> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f1d0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f1d0> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2277b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f1d0> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f358> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f1d0> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f1d0> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8626d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f1d0> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f1d0> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2deac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f1d0> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2deac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f1d0> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2136d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2277b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f1d0> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f1d0> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2277b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f1d0> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f1d0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f358> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f1d0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f1d0> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f1d0> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f4e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f1d0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f4e0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f1d0> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 177
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdeb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdeb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdeb8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b265cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdeb8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2655f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cda90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdeb8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1535f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdeb8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2653c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b265630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdeb8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cda90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdeb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b265860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdeb8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314e10> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdeb8> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdeb8> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdeb8> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b265630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdeb8> 0.0 14
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdeb8> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdeb8> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdeb8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 178
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9630> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b265a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9630> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9630> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9630> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9630> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2baac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b265a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9630> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9630> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2137f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2136a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9630> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9f98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9630> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23fda0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9630> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9630> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9630> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9630> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9630> 0.0 15
Completed Iteration #19
Best Reward: 0
coverage_call_count 5600
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adebc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23fda0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9630> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9f98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9630> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2136a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9630> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23fda0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9630> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 179
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad840f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb6a0> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad840f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb6a0> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad846d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb6a0> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad844a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adebe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb6a0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb6a0> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb6a0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb6a0> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb6a0> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad846d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb6a0> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb6a0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad845c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb6a0> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb6a0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad840f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb6a0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb6a0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad840f0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb6a0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 180
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeba20> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeba20> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeba20> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeba20> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adebb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeba20> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeba20> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeba20> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeba20> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeba20> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeba20> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeba20> 0.0 12
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeba20> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b265c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeba20> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeba20> 0.0 15
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeba20> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeba20> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2baac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb550> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeba20> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 181
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2135f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8fa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8fa90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2135f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8fa90> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8fa90> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2135f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bb00> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 182
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48860> 0.0 2
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48860> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48860> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48860> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48860> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb93c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48860> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48860> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb93c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48860> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adebda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48860> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad489e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48860> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8fdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48860> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48860> 0.0 13
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48860> 0.0 14
Completed Iteration #17
Best Reward: 0
coverage_call_count 5700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad489e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48860> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48860> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48860> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48860> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 183
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad742e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad743c8> 0.0 2
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad747b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad743c8> 0.0 3
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad744e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad743c8> 0.0 4
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad743c8> 0.0 5
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad743c8> 0.0 6
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad609b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad743c8> 0.0 7
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad743c8> 0.0 8
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74b38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad747b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad743c8> 0.0 9
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad744e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad743c8> 0.0 10
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad609b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad743c8> 0.0 11
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad742e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad743c8> 0.0 12
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad742e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad743c8> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad747b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad743c8> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 184
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad486d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad485f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad485f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad485f8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad485f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad485f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad485f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad607b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad485f8> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad485f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad485f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad485f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad485f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad607b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad485f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad482b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad485f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb95c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad485f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad485f8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb97b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60d30> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad485f8> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad485f8> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48d68> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad485f8> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b265748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad485f8> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad485f8> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad485f8> 0.0 22
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad485f8> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 185
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84cf8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1535f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23fcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84cf8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84cf8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84cf8> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84cf8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84cf8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adebc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84cf8> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84cf8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84cf8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84cf8> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84cf8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84cf8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84cf8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84cf8> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84cf8> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23fcf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84cf8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84cf8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84cf8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84cf8> 0.0 20
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb2b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84cf8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 186
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04ef0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04ef0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04ef0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04ef0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04ef0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04ef0> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04ef0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04ef0> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04ef0> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04ef0> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc85c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc82e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04ef0> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc87b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04ef0> 0.0 13
Completed Iteration #15
Best Reward: 0
coverage_call_count 5800
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04ef0> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc82e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04ef0> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04ef0> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc82e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04ef0> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c2b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04ef0> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04ef0> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 187
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc82b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf828> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf828> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf828> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf828> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf828> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3ccf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf828> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf828> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf828> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1535f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf828> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf828> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf828> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3ce48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf828> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf828> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf828> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf828> 0.0 18
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf828> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 188
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cf28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cf28> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cf28> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cf28> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cf28> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad045f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cf28> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cf28> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2656d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cf28> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cf28> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cf28> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd320> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cf28> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cf28> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cf28> 0.0 14
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cf28> 0.0 15
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd320> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cf28> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 189
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf400> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf400> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf400> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf400> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf400> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf400> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf400> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad488d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf400> 0.0 9
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf400> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac933c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf400> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf400> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdfeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf400> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdfeb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf400> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf400> 0.0 15
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac934a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf400> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf5c0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf400> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf400> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 190
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1390> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1390> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1390> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1390> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1390> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1390> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb22e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca14a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1390> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1390> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac935c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1390> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb2710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1390> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
coverage_call_count 5900
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb2978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1390> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb2b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb20f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1390> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca14a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1390> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac933c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1390> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1390> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1390> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca19b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1390> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1390> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04ffd3be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb20f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1390> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac935f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1390> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 191
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93e80> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93e80> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac932b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93e80> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93e80> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93e80> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93e80> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93e80> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8fdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93e80> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93e80> 0.0 10
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93e80> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93e80> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f128> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93e80> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ada58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93e80> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2277b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f128> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93e80> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93e80> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93e80> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 192
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23ff98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f278> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f278> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f278> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f278> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227cf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f278> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f278> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f278> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f278> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227cf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f278> 0.0 10
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23fe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f278> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f278> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23fe80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f278> 0.0 13
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f278> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2dee48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f048> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f278> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23ff60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2dec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23ff98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f048> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f278> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f278> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac934e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f048> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f278> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 193
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227b38> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227b38> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227b38> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3756a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227b38> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3755c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227b38> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227b38> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227b38> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3015f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2def98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227b38> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3017b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227b38> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3010f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227b38> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227b38> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227b38> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3754a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227b38> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2def98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227b38> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227b38> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23fc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227b38> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227b38> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375630> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227b38> 0.0 19
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227b38> 0.0 20
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227b38> 0.0 21
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375630> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227b38> 0.0 22
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 194
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b6d8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b6d8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b6d8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b6d8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b6d8> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b6d8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b6d8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b6d8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
coverage_call_count 6000
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39ae80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b6d8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b6d8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39ae80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b6d8> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b6d8> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b6d8> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38be48> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b6d8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3430b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b6d8> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b6d8> 0.0 17
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b6d8> 0.0 18
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 195
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2def98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bf28> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ded30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bf28> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3757b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3010f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bf28> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2275f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bf28> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bf28> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ded30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bf28> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ded30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bf28> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bf28> 0.0 9
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bf28> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bf28> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23fe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bf28> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bf28> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bf28> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bf28> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23fe10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bf28> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ade10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bf28> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac938d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bf28> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bf28> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 196
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38b898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3015f8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3015f8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3015f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3015f8> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2deb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3015f8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3015f8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23fef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3015f8> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3015f8> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3015f8> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23fef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3015f8> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b08d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3015f8> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39aa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3015f8> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39aa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3015f8> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3015f8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3015f8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3015f8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82dfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23fef0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3015f8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8fd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3015f8> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 197
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82dcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82dc88> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82dc88> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82dc88> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cbeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82dc88> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cbf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82dc88> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cbf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82dc88> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb0b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82dc88> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82dc88> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d0f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82dc88> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b05f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82dc88> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d7b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82dc88> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d7b8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82dc88> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d7b8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82dc88> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac932b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82dc88> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82dc88> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82dc88> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 198
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8787b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0b00> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0b00> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0b00> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cbf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0b00> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cbef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0b00> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0b00> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82dda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b668> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0b00> 0.0 8
Completed Iteration #8
Best Reward: 0
coverage_call_count 6100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca1b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0b00> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0b00> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0b00> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b38bdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0b00> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39af28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878ef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0b00> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0b00> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811b668> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0b00> 0.0 15
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0b00> 0.0 16
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 199
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ade10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac932b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f128> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2dee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2def60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b301c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3759e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bef0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 17
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cbcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93160> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39ab00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39ab00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 22
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cb320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b09b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 23
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 200
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8784e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878080> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878080> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878080> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878080> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878080> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878080> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878080> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8780f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878080> 0.0 9
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878080> 0.0 10
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878080> 0.0 11
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98146f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878080> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98146cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878080> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2dec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878080> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878080> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878080> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98146be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878080> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878080> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878080> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 201
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04efba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2dd8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2dd8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04efdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2dd8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04efa58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2dd8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2dd8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04efba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2dd8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04effd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2dd8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04efa58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2dd8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8530b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2dd8> 0.0 10
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2dd8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8622b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2dd8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2dd8> 0.0 13
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817ab38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2dd8> 0.0 14
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2dd8> 0.0 15
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817aa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2dd8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0a58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2dd8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8625f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2dd8> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8622e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04efba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2dd8> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a160> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2dd8> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a160> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2dd8> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 202
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8620b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8620b8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98146198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8620b8> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98146240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8620b8> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8620b8> 0.0 6
Completed Iteration #4
Best Reward: 0
coverage_call_count 6200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39acf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8620b8> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cbb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8620b8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7aca15f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8620b8> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8620b8> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8620b8> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad9b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8620b8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad9b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8620b8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186ad9b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8620b8> 0.0 14
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8620b8> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8620b8> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8620b8> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39acf8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8620b8> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ade10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8620b8> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8620b8> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39acf8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8620b8> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 203
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2deac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8f5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b09b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b09b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 7
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981463c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 8
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b710> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 9
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 10
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 11
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b710> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b09b0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 13
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981463c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b710> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981463c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98636dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29b710> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 19
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98146208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2de6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ed7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b09b0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 204
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7354e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735f60> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc735f60> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735f60> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b10b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735f60> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735f60> 0.0 6
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6408d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735f60> 0.0 7
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efcf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbda90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735f60> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc735f60> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8627b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735f60> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc735f60> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc735f60> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc735f60> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6408d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc735f60> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b10b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc735f60> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735fd0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc735f60> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc735f60> 0.0 17
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7c4f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735f60> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 205
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7199e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488518> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488518> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc776780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488518> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6adcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6adf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488518> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7190b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488518> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01879ca20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6adf28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488518> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66ffd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488518> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488518> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc640f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6adf28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488518> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66ffd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488518> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186dfa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488518> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488518> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1537b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc640a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488518> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98636550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd7b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc735b00> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488518> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986368d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488518> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488518> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc735390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488518> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7efc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488518> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 206
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1a58> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1a58> 0.0 3
Completed Iteration #1
Best Reward: 0
coverage_call_count 6300
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1a58> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1a58> 0.0 5
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a00f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1a58> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7767f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1a58> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1a58> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1a58> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1a58> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1a58> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1a58> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1a58> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2dee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1a58> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1a58> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2def60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1a58> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0940> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1a58> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93a90> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1a58> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1a58> 0.0 19
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0940> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1a58> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8782b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1a58> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 207
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8620b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3756a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc50> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b375940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc50> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc50> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b39a748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc50> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc50> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc50> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3756a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc50> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3756a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc50> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc50> 0.0 10
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3756a0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc50> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc50> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186855f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc50> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc50> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff41355f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc50> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff41355f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc50> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e2b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc50> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b82d550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186859e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc50> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9811bc50> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 208
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6d30> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6d30> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe04de4a518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6d30> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6ef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6d30> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6d30> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6d30> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0415f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0417f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6d30> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec041d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0417f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6d30> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a05c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6d30> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fea58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ea58> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6d30> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec041550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6d30> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec041550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6d30> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec041550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6d30> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187605c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74e3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6d30> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a1da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0417f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6d30> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fec50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec041e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6d30> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc74ea58> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6d30> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 209
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f65c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186859b0> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e12b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186859b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186859b0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05ef98> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186859b0> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05ef98> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186859b0> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e12b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186859b0> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23feb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186859b0> 0.0 8
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc735940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186859b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186859b0> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8533c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186859b0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186859b0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40fe358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8533c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186859b0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05eb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862dd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186859b0> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec041ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05ef98> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fe0186859b0> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f65c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186859b0> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b343278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3cba90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862dd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186859b0> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23feb8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186859b0> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
coverage_call_count 6400
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 210
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b8782b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2deb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a20b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ad358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 5
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc776b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 6
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40abb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc776b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a15c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981a2828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 12
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 13
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 14
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01876add8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 15
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1d30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 16
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 17
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec093080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0d68> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 18
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0934e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93d30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 19
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc701588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b0b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 20
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7015f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc776b70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 21
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc701518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 22
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc699198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93fd0> 0.0 23
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 211
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4128> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4025cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4128> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc719320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4128> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4128> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01876af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4128> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4128> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6f28> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4128> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec093470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0930f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4128> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40252b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a04e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4128> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec034518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40257b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4128> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec034fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6f28> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4128> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4069c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722780> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4128> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4069828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722780> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4128> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4080978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0930f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4128> 0.0 15
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4080cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4128> 0.0 16
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc701630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0930f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4128> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4080cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec034860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4128> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40cdf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4128> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 212
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd5f8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec06bcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd5f8> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd5f8> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec06beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd5f8> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410ae10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd5f8> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410ae48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b8d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd5f8> 0.0 7
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410a898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cf28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd5f8> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410a5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd5f8> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4069c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b0f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd5f8> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4025f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd5f8> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4080dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4091240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd5f8> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec034160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4080ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd5f8> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd5f8> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd5f8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6997f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b8d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd5f8> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4025d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4025c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd5f8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40808d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4091240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd5f8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 213
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec06b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cde48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b14a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981b16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7220f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4069cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ac93668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cde48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3b0518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4069cc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 13
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0187609e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 15
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4069cc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9817a048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 17
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ef940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab438> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 18
Completed Iteration #20
Best Reward: 0
coverage_call_count 6500
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad8fcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 19
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab438> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 20
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b29bef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7220f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cc18> 0.0 21
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 214
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01876a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a20b8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a20b8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec041ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a20b8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0416a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853940> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981a20b8> 0.0 5
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7013c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a20b8> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec079128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981a20b8> 0.0 7
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec093f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40919e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a20b8> 0.0 8
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093080> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981a20b8> 0.0 9
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec034a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec093080> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf981a20b8> 0.0 10
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40cddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec05e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b853940> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981a20b8> 0.0 11
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3756a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf153828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981a20b8> 0.0 12
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40919e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981a20b8> 0.0 13
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01876a160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981a20b8> 0.0 14
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0792e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40919e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981a20b8> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff40919e8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf981a20b8> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 215
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d50f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5a20> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfb38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5a20> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05ef98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5a20> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfe10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a00b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5a20> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5a20> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404d4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5a20> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404df98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5a20> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40569b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfb38> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5a20> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfe48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5a20> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d50f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5a20> 0.0 11
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5a20> 0.0 12
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfb38> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5a20> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4035748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5a20> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40566a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5a20> 0.0 15
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfe80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5a20> 0.0 16
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4035710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5748> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5a20> 0.0 17
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4035828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d470> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5a20> 0.0 18
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5748> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5a20> 0.0 19
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d50f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5a20> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 216
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40351d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d240> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d240> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d240> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec079208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40351d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404d240> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2dee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0797b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d240> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40356d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d240> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035da0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404d240> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfc88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d240> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d240> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec05ee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b278> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404d240> 0.0 11
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035da0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff404d240> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049b278> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff404d240> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0416a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40351d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdff404d240> 0.0 14
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6f6b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404de80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d240> 0.0 15
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404d240> 0.0 16
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff404de80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdff404d240> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 217
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227ba8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986a0d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc722080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227ba8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227ba8> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b878898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227ba8> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227ba8> 0.0 6
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec034a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227ba8> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227ba8> 0.0 8
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40cd128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc76cba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227ba8> 0.0 9
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227ba8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fbd710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab5f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227ba8> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227ba8> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05609e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff410aa90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227ba8> 0.0 13
Completed Iteration #17
Best Reward: 0
coverage_call_count 6600
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05606d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035400> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227ba8> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054ea20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab5f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227ba8> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227ba8> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40cddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab5f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227ba8> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054ed30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40ab5f8> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227ba8> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f90f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b227ba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 218
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9630> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfdd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9630> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9630> 0.0 4
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e256a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9630> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9630> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05603c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9630> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05603c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9630> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfdd8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9630> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe0186ee4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9630> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05cee80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9630> 0.0 11
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05ce6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9630> 0.0 12
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414ac50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9630> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414ac50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9630> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05603c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9630> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4035e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9630> 0.0 16
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec034b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9630> 0.0 17
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfdd8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9630> 0.0 18
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9978> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9630> 0.0 19
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9630> 0.0 20
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035c88> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9630> 0.0 21
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 219
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e402b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9eb8> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9eb8> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40240> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9eb8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05387b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9eb8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05382e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9eb8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9eb8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7433c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b94a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9eb8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05382e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9eb8> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1430b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c92b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9eb8> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01877f668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05387b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9eb8> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05387b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9eb8> 0.0 12
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9eb8> 0.0 13
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e408d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40240> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9eb8> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9eb8> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc743160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40240> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9eb8> 0.0 16
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e403c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05382e8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9eb8> 0.0 17
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 220
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1f0c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186eee48> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186eee48> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff414a710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186eee48> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f94e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186eee48> 0.0 5
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0538400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186eee48> 0.0 6
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054ea90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186eee48> 0.0 7
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff410ad68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186eee48> 0.0 8
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b23f240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9c88> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186eee48> 0.0 9
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0586908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186eee48> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186eee48> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9780> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186eee48> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc76c390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e1d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fe0186eee48> 0.0 13
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec06bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e1d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fe0186eee48> 0.0 14
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 221
found coverage increase 0
Current Total Coverage 69.08396946564885
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa054e780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034b70> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40f4f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05606d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034b70> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034fd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec034b70> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40917b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034b70> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4035e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034b70> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff41355f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034b70> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018685400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034b70> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3756a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056518> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec034b70> 0.0 9
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034fd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec034b70> 0.0 10
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff404d0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05606d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec034b70> 0.0 11
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0a0ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034b70> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4035b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff40917b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec034b70> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0488390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7898> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec034b70> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfec034b70> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e40c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4056518> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec034b70> 0.0 16
Completed Iteration #20
Best Reward: 0
coverage_call_count 6700
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec079128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034b70> 0.0 17
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec041160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1a7898> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec034b70> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05606d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfec034b70> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec034fd0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdfec034b70> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 222
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0d5cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25710> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049be48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25710> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40b6d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a10f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25710> 0.0 4
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e15780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25710> 0.0 5
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25710> 0.0 6
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25710> 0.0 7
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25710> 0.0 8
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a10f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25710> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a16d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa049be48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25710> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25710> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528f60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25710> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bfc18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25710> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601ef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25710> 0.0 14
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9b00> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25710> 0.0 15
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528f60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25710> 0.0 16
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1160> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25710> 0.0 17
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25710> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce5c0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25710> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 223
found coverage increase 0
Current Total Coverage 69.08396946564885
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186714a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 0.0 2
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018671198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186714a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98601240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fc50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fc50> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 0.0 7
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98676400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186714a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98676668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01876a160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186714a8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3017b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec0bf978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018685400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 0.0 12
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fe5c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 0.0 13
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981b1c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fc50> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 0.0 14
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdff40e5278> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699668> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 0.3816793893129926 15
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc776b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699668> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 0.3816793893129926 16
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfec06bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe018699668> 0.3816793893129926 5
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 0.3816793893129926 17
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc722780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f4e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 0.3816793893129926 18
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 0.7633587786259852 19
Completed Iteration #24
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdfa05b9588> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 1.1450381679389778 20
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #0
root
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 1.1450381679389778 21
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9c88> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 1.5267175572519704 22
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdff40919e8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560630> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9c88> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 1.908396946564963 23
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 1.908396946564963 7
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 2.2900763358779557 24
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f550> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560630> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9c88> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 2.2900763358779557 8
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 2.6717557251909483 25
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 2.2900763358779557 9
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 2.6717557251909483 26
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf98601278> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 2.6717557251909483 8
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 2.6717557251909483 10
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 3.053435114503941 27
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a1550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 2.6717557251909483 11
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 3.053435114503941 28
Completed Iteration #18
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdfa05717b8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8438> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 3.053435114503941 9
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 3.053435114503941 12
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 3.4351145038169335 29
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986769b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98676748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05717b8> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8438> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 3.053435114503941 10
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 3.053435114503941 13
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 3.4351145038169335 30
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdff40cddd8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 3.4351145038169335 14
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 3.816793893129926 31
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdff4080160> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 3.816793893129926 15
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 4.198473282442919 32
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #1
root->5
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfaf143d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05717b8> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8438> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 3.053435114503941 11
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 3.816793893129926 16
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 4.198473282442919 33
Completed Iteration #0
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe018699860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 2.2900763358779557 8
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 3.053435114503941 12
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 3.816793893129926 17
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 4.198473282442919 34
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fda0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 2.6717557251909483 9
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 3.4351145038169335 13
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 4.198473282442919 18
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 4.580152671755911 35
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528550> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98601080> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 3.816793893129926 14
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 4.580152671755911 19
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 4.961832061068904 36
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce208> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528748> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fda0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 3.053435114503941 10
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 4.198473282442919 15
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 4.961832061068904 20
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 5.343511450381897 37
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98601080> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 4.198473282442919 16
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 4.961832061068904 21
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 5.343511450381897 38
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf98676278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 4.198473282442919 17
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 4.961832061068904 22
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 5.343511450381897 39
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198be0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98601080> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 4.580152671755911 18
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 5.343511450381897 23
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 5.725190839694889 40
Completed Iteration #15
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdffc77eda0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4080> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 4.961832061068904 19
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 5.725190839694889 24
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 6.106870229007882 41
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
coverage_call_count 6800
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf981cbb38> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ddf60> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc77eda0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4080> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 5.343511450381897 20
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 6.106870229007882 25
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 6.488549618320874 42
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 5.343511450381897 21
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 6.106870229007882 26
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 6.488549618320874 43
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #2
root->5->2
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 3.4351145038169335 11
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 5.725190839694889 22
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 6.488549618320874 27
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 6.870229007633867 44
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fe04de564e0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd2b0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 3.816793893129926 12
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 6.106870229007882 23
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 6.870229007633867 28
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 7.25190839694686 45
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce518> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9550> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de564e0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd2b0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 4.198473282442919 13
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 6.488549618320874 24
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 7.25190839694686 29
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 7.633587786259852 46
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f1d0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98601860> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fda0> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 4.580152671755911 14
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 6.870229007633867 25
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 7.633587786259852 30
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 8.015267175572845 47
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf986b4860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf198358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f550> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa0560630> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9c88> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 4.580152671755911 15
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 6.870229007633867 26
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 7.633587786259852 31
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 8.015267175572845 48
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 4.580152671755911 16
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 6.870229007633867 27
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 7.633587786259852 32
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 8.015267175572845 49
Completed Iteration #18
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdfa0571e80> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd588> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9c88> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 4.961832061068904 17
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 7.25190839694686 28
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 8.015267175572845 33
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 8.396946564885837 50
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 4.961832061068904 18
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 7.25190839694686 29
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 8.015267175572845 34
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 8.396946564885837 51
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fe01874fa58> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdfaf1989b0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf98601278> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 5.343511450381897 19
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 7.633587786259852 30
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 8.396946564885837 35
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 8.77862595419883 52
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa2e25b70> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 5.343511450381897 20
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 7.633587786259852 31
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 8.396946564885837 36
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 8.77862595419883 53
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad748d0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd2b0> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 5.725190839694889 21
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 8.015267175572845 32
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 8.77862595419883 37
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 9.160305343511823 54
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #3
root->5->2->0
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874fa20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad741d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe04de564e0> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd2b0> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 5.725190839694889 22
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 8.015267175572845 33
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 8.77862595419883 38
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 9.160305343511823 55
Completed Iteration #0
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd630> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a668> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad748d0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd2b0> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 1.908396946564963 7
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 6.106870229007882 23
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 8.396946564885837 34
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 9.160305343511823 39
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 9.541984732824815 56
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc7e1c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe0186859e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 1.908396946564963 8
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 6.106870229007882 24
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 8.396946564885837 35
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 9.160305343511823 40
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 9.541984732824815 57
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8c18> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a630> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 2.2900763358779557 9
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 6.488549618320874 25
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 8.77862595419883 36
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 9.541984732824815 41
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 9.923664122137808 58
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fe01874fda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9865f128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4ff8c18> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a630> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 2.2900763358779557 10
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 6.488549618320874 26
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 8.77862595419883 37
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 9.541984732824815 42
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 9.923664122137808 59
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7b862748> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a630> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 2.6717557251909483 11
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 6.870229007633867 27
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 9.160305343511823 38
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 9.923664122137808 43
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 10.3053435114508 60
Completed Iteration #7
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9862acc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd2b0> 1.5267175572519704 7
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 2.6717557251909483 12
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 6.870229007633867 28
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 9.160305343511823 39
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 9.923664122137808 44
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 10.3053435114508 61
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981ddd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a630> 0.7633587786259852 5
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 2.6717557251909483 13
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 6.870229007633867 29
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 9.160305343511823 40
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 9.923664122137808 45
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 10.3053435114508 62
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdffc7a15c0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a668> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad748d0> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd2b0> 1.908396946564963 8
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 3.053435114503941 14
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 7.25190839694686 30
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 9.541984732824815 41
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 10.3053435114508 46
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 10.687022900763793 63
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74748> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 3.4351145038169335 15
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 7.633587786259852 31
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 9.923664122137808 42
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 10.687022900763793 47
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 11.068702290076786 64
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdffc799828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd2b0> 1.908396946564963 9
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 3.4351145038169335 16
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 7.633587786259852 32
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 9.923664122137808 43
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 10.687022900763793 48
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 11.068702290076786 65
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213cc0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a630> 1.1450381679389778 6
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 3.816793893129926 17
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 8.015267175572845 33
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 10.3053435114508 44
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 11.068702290076786 49
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 11.450381679389778 66
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9a20> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9390> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74748> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 4.198473282442919 18
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 8.396946564885837 34
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 10.687022900763793 45
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 11.450381679389778 50
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 11.832061068702771 67
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb99e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213cc0> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a630> 1.1450381679389778 7
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 4.198473282442919 19
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 8.396946564885837 35
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 10.687022900763793 46
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 11.450381679389778 51
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 11.832061068702771 68
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdffc699198> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04acef0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce518> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdfa05f9550> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fe04de564e0> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd2b0> 2.2900763358779557 10
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 4.580152671755911 20
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 8.77862595419883 36
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 11.068702290076786 47
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 11.832061068702771 52
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 12.213740458015764 69
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff40693c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fe01874f390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213cc0> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a630> 1.1450381679389778 8
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 4.580152671755911 21
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 8.77862595419883 37
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 11.068702290076786 48
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 11.832061068702771 53
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 12.213740458015764 70
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #4
root->5->2->0->12
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf986018d0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9390> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74748> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 4.961832061068904 22
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 9.160305343511823 38
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 11.450381679389778 49
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 12.213740458015764 54
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 12.595419847328756 71
Completed Iteration #0
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 5.343511450381897 23
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 9.541984732824815 39
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 11.832061068702771 50
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 12.595419847328756 55
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 12.977099236641749 72
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb91d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9a20> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9390> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74748> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 5.343511450381897 24
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 9.541984732824815 40
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 11.832061068702771 51
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 12.595419847328756 56
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 12.977099236641749 73
Completed Iteration #3
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213128> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 1.908396946564963 7
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 5.725190839694889 25
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 9.923664122137808 41
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 12.213740458015764 52
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 12.977099236641749 57
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 13.358778625954741 74
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf981ddf98> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 2.2900763358779557 8
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 6.106870229007882 26
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 10.3053435114508 42
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 12.595419847328756 53
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 13.358778625954741 58
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 13.740458015267734 75
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdfa05df080> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 2.6717557251909483 9
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 6.488549618320874 27
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 10.687022900763793 43
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 12.977099236641749 54
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 13.740458015267734 59
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 14.122137404580727 76
Completed Iteration #7
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ddf98> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 2.6717557251909483 10
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 6.488549618320874 28
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 10.687022900763793 44
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 12.977099236641749 55
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 13.740458015267734 60
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 14.122137404580727 77
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314668> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314940> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf986018d0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9390> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74748> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 3.053435114503941 11
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 6.870229007633867 29
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 11.068702290076786 45
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 13.358778625954741 56
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 14.122137404580727 61
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 14.50381679389372 78
Completed Iteration #10
Best Reward: 0.3816793893129926
Completed Iteration #11
Best Reward: 0.3816793893129926
Completed Iteration #12
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314d30> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 3.4351145038169335 12
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 7.25190839694686 30
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 11.450381679389778 46
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 13.740458015267734 57
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 14.50381679389372 62
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 14.885496183206712 79
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf981cbd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf981ddc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314d30> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 3.4351145038169335 13
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 7.25190839694686 31
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 11.450381679389778 47
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 13.740458015267734 58
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 14.50381679389372 63
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 14.885496183206712 80
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf981dd198> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314e80> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74748> 1.908396946564963 7
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 3.816793893129926 14
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 7.633587786259852 32
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 11.832061068702771 48
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 14.122137404580727 59
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 14.885496183206712 64
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 15.267175572519704 81
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad742e8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04acba8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 4.198473282442919 15
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 8.015267175572845 33
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 12.213740458015764 49
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 14.50381679389372 60
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 15.267175572519704 65
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 15.648854961832697 82
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #5
root->5->2->0->12->2
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf9810ae80> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a7b8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 4.580152671755911 16
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 8.396946564885837 34
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 12.595419847328756 50
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 14.885496183206712 61
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 15.648854961832697 66
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 16.03053435114569 83
Completed Iteration #1
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9810aeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810af60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810ae80> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a7b8> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 4.580152671755911 17
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 8.396946564885837 35
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 12.595419847328756 51
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 14.885496183206712 62
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 15.648854961832697 67
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 16.03053435114569 84
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 1.5267175572519704 7
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 4.580152671755911 18
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 8.396946564885837 36
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 12.595419847328756 52
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 14.885496183206712 63
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 15.648854961832697 68
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 16.03053435114569 85
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fe10> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 1.908396946564963 8
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 4.961832061068904 19
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 8.77862595419883 37
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 12.977099236641749 53
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 15.267175572519704 64
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 16.03053435114569 69
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 16.412213740458682 86
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd9e8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 2.2900763358779557 9
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 5.343511450381897 20
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 9.160305343511823 38
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 13.358778625954741 54
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 15.648854961832697 65
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 16.412213740458682 70
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 16.793893129771675 87
Completed Iteration #12
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdfef0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdcc0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213128> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 1.5267175572519704 6
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 2.6717557251909483 10
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 5.725190839694889 21
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 9.541984732824815 39
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 13.740458015267734 55
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 16.03053435114569 66
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 16.793893129771675 71
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 17.175572519084668 88
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9860> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a1d0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 3.053435114503941 11
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 6.106870229007882 22
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 9.923664122137808 40
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 14.122137404580727 56
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 16.412213740458682 67
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 17.175572519084668 72
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 17.55725190839766 89
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a0f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04acba8> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 3.053435114503941 12
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 6.106870229007882 23
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 9.923664122137808 41
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 14.122137404580727 57
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 16.412213740458682 68
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 17.175572519084668 73
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 17.55725190839766 90
Completed Iteration #15
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf9810aef0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74518> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 3.4351145038169335 13
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 6.488549618320874 24
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 10.3053435114508 42
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 14.50381679389372 58
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 16.793893129771675 69
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 17.55725190839766 74
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 17.938931297710653 91
Completed Iteration #16
Best Reward: 0.3816793893129926
coverage_call_count 6900
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdfa04acba8> 0.3816793893129926 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 3.4351145038169335 14
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 6.488549618320874 25
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 10.3053435114508 43
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 14.50381679389372 59
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 16.793893129771675 70
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 17.55725190839766 75
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 17.938931297710653 92
Completed Iteration #17
Best Reward: 0.3816793893129926
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf9810aa20> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213c18> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810aef0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74518> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 3.816793893129926 15
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 6.870229007633867 26
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 10.687022900763793 44
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 14.885496183206712 60
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 17.175572519084668 71
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 17.938931297710653 76
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 18.320610687023645 93
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd6a0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd588> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fe10> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 1.908396946564963 7
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 4.198473282442919 16
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 7.25190839694686 27
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 11.068702290076786 45
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 15.267175572519704 61
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 17.55725190839766 72
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 18.320610687023645 77
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 18.702290076336638 94
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #6
root->5->2->0->12->2->16
Best Reward: 0.3816793893129926
Completed Iteration #0
Best Reward: 0.3816793893129926
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f128> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdfb70> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213128> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 2.2900763358779557 8
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 4.580152671755911 17
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 7.633587786259852 28
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 11.450381679389778 46
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 15.648854961832697 62
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 17.938931297710653 73
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 18.702290076336638 78
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 19.08396946564963 95
Completed Iteration #3
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60be0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad609e8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd9e8> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 2.6717557251909483 9
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 4.961832061068904 18
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 8.015267175572845 29
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 11.832061068702771 47
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 16.03053435114569 63
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 18.320610687023645 74
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 19.08396946564963 79
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 19.465648854962623 96
Completed Iteration #4
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60358> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad609e8> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd9e8> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 2.6717557251909483 10
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 4.961832061068904 19
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 8.015267175572845 30
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 11.832061068702771 48
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 16.03053435114569 64
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 18.320610687023645 75
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 19.08396946564963 80
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 19.465648854962623 97
Completed Iteration #5
Best Reward: 0.3816793893129926
Completed Iteration #6
Best Reward: 0.3816793893129926
Completed Iteration #7
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf9810aa90> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a198> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fe10> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 3.053435114503941 11
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 5.343511450381897 20
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 8.396946564885837 31
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 12.213740458015764 49
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 16.412213740458682 65
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 18.702290076336638 76
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 19.465648854962623 81
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 19.847328244275616 98
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa0528978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 3.053435114503941 12
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 5.343511450381897 21
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 8.396946564885837 32
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 12.213740458015764 50
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 16.412213740458682 66
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 18.702290076336638 77
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 19.465648854962623 82
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 19.847328244275616 99
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fe10> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 3.053435114503941 13
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 5.343511450381897 22
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 8.396946564885837 33
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 12.213740458015764 51
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 16.412213740458682 67
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 18.702290076336638 78
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 19.465648854962623 83
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 19.847328244275616 100
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fe10> 1.1450381679389778 6
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 3.053435114503941 14
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 5.343511450381897 23
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 8.396946564885837 34
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 12.213740458015764 52
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 16.412213740458682 68
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 18.702290076336638 79
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 19.465648854962623 84
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 19.847328244275616 101
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad603c8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd588> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fe10> 1.5267175572519704 7
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 3.4351145038169335 15
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 5.725190839694889 24
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 8.77862595419883 35
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 12.595419847328756 53
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 16.793893129771675 69
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 19.08396946564963 80
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 19.847328244275616 85
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 20.22900763358861 102
Completed Iteration #14
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60b38> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad609e8> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd9e8> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 3.816793893129926 16
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 6.106870229007882 25
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 9.160305343511823 36
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 12.977099236641749 54
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 17.175572519084668 70
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 19.465648854962623 81
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 20.22900763358861 86
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 20.6106870229016 103
Completed Iteration #15
Best Reward: 0.3816793893129926
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdfd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a198> 0.3816793893129926 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fe10> 1.5267175572519704 8
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 3.816793893129926 17
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 6.106870229007882 26
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 9.160305343511823 37
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 12.977099236641749 55
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 17.175572519084668 71
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 19.465648854962623 82
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 20.22900763358861 87
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 20.6106870229016 104
Completed Iteration #18
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad606d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd588> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fe10> 1.5267175572519704 9
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 3.816793893129926 18
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 6.106870229007882 27
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 9.160305343511823 38
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 12.977099236641749 56
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 17.175572519084668 72
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 19.465648854962623 83
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 20.22900763358861 88
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 20.6106870229016 105
Completed Iteration #19
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa04ac390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd588> 0.7633587786259852 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fe10> 1.5267175572519704 10
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 3.816793893129926 19
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 6.106870229007882 28
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 9.160305343511823 39
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 12.977099236641749 57
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 17.175572519084668 73
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 19.465648854962623 84
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 20.22900763358861 89
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 20.6106870229016 106
Completed Iteration #20
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd14e0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9f98> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213128> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 4.198473282442919 20
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 6.488549618320874 29
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 9.541984732824815 40
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 13.358778625954741 58
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 17.55725190839766 74
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 19.847328244275616 85
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 20.6106870229016 90
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 20.992366412214594 107
Completed Iteration #21
Best Reward: 0.3816793893129926
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #7
root->5->2->0->12->2->16->1
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9160> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd470> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd14e0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9f98> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213128> 1.908396946564963 6
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 4.580152671755911 21
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 6.870229007633867 30
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 9.923664122137808 41
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 13.740458015267734 59
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 17.938931297710653 75
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 20.22900763358861 86
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 20.992366412214594 91
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 21.374045801527586 108
Completed Iteration #0
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f320> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60b70> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f128> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdfb70> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213128> 2.2900763358779557 7
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 4.961832061068904 22
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 7.25190839694686 31
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 10.3053435114508 42
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 14.122137404580727 60
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 18.320610687023645 76
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 20.6106870229016 87
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 21.374045801527586 92
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 21.75572519084058 109
Completed Iteration #1
Best Reward: 0.3816793893129926
Completed Iteration #2
Best Reward: 0.3816793893129926
Completed Iteration #3
Best Reward: 0.3816793893129926
Completed Iteration #4
Best Reward: 0.3816793893129926
Completed Iteration #5
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d198> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83db38> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213128> 2.6717557251909483 8
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 5.343511450381897 23
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 7.633587786259852 32
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 10.687022900763793 43
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 14.50381679389372 61
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 18.702290076336638 77
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 20.992366412214594 88
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 21.75572519084058 93
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 22.13740458015357 110
Completed Iteration #6
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74da0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60b70> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f128> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdfb70> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213128> 3.053435114503941 9
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 5.725190839694889 24
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 8.015267175572845 33
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 11.068702290076786 44
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 14.885496183206712 62
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 19.08396946564963 78
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 21.374045801527586 89
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 22.13740458015357 94
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 22.519083969466564 111
Completed Iteration #7
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7b265550> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83db38> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213128> 3.4351145038169335 10
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 6.106870229007882 25
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 8.396946564885837 34
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 11.450381679389778 45
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 15.267175572519704 63
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 19.465648854962623 79
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 21.75572519084058 90
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 22.519083969466564 95
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 22.900763358779557 112
Completed Iteration #8
Best Reward: 0.3816793893129926
Completed Iteration #9
Best Reward: 0.3816793893129926
Completed Iteration #10
Best Reward: 0.3816793893129926
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd14e0> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9f98> 0.7633587786259852 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213128> 3.4351145038169335 11
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 6.106870229007882 26
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 8.396946564885837 35
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 11.450381679389778 46
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 15.267175572519704 64
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 19.465648854962623 80
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 21.75572519084058 91
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 22.519083969466564 96
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 22.900763358779557 113
Completed Iteration #11
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba5f8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdfb70> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213128> 3.816793893129926 12
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 6.488549618320874 27
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 8.77862595419883 36
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 11.832061068702771 47
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 15.648854961832697 65
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 19.847328244275616 81
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 22.13740458015357 92
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 22.900763358779557 97
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 23.28244274809255 114
Completed Iteration #12
Best Reward: 0.3816793893129926
Completed Iteration #13
Best Reward: 0.3816793893129926
Completed Iteration #14
Best Reward: 0.3816793893129926
Completed Iteration #15
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60588> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83db38> 1.1450381679389778 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213128> 4.198473282442919 13
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 6.870229007633867 28
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 9.160305343511823 37
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 12.213740458015764 48
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 16.03053435114569 66
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 20.22900763358861 82
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 22.519083969466564 93
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 23.28244274809255 98
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 23.664122137405542 115
Completed Iteration #16
Best Reward: 0.3816793893129926
Completed Iteration #17
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf9810a5f8> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adb9f98> 1.1450381679389778 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213128> 4.580152671755911 14
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 7.25190839694686 29
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 9.541984732824815 38
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 12.595419847328756 49
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 16.412213740458682 67
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 20.6106870229016 83
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 22.900763358779557 94
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 23.664122137405542 99
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 24.045801526718535 116
Completed Iteration #18
Best Reward: 0.3816793893129926
Completed Iteration #19
Best Reward: 0.3816793893129926
Completed Iteration #20
Best Reward: 0.3816793893129926
Completed Iteration #21
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2650f0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83db38> 1.5267175572519704 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213128> 4.961832061068904 15
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 7.633587786259852 30
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 9.923664122137808 39
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 12.977099236641749 50
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 16.793893129771675 68
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 20.992366412214594 84
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 23.28244274809255 95
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 24.045801526718535 100
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 24.427480916031527 117
Completed Iteration #22
Best Reward: 0.3816793893129926
Completed Iteration #23
Best Reward: 0.3816793893129926
Reward: 0.3816793893129926
backprop <src.mcts.MCTS_Node object at 0x7fdf7b314390> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83dbe0> 0.3816793893129926 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdfef0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cdcc0> 0.7633587786259852 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213128> 5.343511450381897 16
backprop <src.mcts.MCTS_Node object at 0x7fdf7b213400> 8.015267175572845 31
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74f60> 10.3053435114508 40
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad74080> 13.358778625954741 51
backprop <src.mcts.MCTS_Node object at 0x7fdf9862a240> 17.175572519084668 69
backprop <src.mcts.MCTS_Node object at 0x7fdff414a080> 21.374045801527586 85
backprop <src.mcts.MCTS_Node object at 0x7fdffc66f780> 23.664122137405542 96
backprop <src.mcts.MCTS_Node object at 0x7fdfa04c9550> 24.427480916031527 101
backprop <src.mcts.MCTS_Node object at 0x7fdf9865fd68> 24.80916030534452 118
Completed Iteration #24
Best Reward: 0.3816793893129926
Completed Iteration #25
Best Reward: 0.3816793893129926
Completed MCTS Level/Depth: #8
root->5->2->0->12->2->16->1->4
Best Reward: 0.3816793893129926
iteration: 224
found coverage increase 0.3816793893129926
Current Total Coverage 69.46564885496184
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9be0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9828> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9828> 0.0 3
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48080> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9828> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2651d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9828> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48dd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9be0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9828> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9828> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9828> 0.0 8
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9828> 0.0 9
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9be0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9828> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed2b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48080> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9828> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48f28> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9828> 0.0 12
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edcc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9828> 0.0 13
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05606d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdffc6ce828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9be0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9828> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9be0> 0.0 6
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9828> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83db00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9828> 0.0 16
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf9810ad30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9be0> 0.0 7
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9828> 0.0 17
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad489e8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9e80> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9828> 0.0 18
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b265160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9828> 0.0 19
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 225
found coverage increase 0
Current Total Coverage 69.46564885496184
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdfe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad485f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad482b0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83def0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad482b0> 0.0 3
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed2e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad482b0> 0.0 4
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad482b0> 0.0 5
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad482b0> 0.0 6
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a97b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad482b0> 0.0 7
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad047f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad482b0> 0.0 8
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad046d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad482b0> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad482b0> 0.0 10
Completed Iteration #13
Best Reward: 0
coverage_call_count 7000
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e52e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83df60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad482b0> 0.0 11
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad046d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad482b0> 0.0 12
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edb70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad482b0> 0.0 13
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adebd68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83df60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad482b0> 0.0 14
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad482b0> 0.0 15
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edb70> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad482b0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 226
found coverage increase 0
Current Total Coverage 69.46564885496184
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb9e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04940> 0.0 2
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84b38> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adebba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04940> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04940> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04940> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04940> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e57f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04940> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e52b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04940> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfa05606d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adebba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04940> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84588> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04940> 0.0 10
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e52b0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04940> 0.0 11
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04940> 0.0 12
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdfb49a17b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04940> 0.0 13
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad040f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84588> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04940> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdff4fd1ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04940> 0.0 15
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24f7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7adebba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04940> 0.0 16
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e59e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e59b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04940> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 227
found coverage increase 0
Current Total Coverage 69.46564885496184
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48f28> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48be0> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48be0> 0.0 3
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48be0> 0.0 4
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edeb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48be0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48be0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04908> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48be0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48be0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48be0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48be0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2baf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48be0> 0.0 11
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83da58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48be0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04908> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48be0> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48be0> 0.0 14
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84a90> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04908> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48be0> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad842b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48be0> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad841d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48be0> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 228
found coverage increase 0
Current Total Coverage 69.46564885496184
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c9e8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad848d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c9e8> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c9e8> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c9e8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3ccc0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c9e8> 0.0 6
Completed Iteration #5
Best Reward: 0
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84a20> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c9e8> 0.0 7
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c9e8> 0.0 8
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c9e8> 0.0 9
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c9e8> 0.0 10
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c9e8> 0.0 11
Completed Iteration #15
Best Reward: 0
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3ccc0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c9e8> 0.0 12
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c9e8> 0.0 13
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84e80> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c9e8> 0.0 14
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8828> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84a20> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c9e8> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c9e8> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cef0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c9e8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c4a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3ccc0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c9e8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 229
found coverage increase 0
Current Total Coverage 69.46564885496184
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed8d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8cc0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb24a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb2ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8cc0> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8cc0> 0.0 4
Completed Iteration #2
Best Reward: 0
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb2f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c8e208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8cc0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb2940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8cc0> 0.0 6
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c8e4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb27f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8cc0> 0.0 7
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
coverage_call_count 7100
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c8e9b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb2ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8cc0> 0.0 8
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb26d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c8e208> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8cc0> 0.0 9
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c8e128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c8ec88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8cc0> 0.0 10
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca23c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb27f0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8cc0> 0.0 11
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca25c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c8e208> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8cc0> 0.0 12
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c8e748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c8e208> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8cc0> 0.0 13
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c8e048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb27f0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8cc0> 0.0 14
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc87f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb2ac8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8cc0> 0.0 15
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc84a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8b70> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8cc0> 0.0 16
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 230
found coverage increase 0
Current Total Coverage 69.46564885496184
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adeb940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2cd780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8dd8> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc84e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8dd8> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c8eb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8dd8> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8dd8> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8dd8> 0.0 6
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb2fd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc84e0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8dd8> 0.0 7
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb2470> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8dd8> 0.0 8
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad04c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc88d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8dd8> 0.0 9
Completed Iteration #9
Best Reward: 0
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c8eef0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48048> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8dd8> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8dd8> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84cf8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84ba8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8dd8> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad609b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc84e0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8dd8> 0.0 13
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84ba8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8dd8> 0.0 14
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83de10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83deb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8dd8> 0.0 15
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c8e1d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48128> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8dd8> 0.0 16
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3ccc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb2470> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8dd8> 0.0 17
Completed Iteration #23
Best Reward: 0
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb2470> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8dd8> 0.0 18
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 231
found coverage increase 0
Current Total Coverage 69.46564885496184
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edb70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c828> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3ce80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c828> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc86d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cfd0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c828> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a90b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c828> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9ac8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c828> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca2518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c828> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b265320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca25f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c828> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c8e7b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c630> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c828> 0.0 9
Completed Iteration #8
Best Reward: 0
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cfd0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c828> 0.0 10
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca2d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9ac8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c828> 0.0 11
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca29b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca2e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c828> 0.0 12
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca2e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca2e48> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c828> 0.0 13
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca26a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed588> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c828> 0.0 14
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca25f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c828> 0.0 15
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca25f8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c828> 0.0 16
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4b518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5d30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c828> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4bbe0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c828> 0.0 18
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9b70> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cfd0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c828> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca2c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca25f8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3c828> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 232
found coverage increase 0
Current Total Coverage 69.46564885496184
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ed048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60e80> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60e80> 0.0 3
Completed Iteration #1
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca2eb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba3c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60e80> 0.0 4
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4ba20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60e80> 0.0 5
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4bf60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60e80> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba128> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8e10> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60e80> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acc8630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4b860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60e80> 0.0 8
Completed Iteration #7
Best Reward: 0
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c48320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4b860> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60e80> 0.0 9
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c48400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c480b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60e80> 0.0 10
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c485f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4b860> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60e80> 0.0 11
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c487f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4bf60> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60e80> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca2668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c48438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60e80> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c48a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c48438> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60e80> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c482e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4bf60> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60e80> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c48c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba3c8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60e80> 0.0 16
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c48e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba3c8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60e80> 0.0 17
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c48438> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60e80> 0.0 18
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c48cc0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c480b8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60e80> 0.0 19
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c48e48> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c48160> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60e80> 0.0 20
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c480b8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60e80> 0.0 21
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70668> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba3c8> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60e80> 0.0 22
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 233
found coverage increase 0
Current Total Coverage 69.46564885496184
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70518> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c708d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70860> 0.0 2
Completed Iteration #0
Best Reward: 0
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c48390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c708d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70860> 0.0 3
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c48198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70860> 0.0 4
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c702b0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70860> 0.0 5
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c022e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c704a8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70860> 0.0 6
Completed Iteration #6
Best Reward: 0
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c02588> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c48198> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70860> 0.0 7
Completed Iteration #8
Best Reward: 0
coverage_call_count 7200
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c02630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c02278> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70860> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70710> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c021d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70860> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c48198> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70860> 0.0 10
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c704a8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70860> 0.0 11
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c48400> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c708d0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70860> 0.0 12
Completed Iteration #14
Best Reward: 0
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c48940> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c708d0> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70860> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c48860> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70e10> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70860> 0.0 14
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c48d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c485f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70860> 0.0 15
Completed Iteration #21
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b3e5a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70978> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70860> 0.0 16
Completed Iteration #22
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4b5c0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c704a8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70860> 0.0 17
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4bc18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c021d0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70860> 0.0 18
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4beb8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c485f8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70860> 0.0 19
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 234
found coverage increase 0
Current Total Coverage 69.46564885496184
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2658d0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4b320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4bbe0> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c487b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c48f98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4bbe0> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9c88> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4b6d8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4bbe0> 0.0 4
Completed Iteration #3
Best Reward: 0
Completed Iteration #4
Best Reward: 0
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca2198> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca2c18> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4bbe0> 0.0 5
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca2208> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca2c18> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4bbe0> 0.0 6
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2a9ba8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4bbe0> 0.0 7
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4bd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca2748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4bbe0> 0.0 8
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca2908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c700b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4bbe0> 0.0 9
Completed Iteration #10
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b24fe80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca2748> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4bbe0> 0.0 10
Completed Iteration #11
Best Reward: 0
Completed Iteration #12
Best Reward: 0
Completed Iteration #13
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad3cda0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edd30> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4bbe0> 0.0 11
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2eddd8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca2c18> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4bbe0> 0.0 12
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4b780> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edd30> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4bbe0> 0.0 13
Completed Iteration #16
Best Reward: 0
Completed Iteration #17
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb2d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4b320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4bbe0> 0.0 14
Completed Iteration #18
Best Reward: 0
Completed Iteration #19
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7adebf98> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4b6d8> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4bbe0> 0.0 15
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b83d978> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4b6d8> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4bbe0> 0.0 16
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84a58> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2edd30> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4bbe0> 0.0 17
Completed Iteration #24
Best Reward: 0
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 235
found coverage increase 0
Current Total Coverage 69.46564885496184
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c48898> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84e80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84ba8> 0.0 2
Completed Iteration #0
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca2a20> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad60b00> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84ba8> 0.0 3
Completed Iteration #1
Best Reward: 0
Completed Iteration #2
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ba7f0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c8e6a0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84ba8> 0.0 4
Completed Iteration #3
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad489e8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84ba8> 0.0 5
Completed Iteration #4
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c02c50> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48630> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84ba8> 0.0 6
Completed Iteration #5
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c8e5f8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c8e6a0> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84ba8> 0.0 7
Completed Iteration #6
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c8e550> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84ba8> 0.0 8
Completed Iteration #7
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c023c8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb2390> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84ba8> 0.0 9
Completed Iteration #8
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7b2ede80> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf550> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84ba8> 0.0 10
Completed Iteration #9
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb2048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad48630> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84ba8> 0.0 11
Completed Iteration #10
Best Reward: 0
Completed Iteration #11
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf048> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c48320> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84ba8> 0.0 12
Completed Iteration #12
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79ca2240> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb2748> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84ba8> 0.0 13
Completed Iteration #13
Best Reward: 0
Completed Iteration #14
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70908> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c8e6a0> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84ba8> 0.0 14
Completed Iteration #15
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c4b438> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb2390> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84ba8> 0.0 15
Completed Iteration #16
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c02d68> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb2748> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84ba8> 0.0 16
Completed Iteration #17
Best Reward: 0
Completed Iteration #18
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c02da0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acdf550> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84ba8> 0.0 17
Completed Iteration #19
Best Reward: 0
Completed Iteration #20
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c3b0b8> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb2390> 0.0 4
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84ba8> 0.0 18
Completed Iteration #21
Best Reward: 0
Completed Iteration #22
Best Reward: 0
Completed Iteration #23
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c70f60> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf7acb2390> 0.0 5
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84ba8> 0.0 19
Completed Iteration #24
Best Reward: 0
Reward: 0.0
backprop <src.mcts.MCTS_Node object at 0x7fdf79c3b4e0> 0.0 2
backprop <src.mcts.MCTS_Node object at 0x7fdf79c48320> 0.0 3
backprop <src.mcts.MCTS_Node object at 0x7fdf7ad84ba8> 0.0 20
Completed Iteration #25
Best Reward: 0
Completed MCTS Level/Depth: #0
root
Best Reward: 0
Continuing with new batch: simulations failed to find any reward
iteration: 236
found coverage increase 0
Current Total Coverage 69.46564885496184
initial coverage: 67.1756
time passed (minutes): 60.2355
iterations: 237
number of new inputs: 384
final coverage: 69.4656
total coverage increase: 2.29008
